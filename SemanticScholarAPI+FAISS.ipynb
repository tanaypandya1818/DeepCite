{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ccac9d-b333-4f79-abdd-3a8e48d51343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Updated API Endpoint for Semantic Scholar\n",
    "SEMANTIC_SCHOLAR_BASE_URL = \"https://api.semanticscholar.org/graph/v1/paper/search/bulk\"\n",
    "HEADERS = {\"User-Agent\": \"DeepCite/1.0\"}\n",
    "\n",
    "# Function to fetch papers from Semantic Scholar API based on a query\n",
    "def fetch_papers_by_keywords(keywords, fields=\"title,abstract,url,year,citationCount\", limit=1000):\n",
    "    papers = []\n",
    "    offset = 0\n",
    "    while len(papers) < limit:\n",
    "        params = {\n",
    "            \"query\": keywords,\n",
    "            \"fields\": fields,\n",
    "            \"limit\": min(limit - len(papers), 100),  # Fetch in batches of 100\n",
    "            \"offset\": offset\n",
    "        }\n",
    "        response = requests.get(SEMANTIC_SCHOLAR_BASE_URL, headers=HEADERS, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            new_papers = data.get(\"data\", [])\n",
    "            papers.extend(new_papers)\n",
    "            offset += 100  # Move the offset to get the next set of papers\n",
    "        else:\n",
    "            print(f\"Failed to fetch data, status code: {response.status_code}\")\n",
    "            break\n",
    "    return papers[:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14ae9e6a-5383-4d46-857d-e17173945b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def get_embeddings(papers):\n",
    "    \"\"\"Generate embeddings for the list of papers using SentenceTransformer.\"\"\"\n",
    "    titles_and_abstracts = []\n",
    "    for paper in papers:\n",
    "        title = paper.get('title', '')  # Default to empty string if title is missing\n",
    "        abstract = paper.get('abstract', '')  # Default to empty string if abstract is missing\n",
    "        title = title if title else ''  # Ensure title is a string\n",
    "        abstract = abstract if abstract else ''  # Ensure abstract is a string\n",
    "        titles_and_abstracts.append(title + \" \" + abstract)\n",
    "    embeddings = model.encode(titles_and_abstracts, convert_to_tensor=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916e9f71-28dc-4dd3-815f-cd64b2d66f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "# Function to create and store embeddings in FAISS index\n",
    "def create_faiss_index(embeddings):\n",
    "    \"\"\"Create and store embeddings in FAISS index.\"\"\"\n",
    "    # Convert embeddings to a NumPy array for FAISS\n",
    "    embeddings_np = np.array(embeddings.cpu().detach().numpy()).astype('float32')\n",
    "    \n",
    "    # Create the FAISS index (using L2 distance, Euclidean)\n",
    "    index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
    "    index.add(embeddings_np)  # Add embeddings to the index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab340365-6f2d-4249-a549-16ea8b280482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to search a query in FAISS index and retrieve the most relevant papers\n",
    "def search_query(query, faiss_index, papers, top_k=5):\n",
    "    \"\"\"Search query in FAISS index and retrieve the most relevant papers.\"\"\"\n",
    "    # Generate the embedding for the user query\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    query_embedding_np = np.array(query_embedding.cpu().detach().numpy()).astype('float32')\n",
    "    \n",
    "    # Perform the search in the FAISS index\n",
    "    distances, indices = faiss_index.search(query_embedding_np, top_k)\n",
    "    \n",
    "    # Retrieve the top K papers from the indices\n",
    "    recommended_papers = [papers[i] for i in indices[0]]\n",
    "    return recommended_papers, distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1febcc13-8621-4051-8ba0-07e315d09a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to rank papers by citation count and similarity\n",
    "def rank_by_citations_and_similarity(papers, distances):\n",
    "    \"\"\"Rank papers by citation count and similarity distance.\"\"\"\n",
    "    papers_with_distance = list(zip(papers, distances))\n",
    "    \n",
    "    # Sort by citation count first (descending), then by similarity (ascending)\n",
    "    papers_with_distance.sort(key=lambda x: (-x[0]['citationCount'], x[1]))\n",
    "    \n",
    "    return papers_with_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "936eba9d-4270-4e25-a1f5-036261be52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to fetch, rank, and return relevant papers based on a query\n",
    "def get_ranked_papers(query):\n",
    "    \"\"\"Main function to fetch, rank, and return relevant papers based on query.\"\"\"\n",
    "    # Step 1: Fetch papers from Semantic Scholar API\n",
    "    papers = fetch_papers_by_keywords(query, limit=1000)\n",
    "    if not papers:\n",
    "        return \"No relevant papers found.\"\n",
    "    \n",
    "    # Step 2: Generate embeddings for the fetched papers (using title and abstract)\n",
    "    embeddings = get_embeddings(papers)\n",
    "    \n",
    "    # Step 3: Create FAISS index with the embeddings\n",
    "    faiss_index = create_faiss_index(embeddings)\n",
    "    \n",
    "    # Step 4: Search the query in the FAISS index to get top-k relevant papers\n",
    "    recommended_papers, distances = search_query(query, faiss_index, papers, top_k=10)\n",
    "    \n",
    "    # Step 5: Rank papers based on citation count and similarity\n",
    "    ranked_papers = rank_by_citations_and_similarity(recommended_papers, distances)\n",
    "    \n",
    "    # Step 6: Format the result for output\n",
    "    ranked_results = []\n",
    "    for paper, dist in ranked_papers:\n",
    "        ranked_results.append({\n",
    "            \"Title\": paper['title'],\n",
    "            \"DOI\": paper.get('url', \"N/A\"),  # Semantic Scholar doesn't always return DOI\n",
    "            \"Citation Count\": paper['citationCount'],\n",
    "            \"Year\": paper['year'],\n",
    "            \"Similarity Distance\": dist\n",
    "        })\n",
    "    \n",
    "    return ranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c18b154d-8809-4bd1-b03c-3ae57994fad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'A Comprehensive Review on Machine Learning in Healthcare Industry: Classification, Restrictions, Opportunities and Challenges', 'DOI': 'https://www.semanticscholar.org/paper/ac2cffc4b9f96bae24809d738777ae897094ae33', 'Citation Count': 116, 'Year': 2023, 'Similarity Distance': np.float32(18.02309)}\n",
      "{'Title': 'A collaborative empirical analysis on machine learning based disease prediction in health care system', 'DOI': 'https://www.semanticscholar.org/paper/b564b65d08fba33dfbc4a55d3a250cb008fb706b', 'Citation Count': 17, 'Year': 2023, 'Similarity Distance': np.float32(16.87191)}\n",
      "{'Title': 'Artificial Intelligence and Machine Learning in Healthcare', 'DOI': 'https://www.semanticscholar.org/paper/276b72329076a2aedb552f310bb5bbd5168a9a0f', 'Citation Count': 15, 'Year': 2023, 'Similarity Distance': np.float32(12.856625)}\n",
      "{'Title': 'Machine learning applied to healthcare: a conceptual review', 'DOI': 'https://www.semanticscholar.org/paper/40620a51a19bb0cb61a27f920f3f9235c0b44b6b', 'Citation Count': 7, 'Year': 2022, 'Similarity Distance': np.float32(18.700691)}\n",
      "{'Title': 'Application of Machine Learning in Healthcare: An Analysis', 'DOI': 'https://www.semanticscholar.org/paper/4b4eb05c5ec977105fa95f90cb44baa6a4f7aa60', 'Citation Count': 5, 'Year': 2022, 'Similarity Distance': np.float32(19.11332)}\n",
      "{'Title': 'Intelligent Learning Analytics in Healthcare Sector Using Machine Learning', 'DOI': 'https://www.semanticscholar.org/paper/77cca6d6354947359a10526a603261332083a991', 'Citation Count': 2, 'Year': 2020, 'Similarity Distance': np.float32(18.749027)}\n",
      "{'Title': 'Comparative Study of Supervised Machine Learning Algorithms for Healthcare Dataset Using Orange', 'DOI': 'https://www.semanticscholar.org/paper/996abea102c25df397c4d9bac111d55a4dca87ba', 'Citation Count': 1, 'Year': 2021, 'Similarity Distance': np.float32(15.909901)}\n",
      "{'Title': 'APPLICATION OF MACHINE LEARNING IN HEALTHCARE', 'DOI': 'https://www.semanticscholar.org/paper/3561b270bbe783369b25bf048edc739e339340d2', 'Citation Count': 1, 'Year': 2024, 'Similarity Distance': np.float32(19.350948)}\n",
      "{'Title': 'A Framework for Efficient Healthcare Resources Utilization using Semi-supervised Machine Learning Algorithm', 'DOI': 'https://www.semanticscholar.org/paper/46d0c09dc58890e1326ee24f4631d78929b93788', 'Citation Count': 0, 'Year': 2019, 'Similarity Distance': np.float32(16.55736)}\n",
      "{'Title': 'Machine Learning in Healthcare: A Deep Dive into Classification, Limitations, Prospects, And Hurdles', 'DOI': 'https://www.semanticscholar.org/paper/48d264ccc0dbf741a1de41fec22853258d05bd89', 'Citation Count': 0, 'Year': 2024, 'Similarity Distance': np.float32(17.481846)}\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"Supervised machine learning use in healthcare\"\n",
    "ranked_papers = get_ranked_papers(query)\n",
    "\n",
    "# Output the ranked papers\n",
    "for paper in ranked_papers:\n",
    "    print(paper)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
