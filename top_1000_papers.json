[
    {
        "title": "Developing Affordable, Portable and Simplistic Diagnostic Sensors to Improve Access to Care",
        "abstract": "Ophthalmology is a highly technical specialty, especially in the area of diagnostic equipment. While the field is innovative, the access to cutting-edge technology is limited with reference to the global population. A significant way to improve overall healthcare is to understand the needs and possibilities of all possible consumers when developing sophisticated and accurate medical devices. The Smartphone-based Keratograph (SBK), is an example of a new project that uses real world feedback, addresses an unmet medical need, and implements commercially available components to create a device that is affordable, portable and simplistic to operate. The long-term goal of the SBK is to collect data from users for supervised machine-learning. This machine-learning aspect will ultimately aid in the development of an artificial intelligence device to enable even earlier detection of keratoconus, especially in children and adolescents. Again, the ultimate goal of any medical device should be to improve patient care, and to make a significant improvement on vision healthcare for the global population, providing access to this technology is essential.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/003b4013b059084e443fb896a72962355466bdbf",
        "citation_count": 3
    },
    {
        "title": "On the practical applications of objective quality metrics for stereoscopic 3D imaging",
        "abstract": "Objective quality metrics provide cost-efficient methods for quality evaluation, as they are practically algorithms, models, that avoid the necessity of subjective assessment, which is a precise but resource-consuming approach. Their ultimate measure of prediction accuracy fundamentally relies on the correlation between the estimated levels of quality and the actual subjective scores of perceived quality, rated by human individuals. Such metrics have already been developed for every single emerging technology where quality, in general, is relevant. This applies to stereoscopic 3D imaging as well, which is utilized in both industry, healthcare, education and entertainment. In this paper, we introduce an exhaustive analysis regarding the practical applications of objective quality metrics for stereoscopic 3D imaging. Our contribution addresses each and every state-of-the-art objective metric in the scientific literature, separately for image and video quality. The study differentiates the metrics by input requirements and supervision, and examines performance via statistical measures. Machine learning algorithms are particularly emphasized within the paper, such as the Deep Edge and COlor Signal INtegrity Evaluator (DECOSINE) using Segmented Stacked Auto-Encoder (S-SAE), different Convolutional Neural Network (CNN) frameworks, and transfer-learning-based methods like the Xception model, AlexNet, ResNet-18, ImageNet, Caffe, GoogLeNet, and also our very own transfer-learning-based methods. The paper focuses on the actual practical applications of the predictive models, and highlights relevant criteria, along with general feasibility, suitability and usability. The analysis of the investigated use cases also addresses potential future research questions and specifies the appropriate directives for quality-focused, user-centric development.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/0061c84d629da2cfe0fadeaa6c8040d6c27ad414",
        "citation_count": 0
    },
    {
        "title": "Multimodal machine learning for analysing multifactorial causes of disease\u2014The case of childhood overweight and obesity in Mexico",
        "abstract": "Background Mexico has one of the highest global incidences of paediatric overweight and obesity. Public health interventions have shown only moderate success, possibly from relying on knowledge extracted using limited types of statistical data analysis methods. Purpose To explore if multimodal machine learning can enhance identifying predictive features from obesogenic environments and investigating complex disease or social patterns, using the Mexican National Health and Nutrition Survey. Methods We grouped features into five data modalities corresponding to paediatric population exogenous factors, in two multimodal machine learning pipelines, against a unimodal early fusion baseline. The supervised pipeline employed four methods: Linear classifier with Elastic Net regularisation, k-Nearest Neighbour, Decision Tree, and Random Forest. The unsupervised pipeline used traditional methods with k-Means and hierarchical clustering, with the optimal number of clusters calculated to be k = 2. Results The decision tree classifier in the supervised early fusion approach produced the best quantitative results. The top five most important features for classifying child or adolescent health were measures of an adult in the household, selected at random: BMI, obesity diagnosis, being single, seeking care at private healthcare, and having paid TV in the home. Unsupervised learning approaches varied in the optimal number of clusters but agreed on the importance of home environment features when analysing inter-cluster patterns. Main findings from this study differed from previous studies using only traditional statistical methods on the same database. Notably, the BMI of a randomised adult within the household emerged as the most important feature, rather than maternal BMI, as reported in previous literature where unwanted cultural bias went undetected. Conclusion Our general conclusion is that multimodal machine learning is a promising approach for comprehensively analysing obesogenic environments. The modalities allowed for a multimodal approach designed to critically analyse data signal strength and reveal sources of unwanted bias. In particular, it may aid in developing more effective public health policies to address the ongoing paediatric obesity epidemic in Mexico.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/006961bbefde718be28a42c7170db2a0aaa42a03",
        "citation_count": 0
    },
    {
        "title": "Smart science: How artificial intelligence is revolutionizing pharmaceutical medicine",
        "abstract": "Abstract Artificial intelligence (AI) is a discipline within the field of computer science that encompasses the development and utilization of machines capable of emulating human behavior, particularly regarding the astute examination and interpretation of data. AI operates through the utilization of specialized algorithms, and it includes techniques such as deep (DL), and machine learning (ML), and natural language processing (NLP). As a result, AI has found its application in the study of pharmaceutical chemistry and healthcare. The AI models employed encompass a spectrum of methodologies, including unsupervised clustering techniques applied to drugs or patients to discern potential drug compounds or appropriate patient cohorts. Additionally, supervised ML methodologies are utilized to enhance the efficacy of therapeutic drug monitoring. Further, AI-aided prediction of the clinical outcomes of clinical trials can improve efficiency by prioritizing therapeutic intervention that are likely to succeed, hence benefiting the patient. AI may also help create personalized treatments by locating potential intervention targets and assessing their efficacy. Hence, this review provides insights into recent advances in the application of AI and different tools used in the field of pharmaceutical medicine.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0087e8dde3d13ba543e74995d92ae86144a6bd70",
        "citation_count": 1
    },
    {
        "title": "A Study of Differentially Private Machine Learning in Healthcare",
        "abstract": "The field of Machine Learning (ML) has been engaged in intensive research for a while to build an efficient and effective intelligent system for the early identification of chronic diseases such as cancer and diabetes and has recently seen some promising findings. The bulk of the initiatives are aimed at classifying illness onset and minimizing cases of maltreatment. As a supervised learning problem, its accuracy is mostly determined by the training data, which is labeled data on actual patients that is highly privacy-sensitive. Privacy leakage can occur at any point in the machine learning lifecycle, from model training through model deployment, and can lead to a membership inference attack, model inversion attack, and reconstruction attack. As a result, safeguarding users' privacy is critical in healthcare issues, but little has been done to satisfy this demand. In this paper, we propose differential privacy-based Logistic Regression and Naive Bayes models on breast cancer classification and diabetes prediction. We evaluate the two models using the popular Wisconsin Diagnostic Breast Cancer (WDBC) dataset, and Pima Indians Diabetes dataset and depict the privacy requirement and model accuracy trade-off.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/0100641a1f24be215b0c821e460f34f47b9c9539",
        "citation_count": 3
    },
    {
        "title": "Analisis Klasifikasi Diagnosa Penyakit Diabetes Melitus Berdasarkan Komparasi Algoritma Supervised Learning",
        "abstract": "Diabetes mellitus is a serious health problem that threatens various age groups, including children, teenagers, and adults. In 2021, the mortality rate due to diabetes mellitus reached alarming levels, making it a global threat, especially in Indonesia, where the number of patients reached 19.5 million. Efforts to address diabetes mellitus include early prediction of the disease's risk in patients, and machine learning approaches have shown potential in this regard. This study employs a quantitative method by utilizing secondary data from the UC Irvine Machine Learning Repository titled \"Early Stages Diabetes Risk Prediction\". The data was obtained from questionnaires filled out by diabetes patients at Sylhet Diabetes Hospital and validated by healthcare professionals. A total of 520 data samples with 17 attributes were used for analysis. The tested Supervised Learning algorithms include Logistic Regression, K-Nearest Neighbour, Support Vector Machine, Random Forest, Na\u00efve Bayes Classifier, Artificial Neural Network, Decision Tree C4.5, and Gradient Boosting Classifier. The research findings reveal that the Random Forest algorithm achieved the highest accuracy of 98.71% in diagnosing diabetes mellitus. This study significantly contributes to enhancing the understanding of diabetes mellitus and has the potential for further development in finding the best algorithm for early disease prediction. It is hoped that this research will make a significant contribution to the efforts in preventing and managing diabetes mellitus, ultimately improving the quality of life for patients and reducing its impact on the population.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0109c147f1f16eef4aee35e7011ddfc30e92d0a5",
        "citation_count": 0
    },
    {
        "title": "Leveraging machine learning and AI in healthcare: A paradigm shifts from the traditional approaches",
        "abstract": "Electronic health data is becoming more and more accessible, which presents tremendous opportunities for medical research and development as well as useful advancements. Healthcare epidemiologists need computational methods that can handle big, complicated datasets in order to fully utilize these data. These tools are provided by machine learning (ML), which recognizes patterns that can change patient risk stratification, particularly in infectious diseases, and result in focused treatments that stop the spread of pathogens. Health emergencies and disease states can now be predicted more accurately thanks to recent developments in AI and ML. Although there is doubt about ML's usefulness in healthcare, its use is expanding quickly. In fields like radiology, genetics, and neuroimaging, machine learning techniques\u2014including supervised, unsupervised, and reinforcement learning\u2014have demonstrated efficacy. Nevertheless, issues like privacy and morality still need to be taken into account for applications in the future.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/01461f796f63e0529d294b1e7e8155708e883ecc",
        "citation_count": 0
    },
    {
        "title": "Quantifying Self-Reported Adverse Drug Events on Twitter: Signal and Topic Analysis",
        "abstract": "When a drug that is sold exhibits side effects, a well functioning ecosystem of pharmaceutical drug suppliers includes responsive regulators and pharmaceutical companies. Existing systems for monitoring adverse drug events, such as the Federal Adverse Events Reporting System (FAERS) in the US, have shown limited effectiveness due to the lack of incentives for healthcare professionals and patients. While social media present opportunities to mine information about adverse events in near real-time, there are still important questions to be answered in order to understand their impact on pharmacovigilance. First, it is not known how many relevant social media posts occur per day on platforms like Twitter, i.e., whether there is \"enough signal\" for a post-market pharmacovigilance program based on Twitter mining. Second, it is not known what other topics are discussed by users in posts mentioning pharmaceutical drugs. In this paper, we outline how social media can be used as a human sensor for drug use monitoring. We introduce a large-scale, near real-time system for computational pharmacovigilance, and use our system to estimate the order of magnitude of the volume of daily self-reported pharmaceutical drug side effect tweets. The processing pipeline comprises a set of cascaded filters, followed by a supervised machine learning classifier. The cascaded filters quickly reduce the volume to a manageable sub-stream, from which a Support Vector Machine (SVM) based classifier identifies adverse events based on a rich set of features taking into account surface-textual properties, as well as domain knowledge about drugs, side effects and the Twitter medium. Using a dataset of 10,000 manually annotated tweets, a SVM classifier achieves F1=60.4% and AUC=0.894. The yield of the classifier for a drug universe comprising 2,600 keywords is 721 tweets per day. We also investigate what other topics are discussed in the posts mentioning pharmaceutical drugs. We conclude by suggesting an ecosystem where regulators and pharmaceutical companies utilize social media to obtain feedback about consequences of pharmaceutical drug use.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/0175753f9e9e40a54585beb6c305cc3f360dbe85",
        "citation_count": 22
    },
    {
        "title": "Automated classification of primary care patient safety incident report content and severity using supervised machine learning (ML) approaches",
        "abstract": "Learning from patient safety incident reports is a vital part of improving healthcare. However, the volume of reports and their largely free-text nature poses a major analytic challenge. The objective of this study was to test the capability of autonomous classifying of free text within patient safety incident reports to determine incident type and the severity of harm outcome. Primary care patient safety incident reports (n=31333) previously expert-categorised by clinicians (training data) were processed using J48, SVM and Na\u00efve Bayes. The SVM classifier was the highest scoring classifier for incident type (AUROC, 0.891) and severity of harm (AUROC, 0.708). Incident reports containing deaths were most easily classified, correctly identifying 72.82% of reports. In conclusion, supervised ML can be used to classify patient safety incident report categories. The severity classifier, whilst not accurate enough to replace manual processing, could provide a valuable screening tool for this critical aspect of patient safety.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/017b01936e87352fd47d138bcf144e4b149926e1",
        "citation_count": 30
    },
    {
        "title": "Automating Risk of Bias Assessment for Clinical Trials",
        "abstract": "Systematic reviews, which summarize the entirety of the evidence pertaining to a specific clinical question, have become critical for evidence-based decision making in healthcare. But such reviews have become increasingly onerous to produce due to the exponentially expanding biomedical literature base. This study proposes a step toward mitigating this problem by automating risk of bias assessment in systematic reviews, in which reviewers determine whether study results may be affected by biases (e.g., poor randomization or blinding). Conducting risk of bias assessment is an important but onerous task. We thus describe a machine learning approach to automate this assessment, using the standard Cochrane Risk of Bias Tool which assesses seven common types of bias. Training such a system would typically require a large labeled corpus, which would be prohibitively expensive to collect here. Instead, we use distant supervision, using data from the Cochrane Database of Systematic Reviews (a large repository of systematic reviews), to pseudoannotate a corpus of 2200 clinical trial reports in PDF format. We then develop a joint model which, using the full text of a clinical trial report as input, predicts the risks of bias while simultaneously extracting the text fragments supporting these assessments. This study represents a step toward automating or semiautomating extraction of data necessary for the synthesis of clinical trials.",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/01a1db262bc9e599711bdc89dbe334d4386539fb",
        "citation_count": 55
    },
    {
        "title": "A machine learning model to predict the risk factors causing feelings of burnout and emotional exhaustion amongst nursing staff in South Africa",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/01c1b946c20b7a4fe6a5a51faa8e02b1713a4409",
        "citation_count": 0
    },
    {
        "title": "Predicting 120-Day Hospital Readmission Using Medical Administrative Patient Data",
        "abstract": "Hospitals and health-care insurers routinely use models to predict patient readmission, extrapolating from historical data. Subsequently, the predicted quantities can be used for contracting and pricing negotiations between these hospitals and healthcare insurers. The Dutch healthcare system uses unique standardized Care Trajectories (so-called DBCs) for administration and billing of care. Here, we compared supervised machine learning methods on predicting 120-day readmission as an operationally significant metric. We used administrative patient data from 21 common Care Trajectories, in combination with demographic information. A lightGBM model using undersampling to tackle class imbalance yielded an AUROC score of 0.86 and provided the highest recall score (73.8%).",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/01d2d9674da0ad7f5363a8eb818c7e8d2c2efa24",
        "citation_count": 0
    },
    {
        "title": "Self-Supervised Transformers for Activity Classification using Ambient Sensors",
        "abstract": "Providing care for ageing populations is an onerous task, and as life expectancy estimates continue to rise, the number of people that require senior care is growing rapidly. This paper proposes a methodology based on Transformer Neural Networks to classify the activities of a resident within an ambient sensor based environment. We also propose a methodology to pre-train Transformers in a self-supervised manner, as a hybrid autoencoder-classifier model instead of using contrastive loss. The social impact of the research is considered with wider benefits of the approach and next steps for identifying transitions in human behaviour. In recent years there has been an increasing drive for integrating sensor based technologies within care facilities for data collection. This allows for employing machine learning for many aspects including activity recognition and anomaly detection. Due to the sensitivity of healthcare environments, some methods of data collection used in current research are considered to be intrusive within the senior care industry, including cameras for image based activity recognition, and wearables for activity tracking, but recent studies have shown that using these methods commonly result in poor data quality due to the lack of resident interest in participating in data gathering. This has led to a focus on ambient sensors, such as binary PIR motion, connected domestic appliances, and electricity and water metering. By having consistency in ambient data collection, the quality of data is considerably more reliable, presenting the opportunity to perform classification with enhanced accuracy. Therefore, in this research we looked to find an optimal way of using deep learning to classify human activity with ambient sensor data.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/01f6593cb123d2260b4af552e08efb5dc180c2a6",
        "citation_count": 1
    },
    {
        "title": "Characterization of patients with idiopathic normal pressure hydrocephalus using natural language processing within an electronic healthcare record system.",
        "abstract": "OBJECTIVE\nIdiopathic normal pressure hydrocephalus (iNPH) is an underdiagnosed, progressive, and disabling condition. Early treatment is associated with better outcomes and improved quality of life. In this paper, the authors aimed to identify features associated with patients with iNPH using natural language processing (NLP) to characterize this cohort, with the intention to later target the development of artificial intelligence-driven tools for early detection.\n\n\nMETHODS\nThe electronic health records of patients with shunt-responsive iNPH were retrospectively reviewed using an NLP algorithm. Participants were selected from a prospectively maintained single-center database of patients undergoing CSF diversion for probable iNPH (March 2008-July 2020). Analysis was conducted on preoperative health records including clinic letters, referrals, and radiology reports accessed through CogStack. Clinical features were extracted from these records as SNOMED CT (Systematized Nomenclature of Medicine Clinical Terms) concepts using a named entity recognition machine learning model. In the first phase, a base model was generated using unsupervised training on 1 million electronic health records and supervised training with 500 double-annotated documents. The model was fine-tuned to improve accuracy using 300 records from patients with iNPH double annotated by two blinded assessors. Thematic analysis of the concepts identified by the machine learning algorithm was performed, and the frequency and timing of terms were analyzed to describe this patient group.\n\n\nRESULTS\nIn total, 293 eligible patients responsive to CSF diversion were identified. The median age at CSF diversion was 75 years, with a male predominance (69% male). The algorithm performed with a high degree of precision and recall (F1 score 0.92). Thematic analysis revealed the most frequently documented symptoms related to mobility, cognitive impairment, and falls or balance. The most frequent comorbidities were related to cardiovascular and hematological problems.\n\n\nCONCLUSIONS\nThis model demonstrates accurate, automated recognition of iNPH features from medical records. Opportunities for translation include detecting patients with undiagnosed iNPH from primary care records, with the aim to ultimately improve outcomes for these patients through artificial intelligence-driven early detection of iNPH and prompt treatment.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/021f5de8b8118b3697179a0cdffe14f1c4f73c55",
        "citation_count": 5
    },
    {
        "title": "Mining clinical relationships from patient narratives",
        "abstract": null,
        "year": 2008,
        "url": "https://www.semanticscholar.org/paper/022dabcb5997ff38ad50c3c47d2f47ded6e3aeba",
        "citation_count": 46
    },
    {
        "title": "Exploration of Machine Learning to Identify Community Dwelling Older Adults with Balance Dysfunction Using Short Duration Accelerometer Data",
        "abstract": "The incidence of fall-related injuries in older adults is high. Given the significant and adverse outcomes that arise from injurious falls in older adults, it is of the utmost importance to identify older adults at greater risk for falls as early as possible. Given that balance dysfunction provides a significant risk factor for falls, an automated and objective identification of balance dysfunction in community dwelling older adults using wearable sensor data when walking may be beneficial. In this study, we examine the feasibility of using wearable sensors, when walking, to identify older adults who have trouble with balance at an early stage using state-of-the-art machine learning techniques. We recruited 21 community dwelling older women. The experimental paradigm consisted of two tasks: Normal walking with a self-selected comfortable speed on an instrumented treadmill and a test of reflexive postural response, using the motor control test (MCT). Based on the MCT, identification of older women with low or high balance function was performed. Using short duration accelerometer data from sensors placed on the knee and hip while walking, supervised machine learning was carried out to classify subjects with low and high balance function. Using a Gradient Boosting Machine (GBM) algorithm, we classified balance function in older adults using 60 seconds of accelerometer data with an average cross validation accuracy of 91.5% and area under the receiver operating characteristic curve (AUC) of 0.97. Early diagnosis of balance dysfunction in community dwelling older adults through the use of user friendly and inexpensive wearable sensors may help in reducing future fall risk in older adults through earlier interventions and treatments, and thereby significantly reduce associated healthcare costs.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/027b9cba96e5a444c85230e44cb7a2523b694d4f",
        "citation_count": 7
    },
    {
        "title": "A careful approach to artificial intelligence: the struggles with epistemic responsibility of healthcare professionals",
        "abstract": "ABSTRACT Machine learning approaches are being developed to contribute to the treatment of patients and the organisation of care. These new approaches are created in complex environments that include data and computational models as well as new practices, roles and competencies. In such settings, individualised conceptions of agents bearing responsibility need rethinking. In response, we elaborate on the concept of epistemic responsibility based on De la Bellacasa\u2019s work on care (Bellacasa, M.P. de la. (2017). Matters of care: Speculative ethics in more than human worlds. University of Minnesota Press). To better understand these complex environments and the dynamics of responsibility, we use an ethnographic approach and followed Dutch healthcare professionals who learned the basics of (supervised) machine learning, while they pursued a project in their organisations during a four-month-long course. The professionals struggled with different interdependencies and this brought responsibility-in-the-making into relief. Rather than seeing (growing) relations and impure entanglements as standing in the way of responsibility, we show how connections are worthy of inquiry. We argue that connections are essential to knowledge and that producing epistemic responsibility means considering these embedded relations. In contrast to calls for control and clarification of machine learning techniques, and warnings that they create irresponsible black boxes, our care approach shows how responsibility-in-the-making reveals opportunities for ethical reflection and action. Our approach attends to how humans and non-humans are engaged in caring, reveals patterns around kinds of responsibility, and points to opportunities for avoiding neglect and irresponsibility.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/0289a92509aa0042cc2ca85d5f48d4f14065d92a",
        "citation_count": 1
    },
    {
        "title": "Exploring supervised machine learning approaches to predicting Veterans Health Administration chiropractic service utilization",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/02be989c51b15d92b31a11d4a48d1f6d9f35991c",
        "citation_count": 7
    },
    {
        "title": "Use of artificial intelligence for public health surveillance: a case study to develop a machine Learning-algorithm to estimate the incidence of diabetes mellitus in France",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/02f2e130e6dae2393ce099d0478c87b8f9e50418",
        "citation_count": 9
    },
    {
        "title": "Federated Learning: Attacks and Defenses, Rewards, Energy Efficiency: Past, Present and Future",
        "abstract": "Federated Learning (FL) was first introduced as an idea by Google in 2016, in which multiple devices jointly train a machine learning model without sharing their data under the supervision of a central server. This offers big opportunities in critical areas like healthcare, industry, and finance, where sharing information with other organizations\u2019 devices is completely prohibited. The combination of Federated Learning with Blockchain technology has led to the so-called Blockchain Federated learning (B.F.L.) which operates in a distributed manner and offers enhanced trust, improved security and privacy, improved traceability and immutability and at the same time enables dataset monetization through tokenization. Unfortunately, vulnerabilities of the blockchain-based solutions have been identified while the implementation of blockchain introduces significant energy consumption issues. There are many solutions that also offer personalized ideas and uses. In the field of security, solutions such as security against model-poisoning backdoor assaults with poles and modified algorithms are proposed. Defense systems that identify hostile devices, Against Phishing and other social engineering attack mechanisms that could threaten current security systems after careful comparison of mutual systems. In a federated learning system built on blockchain, the design of reward mechanisms plays a crucial role in incentivizing active participation. We can use tokens for rewards or other cryptocurrency methods for rewards to a federated learning system. Smart Contracts combined with proof of stake with performance-based rewards or (and) value of data contribution. Some of them use games or game theory-inspired mechanisms with unlimited uses even in other applications like games. All of the above is useless if the energy consumption exceeds the cost of implementing a system. Thus, all of the above is combined with algorithms that make simple or more complex hardware and software adjustments. Heterogeneous data fusion methods, energy consumption models, bandwidth, and controls transmission power try to solve the optimization problems to reduce energy consumption, including communication and compute energy. New technologies such as quantum computing with its advantages such as speed and the ability to solve problems that classical computers cannot solve, their multidimensional nature, analyze large data sets more efficiently than classical artificial intelligence counterparts and the later maturity of a technology that is now expensive will provide solutions in areas such as cryptography, security and why not in energy autonomy. The human brain and an emerging technology can provide solutions to all of the above solutions due to the brain's decentralized nature, built-in reward mechanism, negligible energy use, and really high processing power In this paper we attempt to survey the currently identified threats, attacks and defenses, the rewards and the energy efficiency issues of BFL in order to guide the researchers and the designers of FL based solution to adopt the most appropriate of each application approach.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/031fd5cc0d9a6706f4fd396870bd72e63f20d201",
        "citation_count": 1
    },
    {
        "title": "Clinical Relationships Extraction C linical Relationships Extraction Clinical Relationships Extraction Clinical Relationships Extraction Techniques from",
        "abstract": "The Clinical E-Science Framework (CLEF) project was used to e xtract important information from medical texts by building a system for the purpose of clinical research, evidence-based healthcare and genotype-meets-phenotype informatics. The system is divided into two parts, one part concerns with the identification of relationships between clinically important entities in the text. The full parses and domain-specific grammars had been used to apply many approaches to extract the relationship. In the second part of the system, statistical machine learning (ML) approaches are applied to extract relationship. A corpus of oncology narratives that hand annotated with clinical relationships can be used to train and test a system that has been designed and implemented by supervised machine learning (ML) approaches. Many features can be extracted from these texts that are used to build a model by the classifier. Multiple supervised machine learning algorithms can be applied for relationship extraction. Effects of adding the features, changing the size of the corpus, and changing the type of the algorithm on relationship extraction are examined.",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/03399c0f874bb406b7205850a7b65a99c892e554",
        "citation_count": 0
    },
    {
        "title": "Machine learning-based clinical decision support using laboratory data",
        "abstract": "Abstract Artificial intelligence (AI) and machine learning (ML) are becoming vital in laboratory medicine and the broader context of healthcare. In this review article, we summarized the development of ML models and how they contribute to clinical laboratory workflow and improve patient outcomes. The process of ML model development involves data collection, data cleansing, feature engineering, model development, and optimization. These models, once finalized, are subjected to thorough performance assessments and validations. Recently, due to the complexity inherent in model development, automated ML tools were also introduced to streamline the process, enabling non-experts to create models. Clinical Decision Support Systems (CDSS) use ML techniques on large datasets to aid healthcare professionals in test result interpretation. They are revolutionizing laboratory medicine, enabling labs to work more efficiently with less human supervision across pre-analytical, analytical, and post-analytical phases. Despite contributions of the ML tools at all analytical phases, their integration presents challenges like potential model uncertainties, black-box algorithms, and deskilling of professionals. Additionally, acquiring diverse datasets is hard, and models\u2019 complexity can limit clinical use. In conclusion, ML-based CDSS in healthcare can greatly enhance clinical decision-making. However, successful adoption demands collaboration among professionals and stakeholders, utilizing hybrid intelligence, external validation, and performance assessments.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/033ef35f30781daab139a40212547cb69aa16fd5",
        "citation_count": 16
    },
    {
        "title": "Machine Reading of Clinical Notes for Automated ICD Coding",
        "abstract": "The International Classification of Diseases (ICD) is a healthcare classification system maintained by the World Health Organization. It provides a set of diagnostic codes for classifying diseases (including a wide range of signs, symptoms and external causes of injury or disease) and surgical procedures. ICD codes are used for a number of different tasks, such as reporting health conditions and carrying out medical billing. The standard coding procedure consists in assigning one or more ICD codes to a patient's hospital visit: this operation is performed by medical coders, who read and review the clinical notes written by physicians and then assign the appropriate ICD codes according to the coding guidelines. This process can be time consuming and error-prone. With the rising popularity of electronic health records (EHRs) systems for the automated reading of the clinical notes and codes assignment have been proposed in the recent years. In the present work we review different supervised learning approaches for automated ICD coding and we propose our model, based on a convolutional neural network with attention layers, which achieves state of the art results. The experiments are performed on the publicly available MIMIC-III dataset, which contains de-identified EHRs of 58,976 patient visits at the Beth Israel Deaconess Medical Center from 2001 to 2012.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/03a94a51db889f74a798fabbdfd12304f1da4c5d",
        "citation_count": 0
    },
    {
        "title": "Smartphone Mode Recognition During Stairs Motion",
        "abstract": "Smartphone mode classification is essential to many applications, such as daily life monitoring, healthcare, and indoor positioning. In the latter, it was shown that knowledge of the smartphone location on pedestrians can improve the positioning accuracy. Most of the research conducted in this field is focused on pedestrian motion in a horizontal plane. In this research, we use supervised machine learning techniques to recognize and classify the smartphone mode (text, talk, pocket and swing) while accounting for the movement up and downstairs. We distinguish between the going up and the down motion, each with four different smartphone modes, making eight states in total. This classification is based on the use of an optimal set of sensors that varies according to battery life and the energy consumption of each sensor. The classifier was trained and tested on a dataset constructed from multiple user measurements (total of 94 min) to achieve robustness. This provided an accuracy of more than 90% in the cross validation method and 91.5% if the texting mode is excluded. When considering only stairs motion, regardless of the direction, the accuracy improves to 97%. These results may assist many algorithms, mainly in pedestrian dead reckoning, in improving a variety of challenges such as speed and step length estimation and cumulative error reduction.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/04136f8195671932833b304d55908c222ed31f0a",
        "citation_count": 2
    },
    {
        "title": "Biologically-inspired machine intelligence technique for activity classification in smart home environments",
        "abstract": "With the widespread adoption of Internet-connected devices and the prevalence of applications in the Internet of things (IoT), devices in smart homes can generate enormous amounts of data. There is a requirement for machine-learning techniques to learn from historical patterns and predict future activities. There is an increased interest in machine-learning techniques that can provide useful and interesting services in the smart home domain. The areas that machine-learning techniques can help advance are varied and ever-evolving. Predicting and classifying the Activities of Daily Living (ADLs) of inhabitants in a smart home environment are key modules to automate smart home devices. Some prominent examples include uses for entertainment, elderly care, healthcare, and security. The abilities of the machine-learning technique to find meaningful spatio-temporal relations of high-dimensional data and to learn from streaming datasets are important requirements. \n \nRecently, the Hierarchical Temporal Memory (HTM) theory has been presented as a biologically-inspired machine-learning theory that attempts to mimic the neocortex, the front part of the human brain. The main features of the HTM theory include the ability to learn and predict temporal patterns. The HTM theory and its computational implementation, Cortical Learning Algorithms (CLA), present a potential alternative to traditional machine intelligence. This research aims to apply a new biologically inspired machine intelligence technique based on the HTM theory and its CLA implementation to classify ADLs of inhabitants by analysing data captured from different sensors in a smart home scenario. \n \nThis research started by reviewing existing research in classification and prediction of ADLs. A comprehensive evaluation of state-of-the-art machine learning techniques and their application in the context of smart homes has been carried out as a primary research. HTM theory and its implementation the CLA have been studied, and experiments were conducted to identify the weaknesses and limitations of applying the HTM theory and the CLA for activity classification in the smart home environment. \n \nTo test and evaluate the performance of a proposed machine intelligence technique, there is a need for a dataset that represents the ADLs in a smart home scenario. Due to the excessive cost of building real smart home datasets and the lack of real datasets from smart homes, to tackle this issue, as a secondary contribution to knowledge, this research used OpenSHS (Open Smart Home Simulator), an open-source, cross-platform 3D smart home simulator. In addition, forty-two ADL datasets, Simulated Activities of Daily Living Dataset (SIMADL) were extracted from the OpenSHS tool and made available publicly. \n \nThis research proposes multi-region CLA techniques to learn short- and long-term patterns. Two novel multi-region CLA techniques featuring a multiple spatial pooler and temporal memory regions that incorporate a hash encoder and a Multi-Layer Perceptron (MLP) classifier were proposed and applied. While, the hash encoder can deal with multi-dimensional datasets, because of the existing encoders of the standard NuPIC encoders are prepared to deal with a single column or a small number of columns and the MLP classifier was used rather than the classifiers used in the current implementation of CLA to produce meaningful predictions. Additionally, the two novel multi-region CLAs, Parallel Spatio-Temporal Memory Stream (CLA2) and Cascaded Temporal Memories Stream (CLA3) were developed to learn short- and long-term patterns from, streaming datasets. To remove the limitation of memory management of the original CLA that contains one spatial pooler and one temporal memory, the original CLA learns using one memory level, such model learns either short-term or long-term patterns, not both of them. A novel CLA2 was proposed and developed, to cope with learning both shortterm and long-term patterns. CLA2 can learn both short-term and long-term patterns in parallel. CLA2 includes two spatial poolers and two temporal memories to simulate short-term and long-term memories. The number of cells per column was decreased in the first region to learn short-term patterns. In the second region, the number of cells per column was increased to learn long-term patterns and the outputs of both regions were concatenated into one vector. The second proposed algorithm (CLA3) has three regions, one spatial pooler, and three cascaded temporal Memories (TM) regions, where the first region learns smaller features, and the second and third regions are more abstract in order to learn and recognise patterns and concatenates the outputs from all three regions into one vector. \n \nAn evaluation and comparison of the proposed algorithms against state-of-the-art supervised machine-learning techniques and the standard CLA for classification was conducted using both the simulated smart home SIMADL dataset, generated using the OpenSHS, and the ARAS dataset, that comprises data captured from real-world activities of residents residing in two houses, the obtained results for the real datasets offered less performance than the synthetic datasets. Because the inhabitants are asked to record their activities manually, it was prone to human errors. The real-world dataset ARAS House A is inconsistent because one of the inhabitants left the house for long period of time, which impacts the performance results. The results of the proposed algorithms for the classification of ADLs show that its performance are promising. For the CLA2, the average overall F-measure for all the synthetic datasets, SIMADL and the real-world datasets, ARAS is 84.88%, while the highest F-measure (86.87%) was achieved by the Convolutional Neural Network (CNN) model. The (CLA2) has achieved an F-measure of 92.63% for House B of the real-world ARAS dataset, which outperforms state-of-the-art classification models. For the CLA3, the average overall F-measure for all the synthetic and real datasets is 84.50% . The proposed algorithms improve the best performance of base-line (standard) CLAs by an average F-measure of 51.81% overall.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/0448fbf8a35412876f7644e0ce88a787301f561f",
        "citation_count": 0
    },
    {
        "title": "Machine learning applications in studying mental health among immigrants and racial and ethnic minorities: an exploratory scoping review",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/049f5255f8def4e7095880aac928fefcf1a08b04",
        "citation_count": 1
    },
    {
        "title": "New Horizons: Evolving Our Understanding of Prognostication in the Era of Machine Learning (RP319)",
        "abstract": "Objectives Increase awareness of machine learning methodologies. Explain how machine learning augments human prognostication. Importance. Significant mismatches exist between patient wishes and care delivery at the end of life. While global capture of end of life patient care preferences remains elusive for the healthcare system, another challenge, especially in an era of rapidly advancing therapies, is accurate prognostication. Objective(s). Increase awareness of machine learning methodologies and use in prognostication. Method(s). We developed a supervised machine learning model utilizing data from 2014-2017 on 18,797 cancer patient records with the goal of predicting 90-day mortality utilizing up to 180 days of data prior to the prediction date. Using a gradient boosted tree algorithm, evaluating 205 features (encompassing labs, age, gender, vitals, medications, and utilization), we trained the model on 14,431 patients and evaluated the model on 4,366 patients, of which 116 patients died within 90 days of the prediction date. Leveraging gradient boosted tree allows limited insight into the predictions (i.e., a gray box model). Using the SHapley Additive exPlanations (SHAP) method, we were able to estimate the contribution of each feature on the prediction score of each true positive patient. Results. Performance on the evaluation set showed a ROC AUC of 0.94 and an average precision (area under the precision-recall curve) of 0.44. We set a decision threshold for a precision of 70%. The model flagged 29 patients, 20 of which were true positives (17.2% recall). The highest weighted features predictive of 90-day mortality in this true positive population included known prognostic factors such as albumin, weight change, and performance status. Machine learning allows more sophisticated analysis, and the model found significance in unique aspects of the data (i.e., evaluating the slope of lab values, minimum value of albumin, or the maximum value for alkaline phosphatase). Other highly prognostic variables are intuitive, but beyond human capability to easily compute, including the percent of all normal labs. Conclusion(s). Machine learning with explanation models to predict prognosis shows promise, but requires further evaluation.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/04f188519567d171490c1427e25d9d321dad2dd3",
        "citation_count": 0
    },
    {
        "title": "Statistical and Machine Learning Models for Classification of Human Wear and Delivery Days in Accelerometry Data",
        "abstract": "Purpose Accelerometers are increasingly utilized in healthcare research to assess human activity. Accelerometry data are often collected by mailing accelerometers to participants, who wear the accelerometers to collect data on their activity. The devices are then mailed back to the laboratory for analysis. We develop models to classify days in accelerometry data as activity from actual human wear or the delivery process. These models can be used to automate the cleaning of accelerometry datasets that are adulterated with activity from delivery. Methods For the classification of delivery days in accelerometry data, we developed statistical and machine learning models in a supervised learning context using a large human activity and delivery labeled accelerometry dataset. We extracted several features, which were included to develop random forest, logistic regression, mixed effects regression, and multilayer perceptron models, while convolutional neural network, recurrent neural network, and hybrid convolutional recurrent neural network models were developed without feature extraction. Model performances were assessed using Monte Carlo cross-validation. Results We found that a hybrid convolutional recurrent neural network performed best in the classification task with an F1 score of 0.960 but simpler models such as logistic regression and random forest also had excellent performance with F1 scores of 0.951 and 0.957, respectively. Conclusion The models developed in this study can be used to classify days in accelerometry data as either human or delivery activity. An analyst can weigh the larger computational cost and greater performance of the convolutional recurrent neural network against the faster but slightly less powerful random forest or logistic regression. The best performing models for classification of delivery data are publicly available on the open source R package, PhysicalActivity.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/054c23ab467f9be9949830a1d8402346ba5bd5b5",
        "citation_count": 2
    },
    {
        "title": "Physiotherapy Exercise Classification with Single-Camera Pose Detection and Machine Learning",
        "abstract": "Access to healthcare, including physiotherapy, is increasingly occurring through virtual formats. At-home adherence to physical therapy programs is often poor and few tools exist to objectively measure participation. The aim of this study was to develop and evaluate the potential for performing automatic, unsupervised video-based monitoring of at-home low-back and shoulder physiotherapy exercises using a mobile phone camera. Joint locations were extracted from the videos of healthy subjects performing low-back and shoulder physiotherapy exercises using an open source pose detection framework. A convolutional neural network was trained to classify physiotherapy exercises based on the segments of keypoint time series data. The model\u2019s performance as a function of input keypoint combinations was studied in addition to its robustness to variation in the camera angle. The CNN model achieved optimal performance using a total of 12 pose estimation landmarks from the upper and lower body (low-back exercise classification: 0.995 \u00b1 0.009; shoulder exercise classification: 0.963 \u00b1 0.020). Training the CNN on a variety of angles was found to be effective in making the model robust to variations in video filming angle. This study demonstrates the feasibility of using a smartphone camera and a supervised machine learning model to effectively classify at-home physiotherapy participation and could provide a low-cost, scalable method for tracking adherence to physical therapy exercise programs in a variety of settings.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/05821e11eeaf4b3f54cb1d4a0d0b58fadb8c5708",
        "citation_count": 18
    },
    {
        "title": "Prediction of Heart Disease using Supervised Learning Algorithms",
        "abstract": "The diagnosis of disease is difficult but critical task in medicine. Data mining is the process of extracting hidden interesting patterns from massive database. In the healthcare industry it plays a significant task for predicting the disease. Heart disease is a single largest cause of death in developed countries and one of the main contributors to disease burden in developing countries. Data mining is a more convenient tool to assist physicians in detecting the diseases by obtaining knowledge and information regarding the disease from patient\u2019s data. By using data mining techniques it takes less time for the prediction of the disease with more accuracy. This paper aims at analyzing the various data mining techniques namely Decision Trees, Naive Bayes, Neural Networks, Random Forest Classification and Support Vector Machine by using the Cleveland dataset for Heart disease prediction. Few of the supervised learning algorithms are used for the prediction of heart disease. It provides a quick and easy understanding of various prediction models in data mining and helps to find the best model for further work",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/05a27449ebd2fca88b480b7cd2276210425a415a",
        "citation_count": 17
    },
    {
        "title": "Using Explainable Supervised Machine Learning to Predict Burnout in Healthcare Professionals",
        "abstract": "Burnout in healthcare professionals (HCPs) is a multi-factorial problem. There are limited studies utilizing machine learning approaches to predict HCPs' burnout during the COVID-19 pandemic. A survey consisting of demographic characteristics and work system factors was administered to 450 HCPs during the pandemic (participation rate: 59.3%). The highest performing machine learning model had an area under the receiver operating curve of 0.81. The eight key features that best predicted burnout are excessive workload, inadequate staffing, administrative burden, professional relationships, organizational culture, values and expectations, intrinsic motivation, and work-life integration. These findings provide evidence for resource allocation and implementation of interventions to reduce HCPs' burnout and improve the quality of care.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/05f195fdbe1627454c9624f9f594ffd9b1854fe5",
        "citation_count": 5
    },
    {
        "title": "Predicting determinants of modern contraceptive use among reproductive-age women in Ethiopia using machine learning algorithm: Evidence from the Performance Monitoring and Accountability (PMA) Survey 2019 dataset",
        "abstract": "Introduction Globally, around 40% of women report unintended pregnancies, with approximately 214 million women in developing countries wanting to avoid pregnancy but not using any contraception. Modern contraceptives (MCs) are effective tools for preventing unintended pregnancies, controlling rapid population growth, and reducing fertility and maternal mortality rates, particularly in developing countries. Low use of contraceptives is responsible for the high fertility and maternal mortality rates in sub-Saharan African nations like Ethiopia. Thus, this study aimed to identify the determinants of modern contraceptive use among Ethiopian women of reproductive age using machine learning (ML) algorithms. Methodology The study utilized secondary data from the 2019 Performance Monitoring and Accountability (PMA) Ethiopia survey, analyzing 8,837 samples. Preprocessing steps included data cleaning, feature engineering, dimensionality reduction, and splitting the data, with 80% used for training and 20% for testing the algorithms. Six supervised ML algorithms were employed and assessed using confusion matrices, with information gain applied to identify critical attributes for predicting MC use. Results Only 24% of participants used modern contraceptives {95% CI (23.1%, 24.9%). Extreme gradient boosting (XGB) demonstrated the highest predictive accuracy (81.97%, 95% CI {79.06%, 82.7%}) and area under the ROC curve (76.63%), followed by logistic regression (80.52%) and support vector machines (80.41%). Key determinants of MC use included starting family planning at age 20 or older, being single, having partner approval, being the wife of the household head, age between 36\u201349 years, advice from healthcare providers, concerns about side effects, and having a household size of five or more. Conclusion and Recommendations The use of modern contraceptives among Ethiopian women remains low. Extreme gradient boosting proved most effective in predicting determinants of MC use. Improved counseling during ANC/PNC visits, promoting partner discussions on family planning, and addressing concerns about family size and contraceptive use are recommended strategies to enhance MC uptake.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/063ab85751870280596a300942ebc6724274d33a",
        "citation_count": 0
    },
    {
        "title": "Machine Learning in Medicare Fraud Detection: Safeguarding Public Resources",
        "abstract": "Fraud in receipt and provision of Medicare is one of the most dangerous threats to public healthcare delivery systems, wasting billions of dollars annually and distorting the foundations upon which healthcare solutions are based. Conventional approaches to identifying fraud have become ineffective owing to the new and complex techniques undertaken by fraudsters. Through this paper, an effort is made to discuss the role of ML in identifying and combating Medicare fraud, specifically to preserve public assets. Using supervised learning, unsupervised learning, and deep learning are promising methods to detect patterns that are possibly related to fraud activities. Applying these techniques can help analyze a huge amount of data, learn from precedents, and identify elaborate and sophisticated trends that are hardly discernable using traditional approaches.\nThis paper will provide an extensive investigation of various ML approaches to Medicare fraud detection. At this step, we experimentally analyze the most popular and effective ones, like decision trees, random forests, SVM, creative neural networks, and clusters. From the results obtained, it is clear that these advanced ML techniques can enhance the performance of fraud detection methods by dramatically minimizing false positives and enhancing the early detection of fraudsters in claims processing. In addition, the ethical concerns, future prospects, and difficulties of employing ML in this particular field. The use of machine learning in Medicare fraud prevention and identification mechanisms to prevent fraud greatly has the potential to transform the protection of public resources, which is crucial to ensuring that healthcare funds are used optimally.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/066056f7c31d592abe74dc19532558bbadf7268c",
        "citation_count": 0
    },
    {
        "title": "Detection of Breast Cancer Through Clinical Data Using Supervised and Unsupervised Feature Selection Techniques",
        "abstract": "Breast cancer is one the most critical disease and suffered many people around the world. The efficient and correct detection of breast cancer is still needed to ensure this medical issue although the researchers around the world are proposed different diagnostic methods for detection of this disease, however these existing methods still needed further improvement to correct and efficient detection of this disease. In this study, we proposed a new breast cancer identification method by using machine learning algorithms and clinical data. In the proposed method supervised (Relief algorithm) and unsupervised (Autoencoder, PCA algorithms) techniques have been used for related features selection from data set and then these selected features have been used for training and testing of classifier support vector machine for accurate and on time detection of breast cancer. Additionally, in the proposed approach k fold cross validation method has been used for model validation and best hyperparameters selection. The model performance evaluation metrics have been used for model performance evaluation. The BC data sets have been used for testing of the proposed method. The analysis of experimental results has been demonstrated that the features selected by Relief algorithm are more related for accurate detection of Breast cancer instead of features selected by Auotencoder and PCA algorithms. The proposed method has been attained high results in terms of accuracy on selected feature selected by Relief algorithm and achieved 99.91% accuracy. We have been employed McNemar\u2019s statistical test for performance comparison of our different models. Further, the proposed method performance has been compared with baseline methods in the literature and the proposed method performance is high as compared to base line methods. Due to the high performance of the proposed method (Relief-Support vector machine) we highly recommended it for the diagnosis of breast cancer. In addition, the proposed method can be easily incorporated into the healthcare system for reliable diagnosis of Breast cancer.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/06794152ca8d1ea8872d671fbc8de79f860db45b",
        "citation_count": 45
    },
    {
        "title": "A New Berlin Questionnaire Simplified by Machine Learning Techniques in a Population of Italian Healthcare Workers to Highlight the Suspicion of Obstructive Sleep Apnea",
        "abstract": "Obstructive sleep apnea (OSA) syndrome is a condition characterized by the presence of repeated complete or partial collapse of the upper airways during sleep associated with episodes of intermittent hypoxia, leading to fragmentation of sleep, sympathetic nervous system activation, and oxidative stress. To date, one of the major aims of research is to find out a simplified non-invasive screening system for this still underdiagnosed disease. The Berlin questionnaire (BQ) is the most widely used questionnaire for OSA and is a beneficial screening tool devised to select subjects with a high likelihood of having OSA. We administered the original ten-question Berlin questionnaire, enriched with a set of questions purposely prepared by our team and completing the socio-demographic, clinical, and anamnestic picture, to a sample of Italian professional nurses in order to investigate the possible impact of OSA disease on healthcare systems. According to the Berlin questionnaire, respondents were categorized as high-risk and low-risk of having OSA. For both risk groups, baseline characteristics, work information, clinical factors, and symptoms were assessed. Anthropometric data, work information, health status, and symptoms were significantly different between OSA high-risk and low-risk groups. Through supervised feature selection and Machine Learning, we also reduced the original BQ to a very limited set of items which seem capable of reproducing the outcome of the full BQ: this reduced group of questions may be useful to determine the risk of sleep apnea in screening cases where questionnaire compilation time must be kept as short as possible.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/06b3b589644817fc34a172a41ae1cda809476931",
        "citation_count": 5
    },
    {
        "title": "Chronic Kidney Disease Prediction Using Na\u00efve Bayesian Classifier and K-NN Machine-Learning Algorithms",
        "abstract": "Long-term renal damage is a critical issue that has to be addressed using healthcare analytics. It is a kind of kidney disease where the kidney's functionality will be degraded over months or years. Hence, accurate prediction needs to be done so that patients can undergo proper treatment at the right time. The machine learning techniques help to accomplish this. The proposed research will examine the effectiveness of supervised or guided classification algorithms such as Naive Bayesian and K-Nearest Neighbor in predicting the disorders on the basis of accuracy. A web application will be implemented that helps doctors and patients identify the disease and undergo medication with a proper diet plan.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/06c4640a302bc4e3ec446d7aeeabd7843f8d6b44",
        "citation_count": 0
    },
    {
        "title": "COVID-19 Vaccination Monitoring Using IoT and Machine Learning\u00a0",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/078fe09225f640687afff996ea8de3f98d37f32c",
        "citation_count": 1
    },
    {
        "title": "Performance Analysis of Real and Synthetic Data using Supervised ML Algorithms for Prediction of Chronic Kidney Disease",
        "abstract": "The introduction of Electronic Health Records (EHRs) is causing fast transformation in healthcare. EHR contains the patient private information and health history in digital form. Hence, EHR data cannot be shared due to privacy concerns to the Machine Learning(ML) research community, through which we can make the healthcare system smarter and provide quality healthcare services to the patients. As a result, synthetic data is utilised as a backup when real-world data (such as EHR data) is unavailable. Synthetic data can be shared without revealing any private information of the patient. This paper focuses on generating synthetic data from the real dataset. As a use case, we have selected Chronic Kidney Disease(CKD) dataset (real) and generated three datasets \u2013 real, synthetic, and a combination of real + synthetic. To test the accuracy of the synthetic data, we ran six supervised machine learning algorithms on these three datasets with all characteristics and reduced features to see if the patient had CKD or not. Supervised ML algorithms on the three datasets are assessed based on the following performance metrics - Confusion Matrix, Accuracy, Recall, Precision, and F1-Score. According to the results, XGBoost surpasses with 100 percent accuracy on all three datasets with full features and a 100 percent accuracy on the mix of real and synthetic datasets with feature reduction.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/07a8a82d0e4c69b39e48a7ad4df59416a99ea5e6",
        "citation_count": 2
    },
    {
        "title": "The Predictive Model of Mental Illness using Decision Tree and Random Forest classification in Machine Learning",
        "abstract": "Ministry of HFW, Government of India ordered the NIMNS - National Institute of Mental Health and Neuro Sciences, Bengaluru, in alliance with 15 institutions from across India and made a survey on mental health issues. This commission covered 12 states, one among that is Punjab from Northern region. As per the report, 15% of the adults in India need treatment for mental disorder. Machine Learning is one of the most substantial proportions of Artificial Intelligence. Machine Learning is widely used in many fields like online fraud detection, speech recognition, and social media. It plays a vital role in healthcare sector. This boosts the interest on the detection of the mental illness using machine learning algorithm. The big challenge is to predict the state of mind. Psychologists impose assessment and therapy to their patients by one to one physical interactions. There are multiple causes to put the person into critical situation like depression, pressure etc. Hence, this research paper proposes an ideal solution to identify the sickness in the person by checking with the recorded dataset. The most preferred Supervised Machine Learning algorithm, Decision Tree Classifier is used for this purpose. The initial goal of the Decision Tress is to create training ideal which is used to forecast the target variable class. The parameters considered here are anxiety disorder, depression disorder and the stress. Random Forest algorithm is applied to predict the illness in the people. The result obtained is to have accurate prediction level compared to the existing model.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/07b757fee8b4d33ff8afeb5a674c0f7550527312",
        "citation_count": 5
    },
    {
        "title": "EARLY PREDICTION OF SEPSIS USING MACHINE LEARNING ALGORITHM: A BRIEF CLINICAL PERSPECTIVE",
        "abstract": "Sepsis is a worldwide cause of death owing to infection and associated immune system response. In situations of septic shock, mortality rates are highest in both developed and underdeveloped countries. Sepsis is a medical illness that requires immediate medical attention but can be avoided with advance warning. Sepsis affects an estimated 30 million people worldwide, with more than 6 million people dying each year. Among them More than 4.2 million new born and children are at risk of contracting the disease. To treat Sepsis, hospitals spend $24 billion (about 13% of all healthcare spending in the United States). The importance of early identification of sepsis in improving sepsis outcomes cannot be overstated. Each hour of delay in treatment increases the risk of death by 4 to 8%. As a result, developing a good model that may be able to tackle this problem becomes urgent and critical. We want to analyse, assess, and design an algorithm that will help us address some of the problems we\u2019ve had when attempting the project.\nKEYWORDS: Sepsis, Machine learning, early prediction, Supervised learning, KNN.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/07d237d2ed2742a27399d29287315165144404b1",
        "citation_count": 0
    },
    {
        "title": "Early Disease Prediction using Ml",
        "abstract": "The approach employed in disease prediction using machine learning involves making forecasts about various diseases by utilizing symptoms provided by patients or other individuals. The supervised machine learning approaches called random forest classifier, KNN classifier, SVMs classifier are employed to forecast the disease. These algorithms are used to determine the disease's probability. Accurate medical data analysis helps with patient care and early disease identification as biomedical and healthcare data volumes rise. Diabetes, heart diseases are just a few of the illnesses we can forecast using linear regression and decision trees. Early detection is beneficial for determining the possibility of diabetes, heart disease.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/07ece4145d55784f8b3b4c32acdbda6ca09981b2",
        "citation_count": 0
    },
    {
        "title": "RO bot Manipulation Learning by Demonstration using G enerative A dversarial N etworks (ROGAN)",
        "abstract": "Following its introduction in industrial manufacturing, robotics is nowadays entering into new application domains through its introduction in urban environments. This provides opportunities but also poses challenges in redefining conventional practices and methods, as is the case in healthcare and well-being that can become more user-oriented, by offering services remotely and with higher degree of autonomy. Our research interest in this thesis proposal concerns the development of such services through the use of humanoid service robots, via machine learning methods capable of transferring human demonstrated skills to the robot. This topic is broadly referred as learning/programming from demonstration (LfD) and deals with task-based coupling of robot action with its sensory/perceptual data. This thesis provides the opportunity to build upon recent work in deep learning and probabilistic graphical models research [12, 6], mainly applied in computer vision applications, to vision-guided robot manipulation skills in use cases related to personal assistance of human users by a companion robot [4]. The thesis is the product of synergy between the teams HAAL of CNRS LabSTICC in IMT-A and PGM group of University of Adelaide, specialized in smart spaces and cognitive robotics on the one hand and high-end artificial intelligence based on deep neural networks and probabilistic graphical models on the other. The thesis will address challenges at a technological and methodological level. In the latter case, it will primarily pursue a task-based mapping of human kinematics to robot arm kinematics, namely, addressing the correspondence problem, via Generative Adversarial Networks (GANs) [10, 8]. This will be the case of supervised human demonstrations given to the robot within the LivingLab facility of IMT-A which emulates the real operating conditions of an assisting robot along human users and experts. Complementary to such demonstrations, the thesis will also explore weakly supervised learning from unanno-",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/0871429e6dc16315e1ff2c10a6a4769b54b27733",
        "citation_count": 0
    },
    {
        "title": "Cirrhosis Prediction in Chronic Liver Disease Patients Using Machine Learning Techniques",
        "abstract": "Liver failure is a serious medical condition that can have life-threatening consequences. The liver is responsible for filtering blood and performing many other important functions. With the rise of machine learning in healthcare, there is an opportunity to use past datasets to predict liver failure early on. The main focus of this research work is to explore the application of supervised machine learning algorithms in predicting liver failure. The study involved pre-processing techniques such as univariate and bivariate analysis, and data visualization to gain better insights into the features of the dataset. Using these techniques, a multi-class classification model was built with machine learning algorithms, and the performance metrics of accuracy, F1 score, and recall were used to compare the algorithms. The results show that machine learning algorithms can accurately predict liver failure and can be an effective tool in healthcare. This study demonstrates the potential of machine learning in predicting liver failure and can contribute to the development of future models in the field. The results of this research study indicates that the proposed algorithm achieved an accuracy of 94.48%. The proposed work will be beneficial to researchers in this field and inspire them to build more advanced and accurate models.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/08994b40ddedc96b9b627fba280f54dc440f2020",
        "citation_count": 5
    },
    {
        "title": "Knowledge Discovery and Diseases Prediction: A Comparative Study of Machine Learning Techniques",
        "abstract": "The use of medical datasets has attracted the attention of researchers worldwide. Data mining techniques have been widely used in developing decision support systems for disease classification through a set of medical datasets. In this paper, we propose a predictive method for diseases prediction using machine learning techniques. The proposed method is developed through clustering, noise removal, and supervised machine learning techniques. Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Neural Network (NN), Adaptive Network-Based Fuzzy Inference System (ANFIS), Support Vector Regression (SVR) and Classification and Regression Trees (CART) are used for diseases prediction task. We also use the Principal Component Analysis (PCA) for dimensionality reduction and to address multi-collinearity problems in the experimental datasets. We test our proposed method on several public medical datasets. Experimental results on Wisconsin Diagnostic Breast Cancer, StatLog, Cleveland and Parkinson\u2019s telemonitoring datasets show has potential to be used as a decision support system in healthcare.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/08a65b16fecce357a32677854b6dd4850e007de2",
        "citation_count": 17
    },
    {
        "title": "An Approach to Supervised Classification of Highly Imbalanced and High Dimensionality COPD Readmission Data on HPCC",
        "abstract": "Hospital readmission within a 30-day period causes severe economic and healthcare impacts. According to a study, 76% of the hospitals readmissions can be prevented by providing out of hospital post-discharge care. In order to appropriately mark the patients with high chances of getting readmitted, numerous studies and researches have been performed which uses various supervised machine learning algorithms to predict the readmission probability of a patient using labeled discharge summaries and clinical notes. The datasets used in these studies are highly imbalanced and has high dimensionality, which affects classification performance negatively. This study uses data sampling technique to reduce the imbalance and feature selection technique to reduce high dimensionality, thereby improving the overall classification performance and reducing the evaluation time as compared to other industry standard hospital readmission frameworks reviewed in this study.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/08af502efde946d04e5be7e3f14c24d6fccb1427",
        "citation_count": 3
    },
    {
        "title": "Early diagnosis of diabetes mellitus using data mining and machine learning techniques",
        "abstract": "The remarkable developments in biotechnology as well as the health sciences have resulted in the production of an enormous amount of data, including high-throughput screening genomics information and clinical information obtained through extensive electronic health records (EHRs). The application of data mining and machine learning techniques in the biosciences is today more vital than ever to achieving this objective as attempts are made to intelligently translate all readily available data into knowledge. Diabetes mellitus (DM), a group of metabolic disorders, is well known to have a serious detrimental effect on population lives all over the world. Large-scale research into all aspects of diabetic has resulted in the production of enormous amounts of data (detection, etiopathophysiology, therapy, etc.). The goal of the current study is to conduct a thorough examination of the use of machine learning, data mining methods and tools in the field of diabetes research, with the first classification making an appearance to be the most popular. These applications relate to a Statistical model and Diagnosis, b) Diabetic Complications, c) Multiple genes Background and Environment, and e) Free Healthcare and Management. Numerous machine learning algorithms were applied. 85% of the methods used were supervised learning approaches, whereas 15% were uncontrolled ones, including association rules. Developed on improved support vector machines, the most successful and widely used algorithm (SVM). Medical datasets were predominantly used in terms of data kind.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/08b769b4d7ce97f0e1c1c220c167bc6b1b3277dc",
        "citation_count": 1
    },
    {
        "title": "STUDY ON HEART DISEASE PREDICATION USING ARTIFICIAL INTELLIGENCE",
        "abstract": "Several disorders may cause cardiovascular disease, or heart disease. Heart disease has several risk factors and requires quick diagnosis for proper treatment. A symptom Data mining is a common way to analyse healthcare data. Researchers employ data mining and machine learning to analyse complex medical data for healthcare practitioners. Cardiologists predict heart disease. This study's model uses heart disease-related parameters. Supervised learning uses Naive Bayes, decision tree, K-nearest neighbour, and random forest. It uses UCI's Cleveland database of heart disease patients. The 303 instances of data include characteristics. Only 14 of the 76 traits are verified, but they're crucial to confirming the claim. Algorithm performance. This research estimates heart disease risk in a population. Patients. K-nearest neighbour has the highest accuracy, as shown in result and discussion.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/08c0aacf9779972919d5b50def5973c8ebc6fb7e",
        "citation_count": 0
    },
    {
        "title": "A WHEELCHAIR SITTING POSTURE DETECTION SYSTEM USING PRESSURE SENSORS",
        "abstract": "The usage of machine learning in the healthcare system, especially in monitoring those who are using a wheelchair for their mobility has also helped to improve their quality of life in preventing any serious life-time risk, such as the development of pressure ulcers due to the prolonged sitting on the wheelchair. To date, the amount of research on the sitting posture detection on wheelchairs is very small. Thus, this study aimed to develop a sitting posture detection system that predominantly focuses on monitoring and detecting the sitting posture of a wheelchair user by using pressure sensors to avoid any possible discomfort and musculoskeletal disease resulting from prolonged sitting on the wheelchair. Five healthy subjects participated in this research. Five typical sitting postures by the wheelchair user, including the posture that applies a force on the backrest plate, were identified and classified. There were four pressure sensors attached to the seat plate of the wheelchair and two pressure sensors attached to the back rest. Three classification algorithms based on the supervised learning of machine learning, such as support vector machine (SVM), random forest (RF), and decision tree (DT) were used to classify the postures which produced an accuracy of 95.44%, 98.72%, and 98.80%, respectively. All the classification algorithms were evaluated by using the k-fold cross validation method. A graphical-user interface (GUI) based application was developed using the algorithm with the highest accuracy, DT classifier, to illustrate the result of the posture classification to the wheelchair user for any posture correction to be made in case of improper sitting posture detected.\nABSTRAK: Penggunaan pembelajaran mesin dalam sistem penjagaan kesihatan terutama dalam mengawasi pergerakan pengguna kerusi roda dapat membantu meningkatkan kualiti hidup bagi mengelak sebarang risiko serius seperti ulser disebabkan tekanan duduk terlalu lama di kerusi roda. Sehingga kini, kajian tentang pengesanan postur ketika duduk di kerusi roda adalah sangat kurang. Oleh itu, kajian ini bertujuan bagi membina sistem pengesan postur khususnya bagi mengawasi dan mengesan postur duduk pengguna kerusi roda dengan menggunakan pengesan tekanan bagi mengelak sebarang kemungkinan ketidakselesaan dan penyakit otot akibat duduk terlalu lama. Lima pengguna kerusi roda yang sihat telah dijadikan subjek bagi kajian ini. Terdapat lima postur duduk oleh pengguna kerusi roda termasuk postur yang memberikan tekanan pada bahagian belakang telah di kenalpasti dan dikelaskan. Terdapat empat pengesan tekanan dilekatkan pada bahagian tempat duduk kerusi roda dan dua pengesan tekanan dilekatkan pada bahagian belakang. Tiga algoritma pengelasan berdasarkan pembelajaran terarah melalui pembelajaran mesin seperti Sokongan Vektor Mesin (SVM), Hutan Rawak (RF) dan Pokok Keputusan (DT) telah digunakan bagi pengelasan postur di mana masing-masing memberikan ketepatan 95.44%, 98.72% dan 98.80%. Semua algoritma pengelasan telah dinilai menggunakan kaedah k-lipatan pengesahan bersilang. Sebuah aplikasi grafik antara muka \u00a0(GUI) telah dibina menggunakan algoritma dengan ketepatan paling tinggi, iaitu pengelasan DT bagi memaparkan keputusan pengelasan postur untuk pengguna kerusi roda bagi membantu pembetulan postur jika postur salah dikesan.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/094574d59a69d2cde0c8fbc4b4f31db8e90d33c1",
        "citation_count": 1
    },
    {
        "title": "Supervised Classification of Healthcare Text Data Based on Context-Defined Categories",
        "abstract": "Achieving a good success rate in supervised classification analysis of a text dataset, where the relationship between the text and its label can be extracted from the context, but not from isolated words in the text, is still an important challenge facing the fields of statistics and machine learning. For this purpose, we present a novel mathematical framework. We then conduct a comparative study between established classification methods for the case where the relationship between the text and the corresponding label is clearly depicted by specific words in the text. In particular, we use logistic LASSO, artificial neural networks, support vector machines, and decision-tree-like procedures. This methodology is applied to a real case study involving mapping Consolidated Framework for Implementation and Research (CFIR) constructs to health-related text data and achieves a prediction success rate of over 80% when just the first 55% of the text, or more, is used for training and the remaining for testing. The results indicate that the methodology can be useful to accelerate the CFIR coding process.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/0996a996559231413685969f96f8626d080feb41",
        "citation_count": 2
    },
    {
        "title": "Assessment of beliefs and attitudes towards benzodiazepines using machine learning based on social media posts: an observational study",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/09acac6daa6c82f70f4fe6ba84206a25b62b705f",
        "citation_count": 1
    },
    {
        "title": "Disease prognosis using machine learning algorithms based on new clinical dataset",
        "abstract": "Today, artificial intelligence-based solutions are produced to facilitate human life in almost every field. The healthcare sector is one of the sectors which took advantage of these solutions. Due to reasons such as the world\u2019s ever-expanding population, ongoing epidemics, and the emergence of new disease types, it is becoming increasingly difficult for a patient to benefit from health services quickly and to make an accurate diagnosis. At this juncture, artificial intelligence reduces the patient density in hospitals, enables patients to access accurate information, and allows medical students to practice by seeing new cases. In this study, a new and reliable dataset was created with disease information obtained from various sources under the supervision of a specialist medical doctor. Then, new patient histories were added to the dataset used in the previous study, the experiments were repeated with the same algorithms, and the accuracy score comparison was presented. The created dataset includes 2006 unique patient histories, 358 symptoms, and 141 diseases and we think it will be a valuable dataset for researchers who make developments using machine learning in the field of healthcare. Various machine learning algorithms have been used in the training process to predict diseases belonging to different branches of medicine, such as diabetes, bronchial asthma, and covid. Besides, Support Vector Machine, Naive Bayes, K-Nearest Neighbors, Multilayer Perceptron, Decision Tree, and Random Forest algorithms, we also studied popular boosting algorithms such as XGBoost and LightGBM. All algorithms were validated with cross-validation and performance comparisons were made with different performance metrics such as accuracy, precision, recall, and f1-score. It is also the first study to achieve\nan accuracy score of 99.33% with a dataset that involves a greater number of diseases than the datasets used in the studies examined.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/09bc41cdcf016b8e1ce2c7d75ff5d12d8ebe271b",
        "citation_count": 2
    },
    {
        "title": "A Medical Model Built on Machine Learning to Evaluating the Relationship between the Depression and Living Standards",
        "abstract": "Future healthcare reforms are being influenced by new technological developments. Finding the elements that contribute to depression may inspire fresh research and therapeutic approaches. Depression is a difficulty that many people experience, because depression is a condition that is increasingly posing a major community health threat. To manage and analyze the diverse data and comprehend the relationship between depression and life satisfaction, this paper uses machine learning techniques. The assessment study is afterwards divided principally in to the two parts. A data consolidation procedure is introduced in the first section. Data relationships are established and each relationship in data is uniquely identified using the Secure Hash Algorithm idea. A model that incorporated was proposed in the second segment. Unsupervised machine learning technique. K-Means is used for clustering. Supervised machine learning algorithms like Naive Bayes, Multi Class Support Vector Machine with Posterior Probability (MCSVMPP), KNN and Voting classifier is used to find the depression according to different factors.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/09bea6244695b6a6e17bd04d98ef664f77a0f178",
        "citation_count": 0
    },
    {
        "title": "Organ Risk Prediction for Parkinson\u2019s Disease using Deep Learning Techniques",
        "abstract": "Parkinson\u2019s Disease is a kind of nervous system disorder whose symptoms start gradually. The signs and symptoms can be different for everyone with no specific diagnosis. Neurological disorders are identified as global threat with Parkinson\u2019s Disease being the second most common. More than 10 billion people are living with Parkinson\u2019s around the world. This disease is most common in countries of the US and Canada. Deep learning an essential part of Artificial Intelligence provides an uncanny power to systems to construct a complex network using layers of perceptrons that mimic the human neurons. This network Combined with algorithms of Machine Learning and Prognostic Modeling may serve as one of the most powerful tools in healthcare to classify and analyze huge amount of medical data and predict future trends through Supervised Learning. In the paper, we focused on the effective prediction of the organ at risk for Parkinson\u2019s Disease (Multi-label Classification). We have examined and refined our model over data collected across data collection of over 300 features. We have put forward an Artificial Neural Network organ risk prediction algorithm using contrasting data. To our finest understanding, none of the previous works have centered on contrasting data in the area of analysis of medical data. The prediction accuracy of our suggested ANN algorithm is 76%.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/09df6c9a3bd0eb45908cb45fc613f3513b363230",
        "citation_count": 6
    },
    {
        "title": "Metaverse, AR, machine learning & AI in Orthopaedics?",
        "abstract": "The use of metaverse technology in medical education and training has the potential to greatly enhance the way healthcare professionals learn, practice, and deliver care. In particular, the use of virtual reality simulations has shown promise in the field of Orthopaedic surgery. But what exactly is metaverse? The term \u201cmetaverse\u201d was coined by science fiction author Neal Stephenson in 1992 to describe a virtual shared space, created by the convergence of virtually enhanced physical reality and physically persistent virtual space, including the sum of all virtual worlds, augmented reality, and the internet. In the context of healthcare, metaverse technology refers to the use of virtual reality, interactive and other immersive technologies, such as augmented reality in real time, to create simulated environments for training, education, and clinical application. One of the main benefits of using metaverse technology in Orthopaedic education and training is the ability to provide immersive learning experiences that more closely mimic real-life surgical scenarios. For example, a study published in the Journal of Orthopaedic Research found that virtual reality simulations were effective in training residents to perform total knee arthroplasty (TKA). The study found that residents who trained using virtual reality simulations had significantly better performance in a simulated TKA task compared to those who did not use simulations. Another study on the use of virtual reality simulation facilitated resident training in total hip arthroplasty (THR). Additional benefit of using metaverse technology in medical education is the ability to use limited resources more efficiently. Training on cadavers and in operating rooms can be costly and time-consuming, whilst simulations using metaverse allow for repeated practices without these constraints. A recent randomised control trial published in the BMJ found that using virtual reality simulations to train surgical trainee on laparoscopic surgery resulted in better proficiency in shorter time compared with traditional training methods. However, there are potential dangers and abuses of metaverse technology in medical settings. For example, there is a risk that students and surgical trainees may not fully understand the limitations of simulations and may have unrealistic expectations for their abilities in real-life surgical scenarios. Some aspects of these issues were highlighted in an earlier publication on the use of virtual reality simulators and training in laparoscopic surgery. This could potentially lead to adverse outcomes for patients. Hence, metaverse in clinical practice is a compliment/ adjunct to, and not a replacement for proper supervised surgical training. There is also the potential for abuse, such as cheating on exams or using simulations to practice procedures without proper supervision. In summary the use of metaverse technology in medical education and surgical training holds great promise for enhancing the way healthcare professionals learn, practice, and deliver care. However, it is important to carefully consider the benefits, drawbacks, potential dangers and abuses of this emerging technology. It is crucial that metaverse technology be used in a responsible, supervised, and ethical manner, in conjunction with formal surgical training, to ensure that healthcare professionals are properly prepared to deliver high-quality patient care.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/0a1f1a7328141e5e65debdd352882449bd798348",
        "citation_count": 16
    },
    {
        "title": "A Machine Learning Approach to Predicting Covid-19 Cases Amongst Suspected Cases and Their Category of Admission",
        "abstract": "The rapid spread of COVID-19 worldwide has claimed thousands of lives and has put unprecedented pressure on the healthcare systems around the world. The World Health Organization has emphasised the need for comprehensive testing in order to fight the virus [1]. With the lack of testing kits available worldwide, there is a call for novel testing methods that can help arrest the spread faster [18]. Every health care worker exposed to the virus puts additional pressure on an already outstretched infrastructure. Here, in this study we propose a machine learning approach towards predicting Covid-19 cases among a sample population who have undergone other clinical tests and blood spectrum tests. The patient data used in this effort has been donated by Hospital Israelita Albert Einstein, at S\u00e3o Paulo, Brazil [6] for the purpose of research. The problem at hand is divided into two parts: Predict confirmed COVID-19 cases amongst suspected cases based on the laboratory tests of their clinical samples. Predict admission to general, semi-ICU, and ICU wards among those who predicted positive for COVID-19 in the first task. Our approach uses Classification from Supervised Learning techniques to solve this problem. The efficacy of this approach could be used to scale and develop automated systems that could predict the likeliness of Covid-19 based on laboratory tests that are readily accessible. From the features presented to us in the dataset, we are able to predict with 87.0 - 97.4 percent accuracy at a 95 percent confidence level that a patient is suffering from Covid-19 when biomarkers are taken into consideration. Among those that tested positive, we were able to demonstrate that our model could predict with 87.0 - 100 percent accuracy at a 95 percent confidence that whether the patient would be admitted to a particular ward.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/0a46a37e31278e3ccaee20d755436e82db57abc6",
        "citation_count": 14
    },
    {
        "title": "ECG Heartbeat Classification Using Machine Learning and Metaheuristic Optimization for Smart Healthcare Systems",
        "abstract": "Early diagnosis and classification of arrhythmia from an electrocardiogram (ECG) plays a significant role in smart healthcare systems for the health monitoring of individuals with cardiovascular diseases. Unfortunately, the nonlinearity and low amplitude of ECG recordings make the classification process difficult. Thus, the performance of most traditional machine learning (ML) classifiers is questionable, as the interrelationship between the learning parameters is not well modeled, especially for data features with high dimensions. To address the limitations of ML classifiers, this paper introduces an automatic arrhythmia classification approach based on the integration of a recent metaheuristic optimization (MHO) algorithm and ML classifiers. The role of the MHO is to optimize the search parameters of the classifiers. The approach consists of three steps: the preprocessing of the ECG signal, the extraction of the features, and the classification. The learning parameters of four supervised ML classifiers were utilized for the classification task; support vector machine (SVM), k-nearest neighbors (kNNs), gradient boosting decision tree (GBDT), and random forest (RF) were optimized using the MHO algorithm. To validate the advantage of the proposed approach, several experiments were conducted on three common databases, including the Massachusetts Institute of Technology (MIT-BIH), the European Society of Cardiology ST-T (EDB), and the St. Petersburg Institute of Cardiological Techniques 12-lead Arrhythmia (INCART). The obtained results showed that the performance of all the tested classifiers were significantly improved after integrating the MHO algorithm, with the average ECG arrhythmia classification accuracy reaching 99.92% and a sensitivity of 99.81%, outperforming the state-of the-art methods.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/0a8b88d05146de1cd8b7b4c30f88f6c077735f40",
        "citation_count": 35
    },
    {
        "title": "HUMAN ACTIVITY RECOGNITION USING SMART PHONE DATA",
        "abstract": "Human activity recognition has seen a tremendous growth in the last decade playing a majorrole in the field of pervasive computing. This emerging popularity can be attributed to its myriad of real-lifeapplications primarily dealing with human-centric problems like healthcare and eldercare. Data from thesensors attached to a person can be utilized to train supervised machine learning models in order to predictthe activity being carried out by the person. In this paper we will be using Data available at UCI machinelearning Repository. It contains data generated from accelerometer , gyroscope and other sensors of Smartphone to train supervised predictive models using machine learning techniques like SVM , Random forestand decision tree to generate a model. which can be used to predict the kind of movement being carried outby the person which is divided into six categories walking, walking upstairs, walking downstairs, sitting,standing and jogging .We will be comparing the accuracy of different models using confusion matrix and Kfold cross validation",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/0aa478b8382ea7018e57bd412a78a0db62086f36",
        "citation_count": 0
    },
    {
        "title": "Prognosis of Supervised Machine Learning Algorithms in Healthcare Sector",
        "abstract": "Medical care is a fundamental liberty. The conquering application of Machine Learning (ML) in this computerized world is noticeable. With the increase in medical data, ML is penetrating in medical care industry resulting in the integration of Machine Learning algorithms and knowledge of medical personnel and designing of prognostic models which can help doctors and patients to analyze risks of any health compilation. Researchers from health domain are exploring ML algorithms to reach out to some useful conclusions. With this paper we aim to help the researchers to understand the efficiency of available ML algorithms on medical datasets, thus helping them to decide which one to choose from the existing methods. This paper implements 5 Supervised Machine Learning algorithms on four different datasets from health domain on Heart Disease, Diabetes, Dermatology, and Breast Cancer. Results of each of the implemented ML algorithms are compared in terms of prediction accuracy and AUC value on medical datasets. Implementation results suggests that Logistic Regression and Random Forest have shown better results with almost all the datasets used for experiment purpose with accuracy (85%-88%) and AUC value (0.89-0.92). The yield of this paper will add to a better understanding of the use of Machine Learning in the Medical Domain.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/0ae29fc8f0d8cdc4cc8a08d9e7c05286ce1ea09b",
        "citation_count": 3
    },
    {
        "title": "Perbandingan Hasil Prediksi Diagnosis pada Indian Liver Patient Dataset (ILPD) dengan Teknik Supervised Learning Menggunakan Software Orange",
        "abstract": "The development of the volume of data every day has resulted in the need for data mining to obtain valuable and meaningful data. There are many data mining software that has been developed, both free and paid. One of the free data mining software is Orange. This software provides modeling, both supervised and unsupervised learning. Orange also provides model evaluation features, such as accuracy, precision, the time required for training and testing, specificity, and other evaluation measures. Therefore, Orange makes it easy for users to perform data mining. One of the users who need Orange is a user with a non-IT background, such as a health user who can make predictions for the diagnosis of a disease. Users do not need to focus on syntax to perform data mining. With Orange, healthcare users can easily and faster predict the diagnosis of the disease. This study uses Indian Liver Patient (ILPD) data from the UCI-Machine Learning Repository. The objective of the diagnosis is to determine whether the patient has a liver disorder or not. The methods that are used in this study are Decision Tree, Random Forest, SVM, Neural Network, Na\u00efve Bayes, k-NN, and Logistic Regression. This study evaluates using a confusion matrix, accuracy level, precision level, training time, and testing time. The results show that the time required for training and testing is relatively short. With the data used, this study has proved that the four best methods based on accuracy are Logistic Regression, Neural Network, Random Forest, and Na\u00efve Bayes.\u00a0\u00a0Perkembangan volume data setiap hari mengakibatkan perlunya data mining untuk mendapatkan data berharga dan berguna. Terdapat banyak data mining software yang telah dikembangkan, baik gratis maupun berbayar. Salah satu data mining software yang gratis adalah Orange. Sofware ini menyediakan pemodelan, baik supervised maupun unsupervised learning. Orange juga menyediakan fitur evaluasi model, seperti akurasi, presisi, waktu yang dibutuhkan untuk training dan testing, spesifisitas, dan ukuran evaluasi lainnya. Oleh karena itu, dapat dikatakan bahwa Orange memudahkan pengguna untuk melakukan data mining. Salah satu pengguna yang membutuhkan Orange adalah pengguna dengan latar belakang non-IT, seperti pengguna bidang kesehatan yang dapat melakukan prediksi untuk diagnosis suatu penyakit. Pengguna tidak perlu berfokus pada sintaks untuk melakukan data mining. Dengan Orange, pengguna bidang kesehatan dapat memprediksi diagnosis suatu penyakit dengan lebih mudah dan lebih cepat. Penelitian ini menggunakan data Indian Liver Patient (ILPD) dari UCI-Machine Learning Repository. Targetnya adalah menentukan diagnosis pasien apakah memiliki ganguan hati atau tidak. Metode yang digunakan adalah Decision Tree, Random Forest, SVM, Neural Network, Na\u00efve Bayes, k-NN, dan Regresi Logistik. Penelitian ini melakukan evaluasi dengan menggunakan confusion matrix, tingkat akurasi, tingkat presisi, waktu training, dan waktu testing. Hasil penelitian menunjukkan bahwa waktu yang dibutuhkan untuk training dan testing terbilang singkat. Dengan data yang digunakan, dalam penelitian ini diperoleh hasil pula empat metode terbaik berdasarkan tingkat akurasi adalah Regresi Logistik, Neural Network, Random Forest, dan Na\u00efve Bayes.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/0b4e0310bb4626dabc1cd9946b23dabe7adf7bde",
        "citation_count": 5
    },
    {
        "title": "Symptomatic & Non-Symptomatic Hepatocellular Carcinoma Prediction using Machine Learning",
        "abstract": "Predicting patients' conditions in the healthcare system is a very proactive step for providing better treatment procedures. Our Study provides and details analysis of some classifier algorithms in the supervised learning approach. For doing this analytical work we have considered a dataset on patients detected with hepatocellular carcinoma which was published by the European Association for the study of the liver and the European organization for research and treatment of cancer for severity prediction. Logistic regression, naive Bayes classifier, k-nearest neighbor, stochastic gradient descent, support vector machine these classifier algorithms have been used here for having a prediction on the severity or not according to the trained model on a normalized form of the dataset. Performance analysis has come up with the best performer with accuracy 0.9 and 0.847 r-squared error which is the support vector machine technique.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/0b54dd51d71627a7d1d2842fb13c8f284a780454",
        "citation_count": 2
    },
    {
        "title": "A review of automatic selection methods for machine learning algorithms and hyper-parameter values",
        "abstract": null,
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/0bf08d3dcc1f4a3b7b4f9a68f9c980c0a3f4ed2a",
        "citation_count": 297
    },
    {
        "title": "EMIXER: End-to-end Multimodal X-ray Generation via Self-supervision",
        "abstract": "Deep generative models have enabled the automated synthesis of high-quality data for diverse applications. However, the most effective generative models are specialized to data from a single domain (e.g., images or text). Real-world applications such as healthcare require multi-modal data from multiple domains (e.g., both images and corresponding text), which are difficult to acquire due to limited availability and privacy concerns and are much harder to synthesize. To tackle this joint synthesis challenge, we propose an End-to-end MultImodal X-ray genERative model (EMIXER) for jointly synthesizing x-ray images and corresponding free-text reports, all conditional on diagnosis labels. EMIXER is an conditional generative adversarial model by 1) generating an image based on a label, 2) encoding the image to a hidden embedding, 3) producing the corresponding text via a hierarchical decoder from the image embedding, and 4) a joint discriminator for assessing both the image and the corresponding text. EMIXER also enables self-supervision to leverage vast amount of unlabeled data. Extensive experiments with real X-ray reports data illustrate how data augmentation using synthesized multimodal samples can improve the performance of a variety of supervised tasks including COVID-19 X-ray classification with very limited samples. The quality of generated images and reports are also confirmed by radiologists. We quantitatively show that EMIXER generated synthetic datasets can augment X-ray image classification, report generation models to achieve 5.94% and 6.9% improvement on models trained only on real data samples. Taken together, our results highlight the promise of state of generative models to advance clinical machine learning.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/0c3612f08814b86a5e44dfd1fe549acb7a1c1801",
        "citation_count": 5
    },
    {
        "title": "A vital sign-based prediction algorithm for differentiating COVID-19 versus seasonal influenza in hospitalized patients",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/0c870fafcf67b801f26caab91410f546a7eb354f",
        "citation_count": 21
    },
    {
        "title": "Building Resilient ML Applications using Ensembles against Faulty Training Data",
        "abstract": "Supervised machine learning (ML) applications are data-driven, and thus require large amounts of data for training. Whether the training data is manually collected or automatically generated, it is prone to faults like mislabelling, accidental deletion, or repetition. Our research focuses on developing the most effective and efficient techniques with minimal human effort to improve the resilience of ML applications against faulty training data. We find that ensembles have a higher resilience to faulty training data than individual models, especially when using ensembles with architecturally diverse constituent models. We also find that ensembles are more effective than many existing techniques against mislabelled training data, even in safety-critical domains such as autonomous vehicles and healthcare. Hence, we aim to improve the applicability of ensembles in real-world systems by (1) optimizing the process of searching for resilient ensembles, and (2) reducing the training cost by maximizing reuse of trained weights and (3) examining methods to make ensembles more explainable to stakeholders.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/0cd254a329fa68d2d43f6dd246763fdf68bc4ebe",
        "citation_count": 0
    },
    {
        "title": "Contrastive Learning Based Human Activity Recognition Using Body Sensors",
        "abstract": "Pervasive sensing and wearable sensor techniques have been increasingly employed to monitor and recognize human activities through body sensors in areas of smart healthcare and manufacturing. However, conventional machine learning or deep learning based human activity recognition (HAR) requires a large amount of labeled data, which is cost-expensive in real-world scenarios. To tackle this issue, we propose a contrastive learning framework for HAR (CL-HAR), which utilizes the generated unlabeled data as the input and explores the supervised features of the unlabeled data under the principle of self-supervised learning. A simple yet effective backbone network as a feature extractor for subsequent activity recognition is proposed. By using a small portion of the labeled samples as the training set which is fed into our learned feature extractor, we build a classifier and use the rest of the data to verify the feasibility and effectiveness of our CL method. Extensive experiments on three benchamark datasets and one real-world dataset demonstrate that CL-HAR can achieve better classification accuracy than compared supervised and semi-supervised methods with less labelled samples, which is of practical use.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/0cef7e0d1e84aa4ec00c0fee658a9f3e735e419b",
        "citation_count": 0
    },
    {
        "title": "Predicting Neonatal Encephalopathy From Maternal Data in Electronic Medical Records",
        "abstract": "Neonatal encephalopathy (NE) is a leading cause of neonatal mortality and lifetime neurological disability. The earlier the risk of NE can be assessed, the more effective interventions can be in preventing adverse outcomes. Existing studies that focus on intrapartum risk factors do not provide the early prognostic forecasting necessary to prepare healthcare professionals to intervene early in a high-risk NE case. This work used maternal data in a supervised machine learning framework to predict NE events. Specifically, we 1) collected the electronic medical records (EMRs) for 104 NE newborns and 31,054 non-NE newborns and their mothers, 2) trained and tested a regularized logistic regression on imbalanced and high-dimensional EMR data, and 3) discerned important features that could be possible risk factors. The learned model offers prenatal predictions of NE cases with an average area under the receiving operator characteristic curve (AUC) of 87% and identified the most important predictors.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/0d0fbb4a18beeca9b3a374377553e51754e0a364",
        "citation_count": 6
    },
    {
        "title": "Comparative Analysis of Supervised Machine Learning Algorithms for Predicting Cardiovascular Disease",
        "abstract": "Heart disease is one of the most dangerous and largest killers in the world. Identifying heart disease early has a vast positive effect on patient outcomes and their quality of life. In this research, we try to identify heart disease using machine learning (ML) algorithms. ML algorithms have the highest probability of success if they work on a data set with extensive and diverse information about the given problem - in this case heart disease. There are multiple types of ML algorithms to test, so we can try many different ones on the data, making the results more precise. Even if there are many different algorithms to test, each machine-learning solution can yield different results depending on the dataset used and our target goals. The main goal of this study is to find the differences between individual ML algorithms being used in our specific case: which ML algorithm, or combination of algorithms, is appropriate to detect heart disease with high accuracy? The ML algorithms used in this research are the Naive Bayes Classifier, the Random Forest classifier, and the Support Vector Machine (SVM) algorithm. Furthermore, this study generates insights into these ML algorithms \u2013 if a particular algorithm\u2019s model performs better than another on the dataset, analyzing this difference can help us understand what makes the model more suitable for diagnostic screening. Changing models\u2019 hyperparameters or their pre-processing techniques allows for a more robust and reliable model that can be readily incorporated into a healthcare environment.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0d485c1f38ed607703320ed39dfe48a8c0dfb79e",
        "citation_count": 0
    },
    {
        "title": "Importance Of Continuous Improvement of Machine Learning Algorithms From A Health Care Management And Management Information Systems Perspective",
        "abstract": "In modern times, researchers in the healthcare sector increasingly acknowledge the significance of data analysis. In the healthcare sector, data can be accessed from various means such as sensor data, Clinical data, and Omics data. Data from various wireless sensor devices and the wearable device are a form of sensor data. Data from the health records that store patient's records during treatment are a form of clinical data. A high dimensional data that contains proteome data types, transcriptome, and Genome are a form of Omics data. Raw data can be very difficult to handle manually, for this reason, the emergence of machine learning proved to be a significant tool for data analysis. The prediction and precision of healthcare data accurately are now more visible because of the various statistical techniques and advanced algorithms that machine learning employs. There are different types of algorithms in machine learning such as the hybrid model, reinforced learning, unsupervised learning, and supervised learning that are utilized for data analysis. In this paper, the description of various types of machine learning algorithms and the analysis of healthcare data are surveyed using the machine learning algorithms.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/0d4a90659c67060c88eed986712aa434df526fdc",
        "citation_count": 4
    },
    {
        "title": "Predicting nutritional status for women of childbearing age from their economic, health, and demographic features: A supervised machine learning approach",
        "abstract": "Background Malnutrition imposes enormous costs resulting from lost investments in human capital and increased healthcare expenditures. There is a dearth of research focusing on the prediction of womens body mass index (BMI), and the malnutrition outcomes (underweight, overweight and obesity) in developing countries. This paper attempts to fill out this knowledge gap by predicting the BMI and the risks of malnutrition outcomes for Bangladeshi women of childbearing age from their economic, health, and demographic features. Methods Data from the 2017-18 Bangladesh Demographic and Health Survey and a series of supervised machine learning (SML) techniques are used. Additionally, this study circumvents the imbalanced distribution problem in obesity classification by utilizing an oversampling approach. Results Study findings demonstrate that support vector machine and k-nearest neighbor are the two best-performing methods in BMI prediction based on coefficient of determination (R2), root mean square error (RMSE), and mean absolute error (MAE). The combined predictor algorithms consistently yield top specificity, Cohens kappa, F1-score, and AUC in classifying the malnutrition status, and their performance is robust to alternative standards. The feature importance ranking based on several nonparametric and combined predictors indicates that socioeconomic status, womens age, and breastfeeding status are the most important features in predicting womens nutritional outcomes. Furthermore, the conditional inference trees corroborate that those three features along with the partners educational attainment and employment significantly predict malnutrition risks. Conclusion To the best of our knowledge, this is the first study that predicts BMI and one of the pioneer studies to classify all three malnutrition outcomes for women of childbearing age in Bangladesh, let alone in any lower-middle income country, using SML techniques. Moreover, in the context of Bangladesh, this paper is the first to identify and rank features that are critical in predicting nutritional outcomes using several feature selection algorithms. The estimators from this study predict the outcomes of interest most accurately and efficiently compared to other existing studies in the relevant literature. Therefore, study findings can aid policymakers in designing policy and programmatic approaches to address the double burden of malnutrition among Bangladeshi women, thereby reducing the countrys economic burden.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/0d5842f1c4b1cac4b13c492e4a35ba0c1791ebbf",
        "citation_count": 8
    },
    {
        "title": "ProteinGym: Large-Scale Benchmarks for Protein Design and Fitness Prediction",
        "abstract": "Predicting the effects of mutations in proteins is critical to many applications, from understanding genetic disease to designing novel proteins that can address our most pressing challenges in climate, agriculture and healthcare. Despite a surge in machine learning-based protein models to tackle these questions, an assessment of their respective benefits is challenging due to the use of distinct, often contrived, experimental datasets, and the variable performance of models across different protein families. Addressing these challenges requires scale. To that end we introduce ProteinGym, a large-scale and holistic set of benchmarks specifically designed for protein fitness prediction and design. It encompasses both a broad collection of over 250 standardized deep mutational scanning assays, spanning millions of mutated sequences, as well as curated clinical datasets providing high-quality expert annotations about mutation effects. We devise a robust evaluation framework that combines metrics for both fitness prediction and design, factors in known limitations of the underlying experimental methods, and covers both zero-shot and supervised settings. We report the performance of a diverse set of over 70 high-performing models from various subfields (eg., alignment-based, inverse folding) into a unified benchmark suite. We open source the corresponding codebase, datasets, MSAs, structures, model predictions and develop a user-friendly website that facilitates data access and analysis.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/0d6c4d483b36100b2dfa5a68411945d0d28eea39",
        "citation_count": 33
    },
    {
        "title": "Prediction of Cardiac Disease using Supervised Machine Learning Algorithms",
        "abstract": "The healthcare industry is dealing with billions of patients all over the world and producing massive data. The machine learning-based models are dissecting the multidimensional medical datasets and generating better insights. In this study, a cardiovascular dataset is classified by using several state-of-the-art Supervised Machine Learning algorithms that are precisely used for disease prediction. The results indicate that the Decision Tree classification model predicted the cardiovascular diseases better than Naive Bayes, Logistic Regression, Random Forest, SVM and KNN based approaches. The Decision Tree bequeathed the best result with the accuracy of 73%. This approach could be helpful for doctors to predict the occurrence of heart diseases in advance and provide appropriate treatment.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/0dcb2aadb79f16d57c0ffbff7d9b6824e9aeb6a3",
        "citation_count": 59
    },
    {
        "title": "Prediction of post-covid-19 using supervised machine learning techniques",
        "abstract": "The COVID-19 pandemic has had a profound impact on global health, necessitating the development of predictive models to manage and mitigate its effects. Early diagnosis is crucial for preventing the progression of diseases that can significantly endanger human life. This study explores the application of supervised machine learning techniques to predict Post-COVID-19 outcomes, including long-term health complications and recovery trajectories. In this study, we utilized 10 advanced supervised machine learning algorithms, including both stand-alone models (Decision Tree, Random Forest, Logistic Regression, K-Nearest Neighbors, Support Vector Machine, and Gaussian Naive Bayes) and ensemble learning techniques (Bagging Decision Tree Ensemble, Boosting Decision Tree Ensemble, Voting Ensemble, and Stacked Generalization \u2013 Stacking Ensemble). These models were applied to analyze and predict the presence of COVID-19 using the COVID-19 Symptoms and Presence dataset from Kaggle. The performance of each model was evaluated using an 80:20 train-test split as well as 5, 10, 15, 20, and 25-fold cross-validation. Evaluation metrics included accuracy, precision, recall, F1-score, and the confusion matrix. The results indicate that the Decision Tree algorithm outperformed the other models, achieving an accuracy of 98.81%, a precision of 1.00, a recall of 0.98, and an F1-score of 0.99. Our results indicate that machine learning models can effectively predict Post-COVID-19 conditions, providing valuable insights for healthcare providers and policymakers.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0e2f83164a8b0c1755a04de85e7d174f442e4f2f",
        "citation_count": 0
    },
    {
        "title": "Some Computational Considerations for Kernel-Based Support Vector Machine",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/0e3c4ba4167da08a5c7049a6c538fbc7627c1bb1",
        "citation_count": 3
    },
    {
        "title": "The application of blood flow sound contrastive learning to predict arteriovenous graft stenosis of patients with hemodialysis",
        "abstract": "End-stage kidney disease (ESKD) presents a significant public health challenge, with hemodialysis (HD) remaining one of the most prevalent kidney replacement therapies. Ensuring the longevity and functionality of arteriovenous accesses is challenging for HD patients. Blood flow sound, which contains valuable information, has often been neglected in the past. However, machine learning offers a new approach, leveraging data non-invasively and learning autonomously to match the experience of healthcare professionas. This study aimed to devise a model for detecting arteriovenous grafts (AVGs) stenosis. A smartphone stethoscope was used to record the sound of AVG blood flow at the arterial and venous sides, with each recording lasting one minute. The sound recordings were transformed into mel spectrograms, and a 14-layer convolutional neural network (CNN) was employed to detect stenosis. The CNN comprised six convolution blocks with 3x3 kernel mapping, batch normalization, and rectified linear unit activation function. We applied contrastive learning to train the pre-training audio neural networks model with unlabeled data through self-supervised learning, followed by fine-tuning. In total, 27,406 dialysis session blood flow sounds were documented, including 180 stenosis blood flow sounds. Our proposed framework demonstrated a significant improvement (p<0.05) over training from scratch and a popular pre-trained audio neural networks (PANNs) model, achieving an accuracy of 0.9279, precision of 0.8462, and recall of 0.8077, compared to previous values of 0.8649, 0.7391, and 0.6538. This study illustrates how contrastive learning with unlabeled blood flow sound data can enhance convolutional neural networks for detecting AVG stenosis in HD patients.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0e81e15dac9f8475e04271103ba35fed1fbf259e",
        "citation_count": 0
    },
    {
        "title": "Extraction of Temporal Events from Clinical Text Using Semi-supervised Conditional Random Fields",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/0e82f7aa4fdaf126765f9a398565954f475e030b",
        "citation_count": 4
    },
    {
        "title": "Unveiling The Shadows: A Guide For Diagnosing Leukemia And Better Outcome",
        "abstract": "Diagnosis of leukemia is performed through blood tests and a bone marrow diagnostic assay, with blood cell counts playing a critical role in the healthcare industry. Traditionally, hospital laboratories manually count blood cells using a hemocytometer. This approach is tedious, prone to errors, and time- consuming. The research introduces a fully automated method for identifying various types of leukemia and detecting nursing platelets in blood samples. This proposed technique employs a multi-class classifier to overcome the limitations and missed opportunities often encountered with traditional cell classification methods. This technique employs geographical metrics to identify various color feature statistics within the context of supervised machine learning. The model, trained and validated using several machine learning approaches, achieves an accuracy of 92%.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0ed9ceb3875a45e8aa4fcddcfb7580ad71e15a21",
        "citation_count": 0
    },
    {
        "title": "Health Care Provider Fraudulent Detection Using Machine Learning",
        "abstract": "Healthcare fraud is a serious problem that affects the financial health and trust in healthcare systems around the world. This research paper focuses on using machine learning to detect fraudulent activities by healthcare providers. We analyze large amounts of data from Medicare claims to find unusual patterns that may indicate fraud. By using different machine learning methods, such as decision trees and random forests, we create a model that can accurately separate legitimate claims from fraudulent ones. To tackle the challenge of imbalanced data, we apply techniques like oversampling, which helps improve our model's performance. Our results show that this machine learning approach significantly enhances the accuracy and reliability of fraud detection compared to traditional methods. Additionally, our findings provide valuable insights for healthcare administrators and policymakers, helping them take action against fraud more effectively. By incorporating these advanced techniques into existing systems, we aim to support efforts to protect healthcare resources and improve patient care. This research not only adds to the understanding of fraud detection in healthcare but also offers practical solutions to fight against it effectively. Keywords: Provider Review, Insurance Claim Detection, Supervised Machine Learning, Support Vector Machine, Random Forest.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0ee237b8823b00def65dcc8ce4374d81721675e3",
        "citation_count": 0
    },
    {
        "title": "Development of Supervised Algorithm for Predicting Chronic Kidney Disease",
        "abstract": "Chronic Kidney Disease (CKD), also referred to as Chronic Nephritic Sickness, is a serious condition caused by impairment of renal function. Higher levels of fluids and waste accumulate in the body during the later phase of Chronic Kidney Disease and could be life-threatening in many ways. However, the cause and symptoms of this disease could be prevented at the earliest possible time when the necessary medical treatments and measures are undertaken. Hence, certain techniques of machine learning have been introduced to detect Chronic Kidney Failure in its early stages. This research study discusses the important Machine Learning methods sufficient for the detection and diagnosis of CKD to avoid fatal issues. An ensemble method, boosting, has been used that mainly focuses on the concept of the AdaBoost technique. The other two models include K-Nearest Neighbour (KNN) and Random Forest techniques. Notably, Random Forest exhibited the highest accuracy, while KNN and Adaboost demonstrated commendable scores. As a result, healthcare practitioners and policymakers can leverage the insights gained from this research to implement targeted screening programs, design personalized treatment plans, and allocate resources more efficiently to manage and mitigate the impact of CKD on individuals and public health. Ultimately, this paper serves as a valuable tool in advancing the early prediction of CKD and laying the groundwork for proactive healthcare strategies to alleviate the burden of this chronic condition.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/0f4887b3b1935ef3859032f21f206cf042155eda",
        "citation_count": 0
    },
    {
        "title": "Disease prediction over big data from healthcare institutions",
        "abstract": "In today\u2019s technology powered world, human health keeping has become weak, and due to long screen times, and minimal exercise, humans now are much more prone to diseases in daily life. Hypertension, obesity, stroke etc. have become common phenomenon for a large part of population. In between all this, it is very important to be able to identify / at least predict possible diseases as soon as possible so that human lives are saved. Also, in recent years, healthcare industry has moved on from purely traditional disease diagnosis methods to also using new technology like Internet Of Things (IoT), Machine learning (ML), and Artificial Intelligence(AI) etc. for effective disease diagnosis. ML is a recently developed technology which is trained using proven data (previous patient data) which, here, will be provided by hospitals, etc. And using that, we will attempt to create an ML model which would predict the possible diseases one may have based on his symptoms. ML will help the system to predict automatically without any human intervention as needed by traditional diagnosis systems. ML can be supervised / unsupervised. But we will be only trying to find a solution using supervised learning.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/1013f150382ca5fb0ccb90e9265d01164c58c77c",
        "citation_count": 2
    },
    {
        "title": "Classification of hospital admissions into emergency and elective care: a machine learning approach",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/10e73d28f176bf92e3f48fa9b9be4690bd59eb81",
        "citation_count": 34
    },
    {
        "title": "Predicting Early-Stage Heart Disease using Machine Learning: A Survey",
        "abstract": "The prediction and detection of heart diseases has always been a critical and challenging task for healthcare professionals. Hospitals and other clinics offer expensive therapies and surgeries to treat heart disease. So, predicting heart diseases in early stages will be helpful for people all over the world to take necessary measures before it gets worse. Heart disease is a significant problem in recent times; the main reason for this disease is the intake of alcohol, tobacco and lack of physical exercise. Over the years, machine learning has shown effective results in making decisions and making predictions from a wide range of data produced by the healthcare industry. Some of the supervised machine learning techniques used in this heart disease prediction are Artificial Neural Network (ANN), Decision Tree (DT), Random Forest (RF), Support Vector Machine (SVM), Naive Bayes) (NB) and k-Nearest Neighbor Algorithm. Next, the performances of these algorithms are summarized.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/113c8bdf7a4be364a072dfd464ad91b2a5dc5d3b",
        "citation_count": 0
    },
    {
        "title": "Applications of Machine Learning in Cardiac Electrophysiology",
        "abstract": "Artificial intelligence through machine learning (ML) methods is becoming prevalent throughout the world, with increasing adoption in healthcare. Improvements in technology have allowed early applications of machine learning to assist physician efficiency and diagnostic accuracy. In electrophysiology, ML has applications for use in every stage of patient care. However, its use is still in infancy. This article will introduce the potential of ML, before discussing the concept of big data and its pitfalls. The authors review some common ML methods including supervised and unsupervised learning, then examine applications in cardiac electrophysiology. This will focus on surface electrocardiography, intracardiac mapping and cardiac implantable electronic devices. Finally, the article concludes with an overview of how ML may impact on electrophysiology in the future.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/1250ae7df829d5133b3563db09d897c2e0dccd0d",
        "citation_count": 14
    },
    {
        "title": "Predictive analytics in smart healthcare for child mortality prediction using a machine learning approach",
        "abstract": "Abstract In developing countries, child health and restraining under-five child mortality are one of the fundamental concerns. UNICEF adopted sustainable development goal 3 (SDG3) to reduce the under-five child mortality rate globally to 25 deaths per 1,000 live births. The under-five mortality rate is 69 deaths per 1,000 live child-births in Pakistan as reported by the Demographic and Health Survey (2018). Predictive analytics has the power to transform the healthcare industry, personalizing care for every individual. Pakistan Demographic Health Survey (2017\u20132018), the publicly available dataset, is used in this study and multiple imputation methods are adopted for the treatment of missing values. The information gain, a feature selection method, ranked the information-rich features and examine their impact on child mortality prediction. The synthetic minority over-sampling method (SMOTE) balanced the training dataset, and four supervised machine learning classifiers have been used, namely the decision tree classifier, random forest classifier, naive Bayes classifier, and extreme gradient boosting classifier. For comparative analysis, accuracy, precision, recall, and F1-score have been used. Eventually, a predictive analytics framework is built that predicts whether the child is alive or dead. The number under-five children in a household, preceding birth interval, family members, mother age, age of mother at first birth, antenatal care visits, breastfeeding, child size at birth, and place of delivery were found to be critical risk factors for child mortality. The random forest classifier performed efficiently and predicted under-five child mortality with accuracy (93.8%), precision (0.964), recall (0.971), and F1-score (0.967). The findings could greatly assist child health intervention programs in decision-making.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/128b586ab10cbcbba5f62b5cc4f67aa673a0e282",
        "citation_count": 1
    },
    {
        "title": "RTIDS: A Robust Transformer-based Approach for Intrusion Detection System",
        "abstract": "Intrusion Detection Systems (FIDSs) with foamy disturbance are crucial for preventing security breaches in the constantly growing world of the internet's interconnectivity across many domains. Among the many applications are supply chains, manufacturing, smart homes, smart grids, healthcare, and environmental tracking. Traditional intrusion detection methods, while effective in conventional contexts, require adaptation and enhancement to cater to the unique challenges, including devices with limited resources, memory, and battery capacity, as well as particular protocol stacks. In this study, we develop a lightweight attack detection method that detects and stops attackers from injecting superfluous data into the network using a supervised machine learning-based FIDS. Our simulation results demonstrate that the suggested FIDS- based classifier works well in terms of classification accuracy and detection speed when it is enhanced by a combination of two or three complex features.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/128bcddd811cd7173d9a2b42977afa759aef15a0",
        "citation_count": 1
    },
    {
        "title": "Comparative Analysis of Different Approaches to Human Activity Recognition Based on Accelerometer Signals",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/12bcf2e79fbc52235611bde579fb6991f55a9efe",
        "citation_count": 3
    },
    {
        "title": "Ophthalmology and Artificial Intelligence: Present or Future? A Diabetic Retinopathy Screening Perspective of the Pursuit for Fairness",
        "abstract": "Computers that simulate human thought were first described in 1950, with the first artificial intelligence (AI) publication in 1943 describing a computer model that generated an autonomous binary output inspired by a human neuron (1). Since then, advances in machine learning and deep learning have expanded AI and created new paradigms in computer science. In healthcare, automatic processes facilitate diagnosis prediction, medical care, smart medical devices implementation, workflow improvement, electronic medical records interpretation, and screening programs (2, 3). Convolutional neural networks are examples of deep learning analytics applied to image processing; they simulate interconnected neurons and provide output after multiple interconnected information layers (2). Machine learning algorithms could be unsupervised, supervised, or reinforced; in every learning method, the construction of datasets is a critical step (3). More than twenty thousand articles have been published regarding AI in the last five years, with more than 1000 pertaining to ophthalmology. Regarding the retina subspecialty, AI has been applied in disease screening for diabetic retinopathy (DR), age-related macular degeneration (AMD), and retinopathy of prematurity (4). AI has already been applied in the IDx-DR system, the first FDA-approved device, with good results in Caucasian, North African, and Sub-Saharan populations (5). In the European Union, EyeArt has been used to exclude low-quality images, estimate DR progression, and recommend referral (5). Other algorithms, including Google\u2019s, Singapore\u2019s SERI-NUS, the Bosch DR Algorithm, and Retinalyze, have been developed (5). Algorithms have also been developed to support decision-making, e.g., in the anti-angiogenic treatment of AMD (6). Despite technological advances, many challenges hamper real-world implementation of AI, such as variability in algorithm performance, patient acceptance in automated processes, and ethical conflicts. Therefore, this article\u2019s objective was to compare characteristics of open-access retinal fundus photos datasets, implementations of AI in ophthalmology, and challenges to AI application in ophthalmology.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/12d85991a7a829b69260b2a537bdb85535821919",
        "citation_count": 4
    },
    {
        "title": "Classi\ufb01cation of healthcare data using genetic fuzzy logic system and wavelets",
        "abstract": "Healthcare plays an important role in promoting the general health and well-being of people around the world. The dif\ufb01culty in healthcare data classi\ufb01cation arises from the uncertainty and the high-dimensional nature of the medical data collected. This paper proposes an integration of fuzzy standard additive model (SAM) with genetic algorithm (GA), called GSAM, to deal with uncertainty and computational challenges. GSAM learning process comprises three continual steps: rule initialization by unsupervised learning using the adaptive vector quantization clustering, evolutionary rule optimization by GA and parameter tuning by the gradient descent supervised learning. Wavelet transformation is employed to extract discriminative features for high-dimensional datasets. GSAM becomes highly capable when deployed with small number of wavelet features as its computational burden is remarkably reduced. The proposed method is evaluated using two frequently-used medical datasets: the Wisconsin breast cancer and Cleveland heart disease from the UCI Repository for machine learning. Experiments are organized with a \ufb01ve-fold cross validation and performance of classi\ufb01cation techniques are measured by a number of important metrics: accuracy, F-measure, mutual information and area under the receiver operating characteristic curve. Results demonstrate the superiority of the GSAM compared to other machine learning methods including probabilistic neural network, support vector machine, fuzzy ART-MAP, and adaptive neuro-fuzzy inference system. The proposed approach is thus helpful as a decision support system for medical practitioners in the healthcare practice. (cid:2) 2014 Elsevier Ltd. All rights reserved.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/12f31434983ceb9701ab8e3f3a4624b2a1a4048b",
        "citation_count": 12
    },
    {
        "title": "Heart Disease Prediction Using Machine Learning",
        "abstract": "This paper revolves around a classification use case of machine learning in which the intention is to predict\nthe possibility of a heart disease in an individual given certain parameters. Machine Learning is extensively\nbeing used across the world. The healthcare industry has also commenced leveraging these data driven\ntechniques. Machine Learning can play a vital role in predicting the likelihood of locomotor disorders, Heart\nailments and more such diseases because machine learning is well known for its use cases in classifying,\ncategorizing and predicting. Such information, if predicted well, can provide key foresight to doctors who can\nhence mould their diagnosis and course of treatment per patient basis. The main advantage of using machine\nlearning in healthcare is its ability to parse and process huge datasets which are beyond the scope of human\nabilities, and then accurately convert the derived analysis of that data into clinical insights that can aid\nmedical practitioners round the globe in planning stratergies for providing care to patients, ultimately leading\nto more promising results, reduced costs of care and last but not the least , increased patient satiation and\nresponse/recovery. To simplify and solve this problem, solutions were provided using multiple supervised\nlearning algorithms like logistic regression, Na\u00efve Bayes, random forests, decision trees, support vector\nmachines and K-nearest neighbours. The best accuracy was seen using random forests.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/1347bcddd14aab1195df79ddc6cff9facaa72bc4",
        "citation_count": 10
    },
    {
        "title": "Data Mining in Healthcare using Machine Learning Techniques",
        "abstract": "Classification techniques have become increasingly important in healthcare due to the need for accurate and efficient disease diagnosis, treatment planning, and patient care. Supervised learning algorithms, such as decision trees, logistic regression, and support vector machines, are used for disease diagnosis, predicting patient outcomes, and identifying potential risk factors. Classification techniques are also used in image recognition and analysis, such as in radiology and pathology. Classification is a supervised learning technique used to predict the class or category of an instance based on the given set of attributes. This research study explores the use of classification techniques in data mining for healthcare applications. The goal of this study is to apply classification algorithms such as Naive Bayes, Logistic Regression and Random Forest to healthcare datasets and evaluate their performance. The datasets used in this study include patient information such as demographics, medical history, and diagnosis. The findings suggest that the classification techniques can be effective in data mining for healthcare applications, enabling healthcare professionals to make more informed decisions based on patient data.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/13a0c027b1911c8240393ace8fa89b7f6b0e2f16",
        "citation_count": 3
    },
    {
        "title": "Activity Recognition Using Transfer Learning",
        "abstract": "The technology for human activity recognition has become an active research topic in recent years as it has many potential applications, such as surveillance systems, healthcare systems, and human-computer interaction. In the research of activity recognition, supervised machine learning approaches have been widely used for activity recognition. However, the cost of collecting labeled sensor data in new environments is high. Furthermore, these methods do not work well in a cross-domain environment using conventional machine learning approaches. In this study, we proposed a transfer learning framework based on principal component analysis (PCA) transformation, Gale\u2013 Shapley similarity measurement, and Jensen\u2013Shannon divergence (JSD) feature mapping. Transfer learning aims to apply new information learned from the source domain to the target domain. The experimental results showed that the proposed approach performs better than the approach merely learned in the source environment. this study, we proposed a transfer learning framework to overcome these problems. The proposed framework consists of three steps: (1) extract seminal information from the source and target environments with principal component analysis (PCA) transformation, (2) measure the feature similarity with the Jensen\u2013Shannon divergence (JSD) algorithm, and (3) map features to a common space based on the Gale\u2013Shapley algorithm. The proposed transfer framework can be used to increase the recognition performance when the model is applied to a new environment where the training sample is insufficient. In addition, it can also reduce the effort of obtaining labeling data.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/13c751d4c1f59f9e26cdba1f449d32c521fb43f3",
        "citation_count": 21
    },
    {
        "title": "Effectiveness of ANN, LSTM, and Various Supervised Machine Learning Algorithms on Human Activity Recognition",
        "abstract": "Plenty of healthcare applications (fitness tracking, sleep pattern monitoring, amount of calories burned, etc.), remote monitoring applications (patient, child or older people), security, and soft biometrics applications require automatic and precise activity recognition. So, this paper demonstrates the best approach among various approaches used for activity classification using the tri-axial gyroscope and accelerometer sensors, which are already integrated into smartphones. Some unique and distinguishable features are extracted using the acquired signals from these sensors. For activity recognition purpose, we have evaluated the performance of the Artificial Neural Network (ANN), Long short term memory (LSTM), and various supervised machine learning algorithms on a human activity recognition data set, UCI HAR dataset (obtained from the inertial sensors of a smartphone). Comparative results obtained on UCI HAR dataset shows that the maximum accuracy achieved so far is 98.57%. Therefore, we have analyzed the effectiveness of various methods using our feature extraction process and observed that 99.9% of accuracy can be achieved with the Ensemble classification method with bagging tree.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/13e18682cf137716a9205fa0b8338c4b01992324",
        "citation_count": 0
    },
    {
        "title": "A Machine Learning Approach for Heart Attack Prediction",
        "abstract": "A heart attack also known as cardiac arrest, diversify various conditions impacting the heart and became one of the chief-reason for death worldwide over the last few decades. Approximately, 31% of total deaths globally are due to CVDs. It constitutes the pinnacle of chronic processes which involve complex interactions between risk factors which can and cannot be improved. Most of the instances or cases of cardiovascular diseases can be allocated to revisable risk factors where most of the instances are considered preventable. ML became the enhancing approach for the evolution of predictive models in health care industries and was decided to test various algorithms to check what extent their prediction scores estimate or ameliorate upon the results acquired. Researchers deploy various machine learning and data mining techniques over a set of enormous data of cardiovascular patients to attain the prediction for heart attacks before their occurrence for helping healthcare industries and professionals. This research comprises various Supervised ML classifiers like, Gradient Boosting, Decision Tree, Random Forest and Logistic Regression that have been used to deploy a model for Myocardial Infarction prediction. It uses the existing datasets from the Framingham database and others from the database of the UCI Heart repository. This research intends to ideate the prediction for probabilities of occurrence of a heart attack in the patients. These classifiers have been deployed in pipeline approach of machine learning to attain the prediction using both ways i.e., without optimizations and feature transformations as well as vice-versa. The results impersonate that the Gradient Boosting classifier is achieving the highest accuracy score in such a way that prediction used by our model is of binary form in where 1 means a chance of heart attack and 0 means no chance. Some of the most influential attributes are chest pain type among which the typical angina is the most influential and asymptotic chest pain is least, cholesterol level in which the level greater than 200mg/dl are more prone, increased heart rate, thal, and age. It is concluded that premature heart attack is preventable in 80% of the total cases just by using a healthy diet along with regular exercises and not using tobacco products also the person who drinks more than 5 glasses of water daily are less likely to develop attacks. The medical checkup of Blood-pressure level, cholesterol level and heart rate on daily basis along with meditation can help you prevent the major heart attacks.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/1453c5fb03f24c9d92a4e624bb8d71ac2b64d9bd",
        "citation_count": 15
    },
    {
        "title": "Heart Disease Prediction Using Different Machine Learning Algorithms",
        "abstract": "Heart disease (HD) cases are increasing rapidly every day, so it is very crucial to detect them beforehand. In recent times, machine learning algorithms (MLA) are trending for heart or cardiovascular disease prediction in the healthcare field. Data mining techniques such as reinforcement, unsupervised, and supervised play a crucial role in examining the enormous amount of data in the medical field industry. The available dataset of HD individuals from the Cleveland database of the UCI repository is employed to test and verify the performance of MLA. This article makes an early prediction of HD by executing different MLA, for example, decision tree (DT), random forest (RF), and logistic regression (LR). After the comparative study of three algorithms, we found that the DT is the most efficient algorithm with the highest accuracy of 94.7 percent. This value is higher than the recently reported value of 83.87 percent.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/147fa06e9fdedf30ef7893f21865f50841d0bc39",
        "citation_count": 9
    },
    {
        "title": "Model Assessment of Supervised Machine Learning Techniques for Predicting Heart Disease",
        "abstract": "Abstract: Stroke is a leading cause of death and permanent disability, making it a serious global health concern. Cell death is the\nresult of impaired blood flow to the brain. Patient outcomes are ultimately impacted by prompt and precise stroke type\nidentification, which is essential for efficient management and treatment. The potential of machine learning algorithms to\ncategorize stroke subtypes and forecast the probability of stroke occurrence is examined in this project. A thorough dataset that\nincluded clinical features, medical imaging results, and patient demographics was put together. To guarantee compatibility with\nmachine learning algorithms, this dataset was preprocessed, fixing missing values and transforming categorical variables into a\nnumerical format. To find the most pertinent variables for prediction, feature selection was done. Four machine learning\nalgorithms were used: Random Forest (an ensemble learning technique), k-NN (a nearest-neighbor method), J48 (a decision\ntree algorithm), and Naive Bayes. A 10-fold cross-validation technique was used to thoroughly assess the model's performance,\nguaranteeing solid and trustworthy outcomes. The Random Forest algorithm proved to be effective in predicting stroke, as\nevidenced by its highest accuracy. The potential of machine learning to help medical professionals prevent, diagnose, and treat\nstrokes is highlighted by this finding. The knowledge gathered from this research could improve patient care and guide the\ncreation of individualized treatment programs. This project highlights the wider application of machine learning in healthcare\nbeyond stroke. Machine learning has the potential to revolutionize healthcare delivery by utilizing data analysis and predictive\nmodeling, which could result in better patient outcomes, more individualized treatments, and better diagnostics.\n",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/147ff149e3397fa8b172f66f7c24bc221d4ca21c",
        "citation_count": 0
    },
    {
        "title": "Multi-Disease Classification Model Using Strassen\u2019s Half of Threshold (SHoT) Training Algorithm in Healthcare Sector",
        "abstract": "In healthcare industry, Neural Network has attained a milestone in solving many real-life classification problems varies from very simple to complex and from linear to non-linear. To improve the training process by reducing the training time, Adaptive Skipping Training algorithm named as Half of Threshold (HOT) has been proposed. To perform the fast classification and also to improve the computational efficiency such as accuracy, error rate, etc., the highlighted characteristics of proposed HOT algorithm has been integrated with Strassen\u2019s matrix multiplication algorithm and derived a novel, hybrid and computationally efficient algorithm for training and validating the neural network named as Strassen\u2019s Half of Threshold (SHoT) Training Algorithm. The experimental outcome based on the simulation demonstrated that the proposed SHOT algorithm outperforms both BPN and HOT algorithm in terms of training time which is reduced with the range of 7% to 54% and its efficiency which is improved with the range of 3% to 15% on various dataset such as Hepatitis, SPeCT, Heart, Liver Disorders, Breast Cancer Wisconsin (Diagnostic), Drug Consumption, Cardiotocography, Splice-junction Gene Sequences and Thyroid Disease dataset that are extracted from Machine Learning Dataset Repository of UCI. It can be integrated with any type of supervised training algorithm.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/14915f25b471a8ba5152c5e7526d3bbaf4139406",
        "citation_count": 34
    },
    {
        "title": "Self-Supervised Transformer for Sparse and Irregularly Sampled Multivariate Clinical Time-Series",
        "abstract": "Multivariate time-series data are frequently observed in critical care settings and are typically characterized by sparsity (missing information) and irregular time intervals. Existing approaches for learning representations in this domain handle these challenges by either aggregation or imputation of values, which in-turn suppresses the fine-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this problem, we propose a Self-supervised Transformer for Time-Series (STraTS) model, which overcomes these pitfalls by treating time-series as a set of observation triplets instead of using the standard dense matrix representation. It employs a novel Continuous Value Embedding technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with multi-head attention layers, which enable it to learn contextual triplet embeddings while avoiding the problems of recurrence and vanishing gradients that occur in recurrent architectures. In addition, to tackle the problem of limited availability of labeled data (which is typically observed in many healthcare applications), STraTS utilizes self-supervision by leveraging unlabeled data to learn better representations by using time-series forecasting as an auxiliary proxy task. Experiments on real-world multivariate clinical time-series benchmark datasets demonstrate that STraTS has better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS, which can identify important measurements in the time-series data. Our data preprocessing and model implementation codes are available at https://github.com/sindhura97/STraTS.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/14de4156385c8931dc13b68f43e22c46baa739e8",
        "citation_count": 97
    },
    {
        "title": "Prostate Cancer Identification And Classification From Microscopy Scans Of Prostate Biopsy Samples Using Machine Learning Algorithms",
        "abstract": "\u2014 This research explores how to apply machine learning (ML) to prostate MRI within the field of radiology (MRI). The fundamentals of machine learning (ML) and traditional rule-based algorithms are first covered, followed by a discussion of supervised, unsupervised, or reinforcement learning. In the last part of this article, the distinctive characteristics of deep learning (DL), an emerging kind of machine learning, are dissected in minute detail. Although ML and DL both possess the potential to really be employed for prostate MRI, the manner in which they accomplish this goal are different. Plain MRI is used in every one of the clinical contexts that are listed below. Detection and diagnosis of prostate cancer, as well as repeatability of location readings; differentiation of malignancies from benign hyperplasia associated with prostatitis; local staging or pre-treatment evaluation. The therapeutic applicability of these results seems to be promising; nevertheless, in order to fully appreciate their potential, more validation will be required across a variety of scanner manufacturers, field strengths, and institutions. Our healthcare systems are being transformed by artificial intelligence (AI), which refers to the ability of a computer to conduct out cognitive processes to attain a goal based on the information supplied. Artificial intelligence (AI) refers to a computer's ability to reason its way to a solution based on the data at hand. Artificial intelligence (AI) is defined as the capacity of a computer to perform cognitive activities in pursuit of a goal using just the information it has been supplied. Bioinformatics, medical imaging, but instead healthcare robotics are just a few examples of fields that have benefited from the widespread availability of powerful computers, sophisticated information processing algorithms, and cutting-edge image processing software capable of extremely fast processing speeds. This is the case for two reasons: first, as a consequence of a availability of ever-increasing computing capabilities, computer-based systems that are also trained to perform complicated things have emerged in. The development of AIs specifically designed to carry out such activities has made it possible for computer systems to assume such responsibilities. Computer-based systems that can be configured to do the aforementioned tasks have progressed to the point where they can actually perform those tasks. Having access to \"big data\" has made it possible for \"cognitive\" computers to sift through vast amounts of unstructured information, pull out the pertinent details, and confidently identify previously hidden patterns. Machine learning (ML)-based computerized decision-support systems may transform healthcare by performing challenging tasks now performed by specialists. The medical field would be forever altered if this were to happen. These responsibilities include, but are not limited to, reducing human resource costs, increasing throughput efficiency, optimizing clinical workflow, extending treatment alternatives, and strengthening diagnostic precision. These features may be particularly helpful in the diagnosis and treatment of prostate cancer, where they are increasingly being used in areas such as digital pathology, genomics, surgical procedures, competency assessment, and training and evaluation of surgical abilities. Urologists, oncologists, radiologists, and pathologists use imaging and pathology frequently and should be familiar with this emerging field. They should also be aware that the development of highly accurate AI-based decision-support applications of ML will necessitate the cooperation of data scientists, computer researchers, and engineers. The medical industry must advance in order to remain competitive. Specialties such as urology, oncology, radiology, and pathology make extensive use of imaging and pathology.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/14df65f861127822a4084b739c203a583ecb4405",
        "citation_count": 0
    },
    {
        "title": "Supervised machine learning to allocate emergency department resources in disaster situations",
        "abstract": "Despite implementing the Hospital Emergency Plan (HEP) in Morocco that manages the massive influx of victims in disaster situations, it is still difficult for healthcare decision-makers to deal effectively with these situations, which has negative impacts on the performance of the emergency department. Thus, managers need decision systems that help save lives and reduce disabilities. This paper aims to improve the HEP by developing a model based on supervised machine learning as a support tool, to allocate the needed human and materials resources according to injuries number. We propose applying a feedforward neural network (FFNN) and backpropagation. We evaluate the proposed model performance indicators. Our framework was conducted on previous experiences between 2009 and 2019 of 4 public hospitals in Casablanca city. The application of the developed model on our data sample showed that the FFNN provided satisfactory precision for the direct implementation and gave feasible solutions according to the available resources. Allocating resources can be performed using FFNN and capitalizing from lessons learned through previous experiences. In addition, this solution can be used as an international reference to provide a new solution that is more performant taking account of the available resources.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/14eea345e4b696cf8f18f3b432c467035f1de3f5",
        "citation_count": 0
    },
    {
        "title": "Predicting health insurance claim frauds using supervised machine learning technique",
        "abstract": "The healthcare sector is growing quickly, making it a complex system. At the same time, fraud in this sector is becoming a serious issue. Misuse of the medical insurance systems is one of the problems. The automated detection of healthcare scams uses data mining and machine learning approaches. In this work, an effort is made to provide a review of healthcare industry frauds and the methods for spotting them. A proposed solution to address issues in health insurance claims involves using a machine learning model that focuses on utilizing appropriate methods, identifying key data sources, and examining the properties of healthcare data. To gain insight into the patterns of the features, univariate and bivariate analysis are conducted on the data. Afterwards, proper data visualization is performed to determine which feature has the greatest impact. Based on the pre-processed data, a machine learning model is constructed and compared with four algorithms: Logistic Regression, Random Forest, Decision Tree Classifier, and Naive Bayes. The highest accuracy was achieved through the Decision Tree Classifier algorithm, with an accuracy of 97.03%.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/151ceb5137d294490808acd90ed71f1157b1b33e",
        "citation_count": 2
    },
    {
        "title": "Fault Detection Effectiveness of Metamorphic Relations Developed for Testing Supervised Classifiers",
        "abstract": "In machine learning, supervised classifiers are used to obtain predictions for unlabeled data by inferring prediction functions using labeled data. Supervised classifiers are widely applied in domains such as computational biology, computational physics and healthcare to make critical decisions. However, it is often hard to test supervised classifiers since the expected answers are unknown. This is commonly known as the oracle problem and metamorphic testing (MT) has been used to test such programs. In MT, metamorphic relations (MRs) are developed from intrinsic characteristics of the software under test (SUT). These MRs are used to generate test data and to verify the correctness of the test results without the presence of a test oracle. Effectiveness of MT heavily depends on the MRs used for testing. In this paper we have conducted an extensive empirical study to evaluate the fault detection effectiveness of MRs that have been used in multiple previous studies to test supervised classifiers. Our study uses a total of 709 reachable mutants generated by multiple mutation engines and uses data sets with varying characteristics to test the SUT. Our results reveal that only 14.8% of these mutants are detected using the MRs and that the fault detection effectiveness of these MRs do not scale with the increased number of mutants when compared to what was reported in previous studies.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/1532ec250f78e49450484d644373ecd7c84d1df1",
        "citation_count": 19
    },
    {
        "title": "Integrating Machine Learning in Business Decision Making: Application and Future directions",
        "abstract": "The copious amount of data generated as a result of Industry 4.0 revolution across every domain including Internet of things (IoT) data, cybersecurity data, business data, social data, and medical data has opened new avenues and business opportunities for organizations. The information imbibed in the data should be intelligently analysed to reap tangible benefits that can improve the efficiency of organizations. The knowledge of Artificial Intelligence (AI), and particularly Machine Learning (ML) algorithms is the requisite to decipher meanings and patterns in the data to gain useful insights. Multiple ML algorithms namely supervised, unsupervised, semi-supervised, and reinforcement learning exists in this field. In this study, an attempt has been made to provide a comprehensive understanding of various ML algorithms that can be applied to enhance the intelligence of the business operations thereby leading to effective solutions for various business problems. The potential contribution of this study is to understand different ML techniques and its applications in various real world business problems such as e-commerce, manufacturing, healthcare, etc. The major challenges and future research directions are presented in the study to further the research in the domain of ML. This study can be used as a reference to gain information about various prominent ML algorithms that have maximum utility in the business domain. Further, this study can assist researchers and practitioners in extending the knowledge to other business problems and aid in problem solving.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/1551295e7bc78fa9148a8fbdd37f2dd4b0675ca1",
        "citation_count": 2
    },
    {
        "title": "A Convolutional Neural Network (CNN) Based Framework for Enhanced Diagnosis and Classification of COVID-19 Pneumonia",
        "abstract": "COVID-19 pneumonia is a persistent worldwide health problem that usually affects the most vulnerable groups in society: the newborn and aged populations. Most of the current endeavors toward handling diagnosis and classification of pneumonia have used numerous techniques for machine learning and deep learning, with a particular focus on COVID-19 pneumonia. However, most of these techniques have raised concerns with regard to diagnostic precision as a result of the limited application of advanced algorithms, datasets whose validation is mostly inadequate and predictive capability. To address these limitations, our research introduces a deep learning-based approach by Convolutional Neural Networks (CNNs), which enhances the performance in classifying COVID-19 pneumonia. Salient features of the proposed method include a four-step process: first, data acquisition from a comprehensive chest X-ray dataset on GitHub; second, processing and analyzing the data through visual means like histograms and scatter plots; third, using CNNs supplemented with techniques for data augmentation in supervised learning; lastly, performance evaluation to benchmark against existing models. The present study uses features from X-ray images with the help of CNN's advanced pattern recognition capabilities in pursuit of achieving better generalization and precision in classification. The model achieved an accuracy of 85.70\\% and precision of 88.6%, which surpasses the existing techniques and thereby built the promise of improving the accuracy of the diagnostic process, hence, leading to improved care for the patients, and more so forms the foundation on which future AI-powered healthcare diagnostics are expected to take off.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/157849c7b6db3fa864eb7fb6a799a0a4efbff221",
        "citation_count": 0
    },
    {
        "title": "Continuous Stress Monitoring for Healthcare Workers: Evaluating Generalizability Across Real-World Datasets",
        "abstract": "Healthcare workers are constantly exposed to high-stress working conditions that increase burnout rates and lower the quality of patient care. While it is vital to continuously monitor healthcare worker stress to provide necessary interventions, traditional survey methods can interfere with tasks in real-world healthcare contexts. Wearable devices offer a non-invasive way to detect worker stress continuously, however, predictions may be influenced by context-specific activities and stress semantics. Our work assesses generalized stress detection for health workers with currently available datasets using shared stress representations. We tested four machine learning algorithms (support vector machines, random forest, feed-forward networks, and extreme boosting). We identified extreme boosting as the top-performing model, achieving ROC-AUC scores of up to 0.83 using real-world health worker data. To benchmark generalizability among machine learning stress detection models, we assessed domain adaptation to enhance the transferability of models. Supervised domain adaptation performs comparably to vanilla prediction methods on the target domain. Our work identifies numerous challenges to generalizing stress detection for health workers, including limited shared modalities, small sample sizes, and varying stress definitions. As more data is collected, we must prioritize shared stress representations to enable continuous stress prediction for health workers.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/166b059be2a77cfe0e58bb4b1be265a11a264927",
        "citation_count": 3
    },
    {
        "title": "P10.19.A MACHINE LEARNING-BASED PREDICTION OF INPATIENT CARE COSTS FOR PATIENTS WITH BRAIN METASTASES: A REAL-WORLD ANALYSIS",
        "abstract": "\n \n \n Brain metastases (BMs) represent a significant cause of cancer-related morbidity and mortality. While BM-related healthcare costs have been previously described, predictive analytics based on recent data, particularly for inpatient care, remain unavailable. This study sought to evaluate inpatient care costs (IPCCs) of patients with BMs and perform predictive modelling through supervised machine learning (sML) using a contemporary, commercial claims database.\n \n \n \n This retrospective study, reported following STROBE and TRIPOD+AI reporting guidelines, included adult patients (aged 18-65 years) in the United States (US) with BMs included in the MarketScan Commercial Claims and Encounters Database who received inpatient care during January 2016 to December 2021. Eligible patients were identified using ICD-10 codes. IPCC measures were adjusted using the Medical Care component of the 2023 Consumer Price Index. Primary study outcome was total IPCC, represented by adjusted gross total payments. After log-transformation performed due to data skew, sML was carried out using Random Forest algorithm with 1000 iterations with a 70:30 training-test data split, followed by residual analysis and evaluation of predictive performance using root-mean-squared error (RMSE), out-of-bag error (OOBE), and calibration curve. Multivariable linear regression (MLR) modelling was carried out for sensitivity analyses.\n \n \n \n A total of 25117 unique admissions across 13477 BM patients were included, with median (IQR) age of 57 years (51-61). Gross median (IQR) CPI-medical-care-adjusted values per admission were: total payments $28,119.51 (16847.45-55111.67); hospital payments $24,678.74 (14601.66-47864.84); and payments to principal physician $884.80 (441.07-2434.15), being 3.6% (IQR 1.9-6.8) of total payment. Median inpatient length of stay was 4 days (IQR 2-8). The ML model had an OOBE of 0.61 and, using test data, an RMSE of 0.85, indicating robust performance.\n \n \n \n Contemporary IPCCs for BM patients in the US are substantial but driven minimally by payments to principal physician for services rendered. sML may be utilized to successfully predict IPCC for patients with BMs.\n",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/16eaec652d0f38edae26621165bc5cd21e4b4cd3",
        "citation_count": 0
    },
    {
        "title": "Prediction Techniques for Diagnosis of Diabetic Disease: A Comparative Study",
        "abstract": "Summary The objective of supervised learning is to construct a distribution model by considering class values for the purpose of prediction. Nowadays data mining is playing an important role for prediction of diseases in the healthcare industry. Data mining process is used for feature selection, information extraction as well as to discover the unknown pattern and relations from the unstructured data. These patterns can be used to write a wise prescription for patients. This paper introduces an expert system for the early prediction of a diabetic patient by using data mining classification techniques. This work is based on a dataset which comprises of 130-US Hospitals for the years 1999_2008 consisting of 50 attributes and more than 100,000 instances. The evaluation and comparison is performed by using RapidMiner, a software platform of data science, which supports various machine learning steps including results visualization. Random Forest, Decision Stump, Random Tree and ID3 were applied to mine the useful information from data. The extracted information will assist the practitioner to write the precise and wise prescription for diabetic patients. This research work presents description of chosen classification models and dataset. Next, makes evaluation and performs a comparison of performance of 5 classification techniques on chosen dataset. Then, it provides results by considering evlaution metrics such as accuracy, precision and recall. This work finds that the decision tree is the best technique for prediction of disease in diabetic patients.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/17f514913b3f8e2f7f79e3c3b224a0d900768fd9",
        "citation_count": 9
    },
    {
        "title": "Real-Time Machine Learning for ICU Hypoxia Prediction: A Pilot Study",
        "abstract": "Continuous and precise monitoring in the intensive care unit (ICU) are essential, particularly for patients with respiratory disorders necessitating mechanical ventilation, as they represent a critical cohort. Hypoxia can be defined as a medical condition characterized by an inadequate supply of oxygen to bodily tissues and organs, leading to an inability to meet their metabolic needs. This condition can manifest in diverse scenarios, such as high-altitude environments for example mountain climbing or in high-altitude flights. Common symptoms of hypoxia include breathing difficulties, confusion, elevated heart rate, and impaired cognitive and physical functions. If left unaddressed, hypoxia can lead to tissue damage, organ failure, and, in severe cases, even death. Traditionally, hypoxia detection relies on post facto measures, with methods implying peripheral capillary oxygen saturation (SpO2) providing valuable but delayed insights. Models providing real-time levels of hypoxia, or even early detection and intervention, would thus be relevant to prevent such a state. They could in fact provide timely detection to trigger automatic ventilation or to alert healthcare personnel promptly via adaptive automation. The goal of this study was to produce a real-time hypoxia detection model using machine-learning techniques in the context of ICU. Methods. We used the open-source eICU database, consisting of critically ill patients treated in ICU across the United States. It contains vital signs recorded at 5-min intervals and many hypoxia events. We utilized parameters according to a feature selection such as SpO2, heart rate (HR), and respiratory rate (RR) to make hypoxia predictions from few prior lags. We selected three hypoxia levels to achieve a supervised learning classification for hypoxia: No Hypoxia (SpO2 > 93%), Low level of Hypoxia (88% < SpO2 < 93%), and Strong level of Hypoxia (SpO2 < 88%). Furthermore, we exported the trained model to the Open Neural Network Exchange (ONNX) format to facilitate real-time predictions deployment in clinical settings, thus offering a valuable tool for early hypoxia detection and proactive patient care in ICU.Results. Mann-Whitney U tests and paired t-tests raised significant differences across levels of hypoxia for the SpO2, HR and RR measures. We tested several machine-learning models and our results showed that a Random Forest model could provide accurate predictions of impending hypoxia events (5 minutes prior to the event). We performed a random search fine-tuning method and a group 5-fold cross-validation and achieved a predictive accuracy of 0.937, a precision rate of 0.85, and a balanced accuracy of 0.813. The ONNX implementation of the model had an inference of 1 millisecond, which allows real-time hypoxia prediction. Discussion. Hypoxia is frequently encountered in the ICU as a result of a wide range of pathologic characteristics. Therefore, detecting hypoxia events before they occur is of paramount importance to ensure timely countermeasures through adaptive automation and prevent fatal outcomes for patients. The use of an ONNX model further enables real-time predictions, enhancing the clinical utility of our approach. The versatility of this approach extends beyond the medical domain, for example in aviation where hypoxia poses a serious threat. Such models have potential for being integrated in real time for pinpointing instances of pilots hypoxia, thus contributing to their health and to overall flight safety.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/182534d4dc30033b12feaeae1f02a1597f2c8840",
        "citation_count": 0
    },
    {
        "title": "Prediction of DNA Interacting Residues",
        "abstract": "DNA residue interaction is one of the most important interaction in the biological system. It is used for describing the working of various biological processes. In this model we tried to predict the DNA interacting residue by training the model using dataset having around 38000 data elements and testing it using dataset having around 2000 data elements. The prediction is done using various supervised machine learning algorithms namely - the decision tree, support vector machine, logistic regression and linear discriminant analysis and subsequently the different accuracies and F-scores are noted. The accuracy of decision tree is 50.6%, support vector machine is 48.9%, logistic regression is 48.6% and linear discriminant analysis is 48.9%. The best algorithm - decision tree is selected based on the accuracy and F-score and can be used for further requirements in the fields such as hospitals, healthcare centres, testing labs, research labs, genetic study. The prediction is done in a noble and effective way and efforts have been made to make the paper unique, usable and highly successful.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/18ae750fc10f956319bcf1865d1bc8d5517240a1",
        "citation_count": 4
    },
    {
        "title": "MP30-08\u2003ANTIBODY RESPONSES TO BNT162B2 mRNA COVID-19 VACCINE IN HEALTHCARE WORKERS AND PATIENTS WITH UROLOGICAL DISEASES IN JAPAN",
        "abstract": "INTRODUCTION AND OBJECTIVE: Patients with cancer and solid organ transplantation are at risk for immune dysregulation related to underlying malignant disease and immunomodulatory therapy. There is a great concern for protective immune response to SARS-CoV-2vaccination in those patients. We aimed to evaluate rates of anti- spike antibody response to a BNT162b2 vaccine in patients with urological cancers, kidney transplantation, and healthy controls in a single tertiary referral hospital in Japan. METHODS: This retrospective study included 280 adult pa- tients with urological cancers, 93 adult patients with kidney transplantation, and 60 healthcare workers (controls) who received the second dose of the BNT162b2 vaccine at least 7 days before evalua-tion. The study was conducted between June 21, 2021, and November 1, 2021, at Hirosaki University Hospital (Hirosaki, Japan). Blood samples were cross-sectionally obtained from the study participants. Serum samples were analyzed and the titers of the IgG antibodies against the SARS-CoV-2 spike receptor-binding domain were determined using the Elecsys Anti-SARS-CoV-2 S RUO (Roche-diagnostics). Seropositivity was de \ufb01 ned as > 15 Unit/mL (suf \ufb01 cient for the presence of neutralizing antibodies). The primary outcome was the rate of seropositivity ( > 15 Unit/mL). Secondary outcomes included the decay of IgG titers over time and identifying factors that were associated with seropositivity using multivariable logistic regression analyses. RESULTS: The analysis included 195 patients with prostate cancer (PC) (median age 75 years), 57 patients with urothelial cancer (UC) (median age 73 years), 28 patients with renal cell carcinoma (RCC) (median age 72 years), 93 patients with kidney transplantation (KT) (median age 55 years), and 60 controls (median age 36 years). Of 433, we observed seropositive in 341 (79%) participants. The rate of seropositive for SARS-CoV-2 anti-spike IgG antibodies after the second vaccine in the patients with KT, PC, UC, RCC, and Ctrl were 23%, 94%, 88%, 96%, and 100%, respectively. The antibody titers were elevated 1 week after the second dose of the BNT162b2 vaccine. Multivariable analysis showed that age (HR 0.95, P [ 0.002), metastatic disease (HR0.25, P [ 0.021), and immunosuppression (HR 0.003, P < 0.01) were signi \ufb01 cantly associated with seropositivity. A minimum dose of steroids or immune-checkpoint inhibitors was not signi \ufb01 cantly associated with seropositivity. CONCLUSIONS: We observed a remarkably lower rate of seropositive in KT patients, while approximately 90% of patients with cancer exhibited adequate antibody response to the BNT162b2 vaccine. Further research is required for the durability and protective ac- tivity of lower titers for breakthrough infections. of serum immunoglobulins (Igs) with a machine learning approach. METHODS: N -glycosylation signatures were measured in 708 urological cancer patients and 207 non-cancer subjects using automated capillary-electrophoresis-based N -glycomics. The obtained concentrations of the 26 glycans were analyzed using a supervised machine learning model to calculate the diagnostic scores for each urological cancer; hormone-sensitive prostate cancer (HSPC), castration-resistant prostate cancer (CRPC), renal cell carcinoma (RCC), upper tract urothelial carcinoma (UTUC), and bladder cancer (BC). Diagnostic performance was evaluated using the area under receiver operating characteristics curve (AUC). RESULTS: Urological cancer patients included 234 HSPC, 94 CRPC, 100 RCC, 104 UTUC, and 176 BC. Non-cancer subjects included 104 healthy volunteers, 95 benign prostatic hyperplasia, and 8 urinary tract infection. The diagnostic scores of HSPC vs. non-HSPC, CRPC vs. non-CRPC, RCC vs non-RCC, UTUC vs non- UTUC, and BC vs non-BC were 65.9% vs. 0.6%, 51.0% vs. 0.6%, 98.7% vs. 0.3%, 43.8% vs. 1.0%, and 88.0% vs. 0.4%, respectively (P < 0.001). The AUCs for the diagnosis of HSPC, CRPC, RCC, UTUC, and BC were 0.94, 0.95, 0.99, 0.95, and 0.99, respectively. CONCLUSIONS: Our diagnostic model using comprehensive N -glycan signature of serum Igs through a machine learning approach could simultaneously discriminate each urological cancer with excellent accuracy. Further external validation studies are needed.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/18ba2d1c45e4d53b57722ebf58af6f896753ce1d",
        "citation_count": 0
    },
    {
        "title": "Diagnosis of Various Thyroid Ailments using Data Mining Classification Techniques",
        "abstract": "- Classification is one of the most considerable supervised learning data mining technique used to classify predefined data sets the classification is mainly used in healthcare sectors for making decisions, diagnosis system and giving better treatment to the patients. In this work, the data set used is taken from one of recognized lab of Kashmir. The entire research work is to be carried out with ANACONDA3-5.2.0 an open source platform under Windows 10 environment. An experimental study is to be carried out using classification techniques such as k nearest neighbors, Support vector machine, Decision tree and Na\u00efve bayes. The Decision Tree obtained highest accuracy of 98.89% over other classification techniques.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/19022e556fbc18778f2437b19e49d213ec84b10a",
        "citation_count": 17
    },
    {
        "title": "Autism Detection Analysis Through Behavioral and Genetic Analysis using Random Forest and XGBoost Algorithm",
        "abstract": "The Autism Detection and Treatment Management System leverages machine learning algorithms for early autism spectrum disorder (ASD) detection and personalized treatment planning. This PHP MySQL full-stack website integrates user-friendly interfaces for data input and analysis. The system employs supervised learning models trained on extensive behavioral and diagnostic datasets to accurately identify potential ASD indicators in individuals. Features include comprehensive profiling, aiding clinicians in tailored intervention strategies. Real- time monitoring and feedback mechanisms enable ongoing assessment and adjustment of treatment plans. The system facilitates collaborative efforts among healthcare providers, educators, and caregivers, fostering a holistic approach to ASD management. Its secure, scalable architecture ensures data confidentiality and accessibility. Through innovative technology and data-driven insights, this system strives to enhance early detection and optimize personalized care for individuals on the autism spectrum.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/1990d4e9154d7af923d6135246aef52e3d5c67e0",
        "citation_count": 0
    },
    {
        "title": "Supervised Machine Learning for RSSI based Indoor Localization in IoT Applications",
        "abstract": "The Internet of Things (IoT) technology has revolutionized every aspect of everyday life by making everything smarter. IoT became more popular in recent years due to its vast applications in many fields such as smart cities, agriculture, healthcare, ambient assisted living, animal tracking, etc. Localization of a sensor node refers to knowing a sensor node's geographical location in the IoT network. In this research, we propose a device free indoor localization mechanism based on the Received Signal Strength Indicator (RSSI), a measure of the receiving signal from the sensor nodes, and supervised Machine Learning (ML) algorithms. An experimental test-bed was implanted in a controlled environment to collect RSSI values from the sensor nodes. The RSSI levels were collected by using multiple and published to a remote MQTT server over the Internet. In this research, RSSI values were used to train supervised ML algorithms, Linear Regression (LR), Polynomial Regression (PR), Decision Tree Regression (DTR), Support Vector Regression (SVR), and Random Forest Regressor (RFR) to estimate the accurate positioning of IoT related localization applications. The error between the actual measured values of the position and the estimated values are compared to validate the system model presented.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/19bef4ab32bc9ef1d7aa51b3907a35bd9201461d",
        "citation_count": 16
    },
    {
        "title": "SPECIFICATION OF HEALTHCARE EXPERT SYSTEMS USING A MULTI-MECHANISM RULE-EXTRACTION PIPELINE",
        "abstract": "The application of knowledge extraction methodologies in support of medical informatics promises interesting developments that could potentially improve many aspects of healthcare services. In this paper we outline a multi-stage rule extraction pipeline for rule-based knowledge discovery. The featured methodology would facilitate operationally straightforward extraction of symbolic rules from medical datasets, in particular those with unannotated ordinal or continuous-valued datavectors. The extracted rulesets will be used in the construction or enrichment of rule-based expert systems. Our pipeline incorporates well-established supervised and unsupervised machine learning methods used for data mining. The motivation for our work stems from the individual effectiveness of data mining methods available for datavector clustering, attribute discretisation and rule extraction. The featured knowledge extraction architecture will be tested and analysed using several wellknown medical datasets.",
        "year": 2003,
        "url": "https://www.semanticscholar.org/paper/19cb6a1815c8701e50f68279d7ed10c42633e173",
        "citation_count": 1
    },
    {
        "title": "RF Sensing for Internet of Things: When Machine Learning Meets Channel State Information",
        "abstract": "With the rapid development of Internet of Things (IoT) techn iques, RF sensing has found wide applications for, e.g., indoor localization, activit y recognition, and healthcare. In this dissertation, we investigate the problem of RF sensing for IoT using channel state information (CSI) and machine learning techniques. In particular, our work mainl y focuses on indoor localization using deep learning and vital sign monitoring for RF sensing. In this dissertation, we first study the problem of CSI based in door localization. For first three works, we exploit deep learning for three different in door localization systems using CSI amplitudes, CSI calibrated phases, and CSI bimodal data, resp ectively. Moreover, we study and analyze CSI data, which is stable for indoor localization. We consider deep autoencoder networks to train CSI data, and employ the weights of the deep netw ork to represent fingerprints. A greedy learning algorithm is leveraged to train the weights layer-by-layer to reduce computational complexity, where a sub-network between two consecutive la y rs forms a Restricted Boltzmann Machine (RBM). In the online stage, we use a probabilistic meth od for online location estimation. Then, we exploit deep convolutional neural networks (DCNN) f or indoor localization. Since DCNN is a supervised method, it only requires to train one grou p f weights for all the training data with related labels, which is different with our prior w orks that requires training weights for every training location. Specially, we use estimated angle of arrival (AOA) images from CSI data as input to the DCNN. By executing four convolutional and subsa mpling layers, the system can automatically extract the features of the estimated AOA ima ges, to obtain training weights. To improve indoor localization accuracy, we propose deep resi dual sharing learning for training two channels CSI tensor data. Moreover, we can stack many residua l haring blocks for adding the depth of the deep network, thus achieving higher learning an d representation ability for CSI tensor",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/1a147800369be3180a0f14def25aa5ffc729f39a",
        "citation_count": 1
    },
    {
        "title": "Detecting drug diversion in health-system data using machine learning and advanced analytics",
        "abstract": "Abstract Purpose The theft of drugs from healthcare facilities, also known as drug diversion, occurs frequently but is often undetected. This paper describes a research study to develop and test novel drug diversion detection methods. Improved diversion detection and reduction in diversion improves patient safety, limits harm to the person diverting, reduces the public health impact of substance use disorder, and mitigates significant liability risk to pharmacists and their organizations. Methods Ten acute care inpatient hospitals across 4 independent health systems extracted 2 datasets from various health information technology systems. Both datasets were consolidated, normalized, classified, and sampled to provide a harmonious dataset for analysis. Supervised machine learning methods were iteratively used on the initial sample dataset to train algorithms to classify medication movement transactions as involving a low or high risk of diversion. Thereafter, the resulting machine learning model classified the risk of diversion in a historical dataset capturing 8 to 24 months of history that included 27.9 million medication movement transactions by 19,037 nursing, 1,047 pharmacy, and 712 anesthesia clinicians and that included 22 known, blinded diversion cases to measure when the model would have detected the diversion compared to when the diversion was actually detected by existing methods. Results The machine learning model had 96.3% accuracy, 95.9% specificity, and 96.6% sensitivity in detecting transactions involving a high risk of diversion using the initial sample dataset. In subsequent testing using the much larger historical dataset, the analytics detected known diversion cases (n = 22) in blinded data faster than existing detection methods (a mean of 160 days and a median of 74 days faster; range, 7-579 days faster). Conclusion The study showed that (1) consolidated datasets and (2) supervised machine learning can detect known diversion cases faster than existing detection methods. Users of the technology also noted improved investigation efficiency.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/1a73ecf4cdb315b5ee7d360bd0d9e09390916b84",
        "citation_count": 8
    },
    {
        "title": "Optimizing Pharmacist Team-Integration for ICU Patient Management: Rationale, Study Design, and Methods for a Multicentered Exploration of Pharmacist-to-Patient Ratio",
        "abstract": "BACKGROUND: The workload of healthcare professionals including physicians and nurses in the ICU has an established relationship to patient outcomes, including mortality, length of stay, and other quality indicators; however, the relationship of critical care pharmacist workload to outcomes has not been rigorously evaluated and determined. The objective of our study is to characterize the relationship of critical care pharmacist workload in the ICU as it relates to patient-centered outcomes of critically ill patients. METHODS: Optimizing Pharmacist Team-Integration for ICU patient Management is a multicenter, observational cohort study with a target enrollment of 20,000 critically ill patients. Participating critical care pharmacists will enroll patients managed in the ICU. Data collection will consist of two observational phases: prospective and retrospective. During the prospective phase, critical care pharmacists will record daily workload data (e.g., census, number of rounding teams). During the retrospective phase, patient demographics, severity of illness, medication regimen complexity, and outcomes will be recorded. The primary outcome is mortality. Multiple methods will be used to explore the primary outcome including multilevel multiple logistic regression with stepwise variable selection to exclude nonsignificant covariates from the final model, supervised and unsupervised machine learning techniques, and Bayesian analysis. RESULTS: Our protocol describes the processes and methods for an observational study in the ICU. CONCLUSIONS: This study seeks to determine the relationship between pharmacist workload, as measured by pharmacist-to-patient ratio and the pharmacist clinical burden index, and patient-centered outcomes, including mortality and length of stay.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/1af14a5983326df5ec46ad4a61e0504ac64f1c16",
        "citation_count": 1
    },
    {
        "title": "Prediction of early-stage melanoma recurrence using clinical and histopathologic features",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/1b069b6d695858e189b7ae6ea94192a899278932",
        "citation_count": 24
    },
    {
        "title": "A Novel Integrated IoT Framework with Classification Approach for Medical Data Analysis",
        "abstract": "In the healthcare systems, usage of advanced integrated technologies like Internet of things (IoT) and Machine learning (ML) techniques were limited. Different amalgams of IoT devices and ML mechanisms are available for medical sector but are limited to certain domains only. These models either provide patients current state data or specific domain analyzing and surveillance pre/post treatment data like heart or brain functions with corresponding medical aid. Also data available is used as clinical study for medical professionals and for better understandings of patients about their state. Specific domain gadgets' like wrist bands or smart bands uses some sensors about vital, temperature and pulse etc., checkups are available but they were not meant for diagnosing or for treatments. In this paper, we proposed an integrated model to use IoT and ML algorithms for a healthcare system. Tracking of patients' status can be done using some sensors such as lightweight, portable, and low-powered sensor nodes. These Sensors sense the patient's status and send the parametric data to the central controller, to take actions during the critical condition of the patients. The data sent to the controller always provided in secure and encryption form. At the same time, patient data is sent to doctors, so that they can provide the instructions to the caretakers of the patients with quick and proper solutions in real-time. For disease prediction, our model uses supervised machine learning algorithms, In order to get the efficient feature set and improve the better accuracy, and pre-processing techniques to eliminate features that are irrelevant, missing values and outliers from biomedical data which aids in better disease prediction. To further strengthen the proposed integrated model design is compared with various traditional classification algorithms to specify its improved accuracy and computational time for accurate prediction of the patient's disease and acts as a decision support system for health care assistants.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/1b195966c37b523edf44f021a7a19178a2bf9438",
        "citation_count": 2
    },
    {
        "title": "An explainable machine learning framework for lung cancer hospital length of stay prediction",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/1b3ae70162005599a21ccfb72e3c83501f217e21",
        "citation_count": 88
    },
    {
        "title": "An Improved Supervised Classification Algorithm in Healthcare Diagnostics for Predicting Opioid Habit Disorder",
        "abstract": "Opioid Habit Disorder (OHD), which has become a mass health epidemic, is defined as the psychological or physical dependency on opioids. This study demonstrates how supervised machine learning procedures help us investigate and examine massive data to discover the hidden patterns in any disease to deliver adapted dealing and predict the disease in any patient. This work presents a generalized model for forecasting a disease in the healthcare sector. The proposed model was investigated and tested using a reduced feature-set of the Opioid Habit Disorder (OHD) dataset collected from the National Survey on Drug Use and Health (NSDUH) using an improved Iterative Dichotomiser 3 (pro-IDT) algorithm. The proposed healthcare model is also compared with further machine learning algorithms such as ID3, Random Forest, and Bayesian Classifier in Python programming. The performance of the proposed work and other machine-learning algorithms has estimated accuracy, precision, misclassification rate, recall, specificity, and F1 score.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/1b83a456aa33125355b834166592aa921e99b3b3",
        "citation_count": 4
    },
    {
        "title": "Detection of carbapenem-resistant Klebsiella pneumoniae on the basis of matrix-assisted laser desorption ionization time-of-flight mass spectrometry by using supervised machine learning approach",
        "abstract": "Background Carbapenem-resistant Klebsiella pneumoniae (CRKP) is emerging as a significant pathogen causing healthcare-associated infections. Matrix\u2010assisted laser desorption/ionisation mass spectrometry time-of-flight mass spectrometry (MALDI\u2010TOF MS) is used by clinical microbiology laboratories to address the need for rapid, cost\u2010effective and accurate identification of microorganisms. We evaluated application of machine learning methods for differentiation of drug resistant bacteria from susceptible ones directly using the profile spectra of whole cells MALDI-TOF MS in 46 CRKP and 49 CSKP isolates. Methods We developed a two-step strategy for data preprocessing consisting of peak matching and a feature selection step before supervised machine learning analysis. Subsequently, five machine learning algorithms were used for classification. Results Random forest (RF) outperformed other four algorithms. Using RF algorithm, we correctly identified 93% of the CRKP and 100% of the CSKP isolates with an overall classification accuracy rate of 97% when 80 peaks were selected as input features. Conclusions We conclude that CRKPs can be differentiated from CSKPs through RF analysis. We used direct colony method, and only one spectrum for an isolate for analysis, without modification of current protocol. This allows the technique to be easily incorporated into clinical practice in the future.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/1bd142a5c8cc1f20b2628a2220d72cb8c0c75585",
        "citation_count": 29
    },
    {
        "title": "Comparison of Data Mining Algorithms for Predicting the Cancer Disease Using Python",
        "abstract": "Fundamentally, machine learning is the part of data science which is nothing but AI. We use machine learning algorithms for predicting the future results after analyzing the past data. This technique of data processing is called data analytics. Machine Learning algorithms are divided in three sections: Supervised, Unsupervised and Reinforcement. These algorithms are further subdivided in other sections. In this paper we are comparing these algorithms by which in future we could easily update the accuracy level of the ML algorithms. For doing this we used the healthcare data which has been uploaded on the kaggle. We implemented the machine learning algorithm using python programming language and calculated the accuracy level of each algorithm.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/1be4e69bac372fde3a5764fe96fa43b9a09158df",
        "citation_count": 0
    },
    {
        "title": "Heart Failure Prediction using Machine Learning Algorithms",
        "abstract": "This day and age individuals are increasingly giving precedence to their material needs as opposed to self-care, leading to physical and mental strain. Cardiovascular diseases (CVDs) present a significant menace worldwide, causing about 17.9 million deaths annually which is roughly 32% of global mortality. Heart failure, which impacts over 550,000 individuals on a yearly basis, emerges as an urgent global health concern. The formulation of effective prediction techniques for heart failure proves to be imperative in lessening its repercussions. Linear and machine learning models are put into service to forecast heart failure utilizing a myriad of inputs, comprising clinical data. With the burgeoning population, the early detection and intervention for heart disease grow more complex. Heart disease prevalence has escalated to concerning levels, culminating in untimely deaths due to arterial plaque accumulation. The premature pinpointing of heart disease holds the potential to rescue many lives by upholding arterial wellness. Our research integrates supervised machine learning algorithms to predict heart disease presence, underscoring methods to enhance classifier efficacy. Null values within the dataset are managed through mean value imputation, whereas irrelevant attributes are expunged utilizing information-gain feature selection. By wielding breakthroughs in machine learning (ML), the key aim of this study is to design prognostic models for cardiovascular disease utilizing 12 clinical attributes. By capitalizing on a dataset offered by Davide Chicco and Giuseppe Jurman, encompassing 12 clinical features and 299 data points, the efficacy of three ML algorithms: Support Vector Machine (SVM), Random Forest, and Logistic Regression is evaluated. Our examination discloses that Logistic Regression showcases the most outstanding accuracy and likelihood in foretelling cardio vascular disease presence. This predictive model exhibits potential in aiding healthcare experts in curtailing heart disease-linked fatalities.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/1c679d557f2fed289ad30a2a40e0fed0bba227ad",
        "citation_count": 1
    },
    {
        "title": "WearMask: Fast In-browser Face Mask Detection with Serverless Edge Computing for COVID-19",
        "abstract": "The COVID-19 epidemic has been a significant healthcare challenge in the United States. According to the Centers for Disease Control and Prevention (CDC), COVID-19 infection is transmitted predominately by respiratory droplets generated when people breathe, talk, cough, or sneeze. Wearing a mask is the primary, effective, and convenient method of blocking 80% of all respiratory infections. Therefore, many face mask detection and monitoring systems have been developed to provide effective supervision for hospitals, airports, publication transportation, sports venues, and retail locations. However, the current commercial face mask detection systems are typically bundled with specific software or hardware, impeding public accessibility. In this paper, we propose an in-browser serverless edge-computing based face mask detection solution, called Web-based efficient AI recognition of masks (WearMask), which can be deployed on any common devices (e.g., cell phones, tablets, computers) that have internet connections using web browsers, without installing any software. The serverless edge-computing design minimizes the extra hardware costs (e.g., specific devices or cloud computing servers). The contribution of the proposed method is to provide a holistic edge-computing framework of integrating (1) deep learning models (YOLO), (2) high-performance neural network inference computing framework (NCNN), and (3) a stack-based virtual machine (WebAssembly). For end-users, our web-based solution has advantages of (1) serverless edge-computing design with minimal device limitation and privacy risk, (2) installation free deployment, (3) low computing requirements, and (4) high detection speed. Our WearMask application has been launched with public access at facemask-detection.com.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/1c6a6242964b56e0b9135c3192199f098f03d5bc",
        "citation_count": 35
    },
    {
        "title": "Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT",
        "abstract": "Speech is the most natural way of expressing ourselves as humans. Identifying emotion from speech is a nontrivial task due to the ambiguous definition of emotion itself. Speaker Emotion Recognition (SER) is essential for understanding human emotional behavior. The SER task is challenging due to the variety of speakers, background noise, complexity of emotions, and speaking styles. It has many applications in education, healthcare, customer service, and Human-Computer Interaction (HCI). Previously, conventional machine learning methods such as SVM, HMM, and KNN have been used for the SER task. In recent years, deep learning methods have become popular, with convolutional neural networks and recurrent neural networks being used for SER tasks. The input of these methods is mostly spectrograms and hand-crafted features. In this work, we study the use of self-supervised transformer-based models, Wav2Vec2 and HuBERT, to determine the emotion of speakers from their voice. The models automatically extract features from raw audio signals, which are then used for the classification task. The proposed solution is evaluated on reputable datasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show the effectiveness of the proposed method on different datasets. Moreover, the model has been used for real-world applications like call center conversations, and the results demonstrate that the model accurately predicts emotions.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/1ca01434c0c1340967d805f6e962e01d16451546",
        "citation_count": 0
    },
    {
        "title": "Wireless Sensor Networks anomaly detection using Machine Learning: A Survey",
        "abstract": "Wireless Sensor Networks (WSNs) have become increasingly valuable in various civil/military applications like industrial process control, civil engineering applications such as buildings structural strength monitoring, environmental monitoring, border intrusion, IoT (Internet of Things), and healthcare. However, the sensed data generated by WSNs is often noisy and unreliable, making it a challenge to detect and diagnose anomalies. Machine learning (ML) techniques have been widely used to address this problem by detecting and identifying unusual patterns in the sensed data. This survey paper provides an overview of the state of the art applications of ML techniques for data anomaly detection in WSN domains. We first introduce the characteristics of WSNs and the challenges of anomaly detection in WSNs. Then, we review various ML techniques such as supervised, unsupervised, and semi-supervised learning that have been applied to WSN data anomaly detection. We also compare different ML-based approaches and their performance evaluation metrics. Finally, we discuss open research challenges and future directions for applying ML techniques in WSNs sensed data anomaly detection.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/1ca89a8cdea9a7427293599c3e2db047d81cb915",
        "citation_count": 8
    },
    {
        "title": "Relation Extraction of Medical Concepts Using Categorization and Sentiment Analysis",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/1cba57effede1c7ce02bd9802c88ff32bc556ed3",
        "citation_count": 21
    },
    {
        "title": "Using Supervised Learning Methods to Develop a List of Prescription Medications of Greatest Concern during Pregnancy",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/1cd542f61c43dc63edf0ac5a7d625ff5ec3caab5",
        "citation_count": 10
    },
    {
        "title": "Managing the Scarcity of Monitoring Data through Machine Learning in Healthcare Domain",
        "abstract": "In the field of Ubiquitous Computing, a significant problem of building accurate machine learning models is the effort and time consuming process to gather labeled data for the learning algorithm. Moreover, efficient data use demands are constantly growing. These demands for efficient data use are growing constantly. Researchers are therefore exploring the use of machine learning techniques to overcome the problem of data scarcity. In healthcare, classification tasks require a ground truth normally provided by an expert physician, ending up with a small set of labeled data with a larger set of unlabeled data. It is also common to rely on self-reported data through questionnaires, however, this introduce an extra burden to the user who is not always able or willing to fill in. Finally, in some healthcare domains it is important to be able to provide immediate response (feedback), even if the user is not familiarized with the use of an application. In all of these cases the amount of available data may be insufficient to produce reliable models. This thesis proposes a new approach specifically designed for the challenges in producing better predictive models. We propose using our novel Intermediate Models to predict the mood variables associated with the questionnaire using data acquired from smartphones. Then, we use the predicted mood variables with the rest of the data to predict the class, in our empirical assessment, the state mood of a bipolar disorder patient or stress levels of employees have been used. The motivation behind this new approach is that there are relevant proposed methods such as latent variables used as intermediate information helping to create better predictive models. These methods are used in literature to complete the missing data using the most common value, the most probable value given the class, or induce a model for predicting missing values using all the information from features and the class. However, these variables are artificially created and used as intermediate information to build better model. In our Intermediate Models, we know in advance how many mood variables to use and we have the information from these variables, which allow us to produce better models. To address scarce data, we propose applying a semi-supervised learning setting while taking advantage of the presence of all unlabeled datasets. In addition, we propose using transfer learning methods that is used to improve the learning performance with the aim at avoiding expensive data labeling efforts. To the best of our knowledge, there are few works that have used transfer learning for healthcare applications to address the problem of limited labeled data. The proposed methods have been applied in two different healthcare fields: mental-health and human behaviour field. This thesis addresses two classification problems, a) classification of episodic state of bipolar disorder patients, and b) detecting work-related stress using data acquired from smartphone sensing modalities.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/1d44ff9a0c282861765cf91620be2843f2324cf1",
        "citation_count": 0
    },
    {
        "title": "Machine Learning in Healthcare Data Analysis: A Survey",
        "abstract": "In recent years, healthcare data analysis is becoming one of the most promising research areas. Healthcare includes data in various types such as clinical data, Omics data, and Sensor data. Clinical data includes electronic health records which store patient records collected during ongoing treatment. Omics data is one of the high dimensional data comprising genome, transcriptome and proteome data types. Sensor data is collected from various wearable and wireless sensor devices. To handle this raw data manually is very difficult. For analysis of data, machine learning is emerged as a significant tool. Machine learning uses various statistical techniques and advanced algorithms to predict the results of healthcare data more precisely. In machine learning different types of algorithms like supervised, unsupervised and reinforcement are used for analysis. In this paper, different types of machine learning algorithms are described. Then use of machine learning algorithms for analyzing various healthcare data are surveyed.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/1d8a78f3f740a01905e925aeb7937df010dfa1df",
        "citation_count": 68
    },
    {
        "title": "HYPERPARAMETER OPTIMIZATION IN CUSTOMIZED CONVOLUTIONAL NEURAL NETWORK FOR BLOOD CELLS CLASSIFICATION",
        "abstract": "Recently, various uses of supervised classification recognition algorithms for medical images are reported in literature. Specifically, in the current deep learning era, machine learning techniques are considered as the most important and used approach for automatic healthcare systems. In this context, many comparisons of supervised deep learning techniques, more precisely, the neural one, are proposed. The proposed approach provides a medical assistance based on relevant aspects of Machine -Learning methods applied for blood cells objects recognition while taking into consideration the property of uncertainty of this kind of image. The overview presented in this article examines the existing literature and the contributions already done in the field of intelligent healthcare systems for blood cell images classification. For this purpose, we summarize previous efforts made to define recognition process with supervised deep learning method, establishing a novel definition of personalized Machine-Learning with a major focus on the uncertainty input image. Departing from this definition, we propose and discuss the efficiency of Convolutional Neural Network for which the architecture is built and examined in detail. A Bayesian optimization of Convolutional Neural Network hyper parameters is also proposed. The main goal is to increase recognition rate while respecting time complexity. That is why an experimental comparison of Convolutional Neural Network with Support Vector Machine and K-nearest neighbor performance is discussed.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/1e8e8f3e6857baf0b09d5d18c29a564f2abb601d",
        "citation_count": 9
    },
    {
        "title": "Supervised Machine Learning-Based Models for Predicting Raised Blood Sugar",
        "abstract": "Raised blood sugar (hyperglycemia) is considered a strong indicator of prediabetes or diabetes mellitus. Diabetes mellitus is one of the most common non-communicable diseases (NCDs) affecting the adult population. Recently, the prevalence of diabetes has been increasing at a faster rate, especially in developing countries. The primary concern associated with diabetes is the potential for serious health complications to occur if it is not diagnosed early. Therefore, timely detection and screening of diabetes is considered a crucial factor in treating and controlling the disease. Population screening for raised blood sugar aims to identify individuals at risk before symptoms appear, enabling timely intervention and potentially improved health outcomes. However, implementing large-scale screening programs can be expensive, requiring testing, follow-up, and management resources, potentially straining healthcare systems. Given the above facts, this paper presents supervised machine-learning models to detect and predict raised blood sugar. The proposed raised blood sugar models utilize diabetes-related risk factors including age, body mass index (BMI), eating habits, physical activity, prevalence of other diseases, and fasting blood sugar obtained from the dataset of the STEPwise approach to NCD risk factor study collected from adults in the Palestinian community. The diabetes risk factor obtained from the STEPS dataset was used as input for building the prediction model that was trained using various types of supervised learning classification algorithms including random forest, decision tree, Adaboost, XGBoost, bagging decision trees, and multi-layer perceptron (MLP). Based on the experimental results, the raised blood sugar models demonstrated optimal performance when implemented with a random forest classifier, yielding an accuracy of 98.4%. Followed by the bagging decision trees, XGBoost, MLP, AdaBoost, and decision tree with an accuracy of 97.4%, 96.4%, 96.3%, 95.2%, and 94.8%, respectively.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/1eaabadf668b5daba49f12c5e77d3e49f32a4d06",
        "citation_count": 1
    },
    {
        "title": "Using Data Mining Algorithms for Thalassemia Risk Prediction",
        "abstract": "This study predict the risk of thalassemia in all age groups based on identified risk of thalassemia. Knowledge about the risk factors for thalassemia was identified using structural interview with experienced medical personnel and questionnaire which was used to collect empirical medical database on the parameters. Supervised machine learning algorithms was used to formulate the predictive model for risk of thalassemia using the parameters and data identified and collected. The predictive model for the risk of thalassemia was simulated using the Waikato Environment for Knowledge Analysis (WEKA). The simulated model was validated using the historical data collected from the hospitals explaining the parameters and the risk of Thalassemia. The results of the study showed that following the collection of data from 51 patients, the parameters identified included demographic variables like gender, age, marital status, ethnicity and social class while the clinical variables included family history, spleen enlargement, diabetes, urine colour changes and parent carriers while the distribution of the risk was 43% no cases, 10% low cases, 16% moderate cases and 31% high cases. The study concluded that using the multi-layer perceptron for the prediction of Thalassemia will improve the decision making process within the healthcare service concerning Thalassemia.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/1ef19db96dd8b56331de1ac15389e21e56eeca10",
        "citation_count": 14
    },
    {
        "title": "Machine learning algorithms-based decision support model for diabetes",
        "abstract": "This research explores the application of machine learning (ML)-based risk prediction models in early diabetes disease detection for healthcare professionals. Diabetes affects millions of people worldwide. In light of significant advancements in biomedical sciences, vast volumes of data have been generated, including high-throughput genetic and diagnostic data sourced from extensive health records. Leveraging an initial diabetes risk prediction dataset from the University of California Irvine (UCI) ML repository, our research focused on supervised learning techniques, constituting 85% of the employed methods. The remaining 15% comprised unsupervised learning approaches, specifically association rules. A key contribution of this study lies in the development of an optimal prediction model utilizing supervised ML algorithms. The Boruta feature selection algorithm was employed to identify pertinent features, and the subsequent models were validated using a preprocessed dataset containing 10 attributes. Notably, the risk prediction models generated through random forest, extreme gradient boosting (XGBoost), and light gradient boosting machine (LightGBM) exhibited impressive average accuracies of 98.13%, 97.37%, and 97.22%, respectively, as determined via 10-fold cross-validation with 15 repetitions. Furthermore, these models achieved exceptional area under the ROC curve (AUC) values of 1, 0.99, and 0.99, respectively, showcasing their robustness and efficacy in diabetes risk prediction.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/1f13e1430cd0a09988c99be9292c16d7fd3340fc",
        "citation_count": 0
    },
    {
        "title": "Exploring Features Contributing to the Early Prediction of Sepsis Using Machine Learning",
        "abstract": "The increasing availability of electronic health records and administrative data and the adoption of computer-based technologies in healthcare have significantly focused on medical informatics. Sepsis is a time-critical condition with high mortality, yet it is often not identified in a timely fashion. The early detection and diagnosis of sepsis can increase the likelihood of survival and improve long-term outcomes for patients. In this paper, we use SHapley Additive exPlanations (SHAP) analysis to explore the variables most highly associated with developing sepsis in patients and evaluating different supervised learning models for classification. To develop our predictive models, we used the data collected after the first and the fifth hour of admission and evaluated the contribution of different features to the prediction results for both time intervals. The results of our study show that, while there is a high level of missing data during the early stages of admission, this data can be effectively utilized for the early prediction of sepsis. We also found a high level of inconsistency between the contributing features at different stages of admission, which should be considered when developing machine learning models.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/1f387c0ba6074aca603c0cdf06d41d5766d963e2",
        "citation_count": 8
    },
    {
        "title": "Accuracy Rejection Normalized-Cost Curves (ARNCCs): A Novel 3-Dimensional Framework for Robust Classification",
        "abstract": "Machine learning (ML) offers several supervised learning algorithms to build classifiers for developing accurate decision support systems. However, the selection of robust classifier for reliable decision making in healthcare domain is three-fold: accuracy, refraining for low confidence decisions, and the cost of decisions. In the field of medical science, there are costs associated with the incorrect and the refraining from decisions, which can have negative implications in devising adequate therapeutic interventions. For example, it may be life threating if a cancer patient is declared as healthy one (misclassification cost) or decision remains pending for some time (rejection cost). In this work we proposed the concept of Accuracy Rejection Normalized-Cost Curves (ARNCCs), which is an extension of Accuracy Rejection Curves (ARCs); a three-dimensional visualization technique to demonstrate the strengths and weaknesses of classification algorithms over different rejection regions and normalized-cost (NC) to select the robust classifier. ARNCCs method holds ARCs plot on two dimensions, in addition it computes NC at third dimension against ratio of false positive costs and ratio of rejection costs obtained at different rejection rates. The proposed three-dimensional graphs have the potential to answer a variety of questions regarding accuracy, rejection rate and NC of a classifier. Six publicly available cancer datasets (four breast cancer and two lung cancer) having clinical parameters obtained from ML repository of University of California, Irvine (UCI) were used to assess the performance of proposed ARNCCs in this study. Empirical results show that ARNCCs provide broad range of decisions to choose the desired parameters (accuracy, rejection rate and NC) for further necessary actions as compared to traditional ARCs method. ARNCCs framework has the ability to more logically compare the performances of classification algorithms in terms of accuracy, rejection rate and NC based scenarios.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/1f3984aa63c025d12be177e1e5982df8369c7631",
        "citation_count": 7
    },
    {
        "title": "Lessons from Crowdsourcing Technology for Guiding a Patient-Centered Research Agenda",
        "abstract": "Background \nSevere atopic dermatitis (AD) is poorly understood and treatment options are limited. Wide variation in practice among clinicians suggests limited agreement on standards of care. Further, patients report poor quality of life associated with the condition. In the absence of proven treatment options, patients with AD seek answers online from patient communities and social media platforms. Information posted in these fora provide insight into the real-world treatment and management issues faced by patients with AD, and provide a guidepost for patient priorities for future research. \nObjective \nUsing natural language processing (NLP) techniques to aggregate patient-generated data from social media sites, we sought to understand/characterize the universe of treatments used by AD patients, their experience with these treatments, and their perceived gaps in treatment and management options as well as desires/needs for future research. \nMethods \nUsing NLP and machine learning techniques, we collected and analyzed informal patient conversations conducted on publicly accessible online social networks, blogs, and forums. Employing targeted healthcare NLP technology, dominant themes were extracted automatically from free form online patient communication. Using a computational framework that combines supervised and unsupervised machine learning techniques to enhance language processing and account for idiosyncracies in language, we identified salient themes related to patients\u2019 experience with AD, the breadth of treatments described, and comments on treatment options. We cross\u2013referenced this data with the findings of a literature review published articles describing treatments for AD and quantified the overlap between data points gathered through a natural language processing/aggregation approach and treatments identified in the published literature, noting commonalities and differences and highlighting promising areas for future research. \nPreliminary Results \nPatient comments from social media venues express significant distress and frustration with managing AD, and wide variation in treatment/management practices. Patients report a need for help with discomfort, cosmetic/appearance issues, and social support. These needs are underserved by current research efforts. \nConclusions \nNatural language processing techniques may provide insight into patients real-world experience with managing a difficult-to-treat dermatology condition and offer direction for future patient-centered research. []",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/1f56920d445342df817f5ed3c332e8338473cd19",
        "citation_count": 0
    },
    {
        "title": "Comparative Study of Supervised Machine Learning Methods for Prediction of Heart Disease",
        "abstract": "With the ever-growing medical data, it became possible to use the data for prediction of diseases using Machine Learning (ML) methods. ML methods have been widely employed in healthcare. In the study, some of the mostly used ML methods such as Support Vector Machine, Na\u00efve Bayes classifier, Random Forest, Decision tree, and K-Nearest Neighbor were used for prediction of heart disease. Further, we aim to provide a comparative analysis of the ML algorithms applied for heart disease prediction using their accuracy metrics. Dataset for the study was taken from Kaggle in .csv format, where data mining steps such as data collection, data cleaning, data preprocessing, and exploratory data analysis have been done. The study highlights the ML methods used for classification, providing the comparative analysis between them. As a result, it was concluded that the random forest gave the highest accuracy rate with the dataset used in the study.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/20bca0e6a599b6f889bd7533432970082939d2b0",
        "citation_count": 5
    },
    {
        "title": "Learning on the Rings",
        "abstract": "This paper presents ssLOTR (self-supervised learning on the rings), a system that shows the feasibility of designing self-supervised learning based techniques for 3D finger motion tracking using a custom-designed wearable inertial measurement unit (IMU) sensor with a minimal overhead of labeled training data. Ubiquitous finger motion tracking enables a number of applications in augmented and virtual reality, sign language recognition, rehabilitation healthcare, sports analytics, etc. However, unlike vision, there are no large-scale training datasets for developing robust machine learning (ML) models on wearable devices. ssLOTR designs ML models based on data augmentation and self-supervised learning to first extract efficient representations from raw IMU data without the need for any training labels. The extracted representations are further trained with small-scale labeled training data. In comparison to fully supervised learning, we show that only 15% of labeled training data is sufficient with self-supervised learning to achieve similar accuracy. Our sensor device is designed using a two-layer printed circuit board (PCB) to minimize the footprint and uses a combination of Polylactic acid (PLA) and Thermoplastic polyurethane (TPU) as housing materials for sturdiness and flexibility. It incorporates a system-on-chip (SoC) microcontroller with integrated WiFi/Bluetooth Low Energy (BLE) modules for real-time wireless communication, portability, and ubiquity. In contrast to gloves, our device is worn like rings on fingers, and therefore, does not impede dexterous finger motion. Extensive evaluation with 12 users depicts a 3D joint angle tracking accuracy of 9.07\u00b0 (joint position accuracy of 6.55mm) with robustness to natural variation in sensor positions, wrist motion, etc, with low overhead in latency and power consumption on embedded platforms.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/21c133191d8259d51ef59ea5eb458c656e499282",
        "citation_count": 11
    },
    {
        "title": "Improving Prostate Cancer Diagnosis with Weakly Supervised Learning and Radiology-Confirmed Negative MRI Data",
        "abstract": "This work demonstrates the effectiveness of convolutional neural networks (CNNs) and proposes a fresh approach to prostate cancer diagnosis through the application of machine learning models. The research makes use of a dataset of 2498 prostate pictures, of which 40% show benign diseases and 60% show cancerous ones. Many machine learning models are trained using comprehensive feature extraction, with an emphasis on texture- and intensity-based variables. With accuracy of 95.8%, precision, recall, and F1 scores of 96.2%, 95.5%, and 95.8%, respectively, CNN performs remarkably well. K-Nearest Neighbors (KNN), Recurrent Neural Network (RNN), and Support Vector Machine (SVM) all show great accuracy with scores of 92.2%, 88.7%, and 86.5%, respectively. A thorough examination can result in more advantages and suitability of various models for prostate cancer screening. CNN is a suitable option for workflow integration in the healthcare industry because of its improved performance metrics and interpretability. With its ability to make better decisions, the accuracy of diagnoses and patient outcomes are improved and also these machine learning models have the potential to fundamentally alter the way prostate cancer is treated. This research shows how computational techniques could revolutionize the way prostate cancer is now identified and open up the opportunity to more accurate and individualized treatment plans.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/21d20d80a019942362569d309862bc338fc80db2",
        "citation_count": 0
    },
    {
        "title": "Efficient User Profiling in Twitter Social Network Using Traditional Classifiers",
        "abstract": null,
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/21fe73e10f272b4ea6518a5fbf9694840f90ef50",
        "citation_count": 14
    },
    {
        "title": "DISEASE PREDICTION USING MACHINE LEARNING & DEEP LEARNING",
        "abstract": "Heart disease, alternatively known as cardiovascular disease, encases va rious conditions that impact the heart and is the primary basis of death worldwide over the span of the past few decades. It associates many risk factors in heart disease and a need of the time to get accurate, reliable, and sensible approaches to make an early diagnosis to achieve prompt man agement of the disease. Data mining is a commonly used technique for processing enormous data in the healthcare domain. Researchers apply several data mining and machine learning techniques to analyse huge complex medical data, helping healthcare professionals to p redict heart disease. This research paper presents various attributes rel ated to heart disease, and the model on basis of supervised learning algorithms as Na\u00efve Bayes, decision tree, K-nearest neighbor, and random forest algorithm. It uses the existing dat aset from the Cleveland database of UCI repository of heart disease patients. The dataset comprises 303 instances and 76 attributes. Of thes e 76 attributes, only 14 attributes are considered for testing, important to substantiate the performance of different algorithms. This research paper aims to envision the probability of developing heart disease in the patients. The results portray that the highest accuracy score is ach ieved with K-nearest neighbor .",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/220d5ced17377d2e49fe7fb172f771d46132c4cb",
        "citation_count": 0
    },
    {
        "title": "Reinforcement Learning in Healthcare: A Survey",
        "abstract": "As a subfield of machine learning, reinforcement learning (RL) aims at optimizing decision making by using interaction samples of an agent with its environment and the potentially delayed feedbacks. In contrast to traditional supervised learning that typically relies on one-shot, exhaustive, and supervised reward signals, RL tackles sequential decision-making problems with sampled, evaluative, and delayed feedbacks simultaneously. Such a distinctive feature makes RL techniques a suitable candidate for developing powerful solutions in various healthcare domains, where diagnosing decisions or treatment regimes are usually characterized by a prolonged period with delayed feedbacks. By first briefly examining theoretical foundations and key methods in RL research, this survey provides an extensive overview of RL applications in a variety of healthcare domains, ranging from dynamic treatment regimes in chronic diseases and critical care, automated medical diagnosis, and many other control or scheduling problems that have infiltrated every aspect of the healthcare system. In addition, we discuss the challenges and open issues in the current research and highlight some potential solutions and directions for future research.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/222baa4e9e7ce691fdfddbc826a70e027daed70d",
        "citation_count": 510
    },
    {
        "title": "A survey on detecting healthcare concept drift in AI/ML models from a finance perspective",
        "abstract": "Data is incredibly significant in today's digital age because data represents facts and numbers from our regular life transactions. Data is no longer arriving in a static form; it is now arriving in a streaming fashion. Data streams are the arrival of limitless, continuous, and rapid data. The healthcare industry is a major generator of data streams. Processing data streams is extremely complex due to factors such as volume, pace, and variety. Data stream classification is difficult owing to idea drift. Concept drift occurs in supervised learning when the statistical properties of the target variable that the model predicts change unexpectedly. We focused on solving various forms of concept drift problems in healthcare data streams in this research, and we outlined the existing statistical and machine learning methodologies for dealing with concept drift. It also emphasizes the use of deep learning algorithms for concept drift detection and describes the various healthcare datasets utilized for concept drift detection in data stream categorization.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/2285236e3de1b908a14b11eec7a9a0ce7d28ff9b",
        "citation_count": 7
    },
    {
        "title": "Advancements and Challenges in Machine Learning: A Comprehensive Review of Models, Libraries, Applications, and Algorithms",
        "abstract": "In the current world of the Internet of Things, cyberspace, mobile devices, businesses, social media platforms, healthcare systems, etc., there is a lot of data online today. Machine learning (ML) is something we need to understand to do smart analyses of these data and make smart, automated applications that use them. There are many different kinds of machine learning algorithms. The most well-known ones are supervised, unsupervised, semi-supervised, and reinforcement learning. This article goes over all the different kinds of machine-learning problems and the machine-learning algorithms that are used to solve them. The main thing this study adds is a better understanding of the theory behind many machine learning methods and how they can be used in the real world, such as in energy, healthcare, finance, autonomous driving, e-commerce, and many more fields. This article is meant to be a go-to resource for academic researchers, data scientists, and machine learning engineers when it comes to making decisions about a wide range of data and methods to start extracting information from the data and figuring out what kind of machine learning algorithm will work best for their problem and what results they can expect. Additionally, this article presents the major challenges in building machine learning models and explores the research gaps in this area. In this article, we also provided a brief overview of data protection laws and their provisions in different countries.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/229b1002fa9d08b45887d6a3c33ba653c36c634c",
        "citation_count": 82
    },
    {
        "title": "Clinical Relationships Extraction Techniques from Patient Narratives",
        "abstract": "The Clinical E-Science Framework (CLEF) project was used to extract important information from medical texts by building a system for the purpose of clinical research, evidence-based healthcare and genotype-meets-phenotype informatics. The system is divided into two parts, one part concerns with the identification of relationships between clinically important entities in the text. The full parses and domain-specific grammars had been used to apply many approaches to extract the relationship. In the second part of the system, statistical machine learning (ML) approaches are applied to extract relationship. A corpus of oncology narratives that hand annotated with clinical relationships can be used to train and test a system that has been designed and implemented by supervised machine learning (ML) approaches. Many features can be extracted from these texts that are used to build a model by the classifier. Multiple supervised machine learning algorithms can be applied for relationship extraction. Effects of adding the features, changing the size of the corpus, and changing the type of the algorithm on relationship extraction are examined. Keywords: Text mining; information extraction; NLP; entities; and relations.",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/2309ad6a2d13e80b65dd848fe6e8b84f85879412",
        "citation_count": 5
    },
    {
        "title": "Analysis of Machine Learning, Deep Learning, and Artificial Neural Network Approaches for Breast Cancer Classification",
        "abstract": "Breast cancer is one of the most common causes of death worldwide among women, with good survival rates if detected early. In our work, we compared supervised, semi- supervised and unsupervised learning on the biomedical dataset, Wisconsin Breast Cancer Dataset, to establish the model with the best performance and hence apply for computer aided diagnosis. The metrics used for the same includes performance of the network as well as the ease of implementation, As a result, we hope to close the gap between technology innovation and its implementation in healthcare.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/231bbb85f94c702d163c4c4207b5c26619c507ea",
        "citation_count": 0
    },
    {
        "title": "Utilizing machine learning in predictive modeling: what\u2019s next?",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/2326dac85cc41d132509f1fd371e51bf7163b3f8",
        "citation_count": 3
    },
    {
        "title": "Influence of Water Droplet Contamination for Transparency Segmentation",
        "abstract": "Computer vision techniques are on the rise for industrial applications, like process supervision and autonomous agents, e.g., in the healthcare domain and dangerous environments. While the general usability of these techniques is high, there are still challenging real-world use-cases. Especially transparent structures, which can appear in the form of glass doors, protective casings or everyday objects like glasses, pose a challenge for computer vision methods. This paper evaluates the combination of transparent objects in conjunction with (naturally occurring) contamination through environmental effects like hazing. We introduce a novel publicly available dataset containing 489 images incorporating three grades of water droplet contamination on transparent structures and examine the resulting influence on transparency handling. Our findings show, that contaminated transparent objects are easier to segment and that we are able to distinguish between different severity levels of contamination with a current state-of-the art machine-learning model. This in turn opens up the possibility to enhance computer vision systems regarding resilience against, e.g., datashifts through contaminated protection casings or implement an automated cleaning alert.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/232f87f9a5cdcbf28555ca3dacb36e29225130ad",
        "citation_count": 0
    },
    {
        "title": "A Cloud-Centric Application for Elderly Heart Disease Detection with Machine Learning and Confusion Matrix",
        "abstract": "Elderly individuals often face limited mobility and remote locations, which can hinder their access to specialist healthcare and result in missed diagnoses and poorer health outcomes. This paper addresses this issue by proposing a novel, cloud-centric application for Remote Patient Monitoring (RPM). The goal of this application is to enable elderly patients to track their vital signs from home using Internet of Things (IoT) sensors, leveraging machine learning for analysis. A high-performing Random Forest model is employed to analyze the data, detecting early signs of cardiovascular disease with an accuracy of 82.6%. Doctors can remotely monitor patient health data, which is integrated with electronic health records, facilitating timely follow-up care and personalized treatment recommendations. The method presents a user-centric approach that combines remote self-diagnosis with advanced technology to improve healthcare accessibility for the elderly. The current iteration focuses on heart disease detection, but future developments could expand the application to a broader range of health parameters. It is essential to note that this application serves as a complementary tool to professional medical advice, not a replacement. Clear communication about these limitations within the app is crucial. This research highlights the importance of doctor supervision and professional evaluation in conjunction with self-monitoring through the application.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/2369d1e9117dc06f7751e3ef049d75c3ad975a4e",
        "citation_count": 0
    },
    {
        "title": "Board 132 - Program Innovations Abstract Learning the Forest One Tree at a Time: Maximizing Learner Engagement in Anesthesia Simulation for Medical Students (Submission #860)",
        "abstract": "Introduction/Background Medical students undergoing their two week anesthesia clerkship have a two hour high fidelity simulation course that occurs at the midpoint. Scenarios are geared toward the induction of anesthesia and peri induction planning, skills and event management. Objectives include selection of drugs for induction, intubation, treatment of light anesthesia, hypotension and hypoxemia. Skills objectives include mask ventilation and intubation with an anesthesia breathing system, manual and mechanical ventilation with an anesthesia machine and the use of the IV system, suction and other basic anesthesia supplies. Prior to the simulation course, students work in the operating room as part of the anesthetizing team and observe and perform many of these skill objectives. The goal of this simulation course is to increase knowledge and skill through a team based, experiential exercise in a simulation lab that provides a safe learning environment. Classical simulation course methodology suggests that debriefing should last approximately twice as long as the case. This format inverts that ratio and allows most of the learning to occur while physically engaged with the simulator environment, mentally engaged in the clinical case and socially engaged with the team. Experience is a valuable teacher, as long as there is feedback. The simulator equipment and environment provide a great deal of feedback on their own and perhaps there is no greater predictor of being able to perform than to have done it before. This reframes the instructor\u2019s role as largely facilitation of learning rather than provider of knowledge. It has also been our experience that multiple learners are able to combine their knowledge and abilities to solve problems beyond the capacity of any single learner. Methods The hypothesis is that students continuously engaged in appropriate but authentic clinical tasks, working as a team will rapidly gain clinically relevant skill and knowledge with only moderate intervention from an instructor. The key design elements that facilitate this process are: 1) Assignment of authentic anesthetic tasks that can transfer into clinical care; 2) Scenario design and role assignment that absolutely requires teamwork; 3) Allowing experiential learning by individuals and the team; 4) Providing only the minimal amount of instructor guidance on a just-in-time basis; 5) Creating tasks that make successes and gaps readily observable; 6) Short debriefing sessions to reinforce successes and address gaps. The course is run with groups of four students in their 3rd ad 4th year of medical school and lasts 2 hours. The students perform four inductions of anesthesia with graded difficulty, following a short prebrief and demonstration by the instructor. Compared to the previous course format, all students are actively involved in four cases and the debriefings are shorter and more focused. The four task stations are as follows: 1) Floating team leader; 2) Head of patient (airway management); 3) Anesthesia machine (ventilation and inhalational anesthetic managment); 4) Anesthesia cart (drug dosing and administration). Each of these task stations absolutely requires coordination of activities with the other stations, which promotes teamwork and situational awareness. During each case, students encounter challenges. In some cases a student is able to work through the challenge without assistance. If this is unsuccessful, the student may ask his peers for assistance and if this is not successful, the instructor provides the minimal guidance necessary to allow the case to progress as intended. The pacing of the exercise allows for experimentation, peer assisted learning and stop and go debriefing interventions by the instructor. After each case, successes and gaps are reviewed in a plus delta format for approximately five minutes. The instructor remains in the room throughout the exercise and in our case, also operates the simulator. The fours cases typically used are: 1) Healthy 35 year old man scheduled for laparoscopic inguinal hernia repair; 2) 35 year old obese smoker scheduled for laparoscopic inguinal hernia repair; 3) 35 year old obese man with a full stomach and an acute open tibia/fibula fracture requiring emergent operative fixation; 4) 80 year old man with hypertension, a full stomach and an acute open tibia/fibula fracture requiring emergent operative fixation. With each successive case, students rotate by one station. This allows each student to experience new challenges and frames with each case and also help his peers with stations he has \"mastered\" already. The peer teaching interaction provides another layer of reinforcement, enabling bidirectional and team communication around a clinical problem. This interaction is perhaps the hidden curriculum in teamwork and professionalism. One other component that this format provides is just-in-time teaching. Teachable moments are easily observable by physical actions, simulator cues and verbal communication. If a student is able to perform a task successfully and correctly, no instructional time needs to be wasted. If a student needs assistance peer assistance often achieves the educational objective and has positive effects for the peer teacher as well. Situations that require instructor intervention are on an as needed basis, reducing the use of excessive instruction to achieve the educational objectives, creating a more efficient learning activity. Results: Conclusion Instructor survey demonstrated a greater perceived level of student participation in the exercise and completion of learning objectives. A student survey, followed by focused interview elucidated student perceptions on learning in this format. A summary of the findings are as follows - Being allowed to struggle in a position of responsibility promotes active thinking and participation. Individual students were able to look to their peers for help. The act of peer teaching helped solidify knowledge. The platform for peer teaching is provided by dividing the anesthesiologist\u2019s role into achievable parts. Instructor intervention prompted students to think structurally about clinical problems. Debriefing sessions provided a framework to approach future problems. Working with same level or near peers was a new and valuable experience for medical students during their clinical years. Students generally felt safer struggling in a peer group compared to traditional hierarchical teams. Teamwork attitudes were uniformly positively affected. With the appropriate time permitted for struggling, the teaching strategy enhances learning through active participation and peer teaching. A simulation session conducted in such manner offers an educational experience that complements the traditional lecture and clinical exposure model. It helps students build a framework of knowledge, skil, and attitudes that may not have been apparent or available to them in the clinical setting or otherwise. References 1. Beard, J. H., O\u2019sullivan, P., Palmer, B. J. A., Qiu, M., & Kim, E. H. (2012). Peer assisted learning in surgical skills laboratory training: A pilot study. Medical Teacher, 34(11), 957-959. doi:10.3109/0142159X.2012.706340. 2. Friedlander, M. J., Andrews, L., Armstrong, E. G., Aschenbrenner, C., Kass, J. S., Ogden, P., Schwartzstein, R., et al. (2011). What Can Medical Education Learn From the Neurobiology of Learning? Academic Medicine, 86(4), 415-420. doi: 10.1097/ACM.0b013e31820dc197. 3. Hallikainen, J., V\u00e4is\u00e4nen, O., Randell, T., Tarkkila, P., Rosenberg, P. H., & Niemi-Murola, L. (2009). Teaching anaesthesia induction to medical students: comparison between full-scale simulation and supervised teaching in the operating theatre. European Journal of Anaesthesiology, 26(2), 101-104. doi:10.1097/EJA.0b013e32831a6a76. 4. Hanson. (2013). Qualitative Research Methods for Medical Educators. Acad Pediatr, 1-12. 5. Kamdar, G., Kessler, D. O., Tilt, L., Srivastava, G., Khanna, K., Chang, T. P., Balmer, D., et al. (2013). Qualitative Evaluation of Just-in-Time Simulation-Based Learning. Simulation in Healthcare: The Journal of the Society for Simulation in Healthcare, 1. doi:10.1097/SIH.0b013e31827861e8. 6. Lockspeiser, T. M., O\u2019Sullivan, P., Teherani, A., & Muller, J. (2006). Understanding the experience of being taught by peers: the value of social and cognitive congruence. Advances in Health Sciences Education, 13(3), 361-372. doi:10.1007/s10459-006-9049-8. 7. Orledge, J., Phillips, W. J., Murray, W. B., & Lerant, A. (2012). The use of simulation in healthcare. Current Opinion in Critical Care, 18(4), 326-332. doi:10.1097/MCC.0b013e328353fb49. 8. Thomas, D. R. (2006). A General Inductive Approach for Analyzing Qualitative Evaluation Data. American Journal of Evaluation, 27(2), 237-246. doi:10.1177/1098214005283748. Disclosures None.",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/23dbfb32640cdb7338ba02ccb9ffd533cdd661d2",
        "citation_count": 0
    },
    {
        "title": "Pima Indians diabetes mellitus classification based on machine learning (ML) algorithms",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/23f2635c6418fba7a4fb6907457f82564ea52277",
        "citation_count": 176
    },
    {
        "title": "Machine Learning Algorithms for Activity-Intensity Recognition Using Accelerometer Data",
        "abstract": "In pervasive healthcare monitoring, activity recognition is critical information for adequate management of the patient. Despite the great number of studies on this topic, a contextually relevant parameter that has received less attention is intensity recognition. In the present study, we investigated the potential advantage of coupling activity and intensity, namely, Activity-Intensity, in accelerometer data to improve the description of daily activities of individuals. We further tested two alternatives for supervised classification. In the first alternative, the activity and intensity are inferred together by applying a single classifier algorithm. In the other alternative, the activity and intensity are classified separately. In both cases, the algorithms used for classification are k-Nearest Neighbors (KNN), Support Vector Machine (SVM), and Random Forest (RF). The results showed the viability of the classification with good accuracy for Activity-Intensity recognition. The best approach was KNN implemented in the single classifier alternative, which resulted in 79% of accuracy. Using two classifiers, the result was 97% accuracy for activity recognition (Random Forest), and 80% for intensity recognition (KNN), which resulted in 78% for activity-intensity coupled. These findings have potential applications to improve the contextualized evaluation of movement by health professionals in the form of a decision system with expert rules.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/2446a51bac6f722a33fbed2abef1d2e7fc84bc8e",
        "citation_count": 11
    },
    {
        "title": "Automated Disease Diagnosis using Deep Learning",
        "abstract": "In this study, a large dataset of medical records, including patient demographics, clinical measurements, and laboratory results, is employed to develop a robust deep learning model. The model utilizes state-of-the-art convolutional neural networks (CNNs) and recurrent neural networks (RNNs) to extract valuable features from multi-modal data sources. These data sources encompass medical images (such as retinal scans and ultrasounds), textual information (patient history, symptoms, and lab reports), and genetic markers. The proposed deep learning model employs both supervised and unsupervised learning techniques. In the supervised phase, the model is trained on labeled data to predict diabetes status accurately. The unsupervised phase leverages the power of deep autoencoders and generative adversarial networks (GANs) to discover latent representations of data, aiding in feature extraction and anomaly detection. The evaluation of the model is conducted on a separate dataset, and its performance is compared to existing diagnostic methods, including traditional clinical assessments and machine learning approaches. The results demonstrate superior accuracy, sensitivity, and specificity in diabetes diagnosis, showcasing the potential of deep learning for improving healthcare outcomes.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/249136c5d20c9302154ff4eddc6976386443afd0",
        "citation_count": 0
    },
    {
        "title": "Machine Learning-based Model for Early Prediction of Coronary Artery Disease",
        "abstract": "The global healthcare industry manages millions of individuals and generates enormous amounts of data. Machine learning-based algorithms are analysing complex medical information and produce superior insights. \u201cCoronary artery disease (CAD)\u201d, the most prevalent form of cardiac disease is getting the greatest interest in the development of predictive models due to its large number of modifiable risk factors. This research study aims at comparing five algorithms of supervised machine learning for the CAD prediction. The research utilizes the Cleveland dataset from the UCI repository for training and testing the algorithms. The results of the comparison revealed that KNN is the best algorithm with significant performance measures which can be effective in predicting CAD accurately. Therefore, it can be suggested that these predictive models, which were developed using machine learning (ML) algorithms, can help doctors identify CAD early and may lead to better results that would help to avoid adverse clinical outcomes.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/24a07e20ec62edfb228a311d21373ebedf7a6c7a",
        "citation_count": 0
    },
    {
        "title": "A Human-in-the-loop Perspective on AutoML: Milestones and the Road Ahead",
        "abstract": "Machine learning (ML) has gained widespread adoption in a variety of real-world problem domains, ranging from business, to healthcare, to agriculture. However, the development of effective ML solutions requires highlyspecialized experts well-versed in both statistics and programming. This high barrier-of-entry stems from the current process of crafting a customized ML solution, which often involves numerous manual iterative changes to the ML workflow, guided by knowledge or intuition of how those changes impact eventual performance. This cumbersome process is a major pain point for machine learning practitioners [4, 53] and has motivated our prior work on Helix, a declarative ML framework [52] targeted at supporting efficient iteration. To make ML more accessible and effortless, there has been recent interest in AutoML systems, both in industry [2, 1, 21] and in academia [15, 37], that automatically search over a predefined space of ML models for some high-level goal, such as prediction of a target variable. For certain tasks, these systems have been shown to generate models with comparable or better performance than those generated by human ML experts in the same time [35, 26]. However, our preliminary study of ML workflows on OpenML [48] (an online platform for experimenting with and sharing ML workflows and results) shows that AutoML is not widely adopted in practice\u2014accounting for fewer than 2% of all users and workflows. While this may be due to a lack of awareness of these tools, we believe that this sparse usage stems from a more fundamental issue: a lack of usability. Our main observation is that the fully-automated setting that current AutoML systems operate on may not be a one-size-fits-all solution for many users and problem domains. Recent work echoes our sentiment that AutoML\u2019s complete automation over model choices may be inadequate in certain problem contexts [18, 50]. The lack of human control and interpretability is particularly problematic when the user\u2019s domain knowledge may influence the choice of workflow [18], in high-stakes decision-making scenarios where trust and transparency are essential [50], and in exploratory situations where the problem is not well-defined [11]. This trade-off between control and automation has been a century-long debate in HCI [23, 22, 44, 5], with modern reincarnations arising in conversational agents, interactive visual analytics, and autonomous driving. A common interaction paradigm to reconcile these two approaches is a mixed-initiative approach, where \u201cintelligent services and users...collaborate efficiently to achieve the user\u2019s goals\u201d [23]. Along the footsteps of these seminal papers, here, we outline our vision for a Mixed-Initiative machine Learning Environment (MILE), by rethinking the role that automation and human supervision play across the ML development lifecycle. MILE enables a better user experience, and benefits from system optimizations that both leverage human input and are tailored to the fact that MILE interacts with a human in the loop. For example, our earlier work HELIX [52] leveraged the fact that workflow development happens iteratively, to intelligently materialize and reuse intermediate data products to speed up subsequent iterations. Similarly, as discussed later in this paper, leveraging user domain knowledge has the potential to drastically narrow down the exhaustive search space typically employed by existing AutoML systems.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/24bb20608df98963d9c706c3e44db0c126573264",
        "citation_count": 57
    },
    {
        "title": "Value of hospital resources for effective pressure injury prevention: a cost-effectiveness analysis",
        "abstract": "Objective Hospital-acquired pressure injuries are localised skin injuries that cause significant mortality and are costly. Nursing best practices prevent pressure injuries, including time-consuming, complex tasks that lack payment incentives. The Braden Scale is an evidence-based stratification tool nurses use daily to assess pressure-injury risk. Our objective was to analyse the cost-utility of performing repeated risk-assessment for pressure-injury prevention in all patients or high-risk groups. Design Cost-utility analysis using Markov modelling from US societal and healthcare sector perspectives within a 1-year time horizon. Setting Patient-level longitudinal data on 34\u2009787 encounters from an academic hospital electronic health record (EHR) between 2011 and 2014, including daily Braden scores. Supervised machine learning simulated age-adjusted transition probabilities between risk levels and pressure injuries. Participants Hospitalised adults with Braden scores classified into five risk levels: very high risk (6\u20139), high risk (10\u201311), moderate risk (12\u201314), at-risk (15\u201318), minimal risk (19\u201323). Interventions Standard care, repeated risk assessment in all risk levels or only repeated risk assessment in high-risk strata based on machine-learning simulations. Main outcome measures Costs (2016 $US) of pressure-injury treatment and prevention, and quality-adjusted life years (QALYs) related to pressure injuries were weighted by transition probabilities to calculate the incremental cost-effectiveness ratio (ICER) at $100\u2009000/QALY willingness-to-pay. Univariate and probabilistic sensitivity analyses tested model uncertainty. Results Simulating prevention for all patients yielded greater QALYs at higher cost from societal and healthcare sector perspectives, equating to ICERs of $2000/QALY and $2142/QALY, respectively. Risk-stratified follow-up in patients with Braden scores <15 dominated standard care. Prevention for all patients was cost-effective in >99% of probabilistic simulations. Conclusion Our analysis using EHR data maintains that pressure-injury prevention for all inpatients is cost-effective. Hospitals should invest in nursing compliance with international prevention guidelines.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/24bdfa747bd949836725749037b08a1c94c0a61d",
        "citation_count": 105
    },
    {
        "title": "Artificial Intelligence (AI) in Medicine and Modern Healthcare Systems",
        "abstract": "The modern healthcare landscape involves collection, processing and analysis of large volumes of data, related to medicines, patient records, treatment paradigms, medical reports, immunization, and various other attributes. These data points need to be handled precisely and efficiently, as they lead to critical health decisions. The role of emerging technologies like AI, ML, Deep Learning, IoT and Robotics is gaining importance in handling such data using various algorithms. Each of these algorithms has a large number of applications in the healthcare domain, including decision on appropriate treatment journeys, analysis of medical reports, making informed clinical decisions, assistance in operational tasks at hospitals, tracking of vital signs, detection of diseases at an early stage and so on. Usage of such technologies introduces a level of automation in these medical procedures. Data can be accessed and analysed accurately and quickly. This also gives more time to health care professionals for patient care. However, it should be ensured that human supervision is maintained, so as to avoid any unexpected risk to patients. Also, human interaction and empathy is necessary for a patient's well-being and thus, not all medical processes should be performed by machines alone.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/24e6303a5aea4768d6c45bee4155a8a919e39098",
        "citation_count": 3
    },
    {
        "title": "Exploring the power of heterogeneous information sources",
        "abstract": "The big data challenge is one unique opportunity for both data mining and database research and engineering. A vast ocean of data are collected from trillions of connected devices in real time on a daily basis, and useful knowledge is usually buried in data of multiple genres, from different sources, in different formats, and with different types of representation. Many interesting patterns cannot be extracted from a single data collection, but have to be discovered from the integrative analysis of all heterogeneous data sources available. Although many algorithms have been developed to analyze multiple information sources, real applications continuously pose new challenges: Data can be gigantic, noisy, unreliable, dynamically evolving, highly imbalanced, and heterogeneous. Meanwhile, users provide limited feedback, have growing privacy concerns, and ask for actionable knowledge. In this thesis, we propose to explore the power of multiple heterogeneous information sources in such challenging learning scenarios. There are two interesting perspectives in learning from the correlations among multiple information sources: Explore their similarities (consensus combination), or their differences (inconsistency detection). \nIn consensus combination, we focus on the task of classification with multiple information sources. Multiple information sources for the same set of objects can provide complimentary predictive powers, and by combining their expertise, the prediction accuracy is significantly improved. However, the major challenge is that it is hard to obtain sufficient and reliable labeled data for effective training because they require the efforts of experienced human annotators. In some data sources, we may only have a large amount of unlabeled data. Although such unlabeled information do not directly generate label predictions, they provide useful constraints on the classification task. Therefore, we first propose a graph based consensus maximization framework to combine multiple supervised and unsupervised models obtained from all the available information sources. We further demonstrate the benefits of combining multiple models on two specific learning scenarios. In transfer learning, we propose an effective model combination framework to transfer knowledge from multiple sources to a target domain with no labeled data. We also demonstrate the robustness of model combination on dynamically evolving data. \nOn the other hand, when unexpected disagreement is encountered across diverse information sources, this might raise a red flag and require in-depth investigation. Another line of my thesis research is to explore differences among multiple information sources to find anomalies. We first propose a spectral method to detect objects performing inconsistently across multiple heterogeneous information sources as a new type of anomalies. Traditional anomaly detection methods discover anomalies based on the degree of deviation from normal objects in one data source, whereas the proposed approach detects anomalies according to the degree of inconsistencies across multiple sources. The principle of inconsistency detection can benefit many applications, and in particular, we show how this principle can help identify anomalies in information networks and distributed systems. We propose probabilistic models to detect anomalies in a social community by comparing link and node information, and to detect system problems from connected machines in a distributed systems by modeling correlations among multiple machines. \nIn this thesis, we go beyond the scope of traditional ensemble learning to address challenges faced by many applications with multiple data sources. With the proposed consensus combination framework, labeled data are no longer a requirement for successful multi-source classification, instead, the use of existing labeling experts is maximized by integratingknowledge from relevant do- mains and unlabeled information sources. The proposed concept of inconsistency detection across multiple data sources opens up a new direction of anomaly detection. The detected anomalies, which cannot be found by traditional anomaly detection techniques, provide new insights into the application area. The algorithms we developed have been proved useful in many areas, including social network analysis, cyber-security, and business intelligence, and have the potential of being applied to many other areas, such as healthcare, bioinformatics, and energy efficiency. As both the amount of data and the number of sources in our world have been exploding, there are still great opportunities as well as numerous research challenges for inference of actionable knowledge from multiple heterogeneous sources of massive data collections.",
        "year": 2011,
        "url": "https://www.semanticscholar.org/paper/25258f31cf33a1fabb8c119dded75abb9110b571",
        "citation_count": 2
    },
    {
        "title": "OSTEO-AI: A Systematic Review and Meta-Analysis of Artificial Intelligence Models for Osteoarthritis and Osteoporosis Detection and Prognosis",
        "abstract": "Introduction: Osteoarthritis (OA) and osteoporosis are leading degenerative bone diseases that diminish quality of life and impose significant socioeconomic costs. Traditional diagnostic approaches, including imaging and bone density assessments, often fail to detect disease in its early stages, delaying critical interventions. Emerging artificial intelligence (AI) techniques, particularly those employing machine learning (ML) and deep learning (DL), offer promising avenues for early detection and more accurate prognostication.\nMethods: We conducted a systematic review of AI models developed between 2018 and 2024, assessing their performance in diagnosing and predicting the progression of OA and osteoporosis. Studies utilizing supervised or unsupervised methods applied to imaging modalities (e.g., X-ray, MRI, DXA) or clinical data were included. We evaluated model accuracy, reliability, clinical applicability, and generalizability. Quality and risk of bias were assessed using a modified CLAIM framework, ensuring alignment with transparency, validity, and clinical integration standards.\nResults: Of 2,300 identified articles, 33 studies met the inclusion criteria. Top-performing models for OA reached up to 97% accuracy, with one study achieving an AUC of 0.93 for MRI-based progression prediction. For osteoporosis, the strongest models attained a C-index of 0.90 using DXA imaging, indicating robust fracture risk prediction. Nevertheless, many studies relied on geographically or demographically homogeneous datasets, limiting broader applicability. Only 15% included external validation, and a substantial proportion lacked interpretability features essential for clinical adoption.\nDiscussion: AI-driven models outperformed conventional diagnostic tools in accuracy and early disease detection. However, the limited dataset diversity, infrequent external validation, and insufficient model interpretability pose barriers to clinical integration. The reliance on male-dominant datasets for osteoporosis and geographically narrow cohorts for OA underscores the need for broader data representation. Standardizing evaluation metrics and improving explainability will enhance cross-study comparisons and support adoption in practice. \nConclusion: AI holds transformative potential for improving OA and osteoporosis diagnostics, facilitating earlier interventions, and informing personalized patient management. Future work should prioritize diverse, well-validated datasets; transparent, clinician-friendly interfaces; and standardized performance metrics. Addressing these challenges will enable AI to evolve from a promising innovation into a cornerstone of global musculoskeletal healthcare.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/257097c2f0ceeef9cab97cdd153d7e4d2e5d538c",
        "citation_count": 0
    },
    {
        "title": "Machine Learning in Workflow Optimization",
        "abstract": "This paper delves into the integration of machine literacy algorithms to enhance effectiveness, productivity, and decision-making in workflow operations. By using prophetic analytics and real-time data processing, machine literacy models can identify patterns and prognosticate implicit backups, enabling visionary adaptations and resource allocation. This exploration focuses on the operation of supervised and unsupervised literacy ways to streamline complex workflows, reduce functional costs, and ameliorate overall performance. crucial case studies from manufacturing, healthcare, and logistics demonstrate the practical benefits of these technologies. The findings punctuate the transformative eventuality of machine literacy in creating adaptive and intelligent workflow systems that can stoutly respond to changing conditions and demands. This study contributes to the growing body of knowledge on the crossroads of machine literacy and workflow optimization, offering perceptivity and strategies for perpetration in different functional surroundings.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/2584a10203e82b478012e1f9564637f1ea97ded2",
        "citation_count": 0
    },
    {
        "title": "Supervised fusion content-based framework for breakdown detection in task-oriented conversational systems",
        "abstract": "Conversational agents (CAs) have been widely used for many domains, such as healthcare, education, and business. One main category of CAs is task-oriented CAs, which aim to help users to complete a set of specific tasks. However, task-oriented CAs can fail to answer the user\u2019s question, which can lead to a breakdown in the dialogue (when it is not possible to complete a conversation with a CA). Breakdown detection is an essential task for developing better CAs. Several related studies have focused on breakdown detection using different sets of features, for example, topic transition, word-based similarity and clustering; but, the existing studies develop features mainly from the system\u2019s outputs or user\u2019s inputs, whereas the features can be extracted from both sides, as well as from the interaction between them. Therefore, in this work, we developed a new supervised fusion machine learning (ML) model that combines the prediction from two machine learning algorithms for breakdown detection CAs services system. We developed features from different groups focusing on both the user input and the system response. Then we select the optimal combined features. The features are based on sentence similarity, sentiment features, and count-based features. The developed fusion model is mainly based on the two best performances of the single classifiers (SVM and RF). We explore several single ML algorithms using different sets of features and the combined features. To verify the effectiveness of the proposed fusion model, we compared the proposed models against baseline methods using four sets of data. We conclude that the proposed fusion model with the combined features outperforms the baselines and all other models in terms of prediction accuracy and f-score measures.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/25bf6fe0e4cc7d863ab825cbff8ca98bfe88a3a4",
        "citation_count": 0
    },
    {
        "title": "Utilizing machine learning to predict hospital admissions for pediatric COVID-19 patients (PrepCOVID-Machine)",
        "abstract": null,
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/25d50ae40604ca8341f689738cac3bec0f618e82",
        "citation_count": 0
    },
    {
        "title": "Rule-Based Prediction of Medical Claims' Payments: A Method and Initial Application to Medicaid Data",
        "abstract": "Imperfections in healthcare revenue cycle management systems cause discrepancies between submitted claims and received payments. This paper presents a method for deriving attributional rules that can be used to support the preparation and screening of claims prior to their submission to payers. The method starts with unsupervised analysis of past payments to determine normal levels of payments for services. Then, supervised machine learning is used to derive sets of attributional rules for predicting potential discrepancies in claims. New claims can be then classified using the created models. The method was tested on a subset of Obstetrics claims for payment submitted by one hospital to Medicaid. One year of data was used to create models, which were tested using the following year's data. Results indicate that rule-based models are able to detect abnormal claims prior to their submission.",
        "year": 2011,
        "url": "https://www.semanticscholar.org/paper/25d8519d03a85e8ec3fca2ea8539e38ff7dda162",
        "citation_count": 12
    },
    {
        "title": "My Son, My Interpreter",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/26460896233b46c707ddf3550dd3128cd01d5989",
        "citation_count": 1
    },
    {
        "title": "Sparsifying machine learning models identify stable subsets of predictive features for behavioral detection of autism",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/267859c822c7c946f5e896557a643c11d37842a5",
        "citation_count": 82
    },
    {
        "title": "Prospects of Machine Learning With Blockchain in Healthcare and Agriculture",
        "abstract": "Presently, machine learning (ML) techniques have gained considerable attention, with growing interest in various areas and applications. Healthcare, agriculture, and bioinformatics are the most identified areas to study with the help of ML. This chapter introduces about the basic principle of ML such as data, model, basic mathematical details of ML, and types of learning. The important aspect of ML is \u201chow to teach a machine.\u201d This chapter focuses on the types of learning: supervised, unsupervised, semi-supervised, and reinforcement learning. Some commonly used ML algorithms such as decision tree (DT), k-nearest neighbor (KNN), support vector machine (SVM), na\u00efve Bayes, k-mean, q-learning, etc. are briefly discussed for understanding. Finally, the author offers the application of ML with blockchain that is reforming the traditional healthcare and agricultural sector to a more reliable means.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/271dfc1f7a6005a1fc8d3d52afba30e5df940fb4",
        "citation_count": 2
    },
    {
        "title": "Research on the Application of Machine Learning in Cancer Prediction and Diagnosis",
        "abstract": "Due to the continuous development and advancement of artificial intelligence technology, the application of machine learning in the medical field, particularly in cancer treatment and prediction, is becoming increasingly widespread and profound. By utilizing machine learning algorithms, healthcare professionals can analyze large volumes of medical data more accurately through specific models. This paper discusses the application of machine learning in cancer diagnosis and treatment, with special attention to prediction, diagnosis and treatment. By analyzing a large number of clinical and genomic data, machine learning, which provides support for early diagnosis, reveals the complex pattern of cancer development. Deep learning technology can help doctors diagnose and predict cancer more accurately in medical image analysis and genome data analysis. Ensemble learning methods such as the random forest model improve the accuracy of prediction. It also introduces semi supervised learning, which provides a new perspective for cancer prediction: enhancing model training by using unlabeled data. The paper also introduces the application of cox-net and survival support vector machine in survival analysis.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/272abb9eca717d0ddeefe0eee8c1910cf18ee146",
        "citation_count": 0
    },
    {
        "title": "AI system for fetal ultrasound in low-resource settings",
        "abstract": "Despite considerable progress in maternal healthcare, maternal and perinatal deaths remain high in low-to-middle income countries. Fetal ultrasound is an important component of antenatal care, but shortage of adequately trained healthcare workers has limited its adoption. We developed and validated an artificial intelligence (AI) system that uses novice-acquired \u201cblind sweep\u201d ultrasound videos to estimate gestational age (GA) and fetal malpresentation. We further addressed obstacles that may be encountered in low-resourced settings. Using a simplified sweep protocol with real-time AI feedback on sweep quality, we have demonstrated the generalization of model performance to minimally trained novice ultrasound operators using low cost ultrasound devices with on-device AI integration. The GA model was non-inferior to standard fetal biometry estimates with as few as two sweeps, and the fetal malpresentation model had high AUC-ROCs across operators and devices. Our AI models have the potential to assist in upleveling the capabilities of lightly trained ultrasound operators in low resource settings. Introduction Despite considerable progress in maternal healthcare in recent decades, maternal and perinatal deaths remain high with 295,000 maternal deaths during and following pregnancy and 2.4 million neonatal deaths each year. The majority of these deaths occur in low-to-middle-income countries (LMICs).1\u20133 The lack of antenatal care and limited access to facilities that can provide lifesaving treatment for the mother, fetus and newborn contribute to inequities in quality of care and outcomes in these regions.4,5 Obstetric ultrasound is an important component of quality antenatal care. The WHO recommends one routine early ultrasound scan for all pregnant women, but up to 50% of women in developing countries receive no ultrasound screening during pregnancy.6 Fetal ultrasounds can be used to estimate gestational age (GA), which is critical in scheduling and planning for screening tests throughout pregnancy and interventions for pregnancy complications such as preeclampsia and preterm labor. Fetal ultrasounds later in pregnancy can also be used to diagnose fetal malpresentation, which affects up to 3-4% of pregnancies at term and is associated with trauma-related injury during birth, perinatal mortality, and maternal morbidity.7\u201311 Though ultrasound devices have traditionally been costly, the recent commercial availability of low-cost, battery powered handheld devices could greatly expand access.12,13,14 However, current ultrasound training programs require months of supervised evaluation as well as indefinite continuing education visits for quality assurance.13\u201318 To address these barriers, prior studies have introduced a protocol where fetal ultrasounds can be acquired by minimally trained operators via a \u201cblind sweep\u201d protocol, consisting of 6 predefined freehand sweeps over the abdomen.19\u201323 In this study, we used two prospectively collected fetal ultrasound datasets to estimate gestational age and fetal malpresentation while demonstrating key considerations for use by novice users in LMICs: a) validating that it is possible to build blind sweep GA and fetal malpresentation models that run in real-time on mobile devices; b) evaluating generalization of these models to minimally trained ultrasound operators and low cost ultrasound devices; c) describing a modified 2-sweep blind sweep protocol to simplify novice acquisition; d) adding feedback scores to provide real-time information on sweep quality. Blind sweep procedure Blind sweep ultrasounds consisted of a fixed number of predefined freehand ultrasound sweeps over the gravid abdomen. Certified sonographers completed up to 15 sweeps. Novice operators (\u201cnovices\u201d), with 8 hours of blind sweep ultrasound acquisition training, completed 6 sweeps. Evaluation of both sonographers and novices was limited to a set of 6 sweeps 3 vertical and 3 horizontal sweeps (Figure 1B). Fetal Age Machine Learning Initiative (FAMLI) and Novice User Study Datasets Data was analyzed from the Fetal Age Machine Learning Initiative cohort, which collected ultrasound data from study sites at Chapel Hill, NC (USA) and the Novice User Study collected from Lusaka, Zambia (Figure 1A).24 The goal of this prospectively collected dataset was to empower development of technology to estimate gestational age.25 Data collection occurred between September 2018 and June 2021. All study participants provided written informed consent, and the research was approved by the UNC institutional review board and the biomedical research ethics committee at the University of Zambia. Studies also included standard clinical assessments of GA and fetal malpresentation performed by a trained sonographer.26 Blind sweep data were collected with standard ultrasound devices (SonoSite M-Turbo or GE Voluson) as well as a low cost portable ultrasound device (ButterflyIQ). Evaluation was performed on the FAMLI (sonographer-acquired) and Novice User Study (novice-acquired) datasets. Test sets consisted of patients independent of those used for AI development (Figure 1A). For our GA model evaluation, the primary FAMLI test set comprised 407 women in 657 study visits in the USA. A second test set, \u201cNovice User Study\u201d included 114 participants in 140 study visits in Zambia. Novice blind sweep studies were exclusively performed at Zambian sites. Sweeps collected with standard ultrasound devices were available for 406 of 407 participants in the sonographer-acquired test set, and 112 of 114 participants in the novice-acquired test set. Sweeps collected with the low cost device were available for 104 of 407 participants in the sonographer-acquired test set, and 56 of 114 participants in the novice-acquired test set. Analyzable data from the low cost device became available later during the study, and this group of patients is representative of the full patient set. We randomly selected one study visit per patient for each analysis group to avoid combining correlated measurements from the same patient. For our fetal malpresentation model, the test set included 613 patients from the sonographer-acquired and novice-acquired datasets, resulting in 65 instances of non-cephalic presentation (10.6%). For each patient, the last study visit of the third trimester was included. Of note, there are more patients in the malpresentation model test set since the ground truth is not dependent on a prior visit. The disposition of study participants are summarized in STARD diagrams (Extended Data Figure 1) and Extended Data Table 1. Mobile-device-optimized AI gestational age and fetal malpresentation estimation We calculated the mean difference in absolute error between the GA model estimate and estimated gestational age as determined by standard fetal biometry measurements using imaging from traditional ultrasound devices operated by sonographers.26 The reference ground truth GA was established as described above (Figure 1A). When conducting pairwise statistical comparisons between blind sweep and standard fetal biometry absolute errors, we established an a priori criterion for non-inferiority which was confirmed if the blind sweep mean absolute error (MAE) was less than 1.0 day greater than the standard fetal biometry\u2019s MAE. Statistical estimates and comparisons were computed after randomly selecting one study visit per patient for each analysis group, to avoid combining correlated measurements from the same patient. We conducted a supplemental analysis of GA model prediction error with mixed effects regression on all test data, combining sonographer-acquired and novice-acquired test sets. Fixed effect terms accounted for the ground truth GA, the type of ultrasound machine used (standard vs. low cost), and the training level of the ultrasound operator (sonographer vs. novice). All patient studies were included in the analysis, and random effects terms accounted for intra-patient and intra-study effects. GA analysis results are summarized in Table 1. The MAE for the GA model estimate with blind sweeps collected by sonographers using standard ultrasound devices was significantly lower than the MAE for the standard fetal biometry estimates (mean difference -1.4 \u00b1 4.5 days, 95% CI -1.8, -0.9 days). There was a trend towards increasing error for bind sweep and standard fetal biometry procedures with gestational week (Figure 2, top left). The accuracy of the fetal malpresentation model for predicting non-cephalic fetal presentation from third trimester blind sweeps was assessed using a reference standard determined by sonographers equipped with traditional ultrasound imagery (described above). We selected the latest study visit in the third trimester for each patient. Data from sweeps performed by the sonographers and novices were analyzed separately. We evaluated the fetal malpresentation model\u2019s area under the receiver operating curve (AUC-ROC) on the test set in addition to non-cephalic sensitivity and specificity. The fetal malpresentation model attained an AUC-ROC of 0.977 (95% CI 0.949, 1.00), sensitivity of 0.938 (95% CI 0.848, 0.983), and specificity of 0.973 (95% CI 0.955, 0.985) (Table 2 and Figure 3). Generalization of GA and malpresentation estimation to novices Our models were trained on up to 15 blind sweeps per study performed by sonographers. No novice-acquired blind sweeps were used to train our models. We assessed GA model generalization to blind sweeps performed by novice operators that performed 6 sweeps. We compared the MAE between novice-performed blind sweep AI estimates and the standard fetal biometry. For the malpresentation model, we reported the AUC-ROC for blind sweeps performed by novices, along with the sensitivity and specificity at the same operating point used for evaluating blind sweeps performed by sonographers. In this novice-acquired dataset, the difference in MAE between blind sweep AI estimates and the standard fetal bio",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/27334b92dd5ce4af3769c553dfa4dff7bed4a5d2",
        "citation_count": 2
    },
    {
        "title": "Artificial Intelligence and Machine Learning in Healthcare",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/276b72329076a2aedb552f310bb5bbd5168a9a0f",
        "citation_count": 15
    },
    {
        "title": "Long-term follow-up of hydrocephalus patients and prediction of risk factors using machine learning",
        "abstract": "Hydrocephalus is a disorder when an excessive amount of cerebrospinal fluid (CSF) accumulates inside the subarachnoid space, which can lead to an enlargement of the ventricular system of the brain and increase the pressure inside the head. Paediatric population, adults, and most elderly ones can be affected by hydrocephalus. This neurological condition can have an excellent diagnosis if treated. However, it also can be life threatening if not treated correctly. With the increasing roll-out of \u2018digital hospitals\u2019, electronic medical records, new data capture and analysis technologies, as well as a digitally enabled health consumer, the healthcare workforce is required to become digitally literate to manage the significant changes in the healthcare landscape. In this study, Machine learning techniques are employed for the long-term follow-up for hydrocephalus patients, for which a data set of 3,262 records of ICP signals of shunted patients from Alder Hey Hospital, was used. Six popular machine-learning based classifiers have been evaluated for the classification of monitoring shunted patients and produce the required risk assessments to follow up shunted patients within a supervised learning setting, which are Ensemble Bagged Tree, Ensemble Boosted Tree, Fine Tree, Quadratic SVM, Gaussian SVM and Cubic SVM. The classifier Ensemble Boosted Tree achieved the highest aggregate performance outcomes of accuracy 98.90, sensitivity 100, specificity 100 and precision of 100. The study concludes that using machine learning techniques represents an alternative procedure that could assist healthcare professionals, as well as the specialist nurse and junior doctor to improve the quality of care and follow-up with hydrocephalus disorder.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/277f42691eb8ffb92a2ea1868ada4e4bceb3f752",
        "citation_count": 0
    },
    {
        "title": "Looking Beyond Historical Patient Outcomes to Improve Clinical Models",
        "abstract": "Clinical models can be improved by decreasing the importance assigned to fitting historical patient outcomes in often small and imperfectly characterized derivation cohorts. When Less Is More Clinical models play an important role in guiding patient care at the bedside, improving our understanding of diseases, and performing objective assessments of healthcare quality. The typical approach to developing these models places great importance on fitting historical patient outcomes in derivation data sets (such as those obtained from clinical studies or patient registries). However, for a fairly broad range of medical applications, these derivation data sets may be small after accounting for inclusionary and exclusionary criteria, and additionally may be imperfectly characterized due to noise and variations in the rates of patient outcomes. Collecting more data offers one approach to address this issue, but is challenging due to the costs and complexity of increasing the size of clinical cohorts. In the setting of small and imperfectly characterized data sets, approaches to developing clinical models that rely exclusively on fitting historical patient outcomes suffer from the implicit assumption that the derivation data sets are representative. Instead, as the new study by Chia et al. explores, the process of developing clinical models can be improved by decreasing the importance placed on fitting historical patient outcomes, and by supplementing these models with information about the extent to which patients differ from the statistical distribution of clinical characteristics within the derivation data set. When evaluated using data from three different clinical applications [patients with acute coronary syndrome enrolled in the DISPERSE2-TIMI33 and MERLIN-TIMI36 trials, patients undergoing inpatient surgery in the National Surgical Quality Improvement Program (NSQIP) registry, and patients undergoing percutaneous coronary intervention in the Blue Cross Blue Shield of Michigan Cardiovascular Consortium (BMC2) registry], this approach of treating derivation data for clinical models as simultaneously labeled and unlabeled consistently improved discrimination between high- and low-risk patients according to different statistical metrics. The idea of decreasing the importance assigned to fitting historical outcomes allows for better clinical models, and ultimately for improvements in the use of these models to study diseases, choose therapies, or evaluate healthcare providers. Conventional algorithms for modeling clinical events focus on characterizing the differences between patients with varying outcomes in historical data sets used for the model derivation. For many clinical conditions with low prevalence and where small data sets are available, this approach to developing models is challenging due to the limited number of positive (that is, event) examples available for model training. Here, we investigate how the approach of developing clinical models might be improved across three distinct patient populations (patients with acute coronary syndrome enrolled in the DISPERSE2-TIMI33 and MERLIN-TIMI36 trials, patients undergoing inpatient surgery in the National Surgical Quality Improvement Program registry, and patients undergoing percutaneous coronary intervention in the Blue Cross Blue Shield of Michigan Cardiovascular Consortium registry). For each of these cases, we supplement an incomplete characterization of patient outcomes in the derivation data set (uncensored view of the data) with an additional characterization of the extent to which patients differ from the statistical support of their clinical characteristics (censored view of the data). Our approach exploits the same training data within the derivation cohort in multiple ways to improve the accuracy of prediction. We position this approach within the context of traditional supervised (2-class) and unsupervised (1-class) learning methods and present a 1.5-class approach for clinical decision-making. We describe a 1.5-class support vector machine (SVM) classification algorithm that implements this approach, and report on its performance relative to logistic regression and 2-class SVM classification with cost-sensitive weighting and oversampling. The 1.5-class SVM algorithm improved prediction accuracy relative to other approaches and may have value in predicting clinical events both at the bedside and for risk-adjusted quality of care assessment.",
        "year": 2012,
        "url": "https://www.semanticscholar.org/paper/27bb3123f410d1624f888f63b14c33425d4a7c5d",
        "citation_count": 22
    },
    {
        "title": "Prediction of Diabetes in Females of Pima Indian Heritage: A Complete Supervised Learning Approach",
        "abstract": "Nowadays, diabetes is a common disease that affects millions of people over the world, and women are mostly affected by this disease. Recent healthcare studies have applied various innovative and advanced technologies to diagnose people and predict their disease based on clinical data. One of such technologies is machine learning (ML) in which diagnosis and prediction can be made more accurately. In this paper, the designed model predicts the diabetes of females of Pima Indians heritage by taking the clinical dataset. Here, this problem is considered as a binary classification problem. Therefore, supervised learning algorithms have been used, such as classification tree (CT), support vector machine (SVM), k-Nearest Neighbour (k-NN), Naive Bayes (NB), Random Forest (RF), Neural Network (NN), AdaBoost (AB) and Logistic Regression (LR). We use the female Pima Indians diabetic dataset from Kaggle and UCI data repository and k-fold cross-validation to carry out the process of training and testing. We determine the area under the curve (AUC), classification accuracy (CA), F1, precision and recall results of all the supervised learning algorithms and compare them to determine the best algorithm that is suitable for prediction. For this, we use the Orange 3.24.1 open-source platform to generate the results, which uses Python open-source libraries. From the results, it is concluded that the LR performs better in comparison to other algorithms",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/27eda78b305168c7445cdc12e6a37a05ea24a5cc",
        "citation_count": 27
    },
    {
        "title": "Learn Feature Representation from Unlabeled Data using Self-Supervised Learning",
        "abstract": "In the recent past, promising performance is achieved by supervised deep learning networks in various domains like computer vision, machine translation, speech recognition, natural language processing (NLP), etc. But current deep-learning approaches required a large amount of manual data to achieve promising performance. However, manual annotation of data is time-consuming and needs human expertise, which is always not possible in a domain like healthcare. Recently an alternative method called Self Supervised Learning (SSL), uses unlabeled data and does not require manual annotation. With the help of a pretext task, SSL extracts and learns features from the unlabeled data, enabling models trained for these tasks to acquire latent representations that enhance subsequent tasks like object detection and classification. In this work, the unlabeled data is fed to the convolution neural network (CNN), which learns features and transfers them to the downstream task to generate the labeled data. The experiments are conducted on the fashion MNIST dataset in a self-supervised learning environment and a comparison is made with a different size of training data and the rotation pretext task approach is compared with SimCLR approach of contrastive learning which achieve state-of-art performance. Another experiment performs on Chest X-ray dataset, COVID-19 CT Scan dataset using SimCLR and other methods of contrastive learning. The experiment concludes that contrastive learning of self-supervised learning achieves better performance over rotation pretext task of self-supervised learning. The self-supervised learning environment is preferable in various domains where human annotation for labeling datasets is very costly or not feasible.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/28298a9bb4ee5bcff15c243d1897ba60f89fdcfa",
        "citation_count": 0
    },
    {
        "title": "Computational Genomics: Theory and Application",
        "abstract": "Networks.-Pattern Recognition.- Image Processing.- Intelligent Computing in Robotics.- Intelligent Control and Automation.- Intelligent Data Analysis and Prediction.- Fuzzy Theory and Algorithms.- Supervised Learning.-Unsupervised Learning.- Kernel Methods and Supporting Vector Machines.- Knowledge Discovery and Data Mining.- Natural Language Processing and Computational Linguistics.- Gene Expression Array Analysis.-Systems Biology.- Computational Genomics.- Computational Proteomics.- Gene Regulation Modeling and Analysis.- Protein-Protein Interaction Prediction.- Next-Gen Sequencing and Metagenomics.- Structure Prediction and Folding.- Evolutionary Optimization for Scheduling.- High-Throughput Biomedical Data Integration and Mining.- Machine Learning Algorithms and Applications.- Heuristic Optimization Algorithms for Real-World Applications.- Evolutionary Multi-Objective Optimization and Its Applications.- Swarm Evolutionary Algorithms for Scheduling and Combinatorial.- Optimization.- Swarm Intelligence and Applications in Combinatorial Optimization.- Advances in Metaheuristic Optimization Algorithm.- Advances in Image Processing and Pattern Recognition Techniques.- AI in Biomedicine.- Bioinformatics.- Biometrics Recognition.- Information Security.- Virtual Reality and Human-Computer Interaction.- Healthcare Informatics Theory and Methods.- Intelligent Computing in Computer Vision.- Intelligent Agent and Web Applications.-Reinforcement Networks.-Pattern Recognition.- Image Processing.- Intelligent Computing in Robotics.- Intelligent Control and Automation.- Intelligent Data Analysis and Prediction.- Fuzzy Theory and Algorithms.- Supervised Learning.-Unsupervised Learning.- Kernel Methods and Supporting Vector Machines.- Knowledge Discovery and Data Mining.- Natural Language Processing and Computational Linguistics.- Gene Expression Array Analysis.-Systems Biology.- Computational Genomics.- Computational Proteomics.- Gene Regulation Modeling and Analysis.- Protein-Protein Interaction Prediction.- Next-Gen Sequencing and Metagenomics.- Structure Prediction and Folding.- Evolutionary Optimization for Scheduling.- High-Throughput Biomedical Data Integration and Mining.- Machine Learning Algorithms and Applications.- Heuristic Optimization Algorithms for Real-World Applications.- Evolutionary Multi-Objective Optimization and Its Applications.- Swarm Evolutionary Algorithms for Scheduling and Combinatorial.- Optimization.- Swarm Intelligence and Applications in Combinatorial Optimization.- Advances in Metaheuristic Optimization Algorithm.- Advances in Image Processing and Pattern Recognition Techniques.- AI in Biomedicine.- Bioinformatics.- Biometrics Recognition.- Information Security.- Virtual Reality and Human-Computer Interaction.- Healthcare Informatics Theory and Methods.- Intelligent Computing in Computer Vision.- Intelligent Agent and Web Applications.-Reinforcement Learning.- Machine Learning.- Modeling, Simulation, and statistical computing using R. The book also presents a case-based discussion on clinical, veterinary, agricultural bioinformatics, and computational bioengineering for application-based learning in the respective \ufb01elds. Further, it o\ufb00ers readers guidance on reconstructing and analysing biological networks and highlights computational methods used in systems medicine and genome-wide association mapping of diseases. Given its scope, this textbook o\ufb00ers an essential introductory book on bioinformatics and computational biology for undergraduate and graduate students in the life sciences, botany, zoology, physiology, biotechnology, bioinformatics, and genomic science as well as systems biology, bioengineering and the agricultural, and veterinary sciences. Proteomics, epigenomics, and pharmacogenomics Toxicogenomics and the assessment of environmental pollutants Applications of plant metabolomics Nutrigenomics and its therapeutic applications Microalgal omics and omics approaches in biofuel production Next-generation sequencing and omics technology for transgenic plant analysis Omics approaches in crop improvement Engineering dark-operative chlorophyll synthesis for detection Environomics strategies for environmental sustainability This timely book explores a wide range of omics application areas in the biomedical, agricultural, and environmental sciences. Throughout, it highlights working solutions as well as open problems and future challenges. Demonstrating the diversity of omics, it introduces readers to state-of-the-art developments and trends in omics-driven research. to be held in Missoula, MT, USA in June 2021. Due to the pandemic, 2020 and AlCoB 2021 were merged and held on these dates together. AlCoB 2020 proceedings were published as LNBI 12099. The 12 full papers included in this volume were carefully reviewed and selected from 22 submissions. They were organized in topical sections on genomics, phylogenetics, and RNA-Seq and other biological processes. The scope of AlCoB includes topics of either theoretical or applied interest, namely: sequence analysis; sequence alignment; sequence assembly; genome rearrangement; regulatory motif \ufb01nding; phylogeny reconstruction; phylogeny structure compressive genomics; proteomics: molecular pathways, interaction networks, mass spectrometry analysis; transcriptomics: splicing isoform inference and quanti\ufb01cation, di\ufb00erential next-generation sequencing: population genomics, of either namely: exact sequence analysis, approximate sequence pairwise sequence \ufb01nding, how to e\ufb00ectively harness the power of Big Data tools when data sets are so large and complex that it is di\ufb03cult to process them using conventional database management systems or traditional data processing applications. Discusses the development and application of data-analytical and theoretical methods, mathematical modeling and computational simulation techniques to the study of biological and behavioral systems. Presents a systematic approach for storing, retrieving, organizing and analyzing biological data using software tools with applications. Provides a systems biology perspective including general guidelines and techniques for obtaining, integrating and analyzing complex data sets from multiple experimental sources using computational tools and software.",
        "year": 2005,
        "url": "https://www.semanticscholar.org/paper/283bbef3127f09c7e04f15bd75dc88539c1e9710",
        "citation_count": 18
    },
    {
        "title": "Developing a Predictive Health Care System for Diabetes Diagnosis as a Machine Learning-Based Web Service",
        "abstract": "Background: \nDiabetes is one of the dangerous and silent illnesses that cause sudden death. It can occur at any time and may cause great injury to the organs of the body or damage them completely. So, we must investigate this disease at the beginning of its appearance and before it gets hard to treat. With the fast advancement of Machine Learning (ML), these approaches enhanced the efficiency of decision processes in a wide range of applications, including medical diagnostics. \nMaterials and Methods: \nIn this paper, we chose a medical application field and used supervised machine learning algorithms to construct a high-accuracy prediction model for diabetes in humans at an early stage, before it progresses to the point of morbidity or fatality. The suggested model can extract hidden knowledge from diabetes-related data gathered from the Kaggle machine learning repository. We utilize Microsoft Azure ML Studio to model these ML algorithms. \nResults: \nThis study will benefit the health industry by offering users an online tool (i.e., web service) that allows them to input data and receive results that predict whether or not the person has diabetes. As a result, prior knowledge and ongoing monitoring of their diabetic health state will lower the risk of complications, morbidity, and death caused by this illness. After running numerous experiments with the classifier models to evaluate the proposed system, several performance indicators, including Recall, Precision, Accuracy, and f1-score, are measured for comparison. Based on the classification output, it was determined that Decision Forest is a better strategy and produces better results than the other ML approaches. \nConclusion: \nThe suggested system's key contribution is to improve healthcare quality, minimize hospitalizations, and lower the high expenditures of healthcare and drugs.\u00a0",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/28895295a2b7536c89db429b5c90be3d4d92ecbd",
        "citation_count": 8
    },
    {
        "title": "Author index",
        "abstract": "PUBLICATION TITLE ARTICLE TITLE SIGNATURE SIGNATURE DATE AUTHOR EMAIL ARTICLE IDENTIFIER A/V RECORDINGS PERMITTEDCOPYRIGHT TYPE PAYMENT STATUS M.Meghana , S.Radhika, V Sheeja Kumari 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Anomaly Detection for Vertical Plant Wall System using Novel Support Vector Machine in comparison with Linear Regression for improving accuracy V Sheeja Kumari 13-04-2023 sheejakumari.sse@saveetha.com 480908 Y IEEE N/A M. Meghana , S. Radhika, V Sheeja Kumari 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Anomaly Detection for Vertical Plant Wall System using Novel Support Vector Machine in Comparison with Artificial Neural Network for improving accuracy V Sheeja Kumari 13-04-2023 sheejakumari.sse@saveetha.com 480906 Y IEEE N/A Bhavanam Bhavya Sri , K.Anbazhagan, S Ramesh 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Iris Flower Species Identification Using Support Vector Machine Over Logistic Activation Function Ramesh S 13-04-2023 rameshsundars.sse@saveetha.com 480904 Y IEEE N/A Ms.Pavithra P, Dr.B.Hariharan 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) A replica-aware optimal path based data transfer scheduling on cloud using adaptive sunflower optimization algorithm P.Pavithra 13-04-2023 pp4752@srmist.edu.in 463154 Y IEEE N/A Mahalakshmi.B, Dr.D. Beulah David 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) An Analytical Survey on Multimodal-Biometric Authentication System for enhancing security levels in cloud computing mahalakshmi B 09-04-2023 jeevamaha.lakshmi@gmail.com 479877 Y IEEE N/A Veena K, Supriya S, D Deepa, J Cruz Antony, GM Karpura Dheepan, Ayila Sri Dharma Siva Pavan 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) PREDICTING HEALTH INSURANCE CLAIM FRAUDS USING SUPERVISED MACHINE LEARNING TECHNIQUE Veena K 08-04-2023 veenakanagaraj07@gmail.com 479885 Y IEEE N/A Vishnu P Parandhaman 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) An Automated Efficient and Robust Scheme in Payment Protocol Using the Internet of Things Vishnu P Parandhaman 08-04-2023 pingvishnu@gmail.com 479887 Y IEEE N/A John Nisha Anita,Sujatha Kumaran 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) A Novel and Robust Meningioma Tumor Identification using Modified Convolutional Neural Network John Nisha Anita 08-04-2023 nishusuban@gmail.com 479891 Y IEEE N/A Jayalakshmi.M, Dr. RajeshKumar R Savaliya, Prashant Atmakuri, Prof.M.V.RAMA PRASAD, Kafila, Kanika. 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) APPLICATION OF CLOUD COMPUTING AND BIG DATA IN ACCOUNTING SOFTWARE Jayalakshmi.M 08-04-2023 illavarason.p@gmail.com 479879 Y IEEE N/A D.Sridhar, L.V.N.Gowtham Pennaru, Navya ponnuri, K.V.B.Bhagya lakshmi, MD.Abbas Mubarak pasha. 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) A Novel and High-precise Approximate Multiplier With evolvable Truncation D.Sridhar 08-04-2023 illavarason.p@gmail.com 479881 Y IEEE N/A D.Sridhar, Bandreddi.Shanmukha Sai, Sripathi Vijaya, Chittibomma Hema, Dammu Venkata Jayasurya 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) NONVOLATILE DLATCH AND FLIP-FLOP DESIGNS BASED ON NEW MEMRISTOR TECHNOLOGY D.Sridhar 08-04-2023 illavarason.p@gmail.com 479883 Y IEEE N/A K.Jeevitha, Bindhu A, Sonia Jenifer Rayen, K. Vidhyalakshmi, Rajalakshmi. D, S. Agnes Shifani 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) An Attention Mechanism for Forest Tree Segmentation based on Efficient Convolutional Neural Networks K.Jeevitha 08-04-2023 kja.ece@rmkec.ac.in 479889 Y IEEE N/A D Bibiana Magdelene, A. Viji Amutha Mary, Mercy Paul Selvan, S. Jancy, L. Suji Helen 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Health care monitoring system with fall detection system. Dr. A. Viji Amutha Mary 03-04-2023 vijiamuthamary.cse@sathyabama.ac.in 465268 Y IEEE N/A N.Sri Sai Venkata Subba Rao, S.John Justin Thangaraj, V Sheeja Kumari, 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Flight Ticket Prediction Using Gradient Boosting Regressor Compared With Linear Regression V Sheeja Kumari 03-04-2023 sheejakumari.sse@saveetha.com 463190 Y IEEE N/A Arani Girish A. Shri Vindhya, M.Kalaiyarasi 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Improving Efficiency in Anticipating the spread of Covid based on Geographical Location Identification over Online Social Network Analysis using Novel LogisticRegression Algorithm comparing Random Forest Algorithm M.Kalaiyarasi 02-04-2023 kalaiyarasim.sse@saveetha.com 463196 Y IEEE N/A K. Likhitha, K. Sashi Rekha, M.Kalaiyarasi 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Improved Accuracy for Exploring Text Based Emotion Recognition in SocialMedia Conversation Generalized Linear Model Compared with Decision Tree M.Kalaiyarasi 02-04-2023 kalaiyarasim.sse@saveetha.com 463195 Y IEEE N/A Ganesh Reddy C, Anitha G 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Simulation and Comparison of Square SRR with TriangularSlot and Square SRR without Slot to Enhance the Return Lossand Bandwidth Performance for ITU Band Applications. shyamala bharathi 02-04-2023 shyamalabharathip.sse@saveetha.com 463356 Y IEEE N/A C.Gnaneswar Raju, V.Amudha, Sajiv.G 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Comparison of Linear Regression and Logistic Regression Algorithms for Ground Water Level Detection with Improved Accuracy Sajiv G 01-04-2023 sajivg2003.sse@saveetha.com 477352 Y IEEE N/A Murali N , D. Beulah David 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) A IOT Edge Advanced VANET Technique for Vehicle Communication and Improve Safety in Hill Station Critical Scenario N Murali 30-03-2023 muralin1001.sse@saveetha.com 463165 Y IEEE N/A Murali N , D. Beulah David 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Advanced VANET Technology for Emergency Vehicle Safety in Time-Critical Scenario N Murali 30-03-2023 muralin1001.sse@saveetha.com 463116 Y IEEE N/A P. Pavan V S N Manikanta, Dr.R.Bhavani , Dr. K. Anbazhagan 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Detecting Cyberbullying Behavior in Cyber Data using Bagging Classifier and Comparing its Capability over Support Vector Machine Algorithm DR. K. ANBAZHAGAN 30-03-2023 anbazhagank.sse@saveetha.com 463197 Y IEEE N/A Manoj.V , Devi.T , Dr. K. Anbazhagan 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Classification of Newspaper Article Classification by Employing Support Vector Machine in Comparison with Perceptron to Improve Accuracy DR. K. ANBAZHAGAN 30-03-2023 anbazhagank.sse@saveetha.com 463198 Y IEEE N/A Dr. E. Gopi ,Mrs. Benita MJ 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) An Investor\u2019s Opinion about Equity Market Gopi E 30-03-2023 ethirajgopi@gmail.com 463406 Y IEEE N/A Nanammal V, Jebastine J, Balajivasan R J 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Voting Machine for Blind and Amyotrophic Lateral Sclerosis People V.NANAMMAL 30-03-2023 sathyajeyamaruthi@gmail.com 463427 Y IEEE N/A Jebastine J, Nanammal V 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Reversible SAL Based Energy Efficient Design of CLA for DSP Application V.NANAMMAL 30-03-2023 sathyajeyamaruthi@gmail.com 462786 Y IEEE N/A Anitha.C, Gracelin Sheeba.R, Ranjith.S,Balachandran.G. 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Remodeling Arrangement of Embedded Benzene Structure Using OBAP & QBAP Algorithm to Design Mesh For Medical Application C.Anitha 30-03-2023 ccanitta@gmail.com 463403 Y IEEE N/A Sowmiya S, Saritha G, Ishwarya R, SayeSudarshana P A, T.Saravanan 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Water quality monitoring system using IOT Sowmiya S 28-03-2023 sowmiyaselvan1802@gmail.com 463280 Y IEEE N/A Kushagra Gupta, Anushka, Dr. Manesh Ramakrishna Palav, Ranjitha Jasmine R, V. Bharathi, Monika Gupta 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) BODY SENSOR NETWORK USING DATA ANALYSIS AND MODELING FOR HEALTHCARE APPLICATION Kushagra Gupta 28-03-2023 mrg.manikandan@gmail.com 465244 Y IEEE N/A Santosh Jangid, Sonam Mittal, Manoj Kataria, Vikas Poonia, Gaurav Sahu 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) MOBILE WIRELESS ADHOC NETWORKS ENERGY CONSUMPTION MONITORING AND QUALITY OF SERVICE ANALYSIS Santosh Jangid 28-03-2023 mrg.manikandan@gmail.com 465245 Y IEEE N/A Amit Gupta, Shaik Meeravali, Arun Singh Chouhan, K.Y.Srinivas 2023 Eighth International Conference on Science Technology Engineering and Mathematics (ICONSTEM) Activity Based Learning System Educational Institutions for Measuring Performance using Machine Learning Technique AMIT GUPTA 28-03-2023 dramitguptacv@gmail.com 465424 Y IEEE N/A N.Sri Sai Venkata Subba Rao, S.John Justin Thangaraj, V Sheeja Kumari, 2023 Eighth International Conference on Sci",
        "year": 1968,
        "url": "https://www.semanticscholar.org/paper/290f052d40ff8893b34ed408323b266bb29bd3a6",
        "citation_count": 0
    },
    {
        "title": "Machine Learning Techniques Usage in Prediction of Multiple Chronical Diseases",
        "abstract": "-Multiple Chronical Disease Prediction System is an effective healthcare predictive application that aims to predict multiple chronical diseases including Chronical Kidney Disease, Heart Disease, Diabetes, Brain Stroke and Lung Cancer with the help of various machine learning algorithms. Scope of the project is all-inclusive, focussing to predict the possibility of various diseases in the human beings taking into account their distinctive health profiles. The electronic health records are acquired from the online sources like UCI machine learning repository, GitHub and Kaggle. This prediction system uses data mining techniques for completing the purpose i.e., data pre-processing and is trained on various ensemble methods like random forest, supervised techniques, unsupervised techniques like decision tree, logistic regression, multi-layer perceptron and naive bayes. As most of these diseases share some common risk factors through our work, we are trying to explore the possible interconnection between these chronical diseases and also the chance of developing these chronical illnesses. Finally, this prediction system with the power of machine learning techniques helps in the identification and prognosis of such diseases at early stages to prevent the extremity of them and at the same time reducing the health care expenditure.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/291c0acd1f610e216dde0f0a6351d5d60046979a",
        "citation_count": 0
    },
    {
        "title": "Depression Risk Model Among Malaysians",
        "abstract": "Depression is a debilitative disease that affects over 300 million people all around the globe. It affects the functionality of people suffering from it, which implicates to socioeconomic burden to individual, families and societal levels. The subjectivity symptoms and signs in diagnosing depression on patients is a great problem among psychiatrists and psychologists. By building a depression risk model, it helps physician to identify depression with higher efficiency, accuracy and specificity. Healthcare will be improved in terms of cutting costs, time of service and energy to serve the patients. By Machine Learning, specifically Supervised Learning uses classifiers and feature extraction tools to identify what are the most significant factors to diagnose depression. This method helps to build a risk model which helps to improve in identifying depression among liable patients.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/29213f884d335b89ede1dcb85d8522f16e5d5900",
        "citation_count": 0
    },
    {
        "title": "Artificial Hydrocarbon Networks: Chemical Nature Inspiration in Machine Learning",
        "abstract": "Inspiration in nature has been widely explored, from macro to micro-scale. When looking into chemical phenomena, stability and organization are two properties that emerge. Recently, artificial hydrocarbon networks (AHN), a supervised learning method inspired in the inner structures and mechanisms of chemical compounds, have been proposed by as a data-driven approach in artificial intelligence. AHN have been successfully applied in data-driven approaches, such as: regression and classification models, control systems, signal processing, and robotics. To do so, molecules \u2013the basic units of information in AHN\u2013 play an important role in the stability, organization and interpretability of this method. Interpretability, saving computing resources, and predictability have been handled by AHN, as any other machine learning model. This short paper aims to highlight the challenges, issues and trends of artificial hydrocarbon networks as a data-driven method. Throughout this document, it presents a description of the main insights of AHN and the efforts to tackle interpretability and training acceleration. Potential applications and future trends on AHN are also discussed. Keywords\u2013 machine learning, supervised learning, artificial organic networks, modeling, learning task Introduction Recently, artificial hydrocarbon networks (AHN), a supervised learning method inspired in the inner structures and mechanisms of chemical compounds, have been proposed as a data-driven approach in artificial intelligence [1]. This algorithm, inspired by nature, loosely mimics stability and organization of molecules in order to build organized structures made of packages of information. AHN have proved to be efficient in predictive power when modeling a data-based problem. However, the organizational property has not been strongly analyzed. If this organization capability is conducted in AHN, the output response in data-driven models will reveal, at least in a partial view, the inner structure and functionality of the systems model. So, new ways in building and training AHN are required. Thus, this paper aims to discuss challenges and trends of AHN as a data-driven method, with emphasis on interpretability and training acceleration. This document lays the foundations on AHN for implementing new training algorithms and the way to reveal the chemical nature of data-driven problems. Key Concepts of Artificial Hydrocarbon Networks AHN method was firstly proposed by Ponce and Ponce [2] as an implementation of their more general technique namely artificial organic networks (AON) [1]. In a nutshell, the purpose of the AHN method is to package information, from a set of instances, in basic units known as molecules. These molecules \u2013 composed of hydrogen and carbon atoms\u2013 are described by nonlinear functions, and they can be related among them using chemical heuristics resulting in complex units of information so-called compounds. Moreover, a set of compounds can be combined together, linearly, producing mixtures. To this end, the mixture constitutes a model [1]. Thus, the inspiration in organic compounds to develop a machine learning method considers three facts observed from nature [3]: (i) stability as the property of compounds to maintain their geometric configurations; (ii) organization based on the ground-state principle aiming to preserve energy minimization within the compounds; and (iii) multi-functionality for promoting transfer learning. For training purposes, the method considers the simple AHN training algorithm [1] which is based on the gradient descent and the numerical solution of least squares estimates via QR-factorization. This training algorithm has reported well performance in predictive power for low-dimensional input spaces, and large training time for computing suitable parameters in the model [4]. Currently, new training methods have been proposed based on hierarchical training [3] or using stochastic-parallel metaheuristic optimization [4]. The later, accelerating training in more than 3,500 times the simple AHN training algorithm. Applications of Artificial Hydrocarbon Networks Literature reports many different applications of AHN. Those can be classified as follows: function approximation and modeling [1]; robust human activity recognition systems [5]; signal processing in denoising audio and face recognition [1,6]; online advertising [6]; intelligent control systems for robotics [1,7,8,11] and mechatronics [1,9,10]; bio/medical applications [5,6,12]; and, theoretical approaches such as hybrid fuzzy-molecular inference systems [8], interpretability of the model [12] and training algorithms [3,4]. Highlights of Artificial Hydrocarbon Networks In these years of AHN, this method has reached notable contributions, as those highlighted following: \u2022 Type-II fuzzy inference like behavior \u2013 AHN have proved to be significantly similar to type-II fuzzy inference systems, handling noise and allowing experts to tune fuzzy partitions/rules [8]. \u2022 Competitive as deep learning \u2013 In [5], AHN reported to be significantly similar in performance as deep neural networks (DNN). This suggests that AHN can be trained with less data and obtaining comparable results as DNN. \u2022 Interpretability of the model \u2013 In contrast to neural networks, AHN can be partially interpreted and converted into decision trees or rules-based models. This interpretability was implemented for medical diagnosis systems [12]. \u2022 Reinforcement learning for continuous domains \u2013 AHN have been applied for continuous reinforcement learning approaches, in both states and actions, typically found in robotics [11,13]. This approach has also revealed insights on using it as a transfer learning method. Challenges and Trends of Artificial Hydrocarbon Networks Until now, AHN have been successfully applied to different problems and different learning tasks. However, there still are challenges and issues about AHN that have to be faced. Trends in the development and application of AHN can be listed as follows: (i) new training algorithms for AHN are required for better computational performance mainly in time; (ii) the next big step in AHN is parallel computing that opens the possibility for parallel processing and big data analysis; (iii) since the predictive power of AHN is well accurate, it is important to study other functions as kernels and relationships in molecules aiming to perform other approximations; (iv) hybrid approaches with AHN might improve solutions to very complex problems, such as robotics, business intelligence, healthcare, and others; (v) few efforts in dynamic modeling using AHN are reported in literature, so it is important to focus some research in this direction; (vi) transfer learning using pre-defined molecules can be done, but more studies are necessary; (vii) interpretability of machine learning models and specifically of AHN models, are of great importance for knowledge extraction, thus automatic procedures for this task are required; and (viii) open-source coding of AHN is specially required for fast adoption, as the first efforts reported in [14]. Conclusions In this short paper, we summarized the challenges, issues and trends of AHN as a data-driven method. Despite this method was proposed recently, it has been successfully applied to many different intelligent systems. However, there is a need to explore new ways on how this method can be useful. Important issues like interpretability, training acceleration and open-source efforts are also required. Finally, we believe that this method can be added as another powerful tool for practitioners, scientists and researchers in artificial intelligence community.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/294ad7ef3f1835baa52b742ef90051e0d8a09add",
        "citation_count": 0
    },
    {
        "title": "Gene-Metabolite Interaction in the One Carbon Metabolism Pathway: Predictors of Colorectal Cancer in Multi-Ethnic Families",
        "abstract": "For personalized healthcare, the purpose of this study was to examine the key genes and metabolites in the one-carbon metabolism (OCM) pathway and their interactions as predictors of colorectal cancer (CRC) in multi-ethnic families. In this proof-of-concept study, we included a total of 30 participants, 15 CRC cases and 15 matched family/friends representing major ethnic groups in southern California. Analytics based on supervised machine learning were applied, with the target variable being specified as cancer, including the ensemble method and generalized regression (GR) prediction. Elastic Net with Akaike\u2019s Information Criterion with correction (AICc) and Leave-One-Out cross validation GR methods were used to validate the results for enhanced optimality, prediction, and reproducibility. The results revealed that despite some family members sharing genetic heritage, the CRC group had greater combined gene polymorphism-mutations than the family controls (p < 0.1) for five genes including MTHFR C677T, MTHFR A1298C, MTR A2756G, MTRR A66G, and DHFR 19bp. Blood metabolites including homocysteine (7 \u00b5mol/L), methyl-folate (40 nmol/L) with total gene mutations (\u22654); age (51 years) and vegetable intake (2 cups), and interactions of gene mutations and methylmalonic acid (MMA) (400 nmol/L) were significant predictors (all p < 0.0001) using the AICc. The results were validated by a 3% misclassification rate, AICc of 26, and >99% area under the receiver operating characteristic curve. These results point to the important roles of blood metabolites as potential markers in the prevention of CRC. Future intervention studies can be designed to target the ways to mitigate the enzyme-metabolite deficiencies in the OCM pathway to prevent cancer.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/2972248cb271b1e2ebf4a8379e1b0d7a7045747b",
        "citation_count": 6
    },
    {
        "title": "Continuous support for rehabilitation using machine learning",
        "abstract": "Abstract Providing a suitable rehabilitation at home after an acute episode or a chronic disease is a major issue as it helps people to live independently and enhance their quality of life. However, as the rehabilitation period usually lasts some months, the continuity of care is often interrupted in the transition from the hospital to the home. Relieving the healthcare system and personalizing the care or even bringing care to the patients\u2019 home to a greater extent is, in consequence, the superior need. This is why we propose to make use of information technology to come to participatory design driven by users needs and the personalisation of the care pathways enabled by technology. To allow this, patient rehabilitation at home needs to be supported by automatic decision-making, as physicians cannot constantly supervise the rehabilitation process. Thus, we need computer-assisted patient rehabilitation, which monitors the fitness of the current patient plan to detect sub-optimality, proposes personalised changes for a patient and eventually generalizes over patients and proposes better initial plans. Therefore, we will explain the use case of patient rehabilitation at home, the basic challenges in this field and machine learning applications that could address these challenges by technical means.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/29f513bc18d1dc64b11931c8254d5f6473005011",
        "citation_count": 7
    },
    {
        "title": "Bidirectional LSTM Deep Model for Online Doctor Reviews Polarity Detection",
        "abstract": "Online medical reviews contain patients' subjective evaluations and reflect their satisfaction with the treatment process and doctors. Mining and analysis of sentiment expressed in these medical data may be vital for different applications including adverse drug effects detection, doctor recommendation, and healthcare quality assessment. Nevertheless, medical sentiment analysis is a challenging and complex task because patients who write the reviews are usually non-professional users and tend to use informal language. The problem is more challenging in the Persian language due to its resource scarcity and complex structure. In this study, we introduce PODOR, a Persian dataset of online doctor reviews extracted from social web. Also, we propose a deep model based on the bidirectional long short-term memory for polarity detection of PODOR reviews. To show the effectiveness and suitability of the proposed model, we compared the model with six traditional supervised machine learning methods and three deep models. Preliminary comparative results indicated that our model outperformed traditional methods by 8% and 7%, and deep models by 2% and 3% in terms of accuracy and f1-measure.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/2a1a818d6a6c018d850ffd32527eae837124fcd4",
        "citation_count": 7
    },
    {
        "title": "Editorial",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/2a717a16b76da4697e395aa728b73372fb783645",
        "citation_count": 0
    },
    {
        "title": "Personalized Medicine Recommendation and Disease Flagging Model Based on User\u2019s Previous Orders",
        "abstract": "The Recommendation systems gaining importance every passing day and are frequently used in e-commerce websites, content streaming platforms, social media platforms, and other applications to analyze large amounts of data and recommend products or services to users based on their past actions, preferences, and other pertinent factors. This kind of system can effectively be used in healthcare to provide personalized recommendations to patients. In this paper, a recommendation model has been proposed that flags the users with the diseases that they may have based on analyzing their historical medicine order and recommends them with alternate related medicines and products. The proposed model is based on a machine learning technique that takes into consideration the user\u2019s medical history, disease diagnosis, and prescription orders and recommends other related medicine and products. The proposed model uses a combination of supervised and unsupervised learning algorithms. A sizable dataset of patient orders from a top pharmaceutical retailer served as the basis for training and validating the model. The simulation results show that the model can handle complex situations, such as multiple medications and medical conditions, and predict medication recommendations with high accuracy.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/2a98cb101760f6a6491480671742fd9476b82328",
        "citation_count": 1
    },
    {
        "title": "Analysis of Machine Learning Methods for COVID-19 Detection Using Serum Raman Spectroscopy",
        "abstract": "ABSTRACT One of the most challenging aspects of the emergent coronavirus disease 2019 (COVID-19) pandemic caused by infection of severe acute respiratory syndrome coronavirus 2 has been the need for massive diagnostic tests to detect and track infection rates at the population level. Current tests such as reverse transcription-polymerase chain reaction can be low-throughput and labor intensive. An ultra-fast and accurate mode of detecting COVID-19 infection is crucial for healthcare workers to make informed decisions in fast-paced clinical settings. The high-dimensional, feature-rich components of Raman spectra and validated predictive power for identifying human disease, cancer, as well as bacterial and viral infections pose the potential to train a supervised classification machine learning algorithm on Raman spectra of patient serum samples to detect COVID-19 infection. We developed a novel stacked subsemble classifier model coupled with an iteratively validated and automated feature selection and engineering workflow to predict COVID-19 infection status from Raman spectra of 250 human serum samples, with a 10-fold cross-validated classification accuracy of 98.0% (98.6% precision and 98.5% recall). Furthermore, we benchmarked nine machine learning and artificial neural network models when evaluated using eight standalone performance metrics to assess whether ensemble methods offered any improvement from baseline machine learning models. Using a rank-normalized scores derived from the performance metrics, the stacked subsemble model ranked higher than the Multi-layer Perceptron, which in turn ranked higher than the eight other machine learning models. This study serves as a proof of concept that stacked ensemble machine learning models are a powerful predictive tool for COVID-19 diagnostics.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/2ab39e7177bc10d1d9eb16d7262e7bc63879a220",
        "citation_count": 10
    },
    {
        "title": "A survey on diabetes risk prediction using machine learning approaches",
        "abstract": "ABSTRACT Background: Diabetes mellitus (DM) is a chronic condition that can lead to a variety of consequences. Diabetes is a condition that is caused by factors such as age, lack of exercise, sedentary lifestyle, family history of diabetes, high blood pressure, depression and stress, poor food, and so on. Diabetics are at a higher risk of developing diseases such as heart disease, nerve damage (diabetic neuropathy), eye problems (diabetic retinopathy), kidney disease (diabetic nephropathy), stroke, and so on. According to the International Diabetes Federation, 382 million people worldwide suffer from diabetes. By 2035, this number will have risen to 592 million. Every day, a large number of people become victims, and many are ignorant whether they have it or not. It primarily affects individuals between the ages of 25 and 74 years. If diabetes is left untreated and undiagnosed, it can lead to a slew of complications. The emergence of machine learning approaches, on the other hand, solves this crucial issue. Aims and Objectives: The aim was to study the DM and analyze how machine learning algorithms are used to identify the diabetes mellitus at an early stage, which is one of the most serious metabolic disorders in the world today. Methods and Materials: Data was obtained from databases such as Pubmed, IEEE xplore, and INSPEC,and from other secondary sources and primary sources in which methods based on machine learning approaches used in healthcare to predict diabetes at an early stage are reported. Results: After surveying various research papers, it was found that machine learning classification algorithms like Support Vector Machine (SVM), K-Nearest Neighbor (KNN), and Random Forest (RF) etc shows the best accuracy for predicting diabetes at an early stage. Conclusion: Early detection of diabetes is critical for effective therapy. Many people have no idea whether or not they have it. The full assessment of Machine learning approaches for early diabetes prediction and how to apply a variety of supervised and unsupervised machine learning algorithms to the dataset to achieve the best accuracy are addressed in this paper.. Furthermore, the work will be expanded and refined to create a more precise and general predictive model for diabetes risk prediction at an early stage. Different metrics can be used to assess performance and for accurate diabetic diagnosis.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/2b4eb2207a6bce06d9975fc4a57a7bcc9c678d63",
        "citation_count": 17
    },
    {
        "title": "Use of Digitalisation and Machine Learning Techniques in Therapeutic Intervention at Early Ages: Supervised and Unsupervised Analysis",
        "abstract": "Advances in technology and artificial intelligence (smart healthcare) open up a range of possibilities for precision intervention in the field of health sciences. The objectives of this study were to analyse the functionality of using supervised (prediction and classification) and unsupervised (clustering) machine learning techniques to analyse results related to the development of functional skills in patients at developmental ages of 0\u20136 years. We worked with a sample of 113 patients, of whom 49 were cared for in a specific centre for people with motor impairments (Group 1) and 64 were cared for in a specific early care programme for patients with different impairments (Group 2). The results indicated that in Group 1, chronological age predicted the development of functional skills at 85% and in Group 2 at 65%. The classification variable detected was functional development in the upper extremities. Two clusters were detected within each group that allowed us to determine the patterns of functional development in each patient with respect to functional skills. The use of smart healthcare resources has a promising future in the field of early care. However, data recording in web applications needs to be planned, and the automation of results through machine learning techniques is required.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/2b5af5cac4480f99d1f039af19e11576c9e8298b",
        "citation_count": 2
    },
    {
        "title": "Machine Learning and Big Data Analytics in IoT based Blood Bank Supply Chain Management System",
        "abstract": "Blood is a perishable product with uncertainties in both supply and demand and blood stock management is therefore a judicious balance between shortage and wastage.Blood service operations are a key component of the healthcare system. Requirement of blood is increasing gradually due to accidents, surgeries etc. Blood transfusion play an important role in healthcare. The intention of Blood Bank Supply Chain is to demand estimate, inventory management and distribute adequate blood.Internet of Things (IoT) has rehabilitated the traditional e-healthcare system.Big data analytics refers to the process of collecting, organizing and analyzing large sets of data (\"big data\") to discover patterns and other useful information in a blood bank system. -Big DataAnalyticsandMachine Learning aretwo important areas ofdatascience. A key benefit of Machine Learning is the analysis and learning of massive amount so fun supervised data, making it a valuable tool for Big Data Analytics where raw data is largely unlabeled and un-categorized. With advance research in health sector, there is variety of perishable data available in health care especially in the Blood bank domain. This paper provides review and importance big data technologies and IoT paradigms used in health care sector. Keywords\u2014 Internet of Things(IoT), Big Data, Machine Learning,Blood Bank, Supply Chain Management, Regional Blood Center (RBC), Hospital Blood Bank (HBB), Radio Frequency Identification (RFID).",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/2b617aef8f8d4d95ce7fe2448c8d714ffaaeb299",
        "citation_count": 2
    },
    {
        "title": "Demographic Predictability in 3D CT Foundation Embeddings",
        "abstract": "Self-supervised foundation models have recently been successfully extended to encode three-dimensional (3D) computed tomography (CT) images, with excellent performance across several downstream tasks, such as intracranial hemorrhage detection and lung cancer risk forecasting. However, as self-supervised models learn from complex data distributions, questions arise concerning whether these embeddings capture demographic information, such as age, sex, or race. Using the National Lung Screening Trial (NLST) dataset, which contains 3D CT images and demographic data, we evaluated a range of classifiers: softmax regression, linear regression, linear support vector machine, random forest, and decision tree, to predict sex, race, and age of the patients in the images. Our results indicate that the embeddings effectively encoded age and sex information, with a linear regression model achieving a root mean square error (RMSE) of 3.8 years for age prediction and a softmax regression model attaining an AUC of 0.998 for sex classification. Race prediction was less effective, with an AUC of 0.878. These findings suggest a detailed exploration into the information encoded in self-supervised learning frameworks is needed to help ensure fair, responsible, and patient privacy-protected healthcare AI.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/2b9d113f71196395a61b12c67d06bf2f49a2339e",
        "citation_count": 0
    },
    {
        "title": "The Diagnosis of Dengue in Patients Presenting With Acute Febrile Illness Using Supervised Machine Learning and Impact of Seasonality",
        "abstract": "Background Symptomatic dengue infection can result in a life-threatening shock syndrome and timely diagnosis is essential. Point-of-care tests for non-structural protein 1 and IgM are used widely but performance can be limited. We developed a supervised machine learning model to predict whether patients with acute febrile illnesses had a diagnosis of dengue or other febrile illnesses (OFI). The impact of seasonality on model performance over time was examined. Methods We analysed data from a prospective observational clinical study in Vietnam. Enrolled patients presented with an acute febrile illness of <72 h duration. A gradient boosting model (XGBoost) was used to predict final diagnosis using age, sex, haematocrit, platelet, white cell, and lymphocyte count collected on enrolment. Data was randomly split 80/20% into a training and hold-out set, respectively, with the latter not used in model development. Cross-validation and hold out set testing was used, with performance over time evaluated through a rolling window approach. Results We included 8,100 patients recruited between 16th October 2010 and 10th December 2014. In total 2,240 (27.7%) patients were diagnosed with dengue infection. The optimised model from training data had an overall median area under the receiver operator curve (AUROC) of 0.86 (interquartile range 0.84\u20130.86), specificity of 0.92, sensitivity of 0.56, positive predictive value of 0.73, negative predictive value (NPV) of 0.84, and Brier score of 0.13 in predicting the final diagnosis, with similar performances in hold-out set testing (AUROC of 0.86). Model performances varied significantly over time as a function of seasonality and other factors. Incorporation of a dynamic threshold which continuously learns from recent cases resulted in a more consistent performance throughout the year (NPV >90%). Conclusion Supervised machine learning models are able to discriminate between dengue and OFI diagnoses in patients presenting with an early undifferentiated febrile illness. These models could be of clinical utility in supporting healthcare decision-making and provide passive surveillance across dengue endemic regions. Effects of seasonality and changing disease prevalence must however be taken into account\u2014this is of significant importance given unpredictable effects of human-induced climate change and the impact on health.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/2bd4fcbcda2ef462c7f01e90065abea0426c606a",
        "citation_count": 11
    },
    {
        "title": "Use of machine learning to identify prognostic variables for outcomes in chronic low back pain treatment: a retrospective analysis.",
        "abstract": "OBJECTIVES\nMost patients seen in physical therapy (PT) clinics for low back pain (LBP) are treated for chronic low back pain (CLBP), yet PT interventions suggest minimal effectiveness. The Cochrane Back Review Group proposed 'Holy Grail' questions, one being: 'What are the most important (preventable) predictors of chronicity' for patients with LBP? Subsequently, prognostic factors influencing outcomes for CLBP have been described, however results remain conflicting due to methodological weaknesses.\n\n\nMETHODS\nThis retrospective observational cohort study examined prognostic risk factors for PT outcomes in CLBP treatment using a sub-type of AI. Bootstrap random forest supervised machine learning analysis was employed to identify the outcomes-associated variables.\n\n\nRESULTS\nThe top variables identified as predictive were: FOTO\u2122 predicted functional status (FS) change score; FOTO\u2122 predicted number of visits; initial FS score, age; history of jogging/walking, obesity, and previous treatments; provider education level; medication use; gender.\n\n\nCONCLUSION\nThis article presents how AI can be used to predict risk prognostic factors in healthcare research. Improving predictive accuracy helps clinicians predict outcomes and determine most appropriate plans of care and may impact research attrition rates.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/2bf71d8c50bd0cce9a74f5c3fa2bb1ff7c2d63ce",
        "citation_count": 1
    },
    {
        "title": "Prediction of Apnea of Prematurity in neonates using Support Vector Machines and Random Forests",
        "abstract": "Machine Learning has a wide array of applications in the healthcare domain and has been used extensively for analyzing data. Apnea of Prematurity is a breathing disorder commonly observed in preterm infants. This paper compares the usage of Support Vector Machines and Random Forests, which are supervised learning algorithms, to predict Apnea of Prematurity at the end of the first week of the child's birth using data collected during the first three days of neonatal life. This paper also uses an optimization method called Synthesized Minority Oversampling Technique (SMOTE) to resolve the class imbalance problem observed in the data. Principal Component Analysis and one-hot encoding have been implemented for feature extraction and data preprocessing respectively. Among the results obtained, an AUC of 0.72 using the amalgamation of Random Forests and SMOTE is found to be the most accurate model.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/2c1511a77ccddbb6b1822f4030c084d1fb6d62ba",
        "citation_count": 9
    },
    {
        "title": "COVID 19 mortality as a reflection of the quality of health in EU countries",
        "abstract": "The article aims to model the COVID-19 mortality in EU member states. It depends on chosen factors, determine the ranking of factors' importance and attempts for their reduction. Further objectives include identifying states with similar values of identified factors and their geographical concentration. This is exploratory research and is a quantitative research study according to the type of data used. Using the supervised machine learning random forest algorithm, we predict the number of COVID-19 deaths depending on analyzed factors. From 23 factors, we choose the seven most important factors. This selection is based on the highest value, Inc Node Purity. The cluster analysis is used to create groups of states with similar values of chosen factors. Because of the nonuniform methodology of reported deaths, we use excess mortality to measure COVID-19 mortality. The most important factor influencing COVID-19 mortality is the death rate due to circulatory system diseases. The second most significant factor is the avoidable mortality. The third most relevant factor is GDP per capita in purchasing power parity. Similar values of analyzed factors can be found in Bulgaria, Romania, the Czech Republic, Poland, Slovakia, Lithuania, Hungary, Croatia, and Latvia. COVID-19 mortality in these countries is almost three times higher than in the rest of the EU. Decision-makers could use the gained findings to decrease inequalities in the field of healthcare, mostly through efficient interventions in public healthcare and primary prevention. The results demonstrate that more investment in promoting health in the future will be necessary in the cohesion policy framework.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/2c31cdaf2de99f12d3170bfb894e1887dd3c2c02",
        "citation_count": 0
    },
    {
        "title": "Technology for Viticulture Using Computer Vision and Machine Learning",
        "abstract": "- Introduction :- The capacity to solve machine intelligence issues in their entirety is a result of the field of artificial intelligence's (AI) progress. Recently, the direct training of computers with minimal human contact has led to the rise in popularity of machine learning (ML). In today's world, the machine will learn automatically, replacing the previous situation of hand feeding. Features like feature extraction, pattern recognition, object identification, and classification are among the specific uses for supervised and unsupervised machine learning approaches. OBJECTIVES:- ML is a key component of Computer Vision (CV) that helps to extract important information from pictures. Numerous fields, including robotics, optical character recognition, surveillance systems, suspect detection, and many more, benefit from CV's excellent contributions. The field of CV research is moving toward the healthcare sector. Medical imaging (MI) is a new technology that is essential to improving picture quality and identifying important characteristics of binary medical images. It also helps to mask the original image into grayscale and sets threshold values for segmentation. CONTRIBUTION:- This paper will discuss the state-of-the-art, machine learning, and its application to computer vision and image processing. The types of tools and applications, datasets, and approaches will all be covered in detail by this survey. Future work problems and past job limitations were also explored. In order to effectively apply machine learning (ML) to computer vision and image processing, we also identify and explore a number of unresolved difficulties that still need to be resolved. METHODS, RESULTS, AND CONCLUSION: This review paper has covered a variety of supervised and unsupervised machine learning techniques and algorithms, as well as a general overview of image processing and its impact on results. It also discusses neural network-enabled models, tools, and applications for CV, as well as important areas of open research for machine learning in CV.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/2caaaed63a8755bac65d0a926f2753c06163fbf3",
        "citation_count": 0
    },
    {
        "title": "Bioinformatics Research Challenges and Opportunities in Machine Learning",
        "abstract": "This research work has studied about the utilization of machine learning algorithms in bioinformatics. The primary purpose of studying this is to understand bioinformatics and different machine algorithms which are used to analyze the biological data present with us. This research study discusses about different machine learning approaches like supervised, unsupervised, and reinforcement which play an essential role in understanding and analyzing biological data. Machine learning is helping us to solve a wide range of bioinformatics problems by describing a wide range of genomics sequences and analyzing vast amounts of genomic data. One of the biggest real-world problems is that machine learning is helping us to identify cancer with a given gene expression, which is done using a support vector machine. In addition, this study discusses about the classification of molecular data, which will help find out minor diseases. With the advancement of machine learning in healthcare and other related applications, data collection becomes a tedious process. This article also focuses on some of the research problems in machine learning domain. The uses of machine learning algorithms in bioinformatics have been extensively studied. These objectives will help to understand bioinformatics and different machine algorithms that are used to analyze the biological data. This research study presents different machine learning approaches like supervised, unsupervised, and reinforcement, which play an important role in understanding and analyzing biological data. Machine learning helps to solve a wide range of bioinformatics related challenges by describing a wide range of genomics sequences and analyzing huge amounts of genomic data. One of the biggest real-time challenges is that the machine learning is helping to identify cancer with a given gene expression, and this is done by using a support vector machine. Finally, this research study has discussed about the classification of molecular data, which will be helpful in finding out minor diseases.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/2d10d3964b30deb1fdd28c11a99b0f3e35d71327",
        "citation_count": 2
    },
    {
        "title": "Synthesising Electronic Health Records: Cystic Fibrosis Patient Group",
        "abstract": "Class imbalance can often degrade predictive performance of supervised learning algorithms. Balanced classes can be obtained by oversampling exact copies, with noise, or interpolation between nearest neighbours (as in traditional SMOTE methods). Oversampling tabular data using augmentation, as is typical in computer vision tasks, can be achieved with deep generative models. Deep generative models are effective data synthesisers due to their ability to capture complex underlying distributions. Synthetic data in healthcare can enhance interoperability between healthcare providers by ensuring patient privacy. Equipped with large synthetic datasets which do well to represent small patient groups, machine learning in healthcare can address the current challenges of bias and generalisability. This paper evaluates synthetic data generators ability to synthesise patient electronic health records. We test the utility of synthetic data for patient outcome classification, observing increased predictive performance when augmenting imbalanced datasets with synthetic data.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/2d1e10b833fb3c5626e0364fb98f74722437e27a",
        "citation_count": 2
    },
    {
        "title": "A Hybrid Machine Learning Model for Estimation of Obesity Levels",
        "abstract": "Obesity has always been a problem which has plagued humans for many generations, which, since the 1975, almost doubled to turn into a global epidemic. The current human dependence on technology has contributed to the problem even more, with the effects visibly pronounced in late teenagers and early adults. Researchers till date, have tried numerous ways to determine the factors that cause obesity in early adults. On that frontier, our hybrid machine-learning model uses the help of some supervised and unsupervised data mining methods like Extremely Randomized Trees, Multilayer Perceptron and XGBoost using Python to detect and predict obesity levels and help healthcare professionals to combat this phenomenon. Our dataset is a publicly available dataset in the UCI Machine Learning Repository, containing the data for the estimation of obesity levels in individuals from the countries of Mexico, Peru, and Colombia, based on their eating habits and physical condition. The proposed model heavily utilizes feature engineering methods and introduces the concept of a hybrid model. This work has shown improved results over prior works and extensive studies have been undertaken to preserve the robustness of this model.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/2d22b6ddb53ce28c0eef691ee0983fc6628efd93",
        "citation_count": 1
    },
    {
        "title": "Ransomware Detection in Healthcare Organizations using Supervised Learning Models: Naive Bayes Classifier.",
        "abstract": "Ransomware attacks are a big problem for healthcare organizations. They cause major disruptions in important tasks and ask for money in exchange for fixing access to servers that have been compromised. This paper introduces a fresh approach that uses static analysis to detect and prevent ransomware attacks more effectively. Instead of relying on time-consuming dynamic analysis like usual, this approach offers a faster and stronger defense against ransomware attacks. Many current classification algorithms struggle to effectively detect and stop ransomware infections in computer systems due to their poor performance. It\u2019s critical to quickly evaluate how effective the current machine learning classification algorithms are at detecting ransomware. By undertaking this task, we can develop algorithms that are both stronger and more efficient, capable of overcoming the limitations of current approaches. Our model doesn\u2019t just find ransomware attacks; it also stops them and prevents bad stuff from happening, making healthcare cybersecurity stronger. This research is an important move in making healthcare systems stronger against the changing cyber threats. What sets our method apart is that it skips the disassembly step, which is unique. This study assessed how well certain classification algorithms, like Naive Bayes and Random Forest, performed. The algorithms\u2019 performance was measured based on Accuracy, Precision, Recall, and F-Measure using these machine learning methods. Based on our experiments, we found that the Naive Bayes algorithm achieved the highest accuracy, reaching 99.2 percentile. This suggests that Naive Bayes performs well in detecting ransomware malware attacks with high accuracy rates.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/2d24f4f59945d9722c9038a81cc9fd868d302c2b",
        "citation_count": 0
    },
    {
        "title": "A Depth of Deep Learning for Big Data and its Applications",
        "abstract": ":- Although Machine Learning (ML) has become synonymous for Artificial Intelligence (AI); recently, Deep Learning (DL) is being used in place of machine learning persistently. While machine learning is busy in supervised and unsupervised methods, deep learning continues its motivation for replicating the human nervous system by incorporating advanced types of Neural Networks (NN).. If we apply Deep Learning to Big Data, we can \ufb01nd unknown and useful patterns that were impossible so far. Deep Learning is applied in self driving cars, visual recognition, healthcare, transportation etc. Nowadays, companies have started to realize the importance of data availability in large amounts in order to make the correct decision and support their strategies. Big Data means extremely huge large data sets, which is heterogeneous whose characteristics (large volume, different forms, speed of processing), analyzed to \ufb01nd the patterns, trends. This paper provides an introductory tutorial to the domain of deep learning for Big Data with its history, evolution, and introduction to some of the sophisticated neural networks such as Deep belief network , Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN)",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/2de954c021c291075bea0dcf494ac0f7303f761f",
        "citation_count": 0
    },
    {
        "title": "A Comparative Study of Machine Learning Algorithms Applied to Predictive Diabetes Data",
        "abstract": "Healthcare industry encompasses abundant data, which is increasing everyday. Conversely, tools for analyzing these records are incredibly less. Machine learning provides a lot of techniques for solving diagnostic problems in a variety of medical domains. Intelligent systems are able to learn from machine learning methods, when they are provided with a set of clinical cases as training set. This paper aims at a comparative study of widely used supervised classification algorithms \u2013 Naive Bayes, Multi Layer Perceptrons, Logistic Model Trees, and Nearest Neighbor with Generalized Exemplars applied to predictive diabetes dataset. The machine learning algorithms used in this study are chosen for their representability and diversity. They are evaluated on the basis of their accuracy, learning time and error rates.",
        "year": 2009,
        "url": "https://www.semanticscholar.org/paper/2ded11b9d955cc353d6454e0cad291f9b04d33c5",
        "citation_count": 0
    },
    {
        "title": "Serological evaluation of risk factors for exposure to malaria in a pre-elimination setting in Malaysian Borneo",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/2e19cc5073583da3c1e708f0ec5de2b596f7c523",
        "citation_count": 3
    },
    {
        "title": "Efficient Cyber Attack Detection on the Internet of Medical Things-Smart Environment Based on Deep Recurrent Neural Network and Machine Learning Algorithms",
        "abstract": "Information and communication technology (ICT) advancements have altered the entire computing paradigm. As a result of these improvements, numerous new channels of communication are being created, one of which is the Internet of Things (IoT). The IoT has recently emerged as cutting-edge technology for creating smart environments. The Internet of Medical Things (IoMT) is a subset of the IoT, in which medical equipment exchange information with each other to exchange sensitive information. These developments enable the healthcare business to maintain a higher level of touch and care for its patients. Security is seen as a significant challenge in whatsoever technology\u2019s reliance based on the IoT. Security difficulties occur owing to the various potential attacks posed by attackers. There are numerous security concerns, such as remote hijacking, impersonation, denial of service attacks, password guessing, and man-in-the-middle. In the event of such attacks, critical data associated with IoT connectivity may be revealed, altered, or even rendered inaccessible to authorized users. As a result, it turns out to be critical to safeguard the IoT/IoMT ecosystem against malware assaults. The main goal of this study is to demonstrate how a deep recurrent neural network (DRNN) and supervised machine learning models (random forest, decision tree, KNN, and ridge classifier) can be utilized to develop an efficient and effective IDS in the IoMT environment for classifying and forecasting unexpected cyber threats. Preprocessing and normalization of network data are performed. Following that, we optimized features using a bio-inspired particle swarm algorithm. On the standard data for intrusion detection, a thorough evaluation of experiments in DRNN and other SML is performed. It was established through rigorous testing that the proposed SML model outperforms existing approaches with an accuracy of 99.76%.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/2e1d0daea8270a996f577430217e836bf7a780a3",
        "citation_count": 97
    },
    {
        "title": "Artificial Intelligence for Unstructured Healthcare Data: Application to Coding of Patient Reporting of Adverse Drug Reactions",
        "abstract": "Adverse drug reaction (ADR) reporting is a major component of drug safety monitoring; its input will, however, only be optimized if systems can manage to deal with its tremendous flow of information, based primarily on unstructured text fields. The aim of this study was to develop an automated system allowing to code ADRs from patient reports. Our system was based on a knowledge base about drugs, enriched by supervised machine learning (ML) models trained on patients reporting data. To train our models, we selected all cases of ADRs reported by patients to a French Pharmacovigilance Centre through a national web\u2010portal between March 2017 and March 2019 (n = 2,058 reports). We tested both conventional ML models and deep\u2010learning models. We performed an external validation using a dataset constituted of a random sample of ADRs reported to the Marseille Pharmacovigilance Centre over the same period (n = 187). Here, we show that regarding area under the curve (AUC) and F\u2010measure, the best model to identify ADRs was gradient boosting trees (LGBM), with an AUC of 0.93 (0.92\u20130.94) and F\u2010measure of 0.72 (0.68\u20130.75). This model was run for external validation showing an AUC of 0.91 and a F\u2010measure of 0.58. We evaluated an artificial intelligence pipeline that was found able to learn how to identify correctly ADRs from unstructured data. This result allowed us to start a new study using more data to further improve our performance and offer a tool that is useful in practice to efficiently manage drug safety information.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/2e1f4cc65323467cc8b503172b25af4d08db6e7d",
        "citation_count": 26
    },
    {
        "title": "Quantitative feature extraction of unstructured data from GitLab BioAI pathology reports of cancer using an enhanced RPA NLP method",
        "abstract": "Unstructured pathology report plays a major role in definitive cancer diagnosis. Accessing or searching unstructured textual information from the clinical pathology reports is one of the major concerns in cancer healthcare sector to provide precise medicine, analysis of cancer outcomes, providing cancer care services, accurate measurement for future prediction, treatment history, and comparative future research work. An efficient methodology has to be introduced for to extract quantitative information from the unstructured cancer data. Integrating computational intelligence in Robotic Process Automation can be done to process this data and automate repetitive activities for evaluating patients clinical pathology report. RPA-based NLP BERT system is designed and evaluated to automatically extract information on these variables for the patients from pathology report. In order to detect tumour and outcomes from documented pathology reports, a supervised machine learning keyword based extraction algorithm was developed in which the pathology data are examined to extract keywords from 2087 reports with 1579 of data reports being processed for the development phase and 508 of data being used for evaluation. The precision recall and accuracy are calculated for organ specimens for cancer test as (0.984, 0.982, 0.9839), test methodology(0.986, 0.981,0.9956) and pathological result(0.986, 0.9938, 0.9795) were achieved. The feasibility of autonomously extracting pre-defined data from clinical narratives for cancer research were established in this work. The outcomes showed that our methodology was suitable for actual use in obtaining essential information from pathology reports.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/2e2b1483504f52f638584b625e0a3db395a688fb",
        "citation_count": 0
    },
    {
        "title": "Prediction of Coronary Heart Disease using Supervised Machine Learning Algorithms",
        "abstract": "New technologies like Machine learning and Big data analytics have been proven to provide promising solutions to biomedical communities, healthcare problems, and patient care. They also help in early prediction of disease by accurate interpretation of medical data. Disease management strategies can further be improved by the detection of early signs of disease. This early prediction, moreover, can be helpful in controlling the symptoms of the disease as well as the proper treatment of disease. Machine learning approaches can be used in the prediction of chronic diseases, such as kidney and heart diseases, by developing the classification models. In this paper, we propose a preprocessing extensive approach to predict Coronary Heart Diseases (CHD). The approach involves replacing null values, resampling, standardization, normalization, classification, and prediction. This work aims to predict the risk of CHD using machine learning algorithms like Random Forest, Decision Trees, and K-Nearest Neighbours. Also, a comparative study among these algorithms on the basis of prediction accuracy is performed. Further, $K$-fold Cross Validation is used to generate randomness in the data. These algorithms are experimented over \u201cFramingham Heart Study\u201d dataset, which is having 4240 records. In our experimental analysis, Random Forest, Decision Tree, and K-Nearest Neighbour achieved an accuracy of 96.8%, 92.7%, and 92.89% respectively. Therefore, by including our preprocessing steps, Random Forest classification gives more accurate results than other machine learning algorithms.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/2ebea9b21d69586882fc2a7c953eacb1e6bd3b77",
        "citation_count": 60
    },
    {
        "title": "Automatic identification of methotrexate-induced liver toxicity in patients with rheumatoid arthritis from the electronic medical record",
        "abstract": "OBJECTIVES\nTo improve the accuracy of mining structured and unstructured components of the electronic medical record (EMR) by adding temporal features to automatically identify patients with rheumatoid arthritis (RA) with methotrexate-induced liver transaminase abnormalities.\n\n\nMATERIALS AND METHODS\nCodified information and a string-matching algorithm were applied to a RA cohort of 5903 patients from Partners HealthCare to select 1130 patients with potential liver toxicity. Supervised machine learning was applied as our key method. For features, Apache clinical Text Analysis and Knowledge Extraction System (cTAKES) was used to extract standard vocabulary from relevant sections of the unstructured clinical narrative. Temporal features were further extracted to assess the temporal relevance of event mentions with regard to the date of transaminase abnormality. All features were encapsulated in a 3-month-long episode for classification. Results were summarized at patient level in a training set (N=480 patients) and evaluated against a test set (N=120 patients).\n\n\nRESULTS\nThe system achieved positive predictive value (PPV) 0.756, sensitivity 0.919, F1 score 0.829 on the test set, which was significantly better than the best baseline system (PPV 0.590, sensitivity 0.703, F1 score 0.642). Our innovations, which included framing the phenotype problem as an episode-level classification task, and adding temporal information, all proved highly effective.\n\n\nCONCLUSIONS\nAutomated methotrexate-induced liver toxicity phenotype discovery for patients with RA based on structured and unstructured information in the EMR shows accurate results. Our work demonstrates that adding temporal features significantly improved classification results.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/2ef537233e8d68eec7f53cf5af06df027efc3d3f",
        "citation_count": 66
    },
    {
        "title": "Forecasting for Vaccinated COVID-19 Cases using Supervised Machine Learning in Healthcare Sector",
        "abstract": "Machine learning (ML)-based forecasting techniques have demonstrated significant value in predicting postoperative outcomes, aiding in improved decision-making for future tasks. ML algorithms have already been applied in various fields where identifying and ranking risk variables are essential. To address forecasting challenges, a wide range of predictive techniques is commonly employed. Research indicates that ML-based models can accurately predict the impact of COVID-19 on Jordan's healthcare system, a concern now recognized as a potential global health threat. Specifically, to determine COVID-19 risk classifications, this study utilized three widely adopted forecasting models: support vector machine (SVM), least absolute shrinkage and selection operator (LASSO), and linear regression (LR). The findings reveal that applying these techniques in the current COVID-19 outbreak scenario is a viable approach. Results indicate that LR outperforms all other models tested in accurately forecasting death rates, recovery rates, and newly reported cases, with LASSO following closely. However, based on the available data, SVM exhibits lower performance across all predictive scenarios.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/2f69e54c8cf154f203f2b18319fce131b404093c",
        "citation_count": 0
    },
    {
        "title": "Classification of Heart Diseases Based on Machine Learning: A Review",
        "abstract": "The article emphasizes the critical need for early and accurate diagnosis of cardiovascular disease (CVD), a leading cause of global mortality. Recent advancements in machine learning (ML) have shown promising results in classifying cardiac disorders, aiming to enhance healthcare practices. It discusses both the benefits and limitations of current ML algorithms used in this field, highlighting their role in improving the management of cardiac diseases through accurate diagnosis. The study evaluates various supervised learning techniques like support vector machines, decision trees, and neural networks, illustrating their effectiveness in handling diverse datasets and identifying significant patterns. Furthermore, it explores unsupervised learning methods such as clustering algorithms, which uncover hidden patterns in cardiac data. The research also investigates the potential of ensemble approaches and deep learning to further enhance classification accuracy. In conclusion, the study provides an overview of the current state of ML-based heart disease classification research, aiming to inform policymakers, physicians, and researchers about the transformative potential of ML in advancing heart disease diagnosis and treatment, ultimately aiming for improved patient outcomes and reduced healthcare costs.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/2f79c64061eede2810a001a38c483068ec332e2e",
        "citation_count": 1
    },
    {
        "title": "Improved Risk Prediction Following Surgery Using Machine Learning Algorithms",
        "abstract": "Background: Machine learning is used to analyze big data, often for the purposes of prediction. Analyzing a patient\u2019s healthcare utilization pattern may provide more precise estimates of risk for adverse events (AE) or death. We sought to characterize healthcare utilization prior to surgery using machine learning for the purposes of risk prediction. Methods: Patients from MarketScan Commercial Claims and Encounters Database undergoing elective surgery from 2007\u20132012 with \u22651 comorbidity were included. All available healthcare claims occurring within six months prior to surgery were assessed. More than 300 predictors were defined by considering all combinations of conditions, encounter types, and timing along with sociodemographic factors. We used a supervised Naive Bayes algorithm to predict risk of AE or death within 90 days of surgery. We compared the model\u2019s performance to the Charlson\u2019s comorbidity index, a commonly used risk prediction tool. Results: Among 410,521 patients (mean age 52, 52 \u00b1 9.4, 56% female), 4.7% had an AE and 0.01% died. The Charlson\u2019s comorbidity index predicted 57% of AE\u2019s and 59% of deaths. The Naive Bayes algorithm predicted 79% of AE\u2019s and 78% of deaths. Claims for cancer, kidney disease, and peripheral vascular disease were the primary drivers of AE or death following surgery. Conclusions: The use of machine learning algorithms improves upon one commonly used risk estimator. Precisely quantifying the risk of an AE following surgery may better inform patient-centered decision-making and direct targeted quality improvement interventions while supporting activities of accountable care organizations that rely on accurate estimates of population risk.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/2f7aaa2bfacd44e6486a507d096a5092b7d7bdb7",
        "citation_count": 25
    },
    {
        "title": "Iterative Annotation of Biomedical NER Corpora with Deep Neural Networks and Knowledge Bases",
        "abstract": "The large availability of clinical natural language documents, such as clinical narratives or diagnoses, requires the definition of smart automatic systems for their processing and analysis, but the lack of annotated corpora in the biomedical domain, especially in languages different from English, makes it difficult to exploit the state-of-art machine-learning systems to extract information from such kinds of documents. For these reasons, healthcare professionals lose big opportunities that can arise from the analysis of this data. In this paper, we propose a methodology to reduce the manual efforts needed to annotate a biomedical named entity recognition (B-NER) corpus, exploiting both active learning and distant supervision, respectively based on deep learning models (e.g., Bi-LSTM, word2vec FastText, ELMo and BERT) and biomedical knowledge bases, in order to speed up the annotation task and limit class imbalance issues. We assessed this approach by creating an Italian-language electronic health record corpus annotated with biomedical domain entities in a small fraction of the time required for a fully manual annotation. The obtained corpus was used to train a B-NER deep neural network whose performances are comparable with the state of the art, with an F1-Score equal to 0.9661 and 0.8875 on two test sets.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/306519f049fe470a2380326f7d52f813b0723be2",
        "citation_count": 17
    },
    {
        "title": "Online Machine Learning Algorithms Review and Comparison in Healthcare",
        "abstract": "Currently, the healthcare industry uses Big Data for essential patient care information. Electronic Health Records (EHR) store massive data and are continuously updated with information such as laboratory results, medication, and clinical events. There are various methods by which healthcare data is generated and collected, including databases, healthcare websites, mobile applications, wearable technologies, and sensors. The continuous flow of data will improve healthcare service, medical diagnostic research and, ultimately, patient care. Thus, it is important to implement advanced data analysis techniques to obtain more precise prediction results. Machine Learning (ML) has acquired an important place in Big Healthcare Data (BHD). ML has the capability to run predictive analysis, detect patterns or red flags, and connect dots to enhance personalized treatment plans. Because predictive models have dependent and independent variables, ML algorithms perform mathematical calculations to find the best suitable mathematical equations to predict dependent variables using a given set of independent variables. These model performances depend on datasets and response, or dependent, variable types such as binary or multi-class, supervised or unsupervised. The current research analyzed incremental, or streaming or online, algorithm performance with offline or batch learning (these terms are used interchangeably) using performance measures such as accuracy, model complexity, and time consumption. Batch learning algorithms are provided with the specific dataset, which always constrains the size of the dataset depending on memory consumption. In the case of incremental algorithms, data arrive sequentially, which is determined by hyperparameter optimization such as chunk size, tree split, or hoeffding bond. The model complexity of an incremental learning algorithm is based on a number of parameters, which in turn determine memory consumption.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/30921a80657016ec53f909d93a1e6ca7a08cc43c",
        "citation_count": 2
    },
    {
        "title": "Comparative Analysis of Diagnosis of Non-Alcoholic Fatty Liver Disease (NAFLD) Using Machine Learning Algorithms",
        "abstract": "Liver disease is one of the leading cause of deaths in the world. It could be reversed if detected at early stage and many lives could be saved thereby. Therefore, it is crucial to detect the liver disease at an early stage. The primary goal of this review is to present a thorough summary of recent research, which have been carried out using machine learning (ML) techniques. These techniques have been developed by researchers to help healthcare professionals to detect non-alcoholic fatty liver disease (NAFLD). In this study, several ML techniques viz., supervised, unsupervised, and semi-supervised reinforcement learning are covered, whose performance is compared in terms of sensitivity, accuracy, and precision. The prime objective of this study is to present a comparative analysis of different ML methods for the diagnosis and early prediction of liver disease in the medical images.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/30ff38d793086bd48ca4cca2a7ad971af1a3de87",
        "citation_count": 0
    },
    {
        "title": "A Systematic Review of Features Forecasting Patient Arrival Numbers",
        "abstract": "Adequate nurse staffing is crucial for quality healthcare, necessitating accurate predictions of patient arrival rates. These forecasts can be determined using supervised machine learning methods. Optimization of machine learning methods is largely about minimizing the prediction error. Existing models primarily utilize data such as historical patient visits, seasonal trends, holidays, and calendars. However, it is unclear what other features reduce the prediction error. Our systematic literature review identifies studies that use supervised machine learning to predict patient arrival numbers using nontemporal features, which are features not based on time or dates. We scrutinized 26 284 studies, eventually focusing on 27 relevant ones. These studies highlight three main feature groups: weather data, internet search and usage data, and data on (social) interaction of groups. Internet data and social interaction data appear particularly promising, with some studies reporting reduced errors by up to 33%. Although weather data are frequently used, its utility is less clear. Other potential data sources, including smartphone and social media data, remain largely unexplored. One reason for this might be potential data privacy challenges. In summary, although patient arrival prediction has become more important in recent years, there are still many questions and opportunities for future research on the features used in this area.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/312da52046326f90ed88893644a5c7cf768b13ee",
        "citation_count": 0
    },
    {
        "title": "A Novel Methodology for Building Longitudinal, Patient-Centric Real World Datasets in Hemophilia A",
        "abstract": "\n Background: There are limited real-world data (RWD) available on the unmet needs of people with mild or moderate hemophilia A (PwHA). This population accounts for 40-52% of all PwHA, including nearly all women with hemophilia A (HA), and is under-represented in scientific literature (Michele, et al. Haemophilia 2014; Benson, et al. Blood Transfus 2018; Peyvandi, et al. Haemophilia 2019). Available claims data from payer databases are confined to billing codes, and lack key information on outcomes and disease characterization (e.g. severity, treatment response.) (Tyree, et al. Am J Med Qual 2006). Registry datasets can require resource-intensive data entry and potentially miss key information about care received at outside facilities, at home, or after patients switch providers (Gliklich, et al. Registries for Evaluating Patient Outcomes: A User's Guide. 2014). To address these data gaps, we developed a novel, patient-centered approach to create a longitudinal healthcare database from individuals with mild and moderate HA in the United States. This study assessed the feasibility of this approach, which integrates medical record data collected during routine clinical care along with patient-reported outcomes (PROs) to provide needed insights into this under-represented population.\n Methods: Recruitment began in June 2020 via a broad strategy of social media outreach, healthcare provider partnerships, and patient advocacy groups. Eligibility was confined to mild or moderate PwHA, confirmed via physician report within provider notes in combination with baseline factor VIII levels (>5-50% mild, 1-5% moderate.) This study received research ethics board approval and abides by the guiding principles of the Declaration of Helsinki.\n PwHA enrolled via an online record management platform, PicnicHealth. After signing authorization forms for collection of their electronic health records (EHR) and informed consent to share their de-identified data for research, participants were prompted to enter information on their care providers. Records were gathered from all providers, across any facility, retrospectively as records were available. (Figure 1) All records obtained were made available to the participants via a medical timeline.\n Records were translated to text via optical character recognition with human review. Data elements from structured text as well as disease-specific elements from narrative text were captured using natural language processing and supervised machine learning. All elements, including visit metadata, conditions, measurements, drugs, and procedures were mapped to standardized medical ontologies and reviewed by a team of nurses. (Table 1) Quality control was assessed via inter-abstractor agreement on outputs with physician review.\n Patient-reported bleed, treatment, and pain data were collected via online questionnaire for a subset of PwHA, with participants prompted to enter data every 2 weeks. Abstracted EHR data was linked to PRO responses in a de-identified dataset. Cohort and abstraction characteristics were summarized descriptively.\n Results: From June 1, 2020 to June 30, 2021, 104 PwHA met eligibility criteria for enrollment (65 [62.5%] mild; 39 [37.5%] moderate). Participants saw providers across 34 states in the US, 22.1% (23/104) were female, and 20.6% (14/68) of those with known race/ethnicity status were from minority groups.\n Records were gathered from a median of six care sites and 16 providers per participant. A median of 50 (IQR [21-93]) clinical documents from 11 years were processed for each PwHA. (Table 2) Inter-abstractor agreement to assess abstraction quality averaged 95.9% for condition, 99.5% for drug name, and 95.4% for drug start date. As of June 2021, the average PRO response rate was 90.3% (150/166 of all requests) and continues prospectively.\n Conclusions: The patient-centric data collection methods implemented in this study provide a novel approach to build longitudinal real-world data sets. Technology-enabled data abstraction showed consistent high quality when processing the heterogeneous clinical records across disparate providers and care sites, and direct engagement with patients complements potential gaps in the clinical record. Additionally, this approach provides needed data on groups under-represented in RWD and traditional PwHA cohorts, including those with mild and moderate disease and women with HA.\n Figure 1 Figure 1.\n \n \n \n Skinner:\u2008ICER: Membership on an entity's Board of Directors or advisory committees; Spark (DMC): Honoraria; Sanofi: Honoraria; F. Hoffmann-La Roche Ltd/Genentech, Inc.: Honoraria; Pfizer (DMC): Honoraria; Bayer: Honoraria, Membership on an entity's Board of Directors or advisory committees; uniQure: Research Funding; Takeda: Honoraria, Research Funding; F. Hoffmann-La Roche Ltd: Research Funding; Freeline: Research Funding; BioMarin: Honoraria, Research Funding; IPA Ltd.: Current holder of individual stocks in a privately-held company; National Hemophilia Foundation: Consultancy; Institute for Policy Advancement Ltd: Current Employment; WFH USA: Membership on an entity's Board of Directors or advisory committees; BCBS MAP: Membership on an entity's Board of Directors or advisory committees. Hanson:\u2008PicnicHealth: Current Employment, Current holder of stock options in a privately-held company. Xu:\u2008F. Hoffmann-La Roche AG: Current Employment. Ofori-Asenso:\u2008F. Hoffmann-La Roche Ltd: Current Employment. Ko:\u2008Genentech, Inc.: Current Employment; Genentech, Inc.-Roche: Current equity holder in publicly-traded company, Current holder of individual stocks in a privately-held company, Current holder of stock options in a privately-held company. Cibelli:\u2008PicnicHealth: Current Employment. Nissen:\u2008Novartis: Consultancy; Actelion: Consultancy; F. Hoffmann-La Roche Ltd: Current Employment, Current holder of stock options in a privately-held company. Witkop:\u2008Roche Advisory Panel: Consultancy; National Hemophilia Foundation: Current Employment. Sanabria:\u2008F. Hoffmann-La Roche Ltd: Current Employment, Current holder of individual stocks in a privately-held company. Shapiro:\u2008Novartis: Research Funding; Novo Nordisk: Other: Advisory board fees, Research Funding, Speakers Bureau; Octapharma: Research Funding; Pfizer: Research Funding; OPKO: Research Funding; Prometric BioTherapeutics: Research Funding; Sangamo: Other: Advisory board fees, Research Funding; Sigilon Therapeutics: Other: Advisory board fees, Research Funding; Takeda: Research Funding; Kedrion Biopharma: Research Funding; Glover Blood Therapeutics: Research Funding; Genentech: Other: Advisory board fees, Research Funding, Speakers Bureau; Daiichi Sankyo: Research Funding; Bioverativ (a Sanofi company): Other: Advisory board fees, Research Funding; BioMarin: Research Funding; Agios: Research Funding.\n",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/312f4d9a1603365eb788f5281194ad7bab8f5682",
        "citation_count": 0
    },
    {
        "title": "Hospital-acquired infections surveillance: The machine-learning algorithm mirrors National Healthcare Safety Network definitions",
        "abstract": "Abstract Background: Surveillance of hospital-acquired infections (HAIs) is the foundation of infection control. Machine learning (ML) has been demonstrated to be a valuable tool for HAI surveillance. We compared manual surveillance with a supervised, semiautomated, ML method, and we explored the types of infection and features of importance depicted by the model. Methods: From July 2021 to December 2021, a semiautomated surveillance method based on the ML random forest algorithm, was implemented in a Brazilian hospital. Inpatient records were independently manually searched by the local team, and a panel of independent experts reviewed the ML semiautomated results for confirmation of HAI. Results: Among 6,296 patients, manual surveillance classified 183 HAI cases (2.9%), and a semiautomated method found 299 HAI cases (4.7%). The semiautomated method added 77 respiratory infections, which comprised 93.9% of the additional HAIs. The ML model considered 447 features for HAI classification. Among them, 148 features (33.1%) were related to infection signs and symptoms; 101 (22.6%) were related to patient severity status, 51 features (11.4%) were related to bacterial laboratory results; 40 features (8.9%) were related to invasive procedures; 34 (7.6%) were related to antibiotic use; and 31 features (6.9%) were related to patient comorbidities. Among these 447 features, 229 (51.2%) were similar to those proposed by NHSN as criteria for HAI classification. Conclusion: The ML algorithm, which included most NHSN criteria and >200 features, augmented the human capacity for HAI classification. Well-documented algorithm performances may facilitate the incorporation of AI tools in clinical or epidemiological practice and overcome the drawbacks of traditional HAI surveillance.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3154c459f7ecbe870b6e3a3085ab5472c15fec1f",
        "citation_count": 2
    },
    {
        "title": "Editorial: The Artificial Intelligence in Translational Medicine and Biomedical Research, How Future Can be Shaped?!!",
        "abstract": "\n\n\n\nThe new era of translational medicine is facing a special and unique transition as the Artificial Intelligence (AI) and Machine Learning (ML) advance. The latest findings in many laboratories around the globes are promising and paved the way toward extraordinary innovative development in the field of medicine and medical research.\nIn medical research, gradual and consistent advancement, from rudimentary origins, were initial key steps toward medical discoveries and innovation. However, with the AI inclusion into these research approaches, the traditional translational medicine is pacing up. Creating a great hope for filling many sophisticated gaps in knowledge that has been a challenge by the traditional methodology. Such advancements in AI and its involvement in biomedicine and healthcare are forging the framework for a flourishing and visionary translational medicine and biomedical research.\nLately, following the discoveries made by a collaborative team of scientists from the University of Vermont and Tufts University (The xenobots), enormous research and investigation started to glance in the field. Attempts toward drug discovery, wound recoveries and self-proliferating stem cells were made. Most recently, scientists at Tufts University and Harvard University\u2019s Wyss Institute have designed and created living small robots from cells of human trachea. In an in vitro world, these created cells could induce tissue damage recovery.\nThe AI based medical diagnosis is also a revolutionary step toward proper diagnosis and consequently, medical intervention. The AI and ML are becoming so intelligent to an extent not to only diagnose the disease but also predict disease prognosis in future. The narrow AI (WatsonX) that was introduced by the IBM company can play a major role in assisting clinical decisions and image analysis. The challenge that faced the globe after the COVID-19 outbreak with multiple false negativity and false positivity outcomes in the diagnose necessitated the support of the AI in this field.\n\n\n\n\nAdditionally, the Neuralink that is introduced by Neuralink Corp. is taking a historical step after gaining the approval from FDA to start human trials. Such dramatical change in the brain interface using AI can be a solution for many diseases that human couldn\u2019t treat. Restoring brain activity and autonomy through integration of an AI to human nervous system is a mind-boggling promise that AI can give to medicine and medical science.\nFinally, these new approaches and advancement in AI and ML are prone to proper design and supervision, as well as, performing randomized clinical trials prior to the use in real-life medical interventions. Nonetheless, research and experimentations for AI inclusion in medicine are still an ongoing process, yet the opportunities are realistic that AI can be of great benefit in supporting medicine and biomedical research, specifically, where there is gap in knowledge and inability of human capacity to resolve them. There is no doubt that AI will be a significant party of the healthcare system in the future and a core medical support.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3177fe3e9b025f18149a7def22a1544a39dd8565",
        "citation_count": 0
    },
    {
        "title": "Predictive hospital site selection model using machine learning techniques",
        "abstract": "Globally, countries are faced with healthcare challenges that vary from one to the next. While health service delivery challenges are more often seen in countries with a very high HumanDevelopment Index (HDI), inefficient healthcare intervention challenges attract more attention in those with a low HDI. Health systems and infrastructure interventions are major challenges for most countries in Africa. The conventional or traditional approach to situating hospitals has been subjected to the unreliable intuition of experts and perhaps biased by nepotism, favoritism, and tribalism of recognized interest. In this research, we prioritize health factors for hospital site predictions. A hospital is a healthcare intervention infrastructure that should meet the healthcare needs of people where it is located. Many hospital site selection researchers have considered other important factors such as geographical, economic, and socio-demographic factors. However, healthcare factors that will specifically address the healthcare needs of people in that locality have not been mentioned. This paper considers a robust, viable, reliable, and dependable approach to solve the specific problem of selecting the best location for building new hospitals based on the specific healthcare needs of the location for improved healthcare service delivery. We propose a supervised machine learning approach to predict the most suitable sites for building new hospitals. Support Vector Machine (SVM), K-Nearest Neighbours (KNN), Logistic Regression (LGR), and Decision Tree (DT) machine learning algorithm are used to predict the optimal location for hospital site selection on the basis of various attributes used in the dataset. The dataset was extracted from clinical exploratory data using parameters such as reproductive, maternal, newborn, and child health, Infectious diseases, Noncommunicable diseases, Adequate sanitation, Service capacity, and access to essential medicines as a Universal Health Coverage (UHC) standard by World Health Organization (WHO). The model is implemented using Python programming language. The system will improve health systems and infrastructural interventions, thereby enabling efficient healthcare service delivery in developing countries, especially in Africa.\u00a0",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/31cbea6e7d7ed67463fb18f18c0a8c8a31a36fdf",
        "citation_count": 0
    },
    {
        "title": "Using machine learning to improve anaphylaxis case identification in medical claims data.",
        "abstract": "Objectives\nAnaphylaxis is a severe life-threatening allergic reaction, and its accurate identification in healthcare databases can harness the potential of \"Big Data\" for healthcare or public health purposes.\n\n\nMaterials and methods\nThis study used claims data obtained between October 1, 2015 and February 28, 2019 from the CMS database to examine the utility of machine learning in identifying incident anaphylaxis cases. We created a feature selection pipeline to identify critical features between different datasets. Then a variety of unsupervised and supervised methods were used (eg, Sammon mapping and eXtreme Gradient Boosting) to train models on datasets of differing data quality, which reflects the varying availability and potential rarity of ground truth data in medical databases.\n\n\nResults\nResulting machine learning model accuracies ranged from 47.7% to 94.4% when tested on ground truth data. Finally, we found new features to help experts enhance existing case-finding algorithms.\n\n\nDiscussion\nDeveloping precise algorithms to detect medical outcomes in claims can be a laborious and expensive process, particularly for conditions presented and coded diversely. We found it beneficial to filter out highly potent codes used for data curation to identify underlying patterns and features. To improve rule-based algorithms where necessary, researchers could use model explainers to determine noteworthy features, which could then be shared with experts and included in the algorithm.\n\n\nConclusion\nOur work suggests machine learning models can perform at similar levels as a previously published expert case-finding algorithm, while also having the potential to improve performance or streamline algorithm construction processes by identifying new relevant features for algorithm construction.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/31f8e97e78ce22ccb8fc1ed38855c310c8fa99ec",
        "citation_count": 0
    },
    {
        "title": "Disha: An Implementation of Machine Learning Based Bangla Healthcare Chatbot",
        "abstract": "While humans as a whole do live longer nowadays than ever before, we now suffer certain illnesses to a degree never seen in the past - including rising rates of Diabetes, Hypertension, Hypotension, Cholesterol imbalance, obesity and, ailments such as fever. People around the world are preemptively seeking medical advices on how to live a healthy lifestyle. They are looking to lower their risk of various diseases. A healthcare chatbot can play a significant role to monitor a person\u2019s health status. A healthcare chatbot is a computer program designed to simulate conversation with human users as a virtual medical assistant. Our study shows, there are some healthcare chatbots available in English and other languages but not in Bangla. In this paper, we have demonstrated a machine learning-based closed domain Bangla healthcare chatbot \u2018Disha (Direction)\u2019 which can converse in Bangla with the user with the help of its knowledge base and through learning from interactions with the user. It helps a user to diagnose potential diseases based on inputted symptoms, keep track of a user\u2019s health status, and alert a user from potential health hazards. This paper explores the use of six supervised machine learning approaches and showed significant efficiency.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/3262f3cc5b32ba5a997392480acd5fc93caa7939",
        "citation_count": 31
    },
    {
        "title": "Machine Learning-Driven Insights into Autoimmune Disease Prediction and Patient Outcomes",
        "abstract": "Machine learning has given a great contribution in the field of healthcare whether it is pre-diagnosis of disease or personalized medicine approaches for genetic diseases. Autoimmune diseases, when the body's immune system mistakenly attacks healthy cells, tissues, and organs. This can happen when the immune system produces proteins called autoantibodies that signal the body to attack healthy tissues, as if they were foreign organisms. Understanding the genetic underpinnings of these diseases is crucial for improving diagnosis, treatment, and patient outcome. It enables the identification of key genetic markers and pathways, paving the way for targeted therapies and better disease management. Our objective is to leverage machine learning (ML) to work on such diseases for predicting and classifying them on the basis of a patient's symptoms. To achieve this, employment of supervised machine learning techniques will be used. Initially, we will pre-process patient data, including symptoms and clinical history. Training of various machine learning models will provide metrics to evaluate the model. Model also identified other conclusions about the percentage possibility of prevalence of disease among tested data.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/32a1d2bd86cf84321f4fa96ccf48d506ea7b6ba4",
        "citation_count": 0
    },
    {
        "title": "Development of a recommender system for dental care using machine learning",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/32a56d826b9a2dd420b712b79e02ce9a4dea6934",
        "citation_count": 13
    },
    {
        "title": "An IoT-based wearable system using accelerometers and machine learning for fetal movement monitoring",
        "abstract": "Fetal movement is an essential index of fetal well-being. However, existing technologies in clinical applications cannot provide an effective, long-term and easily accessible way for fetal movement monitoring. This paper presents a wearable system using accelerometers and machine learning for automatic monitoring of fetal movement. To realize the concept of the e-health home care, Internet of Things (IoT) is applied on the system to connect all the terminal monitoring units to a control center. The whole system mainly consists of two parts: the local monitoring unit and the remote health evaluation unit, respectively. The local monitoring unit includes: (1) a garment integrating accelerometers for data acquisition and an embedded system for signal processing and machine learning, (2) an Android-based local monitoring platform used for visualization of statistics on fetal health status based on information received from the garment via Bluetooth. The local monitoring unit is also designed to alarm the mother if fetal movements reduce significantly or if the intensity is weakened. The remote health evaluation unit consists of a cloud computing platform and an expert system. Connecting each terminal local monitoring unit via the Internet, the remote health evaluation unit allows an expert to access the information at distance for further medical supervision, make advanced diagnosis as well as take actions in case of emergency. The cloud computing platform is also designed for convergence of medical data from each individual patient to build a general medical database for scientific research. The proposed local fetal movement monitoring unit along with the remote health evaluation platform could be regarded as a good example of IoT application in the field of smart textile and home healthcare.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/32b7b9799d1a4a2d6da16e5ba8d895e3e0ca3e57",
        "citation_count": 21
    },
    {
        "title": "The effects of class rarity on the evaluation of supervised healthcare fraud detection models",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/32d8bc455bc5e4d90a15d6468da604dc7d1736f8",
        "citation_count": 43
    },
    {
        "title": "Detecting adverse drug reactions in the general practice healthcare database",
        "abstract": "The novel contribution of this research is the development of a supervised algorithm that extracts relevant attributes from The Health Improvement Network database to detect prescription side effects. Prescription drug side effects are a common cause of morbidity throughout the world. Methods that aim to detect side effects have historically been limited due to the data available, but some of these limitations may be overcome by incorporating longitudinal observational databases into pharmacovigilance. Existing side effect detecting methods using longitudinal observational databases have shown promise at becoming a fundamental component of post marketing surveillance but unfortunately have high false positive rates. An extra step is required to further analyse and filter the potential side effects detected by existing methods due to their high false positive rates, and this reduces their efficiency. In this thesis a novel methodology, the supervised adverse drug reaction predictor (SAP) framework, is presented that learns from known side effects, and identifies patterns that can be utilised to detect unknown side effects. The Bradford-Hill causality considerations are used to derive suitable attributes as inputs into a learning algorithm. Both supervised and semi-supervised techniques are investigated due to the limited number of definitively known side effects. The results showed that the SAP framework implementing a random forest classifier outperformed the existing methods on The Health Improvement Network longitudinal observational database, with AUCs ranging between 0.812-0.937, an overall MAP of 0.667, precision values between 0.733-1 and a false positive rate \u2264 0.013. When applied to the standard reference the SAP framework implementing a support vector machine obtained a MAP score of 0.490, an average AUC of 0.703 and a false positive rate of 0.16. The false positive rate is lower than that obtained by existing methods on the standard reference.",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/32e60b7d39e54c3019ccbbb3ac96abf1b902d725",
        "citation_count": 2
    },
    {
        "title": "Human Recognition using Single-Input-Single-Output Channel Model and Support Vector Machines",
        "abstract": "WiFi based human motion recognition systems mainly rely on the availability of Channel State Information (CSI). Embedded within WiFi devices, the present radio subsystems can output CSI that describes the response of a wireless communication channel. Radio subsystems as such, use complex hardware architectures that consume lots of energy during data transmission, as well as exhibit phase drift in the sub-carriers. Although human motion recognition (HMR) based on multicarrier transmission systems show better classification accuracy, transmission of multiple sub-carriers results in an increase in the overall energy consumption at the transmitter. Apparently CSI based systems can be perceived as process intensive and power hungry devices. To alleviate the process intensive computing and reduce energy consumption in WiFi, this study proposes a human recognition system that uses only one radio carrier frequency. The study uses two software defined radios and a machine learning classifier to identify four humans, and the study results show that human identification is possible with 99% accuracy using only one radio carrier. The results of this study will have an impact on the development process of smart sensing systems, particularly those that relate to healthcare, authentication, and passive monitoring and sensing. Keywords\u2014Motion detection; pattern recognition; received signal strength indicator; Software Defined Radio (SDR); supervised learning",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/333b50a335b31d5da6556a75ff715fa86418b4ed",
        "citation_count": 4
    },
    {
        "title": "A HOG feature extraction and CNN approach to Parkinson\u2019s spiral drawing diagnosis",
        "abstract": "of machine learning, trains algorithms using data and their corresponding labels (9). The algorithms form relationships between the data and their labels before being tested on unseen data with the goal of predicting the correct label (9). Current healthcare applications of machine and deep learning include precision medicine and radiomics (10). Applications in precision medicine involve the use of modeling techniques to predict optimal treatment methods for individual patients (10). Radiomics is the general extraction of numerical features from medical images, and often involves the identification of cancerous lesions in image data using features not visibly distinguishable (10). We utilized two supervised learning algorithms, support vector machines and neural networks, to aid in the early diagnosis of PD. The goal of this study was to create two models that could be used to increase accessibility to an accurate and more efficient baseline PD diagnosis to alleviate undiagnosed",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/336d14d8f1f51e89a8d7313f3f3ed1b20350f8ee",
        "citation_count": 0
    },
    {
        "title": "Insight Extraction From E-Health Bookings by Means of Hypergraph and Machine Learning",
        "abstract": "New technologies are transforming medicine, and this revolution starts with data. Usually, health services within public healthcare systems are accessed through a booking centre managed by local health authorities and controlled by the regional government. In this perspective, structuring e-health data through a Knowledge Graph (KG) approach can provide a feasible method to quickly and simply organize data and/or retrieve new information. Starting from raw health bookings data from the public healthcare system in Italy, a KG method is presented to support e-health services through the extraction of medical knowledge and novel insights. By exploiting graph embedding which arranges the various attributes of the entities into the same vector space, we are able to apply Machine Learning (ML) techniques to the embedded vectors. The findings suggest that KGs could be used to assess patients' medical booking patterns, either from unsupervised or supervised ML. In particular, the former can determine possible presence of hidden groups of entities that is not immediately available through the original legacy dataset structure. The latter, although the performance of the used algorithms is not very high, shows encouraging results in predicting a patient's likelihood to undergo a particular medical visit within a year. However, many technological advances remain to be made, especially in graph database technologies and graph embedding algorithms.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/33aeaf43e80eaac49c5ed7b0cdffaf30d0ce9107",
        "citation_count": 4
    },
    {
        "title": "Emergency department admissions during COVID-19: explainable machine learning to characterise data drift and detect emergent health risks",
        "abstract": "Supervised machine learning algorithms deployed in acute healthcare settings use data describing historical episodes to predict clinical outcomes. Clinical settings are dynamic environments and the underlying data distributions characterising episodes can change with time (a phenomenon known as data drift), and so can the relationship between episode characteristics and associated clinical outcomes (so-called, concept drift). We demonstrate how explainable machine learning can be used to monitor data drift in a predictive model deployed within a hospital emergency department. We use the COVID-19 pandemic as an exemplar cause of data drift, which has brought a severe change in operational circumstances. We present a machine learning classifier trained using (pre-COVID-19) data, to identify patients at high risk of admission to hospital during an emergency department attendance. We evaluate our model's performance on attendances occurring pre-pandemic (AUROC 0.856 95%CI [0.852, 0.859]) and during the COVID-19 pandemic (AUROC 0.826 95%CI [0.814, 0.837]). We demonstrate two benefits of explainable machine learning (SHAP) for models deployed in healthcare settings: (1) By tracking the variation in a feature's SHAP value relative to its global importance, a complimentary measure of data drift is found which highlights the need to retrain a predictive model. (2) By observing the relative changes in feature importance emergent health risks can be identified.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/33c8c64369e4ad47143dc24b058651f8b27fb3ff",
        "citation_count": 1
    },
    {
        "title": "Artificial Intelligence enabled Web-Based Prediction of Diabetes using Machine Learning Approach",
        "abstract": "Healthcare is the preservation of health that includes diagnosis, surgery, therapy, cure and other related to health of the people. With the advancement of technology, healthcare is enhanced by practicing smart healthcare, e-health and m-Health. In recent years, computerized physician consultant has become popular for the improvement of people's health and this requires a wide range of study of disease that emerges to the clinical decision support system. In this work, an early stage diabetes risk prediction dataset is trained with supervised machine learning and categorized with unsupervised machine learning. The diabetes is classified by best accuracy among supervised machine learning algorithms for a new patient examination. A Web application is created to predict early stage risk of diabetes by classifying results based on the questionnaire of the patient without testing kit using machine learning. Also, the result is analyzed and predicted the chance of having positive or negative diabetes based on the examination falls into clusters by unsupervised machine learning. The evaluation of the prediction is observed to improve the accuracy further with a deep learning approach.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/341348968e97f6308eae9d2dc246a97833c27f21",
        "citation_count": 3
    },
    {
        "title": "Site-Specific Crop Management",
        "abstract": "Machine learning (ML) is an emerging technology in which both researchers and academic communities have been able to obtain a distinct range of numerous applications such as image recognition, healthcare, fraud detection, and so on. In addition to this, ML algorithms have been identified for prediction, classification, and other purposes. On the contrary, agriculture plays an important role in a country's economy. Further crop yield is mainly affected by diverse factors like types of soil, temperature, moisture, and rainfall. Moreover, the crops are not evenly distributed in an agricultural field restricting the possibility of complete utilization of the field. Even modern technology like artificial intelligence(AI), ML, and the Internet of Things(IOT) help to overcome problems related to agricultural aspects. Therefore ML is reliable, suitable and well developed, which are not utilized properly by farmers. The proposed research work is to predict the crop yield of a given area and map the yield distribution using an ML algorithm through the Random Forest (RF) mechanism. RF approach is a widely used supervised learning technique that may be applied to regression and classification problems. Hence crop yield prediction is carried out by analyzing data on various factors affecting agriculture like temperature, soil type, moisture, etc. Subsequently, the main motivation of this research is to build an interactive user-friendly interface for the farmers which provides the yield map distinguishing the yield rate in a given field along with suggestions for the better utilization of the low-yielding areas.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3415445bb9ba8bfea87dab2993a889d7b025d4d9",
        "citation_count": 0
    },
    {
        "title": "Machine learning in atrial fibrillation\u2014racial bias and a call for caution",
        "abstract": "\u00a9 Journal of Medical Artificial Intelligence. All rights reserved. J Med Artif Intell 2021;4:6 | https://dx.doi.org/10.21037/jmai-21-12 Early diagnosis of atrial fibrillation (AF), a common arrhythmia that can cause adverse events such as stroke, is a major clinical challenge. Due to its often asymptomatic and paroxysmal nature, AF is easily missed on single electrocardiograms (ECGs), making outpatient screening challenging. As a result, patients may not receive a timely diagnosis, with up to 5% of all AF cases being diagnosed at the time of stroke (1). Various machine learning (ML) models, primarily involving supervised ML methods, have been developed with the hopes of bringing an effective population screening tool to the forefront. While these models show strong performance in their respective studies, data regarding their effectiveness across racial groups is lacking. Therefore, using ML for AF screening requires two important considerations: (I) any biases in the training set data will be perpetuated in the predictions that the models offer; (II) AF has a known racial paradox, where traditional risk factors that were derived from a largely Caucasian population have a weaker correlation with AF incidence in Black patients. Below, we elaborate on these points and argue that while ML presents a unique opportunity to increase the detection of AF, it also deserves special caution to avoid reinforcing existing healthcare disparities. ML AF screening tools are commonly developed using ECG data about p-waves, R-R intervals, heart rate, and other parameters. While this has shown the ability to produce strong predictive models, the actual data sources deserve scrutiny (2). A recently published systematic review identified that while more than 100 publications exist using ECG data to develop ML models, more than half of them used the same four open-access ECG databases (3). In theory, this is not necessarily problematic, and it is understandable that so many studies reuse well known and freely available datasets. Ideally, however, the datasets would report a sufficient level of patient diversity to well represent the entire US population. Instead, many of the most commonly used ECG datasets only report limited demographic data, including the patient\u2019s age, gender, and/or baseline clinical characteristics, without reporting racial or ethnic background. Considering the known racial differences that exist in several baseline ECG parameters, including left ventricular hypertrophy, right axis deviation, bundle branch blocks, and others, transparency about racial demographic information in these datasets is critical (4). Table 1 summarizes the most commonly used ECG databases, as well as the readily available demographic information provided by each. The reuse of these datasets carries particular concern in the diagnosis of AF, a disease with a known \u201cracial paradox\u201d. This paradox refers to the fact that while Black patients have a higher burden of AF risk factors including hypertension, diabetes, congestive heart failure, and others, they paradoxically have a lower incidence of AF (5). Many explanations for this paradox have been proposed, including underdiagnosis of AF in Black patients due to lower healthcare access, regional genetic variations, or an unequal influence of certain risk factors between racial groups (6-8). In either case, the presence of this paradox makes data transparency in AF an even greater priority. In the same way that traditional risk factors for AF showed worse correlations with incidence in Black patients, we may now be developing ML models with the same shortcomings. One solution is for hospital systems to develop AF models using their own internal databases. The Mayo Letter to the Editor",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/342effdd6abf05c292a78c1b9aa52729ebf0b1b8",
        "citation_count": 0
    },
    {
        "title": "An Unobtrusive Human Activity Recognition System Using Low Resolution Thermal Sensors, Machine and Deep Learning",
        "abstract": "Given the aging population, healthcare systems need to be established to deal with health issues such as injurious falls. Wearable devices can be used to detect falls. However, most wearable devices are obtrusive, and patients generally do not like or may forget to wear them. In this study, we developed an unobtrusive monitoring system using infrared technology to unobtrusively detect locations and recognize human activities such as sitting, standing, walking, lying, and falling. We prototyped a system consisting of two 24\u00d732 thermal array sensors and collected data from healthy young volunteers performing ten different scenarios. A supervised deep learning (DL)-based approach classified activities and detected locations from images. The performance of the DL approach was also compared with the machine learning (ML)-based methods. In addition, we fused the data of two sensors and formed a stereo system, which resulted in better performance compared to a single sensor. Furthermore, to detect critical activities such as falling and lying on floor, we performed a binary classification in which one class was falling plus lying on floor and another class was all the remaining activities. Using the DL-based algorithm on the stereo dataset to recognize activities, overall average accuracy and F1-score were achieved as 97.6%, and 0.935, respectively. These scores for location detection were 97.3%, and 0.927, respectively. These scores for binary classification were 97.9%, and 0.945, respectively. Our results suggest the proposed system recognized human activities, detected locations, and detected critical activities namely falling and lying on floor accurately.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3431d68e11a49cf8617cb60e2d4e7a93fc6dfe29",
        "citation_count": 13
    },
    {
        "title": "Non-Linear Model for Psychiatric Health Analysis",
        "abstract": "Psychiatric problems, such as depression, have been shown to affect a person's physical wellbeing. These symptoms are typical of a large population. Recently developed Unsupervised Machine technologies, like as non-linear ensemble learning, have demonstrated superiority in a variety of practical domains, from computer vision to healthcare. Non-linear ensemble learning has been proven effective in several contexts. There is some study to examine how DL (Deep Learning) algorithms may be integrated into studies of mental health analysis by reviewing the existing literature on the subject. Here are the four groups into which have placed all the things that seem to fit the bill, according to the various use cases: Genetics, genomes, and clinical data for diagnosis and prognosis Analysis of Data for disease identification. In the research paper, too many machine learning algorithms are used to analysis the psychiatric health analysis. There are some supervised and Unsupervised machine learning algorithms are used for training and testing purposes. Main objective of the research paper is essential for making progress for understanding of mental health issues. In this paper address some of the difficulties that arise when attempting to employ Non- Linear Ensemble algorithms to enhance our knowledge of the factors that contribute to psychiatric disorders, and its offer some suggestions for future research that could lead to advances in the diagnosis and treatment of these ailments. When passed through different algorithms, Non-Linear Regression performed is better then other machine learning algorithms.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/34729cc96fa4aa259438e6bb9b37ed94bfe9aa0d",
        "citation_count": 0
    },
    {
        "title": "Robust Prediction of Patient-Specific Cancer Hallmarks Using Neural Multi-Task Learning: a model development and validation study",
        "abstract": "Background Accurate quantification of cancer hallmark activity is essential for understanding tumor progression, tailoring treatments, and improving patient outcomes. Traditional methods, such as histopathological grading and immunohistochemistry for protein expression, often overlook the complex interplay between cancer cells and the tumor microenvironment and provide limited insight into hallmark-specific mechanisms. We aimed to develop OncoMark, a high-throughput deep learning-enabled neural multi-task learning framework capable of systematically quantifying integrative hallmarks activities using transcriptomics data from routine tumor biopsies. Methods In this study, we acquired single-cell transcriptomics data from 941 tumor samples across 14 tissue types, comprising nearly 3.1 million cells from 56 studies conducted worldwide, to form a large multicenter dataset. Our model employs a supervised neural multi-task learning method designed to predict multiple cancer hallmarks present in the biopsy samples simultaneously. The OncoMark model was developed and tested on 90% of the studies (patients from 51 studies) using repeated five-fold cross-validation performed twice. For further evaluation, the model was assessed on the remaining 10% of the studies (patients from 5 studies) that were excluded from the initial training and testing dataset. Additionally, we included patients from publicly available datasets, including TCGA, GTEx, ANTE, MET500, POG570, CCLE, TARGET, and PCAWG to validate the model\u2019s performance. The primary objective was to evaluate the performance of the model in identifying cancer hallmarks in cancer datasets and ensure no hallmark predictions were made in normal samples across the four prespecified groups: (i) internal test set, (ii) external test set, (iii) normal samples (real-world), and (iv) cancer samples (real-world). Findings OncoMark demonstrated exceptional performance in predicting cancer hallmark states, achieving near-perfect accuracy across internal test data and five external test datasets. Internal testing consistently showed accuracy, precision, recall, and F1 scores exceeding 99%, underscoring the model\u2019s reliability across hallmarks. External test further confirmed these findings, with accuracy, precision, recall, F1 scores, and balanced accuracy consistently exceeding 96\u00b76%, and multiple datasets achieving perfect scores, highlighting the model\u2019s exceptional generalizability and robustness. Specificity tests using GTEx and ANTE datasets accurately classified normal tissues, while sensitivity analysis on TCGA, MET500, CCLE, TARGET, PCAWG, and POG570 datasets effectively identified cancer hallmarks. Interpretation We developed an AI-based framework that enables accurate, efficient, and cost-effective quantification of cancer hallmark activity directly from transcriptomics data. The framework demonstrated significant potential as an assistive tool for guiding personalized treatment strategies and advancing the clinical management of cancer patients. Funding Ashoka University, S.N. Bose National Centre for Basic Sciences, Mphasis F1 Foundation, DST SERB Core Research Grant. Research in Context Evidence before this study We conducted an extensive literature search using Google Scholar and PubMed without language restrictions, employing search terms such as \u201c(Predicting OR Classifying OR Annotating) and (cancer hallmarks) AND (Deep OR Machine Learning) OR (Artificial Intelligence OR AI).\u201d While there have been advancements in molecular oncology and computational methodologies over the two decades since the concept of cancer hallmarks was first introduced, a comprehensive machine learning or deep learning framework to annotate all cancer hallmarks simultaneously from tumor biopsy samples remains to be developed. Additionally, the scarcity of hallmark-annotated datasets has posed a significant challenge, hindering the development of robust predictive models. Added value of this study This study introduces OncoMark, a novel high-throughput neural multi-task learning (N-MTL) framework designed to predict all cancer hallmark activities simultaneously from biopsy samples. OncoMark addresses the lack of annotated hallmark-specific data by generating synthetic biopsy (pseudo-bulk) datasets annotated with hallmark activity, meticulously modeled to reflect real-world tumor biology while maintaining clinical relevance. The framework employs a multi-task learning approach to capture interdependencies among hallmarks, advancing beyond isolated predictions to offer a holistic view of tumor biology. Validation on five independent datasets comprising 95 patient samples demonstrated its generalizability and reproducibility. Further external validation using eight datasets, encompassing over 11,679 cancer and 8348 normal patient samples, reinforced its robustness. To promote clinical integration, a user-friendly web-based tool was developed, enabling seamless access for oncologists and researchers. Implications of all the available evidence The OncoMark framework represents a transformative advancement in cancer diagnostics and treatment planning. By enabling accurate and reproducible prediction of all hallmark activities simultaneously from biopsy samples, this model paves the way for precision oncology at scale. Its ability to systematically capture hallmark interdependencies provides deeper insights into tumor behavior, guiding the development of individualized targeted therapies. The incorporation of a web-based interface ensures the accessibility of this innovation to clinicians worldwide, bridging the gap between computational oncology and clinical practice. Following further validation and integration into healthcare workflows, OncoMark has the potential to improve cancer outcomes by delivering timely, cost-effective, and precise tumor analyses, facilitating informed therapeutic decision-making with unparalleled precision. Cancer progression is driven by a set of well-defined biological principles\u2014collectively termed the \u201challmarks of cancer\u201d\u2014yet current diagnostic approaches seldom incorporate these distinct molecular features into clinical practice. Despite substantial progress in molecular oncology, traditional methods like histopathological grading and immunohistochemical assays often fail to capture the complex interplay between cancer cells and the tumor microenvironment, emphasizing the need for robust computational frameworks capable of systematically quantifying hallmark-specific activity. Here, we address this gap by developing OncoMark, a high-throughput neural multi-task learning (N-MTL) framework designed to simultaneously quantify hallmark activities in tumor biopsies using transcriptomics data. We show that OncoMark achieves near-perfect accuracy, precision, recall, and F1 scores (>99%) in cross-validation, with external validation consistently exceeding 96.6% on five independent datasets. Further evaluation on eight additional datasets\u2014including large-scale cancer cohorts (TCGA, MET500, CCLE, TARGET, PCAWG, POG570) and normal tissue datasets (GTEx, ANTE)\u2014demonstrated high specificity for normal samples and robust sensitivity for hallmark prediction in cancer. By delivering a comprehensive and cost-effective molecular portrait of tumor biology and providing a user-friendly web platform accessible at https://oncomark-ai.hf.space/, OncoMark has the potential to guide tailored treatment strategies and advance precision oncology. More broadly, this framework signifies a transformative step toward routine hallmark-based diagnostics, promising to improve patient outcomes by facilitating timely and precise tumor profiling.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/35214bb06d48a965da984a3f7caff18e1a8ce529",
        "citation_count": 0
    },
    {
        "title": "APPLICATION OF MACHINE LEARNING IN HEALTHCARE",
        "abstract": "Signi\uf001cant progress has been made in the areas of disease populations, disease status, immunological response, and health emergency prediction\nand identi\uf001cation, among others, thanks to recent developments in AI and MLtechnologies. The use of ML-based approaches in healthcare settings\nis growing quickly, despite ongoing skepticism about the usefulness of these approaches and how to interpret their \uf001ndings. Here, using examples,\nwe give a quick rundown of machine learning-based methodologies and learning algorithms, such as supervised, unsupervised, and reinforcement\nlearning. Second, we go over the use of machine learning (ML) in many healthcare domains, such as genetics, neuroimaging, radiology, and\nelectronic health records. We also offer recommendations for future applications and a brief discussion of the risks and dif\uf001culties associated with\nusing machine learning to healthcare, including issues with system privacy and ethics.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3561b270bbe783369b25bf048edc739e339340d2",
        "citation_count": 1
    },
    {
        "title": "AI-Assisted Annotator Using Reinforcement Learning",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/3564e7ec8df51e499f64cd76706a7687fa21f855",
        "citation_count": 2
    },
    {
        "title": "Artificial intelligence to decode the peptide sequences driving the immune response",
        "abstract": "Understanding the immune system is of utmost importance for advancements in biomedical research and human healthcare. Deep learning has the potential to uncover the hidden secrets of proteins and peptides, leading to significant improvements in diagnostics, vaccine development, and cancer therapies. In this thesis, we developed and applied various deep learning techniques to get insights from peptides that drive the adaptive immune response. We investigated pathogen recognition and immune response by looking into T-cell receptor and epitope interactions. We apply interpretable deep learning to interaction prediction models and link this to the three-dimensional structure of the molecules to get insights into the factors determining T-cell\u2013epitope binding affinity. Additionally, our results show the importance of using interpretability techniques to verify machine learning models and avoid that small hard-to-detect problems can accumulate to inaccurate results. We address the issue of data bias in machine learning. We show how it can lead to overly optimistic performance that cannot be reproduced on real-world data. We underscore the necessity of rigorous data evaluation and advocate for the use of unbiased benchmarking datasets to ensure generalizability and applicability of prediction models. We develop a novel transformer-based machine learning model for interaction prediction of biological sequences. This architecture encodes the interaction between protein or peptide sequences in a biologically meaningful way while also providing valuable visualizations for model interpretability. We end by focussing on boosting the identification rate of peptides, such as those recognized by the immune system. We find that the training dataset size can have a substantial impact on the performance of machine learning models used in computational proteomics. This underscores the necessity for high-quality, comprehensive, standardized datasets to train robust machine learning models. To address data scarcity, we explore algorithmic strategies such as self-supervised pretraining and multi-task learning. We find that self-supervised learning can be a very valuable technique and hypothesize that the benefits of multi-task learning could become more apparent when used in combination with more comprehensive datasets for all peptide properties. Artificial intelligence shows great potential to revolutionize biomedical research, however, as shown in this thesis, large, unbiased, high-quality datasets are required for it to make an impact. The findings of this research can hopefully make progress towards more accurate, interpretable, and reliable predictive models, which are crucial for future breakthroughs in diagnostics, therapeutic development, and personalized medicine.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/35adc0f2b090ef73ea5dacbb40abb11c57d5fe29",
        "citation_count": 0
    },
    {
        "title": "Machine Learning for X-ray and CT-based COVID-19 Diagnosis",
        "abstract": "The rapid diagnosis of COVID-19 has become a pressing issue due to the strain the outbreak has placed on the healthcare system. This article aims to investigate the rapid and accurate diagnosis of COVID-19. This paper first introduces several widely used COVID-19 diagnostic techniques: rRT-PCR has excellent specificity and sensitivity, making it one of the most trustworthy ways to find the SARS-CoV-2 virus. Diagnostics based on X-rays are frequently employed as an adjunctive method. CT-based diagnosis can offer comprehensive details regarding lung health. It then highlights how machine learning combined with X-ray and CT images can be used to diagnose COVID-19. This approach can improve the accuracy and efficiency of detecting and evaluating the disease, helping healthcare professionals make decisions. Several standard machine learning methods are introduced, including supervised, unsupervised, and semi-supervised learning. Lastly, it forecasts machine learning development in the healthcare sector.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/35ccc74fbccf3c45d0a5d60e00f7b89702e55e35",
        "citation_count": 0
    },
    {
        "title": "A Machine Learning-Based algorithm for the assessment of clinical metabolomic fingerprints in Zika virus disease",
        "abstract": "Data analysis for metabolomic studies is challenging considering the number of statistical tools and standardization processes, which provides different results and projection in a single study. In addition, generation of high complexity data is common for untargeted metabolomics, requiring careful analysis and interpretation of results. In order to propose an innovative method for the analysis of a mass spectrometry metabolomics dataset, data from a Zika virus study was used. The analysis of this dataset combined principal component analysis and supervised learning methods such as support vector machines and logistic regression, to provide a truthful prediction model for discriminating samples of individuals with Zika virus infection and healthy controls. These supervised methods were used to learn the features that configured the \u201cfingerprint\u201d for the viral infection, showing over 98% of accuracy in a validation set. This model could be used as a fast and reliable test for determining Zika virus infections as part of healthcare services. Furthermore, this novel method shows potential for diagnosing other arboviral diseases.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/361ba10ffc4a7f0965418db6360d98ad7bde8fe7",
        "citation_count": 4
    },
    {
        "title": "Cardiovascular Disease Prediction based on Decision Tree",
        "abstract": "This study uses advanced data analytics approaches to explore the vital field of heart disease, a prevalent and potentially fatal disorder. The study uses supervised machine learning to identify predicted patterns in people\u2019s vulnerability to heart disease, primarily concentrating on the Decision Tree (DT) method. The study is taking place in the context of rising mortality rates from cardiovascular diseases, which highlights the critical need for preventative healthcare measures. Notably, the DT algorithm proves to be an exceptional performer, predicting the risk of cardiovascular illness with an astounding 99% accuracy. This supports its usefulness as a diagnostic tool and highlights how revolutionary preventative healthcare may be with its potential. The work adds to the growing conversation on the use of technology to solve pressing healthcare issues in addition to illuminating the predictive power of machine learning in cardiovascular health. The research\u2019s conclusions have ramifications for data-driven healthcare treatments and personalized therapy in the future, opening the door to creative ways to treat cardiac disease.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/36529ee035bf101d91efe15fbc9bd495fc78396e",
        "citation_count": 0
    },
    {
        "title": "An Interactive and Predictive Pre-diagnostic Model for Healthcare based on Data Provenance",
        "abstract": "The future of healthcare may look completely different from the current clinic-center services. \u00a0Rapidly growing and developing technologies are expected to change clinics throughout the world. However, the healthcare delivered to impaired patients, such as elderly and disabled people, possibly still requires hands-on human expertise. The aim of this study is to propose a predictive model that pre-diagnose illnesses by analyzing symptoms that are interactively taken from patients via several hand gestures during a period of time. This is particularly helpful in assisting clinicians and doctors to gain better understanding and make more accurate decisions about future plans for their patients\u2019 situations. The hand gestures are detected, the time of the gesture is recorded and then they are associated to their designated symptoms. This information is captured in the form of provenance graphs constructed based on the W3C PROV data model. The provenance graph is analyzed by extracting several network metrics and then supervised machine-learning algorithms are used to build a predictive model. The model is used to predict diseases from the symptoms with a maximum accuracy of 84.5%.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/367ae26374491b024e38ce6c8ddb455b0622cc1b",
        "citation_count": 2
    },
    {
        "title": "iPAL: A Machine Learning Based Smart Healthcare Framework For Automatic Diagnosis Of Attention Deficit/Hyperactivity Disorder (ADHD)",
        "abstract": "ADHD is a prevalent disorder among the younger population. Standard evaluation techniques currently use evaluation forms, interviews with the patient, and more. However, its symptoms are similar to those of many other disorders like depression, conduct disorder, and oppositional defiant disorder, and these current diagnosis techniques are not very effective. Thus, a sophisticated computing model holds the potential to provide a promising diagnosis solution to this problem. This work attempts to explore methods to diagnose ADHD using combinations of multiple established machine learning techniques like neural networks and SVM models on the ADHD200 dataset and explore the field of neuroscience. In this work, multiclass classification is performed on phenotypic data using an SVM model. The better results have been analyzed on the phenotypic data compared to other supervised learning techniques like Logistic regression, KNN, AdaBoost, etc. In addition, neural networks have been implemented on functional connectivity from the MRI data of a sample of 40 subjects provided to achieve high accuracy without prior knowledge of neuroscience. It is combined with the phenotypic classifier using the ensemble technique to get a binary classifier. It is further trained and tested on 400 out of 824 subjects from the ADHD200 data set and achieved an accuracy of 92.5% for binary classification The training and testing accuracy has been achieved upto 99% using ensemble classifier.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/36eadf82daa89c4ab0462d576499e6330b16db4e",
        "citation_count": 2
    },
    {
        "title": "Heart disease Prediction System Using data Mining Techniques",
        "abstract": "In today\u2019s modern world cardiovascular disease is the most lethal one. This disease attacks a person so instantly that it hardly gets any time to get treated with. So diagnosing patients correctly on timely basis is the most challenging task for the medical fraternity. A wrong diagnosis by the hospital leads to earn a bad name and loosing reputation. At the same time treatment of the said disease is quite high and not affordable by most of the patients particularly in India. The purpose of this paper is to develop a cost effective treatment using data mining technologies for facilitating data base decision support system. Almost all the hospitals use some hospital management system to manage healthcare in patients. Unfortunately most of the systems rarely use the huge clinical data where vital information is hidden. As these systems create huge amount of data in varied forms but this data is seldom visited and remain untapped. So, in this direction lots of efforts are required to make intelligent decisions. The diagnosis of this disease using different features or symptoms is a complex activity. In this paper using varied data mining technologies an attempt is made to assist in the diagnosis of the disease in question. key words: Data mining, Decision Tree, Neural Network, Naive Bayes, cardiovascular disease. Cardiovascular diseases are one of the highestflying diseases of the modern world1. According to world health organization about more than 12 million deaths occurs worldwide, every year due to heart problems. It is also one of the fatal diseases in India which causes maximum casualties. The diagnosis of this disease is intricate process. It should be diagnosed accurately and correctly. Due to limitation of the potential of the medical experts and their unavailability at certain places put their patients at high risk. Normally, it is diagnosed using intuition of the medical specialist. It would be highly advantageous if the techniques will be integrated with the medical information system. A 458 TANeJA, Orient. J. Comp. Sci. & Technol., Vol. 6(4), 457-466 (2013) computer based information or decision support systems can facilitate accurate diagnosis that\u2019s too at reduced cost1-2. This integration of varied data mining techniques with the existing medical decision support system requires comparison of different data mining techniques for finding out their suitability for the said job. This paper tries to find out different data mining techniques suitable for the said job. Literature Review A model Intell igent Hear t Disease Prediction System built with the aid of data mining techniques like Decision Trees, Na\u00efve Bayes and Neural Network was proposed by Palaniappan and Awang, they used a CRISP-DM methodology to build the mining models on a dataset obtained from the Cleveland Heart Disease database3. The results demonstrated the strange strength of each of the methodologies in realizing the objectives of the specified mining objectives. Intelligent Heart Disease Prediction System was capable of answering queries that the conventional decision support systems were not able to. It facilitated the establishment of vital knowledge, e.g. patterns, relationships amid medical factors connected with heart disease. Another study experimented on a sample database of patients\u2019 records. The Neural Network is tested and trained with 13 input variables such as Age, Blood Pressure, Angiography\u2019s report and the like. The supervised network has been recommended for diagnosis of heart diseases4. Training was carried out with the aid of back propagation algorithm. Whenever unknown data was fed by the doctor, the system identified the unknown data from comparisons with the trained data and generated a list of probable diseases that the patient is vulnerable to. The success rate for imprecise inputs to retrieve the desired output is closest to 100%. In another study the problem of identifying constrained association rules for heart disease prediction was studied by5. The underlying dataset encompassed medical records of people having heart disease with attributes for risk factors, heart perfusion measurements and artery narrowing. Three constraints were introduced to decrease the number of patterns. First one necessitates the attributes to appear on only one side of the rule. The second one segregates attributes into uninteresting groups. The ultimate constraint restricts the number of attributes in a rule9. experiments illustrated that the constraints reduced the number of discovered rules remarkably besides decreasing the running time. Two groups of rules envisaged the presence or absence of heart disease in four specific heart arteries. In year 2010, a study was conducted for predictive model for the Ischemic Heart Disease (IHD); they applied Back-propagation neural network (BPNN), the Bayesian neural network (BNN), the probabilistic neural network (PNN) and the support vector machine (SVM) to develop classification models for identifying IHD patients on a data obtained from measurements of cardiac magnetic field at 36 locations (6 \u00d7 6 matrices) above the torso6. The result shows that BPNN and BNN gave the highest classification accuracy of 78.43 %, while RBF kernel SVM gave the lowest classification accuracy of 60.78 %. BNN presented the best sensitivity of 96.55 % and RBF kernel SVM displayed the lowest sensitivity of 41.38 %. Both polynomial kernel SVM and RBF kernel SVM presented the minimum and maximum specificity of 45.45 % and 86.36 %, respectively. After reviewing the above literatures the researcher was motivated to work on a classification model that is sought to predict heart disease cases based on patterns generated from International Cardiovascular Hospital database7. This study is different in two ways from the studies that are presented above, the first one is the data that is used for this study is collected from transthoracic echocardiography report of patients and the second one is the classification models are developed on a much larger dataset. As far as the knowledge of the researcher is concerned this study will be the first of its kind in ethiopia that applied data mining to predict heart disease8. Research Methodology In this study, to develop a prediction model that can predict heart disease cases based on measurements taken from transthoracic echocardiography examination, and we have used 459 TANeJA, Orient. J. Comp. Sci. & Technol., Vol. 6(4), 457-466 (2013) the Knowledge Discovery in Database (KDD) methodology as described by2. To define the problem and determine medical goals, I have thoroughly discussed with medical fraternity particularly cardiologists at PGI, Chandigarh. Since the knowledge gained from the different experts are a high-level description of the problem from the medical point of view, a literature review was carried out and relevant works related to data mining and heart disease have been reviewed to have more knowledge about the domain. Furthermore, a real time observation of the system was performed to understand the business process of the hospital. A key sub goal in this step is determination of data mining goals and their success criteria. The goals are obtained by translating medical goals into data mining goals. I have used data collected from PGI, Chandigarh which contains transthoracic echocardiography report of 7,008 patients from the year 2008 to the first quarter of year 2010. Data was collected from various measurements that were taken during the echocardiography examination that also included information of 20 variables. In an effort to reduce the number of variables, then I turned to a domain expert for assistance. The expert selected 15 of the most important variables for inclusion in the dataset. As the hospital keeps the record of each patient in a separate hard file, therefore that file is converted into a separate Microsoft Word file, in order to integrate the data it was needed to create a database with variables of interest and record the values of each variable into the new database. After recording, the new database now contains 7,339 instances each instance resembling a single file. The selected data was checked for noise, inconsistency and missing values using distribution frequency while outlier detection was done using box plots. Noises and inconsistencies identified in the dataset were corrected manually, while missing values were replaced with the most probable value determined with regression and outliers were replaced with the mean value of the attributes. All the data cleaning was performed after addressing issues and requirements of the tools selected for the preprocessing phase. At this stage after consulting with the domain expert a few transformations were implemented on the dataset to make the data more suitable for the data mining algorithms. The other data transformation like attribute selection was necessary to reduce the number of features a classification algorithm has to examine and reduce errors from irrelevant features. I have used best first search method to select the best attributes from 15 attributes that were available. In the next step I have selected appropriate data mining technique for developing a predictive model. After thoroughly checking the available algorithms in Weka machine learning software the algorithms Decision Tree, Neural Network and Bayesian Classifier were selected for this study. To employ the selected classification algorithms four experiments were designed and the experiments were conducted on a full training dataset containing 7,339 instances. In all of the experiments two scenarios were considered, one containing all 15 attributes and the other only 8 selected attributes. 10-Fold Cross Validation was adopted for randomly sampling the training and test data sets. The Weka 3.6.4 machine learning software was used for these purposes. All the models built were evaluated to see how they fulfill data mining goa",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/36ee7596ab9b01e8850bf853ad8e3326318bdde7",
        "citation_count": 0
    },
    {
        "title": "Emo-CNN for Perceiving Stress from Audio Signals: A Brain Chemistry Approach",
        "abstract": "Emotion plays a key role in many applications like healthcare, to gather patients emotional behavior. There are certain emotions which are given more importance due to their effectiveness in understanding human feelings. In this paper, we propose an approach that models human stress from audio signals. The research challenge in speech emotion detection is defining the very meaning of stress and being able to categorize it in a precise manner. Supervised Machine Learning models, including state of the art Deep Learning classification methods, rely on the availability of clean and labelled data. One of the problems in affective computation and emotion detection is the limited amount of annotated data of stress. The existing labelled stress emotion datasets are highly subjective to the perception of the annotator. \nWe address the first issue of feature selection by exploiting the use of traditional MFCC features in Convolutional Neural Network. Our experiments show that Emo-CNN consistently and significantly outperforms the popular existing methods over multiple datasets. It achieves 90.2% categorical accuracy on the Emo-DB dataset. To tackle the second and the more significant problem of subjectivity in stress labels, we use Lovheim's cube, which is a 3-dimensional projection of emotions. The cube aims at explaining the relationship between these neurotransmitters and the positions of emotions in 3D space. The learnt emotion representations from the Emo-CNN are mapped to the cube using three component PCA (Principal Component Analysis) which is then used to model human stress. This proposed approach not only circumvents the need for labelled stress data but also complies with the psychological theory of emotions given by Lovheim's cube. We believe that this work is the first step towards creating a connection between Artificial Intelligence and the chemistry of human emotions.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/3707a17b5180a7eaf9e43da9406fbb29bb2d516e",
        "citation_count": 1
    },
    {
        "title": "A Semi-Supervised Machine Learning Model for Risk Analysis of Urinary Tract Infections in People with Dementia",
        "abstract": "Background: Urinary Tract Infections (UTIs) are common conditions in the elderly population and one of the key causes of hospital admissions in people with dementia. One of the key challenges in dealing with UTIs is that the condition often remains undiagnosed until it advances and shows severe symptoms which can lead to hospitalisation.\u00a0\u00a0 \u00a0\u00a0 \n \nMethod: This study presents a new system for detecting UTI in people with dementia. The system relies on low-cost in-home sensory monitoring combined with a novel machine learning algorithm. Environmental and physiological monitoring devices provide continuous data collection from homes, and the proposed machine learning model is trained to extract and identify the risk of UTIs. In conditions such as UTI, collecting sufficient training data to train machine learning models is a challenging task. The limited access to labelled data and examples creates the risk that learning models can become overfitted or biased. We propose a semi-supervised learning model to process a large unlabelled data set in combination with a smaller labelled dataset. We use an unsupervised learning technique which trains a model by extracting the underlying features from a set of unlabelled data and use the probabilistic neural network to estimate the density distribution. We use the unsupervised model for feature extraction and use these features from the smaller dataset to train a supervised classifier. \u00a0The proposed approach is tested in real-world application and within a healthcare monitoring system with 110 participants.\u00a0 \u00a0 \n \nFinding: The proposed system can record the environmental and clinical data in an integrated framework. This provides information for the proposed machine learning model to identify the risks of UTIs by processing the patterns and changes in vital signs and activity patterns. The evaluation results show that the proposed model can detect the risk of UITs with an F1-score of 84%, which outperforms the baseline methods by 10% on average. \u00a0\u00a0 \n \nInterpretation: The proposed model uses continuous environmental monitoring data and vital signs to detect early symptoms and the risk of UTIs. This is a first study using deep learning and semi-supervised models to analyse in-home sensory data in remote healthcare monitoring scenarios. The model provides a new approach to analyse and interpret continuous observation and measurement data for dementia care.\u00a0 \n \nFunding: The UK Dementia Research Institute, Medical Research Council (MRC), Alzheimer's Society and Alzheimer's Research UK. \n \nDeclaration of Interests: The authors declare no competing interests. \n \nEthics Approval Statement: The study protocol for this work has been reviewed and approved by the South East Coast Surrey NHS Research Ethics Committee and all the research has been performed in accordance with relevant guidelines and regulations. We obtained informed consent from all the study participants.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/371718a54b03d057c3b7cf8328c3418b159a1c3c",
        "citation_count": 4
    },
    {
        "title": "Reduction of Biosensor False Responses and Time Delay Using Dynamic Response and Theory-Guided Machine Learning",
        "abstract": "Here, we provide a new methodology for reducing false results and time delay of biosensors, which are barriers to industrial, healthcare, military, and consumer applications. We show that integrating machine learning with domain knowledge in biosensing can complement and improve the biosensor accuracy and speed relative to the performance achieved by traditional regression analysis of a standard curve based on the biosensor steady-state response. The methodology was validated by rapid and accurate quantification of microRNA across the nanomolar to femtomolar range using the dynamic response of cantilever biosensors. Theory-guided feature engineering improved the performance and efficiency of several classification models relative to the performance achieved using traditional feature engineering methods (TSFRESH). In addition to the entire dynamic response, the technique enabled rapid and accurate quantification of the target analyte concentration and false-positive and false-negative results using the initial transient response, thereby reducing the required data acquisition time (i.e., time delay). We show that model explainability can be achieved by combining theory-guided feature engineering and feature importance analysis. The performance of multiple classifiers using both TSFRESH- and theory-based features from the biosensor\u2019s initial transient response was similar to that achieved using the entire dynamic response with data augmentation. We also show that the methodology can guide design of experiments for high-performance biosensing applications, specifically, the selection of data acquisition parameters (e.g., time) based on potential application-dependent performance thresholds. This work provides an example of the opportunities for improving biosensor performance, such as reducing biosensor false results and time delay, using explainable machine learning models supervised by domain knowledge in biosensing.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/376b23d9b7782fe5fe41cc517bbe57d404b779e6",
        "citation_count": 7
    },
    {
        "title": "SIGNIFYING SENTENCE FRAMEWORK IN MACHINE LEARNING METHOD FOR INFORMATION MINING",
        "abstract": "Electronic Health Records are becoming the criterion in the healthcare province. The potential benefits of having an Electronic Health Records system are: Health information recording and clinical data repositories, Medication supervision, Decision hold up, Obtain treatments that are personalized to definite health needs. Usage of Natural Language Processing and Machine Learning techniques build a tool, capable to recognize and distribute textual information related to diseases and treatments. An extensive study of various Machine Learning algorithms and textual representations for classifying short medical texts and recognizing semantic relations among two medical entities diseases and treatments. There are at least two challenges that can be come across although working with Machine Learning method. One is to discover the most appropriate model for prediction. The Machine Learning field offers a collection of predictive models that can be used and deployed. The job of finding the appropriate one relies greatly on empirical studies and knowledge proficiency. The second one is to find a good data depiction and to do aspect engineering because features powerfully manipulate the performance of the models.",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/377a13afb7437314455668704d21ae256f963327",
        "citation_count": 0
    },
    {
        "title": "A Machine Learning Model for Predicting Performance of Gamified Software Test Specialist",
        "abstract": "Gamification is one of the new trend in software development and it has already gained a well-deserved popularity in finance, healthcare, education and even manufacturing. Software testing is a continuous cycle layered with several stages and spanning across multiple types of testing. Teams need to design test suites and implement test execution methodologies in each stage of development. For this reason, software testing teams comprise many individuals skilled in different aspects of software testing. The inclusion of gamification in this course can lead to positive benefits based on the idea that it is used to influence behavior. This paper presents an preliminary study of Machine Learning (ML) approach for predicting performance gamification of software tester specialists under a gamified testing environment. ImonaGame is a software company that delivers gamification as a service for software testing team of 30 members with different static and dynamic data. User behavior collected in dynamic data sets was classified into categories by deconstructing complex activities into behavior chains using supervision of domain experts. The classification approach was centered on the system\u2019s testing processes\u2019 performance objectives and potential for encouragement or dissuasion. Motivators and obstacles for the target activity and its behaviors will be found when the model has been developed. After conducting preliminary research, it is possible to determine whether gameful design is an effective and efficient tactic for achieving the desired result by analyzing needs, motives, and obstacles. The source data was classified target data in four categories such as I: Static feature (personal information; 4), II: Daily feature (gamification elements; 14), III: Mission feature (points; 7 sources) and IV: Cumulative futures (Sum of daily and mission features; 13).",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/387946035e22aa595103dbc5e40a7b00208e3901",
        "citation_count": 0
    },
    {
        "title": "Development Of Electronic Data Analytics For Public Health Surveillance And Epidemiology",
        "abstract": "The process of assessing patient data that is taken from various medical devices is known as health care analytics. The patient's condition is projected by the analytics, which helps the physician support the diagnosis. The data created are referred to as Electronic Health Records (EHR) / Electronic Medical Records (EMR). Large volumes of electronic health and medical records being produced, giving rise to the idea of medical big data. Medical data may be in its early stages of development or fully developed and organised. The data research community now has a new way to experiment with medical data and access the results of intelligent algorithms through testing or historical experiences. The vast amount of medical big data used in this study project served as the impetus for an attempt to handle the data using supervised classifiers and predictors from clever machine learning techniques.\u00a0 In healthcare, this analytical model is used to forecast illnesses. The goal of this project is to develop an intelligent framework for mining large amounts of medical data in order to assess public health issues and forecast illness occurrences.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/38e2327b62f1ead857a833bbcafc756b76ec3741",
        "citation_count": 0
    },
    {
        "title": "Revolutionizing Drug Discovery: Harnessing Machine Learning Algorithms",
        "abstract": "Drug discovery is a crucial element of biomedical research, with the goal of finding and creating new medical treatments for a variety of illnesses. Yet, the conventional process of finding new drugs is frequently impeded by its intrinsic difficulties, such as expensive expenses, long durations, and poor success rates in trials with patients. Recently, the incorporation of machine learning (ML) algorithms has become a revolutionary method to streamline and improve different phases of drug discovery. This summary offers a glimpse into the rapidly growing area of drug discovery using machine learning algorithms, emphasizing its potential to transform the process of developing treatments.\nThe usual process of discovering drugs involves various stages such as identifying the target, finding lead compounds, conducting preclinical tests, undergoing clinical trials, and obtaining regulatory approval. All these phases require a lot of labor, time, and resources, leading to high attrition rates and limited success in turning potential compounds into approved therapies. Nevertheless, researchers can enhance and speed up crucial parts of the drug discovery process by using ML algorithms.\nML algorithms use data to aid in drug discovery by utilizing computational models to examine large quantities of biological, chemical, and clinical data. These algorithms can learn from various types of data, such as genomic data, chemical structures, protein interactions, and clinical outcomes, to discover hidden patterns, find new targets for drugs, and forecast the effectiveness and safety of potential treatments. Moreover, machine learning algorithms allow for the investigation of intricate connections between molecular structures and biological effects, making it easier to create improved drug candidates with better effectiveness and specificity.\nImportant uses of machine learning in pharmaceutical research involve finding and confirming targets, screening compounds and improving leads, repurposing drugs, and tailoring treatments for individuals. Commonly used for classification and regression tasks, supervised learning algorithms like support vector machines and random forests predict compound activity, toxicity, and pharmacokinetic properties. Clustering and dimensionality reduction techniques utilized in unsupervised learning algorithms help analyze vast datasets and discover new drug-target interactions. Advanced abilities for analyzing molecular structures, virtual screening, and designing new drugs are provided by deep learning models like convolutional neural networks and recurrent neural networks.\nMultiple case studies demonstrate how ML algorithms can significantly impact drug discovery. Collaboration among academia, industry, and research institutions has resulted in the creation of new ML-based methods for drug development, identifying targets, and categorizing patients. Nevertheless, there are challenges accompanying the widespread use of ML in drug discovery. In healthcare, it is crucial to address ethical considerations, regulatory hurdles, and data privacy concerns to ensure the responsible and ethical use of ML algorithms.\nThe potential for transforming drug discovery and therapeutic development is immense with the incorporation of machine learning algorithms. Through utilizing data-driven methods, researchers can speed up the discovery of new potential drugs, enhance the effectiveness of treatments, and ultimately enhance the results for patients. Ongoing innovation, teamwork, and cross-disciplinary studies are crucial to fully leverage the potential of ML in revolutionizing drug discovery and precision medicine.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/39298bed391759133bbc6e09e80ea4f002528fdc",
        "citation_count": 0
    },
    {
        "title": "Effective Study of Machine Learning Algorithms for Heart Disease Prediction",
        "abstract": "Heart disease has been a major public health concern in recent years, excessive alcohol consumption, cigarette, and a sedentary lifestyle are the primary factors, and it is the leading cause of mortality among patients. Medically, heart disease is known for being difficult to forecast, detect, and diagnose. To treat heart diseases, hospitals and other clinics are giving costly therapies and treatments. According to a recent WHO research, heart disease is on the rise. In 2019, 17.9 million people die as a result of this. It becomes more difficult to diagnose as the population grows. As a result, detecting cardiac disease early on will benefit people all across the world, allowing them to receive necessary therapy before it becomes critical. Thanks to recent technical breakthroughs, machine learning has shown to be effective in making decisions and predictions from a big set of data provided by the healthcare sector. In this paper, some of the supervised machine learning techniques used in this prediction of heart disease which are Support Vector Machines (SVMs), Gradient Boosting Classifier (GB), Decision tree (DT), Random forest (RF), Logistic Regression (LR) on the \u201cUCI Machine learning repository for Statlog (Heart) Data Set\u201d Furthermore, the findings of these algorithms are reported, and a proposal is made to employ the algorithm with the highest accuracy for predicting Heart Disease on a web application. This application will be used as a decision support system by medical practitioners in their clinics as well as people at home.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/394c94ef144fec7d99ad60e10bf3e64c5ba58fdf",
        "citation_count": 19
    },
    {
        "title": "Using Deep Learning Techniques to Evaluate Lung Cancer Using CT Images",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/395882ca7a4683cdddc272417b7a6dc17acb1524",
        "citation_count": 6
    },
    {
        "title": "Management Information Systems",
        "abstract": null,
        "year": 1990,
        "url": "https://www.semanticscholar.org/paper/398e1969fdae7818a51f621b559b86ceaaffaf31",
        "citation_count": 0
    },
    {
        "title": "Special issue on information, intelligence, systems and applications",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3a1125a414a3780e30581157d57b4cacf0083b7e",
        "citation_count": 1
    },
    {
        "title": "Efficient Deep Learning and Machine Learning Models for Early-stage Identification of Autism Spectrum Disorder in Toddlers: Evidence from Saudi Arabia",
        "abstract": "Autism Spectrum Disorder (ASD) is a type of developmental disorder that can have notable effects on a person\u2019s cognitive abilities, language skills, ability to recognize objects, social interactions, and communication skills. The primary etiology of this condition is attributed to genetics, and prompt detection and intervention may mitigate the potential for the individual to face exorbitant healthcare expenses and protracted diagnostic procedures. A machine learning (ML) and deep learning architecture was developed with the capability to effectively analyze datasets of autistic toddlers, accurately classifying and identifying ASD traits. To explore the feasibility of predicting and analyzing ASD characteristics across various age cohorts, we employed multiple supervised ML models, namely support vector machine (SVM), k-nearest neighbors algorithm, and decision tree, and deep learning models, such as long short-term memory (LSTM). In this study, we analyzed the ASD screening dataset of toddlers from Saudi Arabia. The ASD screening datasets of toddlers from Kaggle were used to test these models. The first dataset includes 1054 instances and 19 toddler-related features, while the remaining datasets consist of 16 features, 507 instances, 165 normal, and 141 ASD cases. We report baseline results of behavior classification using ML and DL approaches. The SVM approach achieved 100% accuracy, whereas the LSTM approach attained 100% accuracy in terms of the accuracy metric. The developed system demonstrates the efficacy of the ASD system in detecting ASD toddlers in Saudi Arabia. Furthermore, the ASD system has the potential to assist parents in examining their children at an early stage.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3a21ff629191855f42b4f2dfd7b9b3af8452d8f0",
        "citation_count": 1
    },
    {
        "title": "Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/3a253dc80d8b7d627b90d0f1e872afea036c1a33",
        "citation_count": 0
    },
    {
        "title": "Machine learning identifies factors most associated with seeking medical care for migraine: Results of the OVERCOME (US) study.",
        "abstract": "OBJECTIVE\nUtilize machine learning models to identify factors associated with seeking medical care for migraine.\n\n\nBACKGROUND\nMigraine is a leading cause of disability worldwide, yet many people with migraine do not seek medical care.\n\n\nMETHODS\nThe web-based survey, ObserVational survey of the Epidemiology, tReatment and Care Of MigrainE (US), annually recruited demographically representative samples of the US adult population (2018-2020). Respondents with active migraine were identified via a validated diagnostic questionnaire and/or a self-reported medical diagnosis of migraine, and were then asked if they had consulted a healthcare professional for their headaches in the previous 12\u2009months (i.e., \"seeking care\"). This included in-person/telephone/or e-visit at Primary Care, Specialty Care, or Emergency/Urgent Care locations. Supervised machine learning (Random Forest) and Least Absolute Shrinkage and Selection Operator (LASSO) algorithms identified 13/54 sociodemographic and clinical factors most associated with seeking medical care for migraine. Random Forest models complex relationships (including interactions) between predictor variables and a response. LASSO is also an efficient feature selection algorithm. Linear models were used to determine the multivariable association of those factors with seeking care.\n\n\nRESULTS\nAmong 61,826 persons with migraine, the mean age was 41.7\u2009years (\u00b114.8) and 31,529/61,826 (51.0%) sought medical care for migraine in the previous 12\u2009months. Of those seeking care for migraine, 23,106/31,529 (73.3%) were female, 21,320/31,529 (67.6%) were White, and 28,030/31,529 (88.9%) had health insurance. Severe interictal burden (assessed via the Migraine Interictal Burden Scale-4, MIBS-4) occurred in 52.8% (16,657/31,529) of those seeking care and in 23.1% (6991/30,297) of those not seeking care; similar patterns were observed for severe migraine-related disability (assessed via the Migraine Disability Assessment Scale, MIDAS) (36.7% [11,561/31,529] vs. 14.6% [4434/30,297]) and severe ictal cutaneous allodynia (assessed via the Allodynia Symptom Checklist, ASC-12) (21.0% [6614/31,529] vs. 7.4% [2230/30,297]). Severe interictal burden (vs. none, OR 2.64, 95% CI [2.5, 2.8]); severe migraine-related disability (vs. little/none, OR 2.2, 95% CI [2.0, 2.3]); and severe ictal allodynia (vs. none, OR 1.7, 95% CI [1.6, 1.8]) were strongly associated with seeking care for migraine.\n\n\nCONCLUSIONS\nSeeking medical care for migraine is associated with higher interictal burden, disability, and allodynia. These findings could support interventions to promote care-seeking among people with migraine, encourage assessment of these factors during consultation, and prioritize these domains in selecting treatments and measuring their benefits.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3a61a6e3991f3d00caeff4c4756874c95e375884",
        "citation_count": 1
    },
    {
        "title": "Early diagnosis of autism using indian autism grading tool",
        "abstract": "Autism spectrum disorder is a neuro-developmental disorder that affects communication and social skills in individuals. Screening and diagnosis of autism using conventional methods, such as interviews with parents or caregivers and observational assessments takes a long time. The accurate diagnosis of autism by physicians and healthcare professionals seems to be challenging. By analyzing data on autistic children, medical professionals can learn about autism screening assessment decision making. The present study aims to develop a parental autism screening tool termed the Indian Autism Grading Tool (IAGT) for early screening of autism. Data are collected using the Indian Autism Parental Questionnaire and assigned with grades. This dataset is employed to test five supervised machine learning models, which compare classification performance based on accuracy, precision and recall. The most effective model should be used to implement the autism screening application. MLR is known to be more robust and to support fewer data sets, so it can be employed for the implementation of ML-powered mobile applications. MLR achieves the overall accuracy of 97.85%, which equates to 0.72%, 2.37%, 0.84% and 1.54% better than SVM, DT, KNN and GNB respectively. The proposed tool is developed in both Tamil and English. The pilot study is conducted with 30 children and the predictability of the tool is compared with the clinician. Therefore, the tool consistently achieves the same level of accuracy as clinicians.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3aefca2b5f751b5337f779c748ea7737eb68ae17",
        "citation_count": 3
    },
    {
        "title": "Automated Disease Prediction Using Machine Learning Technology",
        "abstract": "Majority of medical misfortunes are a result of inaccurate diagnosis. Medical professionals may find difficulty to effectively diagnose diseases and assess symptoms at an early stage due to the lack of time with the patients and the lack of resources to recognize huge amounts of data on time. Machine learning (ML) can help in analyzing large datasets and identify patterns that are usually not visible to human eyes. It reduces cost and repetitive tasks to provide a more personalized diagnosis. In this paper., supervised machine learning (ML) algorithms have demonstrated potential in surpassing current disease diagnosis techniques and supporting healthcare workers in the early identification of high-risk conditions. The proposed system evaluates the user-provided symptoms as input and outputs the likelihood of the condition. It implements different machine learning models to evaluate their performance on predicting diseases. In addition., algorithms like the decision tree algorithm., Naive Bayes algorithm etc. is also done to determine the best ML algorithm forthe prediction of diseases.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3b07f659e73e3b3b30da89c393e1d6bfa9603d19",
        "citation_count": 2
    },
    {
        "title": "Advancements in Object Detection for Accurate and Efficient Visual Recognition Using Machine Learning",
        "abstract": "Object detection in images and videos is a vital task in computer vision where its application goes beyond the automobile driving and surveillance, to healthcare. The paper introduces an object detection model which is specific and powerful, that is able to recognize visually with machine learning. The framework is constructed on the basis of the recent innovations in deep learning and attentive mechanisms, which not only lead to the best performance in object detection today but also guarantee the widest applicability. Using an extensive experiment which reveals the described model superiority over the current state-of-the-art algorithms by evaluating mAP indices, whereas the latter has a normal complexity. The ablation study uncovers the impact of core parameters including attention mechanisms and semi-supervised techniques, underlining their importance in the growth of detection precision. Moreover, the illustrative comparison of outcomes from detecting objects on the framework calls for attention to the capacity of the networks to objectify in different categories. Our outcome also suggest that although the proposed framework has a human-level performance in task of object detection there is still a scope to enhance their performance above the human level. Summarizing, this work concludes the conversation and can be considered in the progress of research developments of the object detection systems aimed at practical object meeting situations.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3b29efdae80746a82c8abac869975f1218e27ecf",
        "citation_count": 0
    },
    {
        "title": "Machine learning for predictive maintenance in self-healing software services",
        "abstract": "Automated self-repairing systems, catalyzed by predictive maintenance and ML, are the new formative model in today\u2019s software industry. Predictive maintenance is used widely for anticipating and avoiding system failures, and it forms a critical element in improving reliability and performance of software services. This article focuses on machine learning and application like predict and prevent maintenance and self-healing system that helps minimize downtimes, increases overall system performance of a system and selects optimal use of resources. The first part gives an overview of the development of software systems whereby an analysis was done on the general transition from simple static systems to autonomous systems that can self repair. It talks about predictability maintenance as a way of foreseeing failures, therefore avoiding undue disasters which are likely to inconvenience end users. The article then proceeds to explain the underlying ideas of predictive maintenance and differentiating it from the preventive and reactive kinds. This paper elaborates the methodology of how predictive maintenance integrates with self-healing and also with focus on without human intervention techniques used in autonomous systems wherein faults are corrected in real time. The discussion goes on to Machine learning methods ubiquitous in the predictive maintenance. Fault detection is tackled in supervised learning, and anomalous patterns in system logs are detected in unsupervised learning; reinforcement learning is applied to form recovery models to enhance self-healing mechanisms. The article goes on to discuss some of the difficulties in data quality, scaling of models and the combination of ML systems into existing structures, with solutions put forward including the use of cloud and the use of mix-model solutions. The use of predictive maintenance in the real world includes; In the healthcare sector and in cloud computing to name but a few. These case studies illustrate how organizations deploy these technologies for dependable and high performing operation in critical applications. Last but not least, the article brings vision for the future, with new interesting enhancements in self-healing solutions and the progression of AI/ML making the shift towards autonomous and self-optimizing systems.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3b5934a4679ceafba6b0b2d14fdd05dd197f5db3",
        "citation_count": 0
    },
    {
        "title": "A Hybrid Instance-based Transfer Learning Method",
        "abstract": "In recent years, supervised machine learning models have demonstrated tremendous success in a variety of application domains. Despite the promising results, these successful models are data hungry and their performance relies heavily on the size of training data. However, in many healthcare applications it is difficult to collect sufficiently large training datasets. Transfer learning can help overcome this issue by transferring the knowledge from readily available datasets (source) to a new dataset (target). In this work, we propose a hybrid instance-based transfer learning method that outperforms a set of baselines including state-of-the-art instance-based transfer learning approaches. Our method uses a probabilistic weighting strategy to fuse information from the source domain to the model learned in the target domain. Our method is generic, applicable to multiple source domains, and robust with respect to negative transfer. We demonstrate the effectiveness of our approach through extensive experiments for two different applications.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/3bf249f716a384065443abc6172f4bdef88738d9",
        "citation_count": 17
    },
    {
        "title": "Support Vector Machine Classifier for Prediction of Breast Malignancy using Wisconsin Breast Cancer Dataset",
        "abstract": "Cancer is the world's second largest cause of death. In 2018, 9.6 million people died from cancer. In any medical sickness, breast cancer is one of the most delicate and endemic diseases. This is one of the primary causes of female death in the world. Breast cancer kills one out of every eleven women around the world. \"Early detection equals improved odds of survival,\" says a well-known cancer adage. As a result, early detection is essential for successfully preventing breast cancer and lowering morality. Breast Cancer is a type of cancer that affects one of the most significant issues that humanity has faced in recent decades has been diagnosis and prediction. Cancer detection that is accurate can save millions of lives. Effective technologies for diagnosing malignant breasts aid healthcare providers in diagnosing and treating patients in a fast and accurate manner. Experiments were carried out in this study to categorise breast cancer as benign or malignant using the Wisconsin Diagnosis Breast Cancer (WDBC) database. Support Vector Machine is a supervised learning technique (SVM). The SVM classifier's classification performance is evaluated. Experiments demonstrate that the SVM model has a fantastic performance, with a classification accuracy of 96.09 percent on the testing subset.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/3bf482e42e2a1da42b015b69c8ccba65a773c9f6",
        "citation_count": 3
    },
    {
        "title": "Prediction of the synergistic effect of antimicrobial peptides and antimicrobial agents via supervised machine learning",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3c2a101f836962ec750a0737d3bedc63eefbf146",
        "citation_count": 9
    },
    {
        "title": "Diabetes Detection System by Mixing Supervised and Unsupervised Algorithms",
        "abstract": "Diabetes mellitus is also called gestational diabetes when a woman has high blood sugar while pregnant. It can show up at any time during pregnancy and cause problems for the mother and baby during or after the pregnancy. If the risks are found and dealt with as soon as possible, there is a chance that they can be reduced. The healthcare system is one of the many parts of our daily lives that are being rethought thanks to the creation of intelligent systems by machine learning algorithms. In this article, a hybrid prediction model is suggested to determine if a woman has gestational diabetes. The recommended model reduces the amount of data using the K-means clustering method. Predictions are made using several classification methods, such as decision trees, random forests, SVM, KNN, logistic regression, and naive Bayes. The results show that accuracy increases when clustering and classification are used together.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3c63ea110faae15ff351c8c9dfa913c42703d5da",
        "citation_count": 7
    },
    {
        "title": "Efficient Early Detection of Patient Diagnosis and Cardiovascular Disease using an IoT System with Machine Learning and Fuzzy Logic",
        "abstract": ": Rising healthcare challenges, particularly undiagnosed heart disease due to subtle symptoms and limited access to diagnostics, necessitate innovative solutions. This study introduces an innovative Internet of Things (IoT)-based system for early detection, leveraging the strengths of both fuzzy logic and machine learning. By analyzing patient-specific data such as heart rate, oxygen saturation, galvanic skin response, and body temperature, our system utilizes fuzzy logic to evaluate potential disease symptoms, enabling self-diagnosis under medical supervision. This personalized approach enables individuals to monitor their health and seek prompt medical attention as needed. Additionally, we train multiple machine learning algorithms (Decision Tree, KNN, SVM, Random Forest, Logistic Regression) on the well-established Cleveland heart disease dataset. Among these, Random Forest achieved the highest accuracy (82.6%), precision (81.5%), recall (83.7%), and F1-Score (82.5%), showcasing its e ff ectiveness in predicting cardiovascular disease. This unique blend of fuzzy logic for personalized symptom assessment and machine learning for CVD prediction presents a new method for early diagnosis. While promising, further validation through large-scale clinical trials is essential. Ultimately, this system underscores the significance of integrating AI with medical expertise for optimal patient care, providing a potential pathway to improved health outcomes and enhanced accessibility to early detection of cardiovascular disease.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3ce9b2fa1d31adece9213e639a414bc919ddf99f",
        "citation_count": 2
    },
    {
        "title": "Comparing Sampling Strategies for Tackling Imbalanced Data in Human Activity Recognition",
        "abstract": "Human activity recognition (HAR) using wearable sensors is an increasingly active research topic in machine learning, aided in part by the ready availability of detailed motion capture data from smartphones, fitness trackers, and smartwatches. The goal of HAR is to use such devices to assist users in their daily lives in application areas such as healthcare, physical therapy, and fitness. One of the main challenges for HAR, particularly when using supervised learning methods, is obtaining balanced data for algorithm optimisation and testing. As people perform some activities more than others (e.g., walk more than run), HAR datasets are typically imbalanced. The lack of dataset representation from minority classes hinders the ability of HAR classifiers to sufficiently capture new instances of those activities. We introduce three novel hybrid sampling strategies to generate more diverse synthetic samples to overcome the class imbalance problem. The first strategy, which we call the distance-based method (DBM), combines Synthetic Minority Oversampling Techniques (SMOTE) with Random_SMOTE, both of which are built around the k-nearest neighbors (KNN). The second technique, referred to as the noise detection-based method (NDBM), combines SMOTE Tomek links (SMOTE_Tomeklinks) and the modified synthetic minority oversampling technique (MSMOTE). The third approach, which we call the cluster-based method (CBM), combines Cluster-Based Synthetic Oversampling (CBSO) and Proximity Weighted Synthetic Oversampling Technique (ProWSyn). We compare the performance of the proposed hybrid methods to the individual constituent methods and baseline using accelerometer data from three commonly used benchmark datasets. We show that DBM, NDBM, and CBM reduce the impact of class imbalance and enhance F1 scores by a range of 9\u201320 percentage point compared to their constituent sampling methods. CBM performs significantly better than the others under a Friedman test, however, DBM has lower computational requirements.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3d13decf4f8b33e21483b3c1ebd1c1f32730af7c",
        "citation_count": 16
    },
    {
        "title": "Application of machine learning in measurement of ageing and geriatric diseases: a systematic review",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3d4678aebad150e2e896104e0118833814f42fc3",
        "citation_count": 8
    },
    {
        "title": "Diabetes Prediction and Recommendations Using Machine Learning and Generative AI",
        "abstract": "\nMachine learning along with artificial intelligence (AI) seem to make a paradigm shift into the healthcare domain by ensuring better diagnosis and treatment approaches. Considering the Mexico\u2019s increasing prevalence of dia- betes, timely diagnosis and properly determined interven- tion approach becomes essential. This project presents a unique AI-based web application that simulates and eval- uates diabetes risk in individuals with the help of machine learning and generative AI, enabling personalized health recommendations. Specifically, the application evaluates eight parameters such as glucose, blood pressure, BMI, age, etc. All of the parameters will allow users to foresee the risk of diabetes and determine the appropriate response to it. Moreover, the application uses Google Gemini, a generative AI model, to provide customized diabetes interventions by analyzing a patient\u2019s health data, and determines likely future health scenarios. Such interven- tions relate and explain the causes of diabetes, abnormal characteristics of human health, and effective dietary and lifestyle changes. The system is built using Streamlit which allows for a graphic interface that is convenient whereby the users input health data and instantly get diagnosis and interventions. It can be inferred that there is a huge opportunity in the realm of health technology advancing in terms of better preventive healthcare, which results in better patient outcomes as well as better integration of machine learning and AI.\nKeywords\u2014Diabetes prediction, machine learning, generative AI, healthcare analytics, Streamlit, supervised learning.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/3d75d8132d6edf297fa7f30fa22791dd05bd1748",
        "citation_count": 0
    },
    {
        "title": "Consequential Advancements of Self-Supervised Learning (SSL) in Deep Learning Contexts",
        "abstract": "Self-supervised learning (SSL) is a potential deep learning (DL) technique that uses massive volumes of unlabeled data to train neural networks. SSL techniques have evolved in response to the poor classification performance of conventional and even modern machine learning (ML) and DL models of enormous unlabeled data produced periodically in different disciplines. However, the literature does not fully address SSL\u2019s practicalities and workabilities necessary for industrial engineering and medicine. Accordingly, this thorough review is administered to identify these prominent possibilities for prediction, focusing on industrial and medical fields. This extensive survey, with its pivotal outcomes, could support industrial engineers and medical personnel in efficiently predicting machinery faults and patients\u2019 ailments without referring to traditional numerical models that require massive computational budgets, time, storage, and effort for data annotation. Additionally, the review\u2019s numerous addressed ideas could encourage industry and healthcare actors to take SSL principles into an agile application to achieve precise maintenance prognostics and illness diagnosis with remarkable levels of accuracy and feasibility, simulating functional human thinking and cognition without compromising prediction efficacy.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3d7c87b1f05016d8127cd06334f3822aca02fcce",
        "citation_count": 9
    },
    {
        "title": "OP0288\u2005Lessons Learned from the Scottish Rheumatology Ultrasound Mentoring Network Project",
        "abstract": "Background Direct supervision of musculoskeletal ultrasound (MSUS) by an expert mentor is recognized as the best method for training. Lack of access to mentors creates a barrier to learning and limits the capacity to train individuals in MSUS. Objectives The Scottish Rheumatology Ultrasound Mentoring Network (RUM-Net) project was created to overcome mentor related barriers to MSUS training for rheumatologists and allied health professionals (AHPs) in Scotland. The aims of the project were to: 1 - create a foundation for future MSUS training courses, 2 - provide an infra-structure to support work based learning, 3 - provide mentoring support throughout Scotland. Methods A three year development plan was devised by the Scottish Rheumatology Ultrasound Group (SRUG). On-line survey of the Scottish Society for Rheumatology (SSR) membership was conducted to establish the level of expertise in MSUS within Scotland, to define the local training need and to identify individuals who were interested in becoming future MSUS mentors. A program of annual Teach the Teachers (TT) courses were developed. Prior to the course, each delegate completed a self-assessment questionnaire, which along with the competency assessment by the tutors formed the basis to develop an individual learning plan for the 12 month period following the course. Peer learning group sets were created to support the ongoing training activities. The use of log-books was encouraged. Results 87 of SSR members (30%) responded the online survey. 65% of the respondents had access to an ultrasound machine, of these 68% felt unable to perform MSUS due to lack of training and experience. The survey identified 16 rheumatologists and AHPs who expressed a desire to becoming a MSUS mentor. The first TT course in 2011 was attended by 11 delegates from various geographical areas of Scotland. The self-assessment by participants was generally in agreement with the tutors\u2019 assessment of skills. Five of participants were rated as intermediate level and none was on the advanced level of competency. This intensive course, 2 day course with a faculty consisting of internationally recognized leaders in the field, had a high tutor to delegate ratio (5:11) and subsequently feedback of the course was highly positive. Seven of the original 11 delegates were able to attend the second TT course in 2012. Faculty assesments determined that four delegates had increased their skills level to that of a tutor for basic courses, whilst two had remained static due to inability to perform regular scanning within current job plans. Poor communication between groups and lack of available time to regularly use MSUS in clinic, were cited as major barriers to progression in training. Conclusions The RUM-Net project was successful in developing a training network for rheumatologists and AHPs across Scotland despite difficulties related to limited communication between participants. Collaboration with an academic center with facilities for developing a learning environment is currently being sought to overcome this problem. The experience of SRUG in running the RUM-Net project, the areas of success and those where improvements need to be made will provide a valuable insight to other groups who wish to develop similar MSUS training initiatives. Acknowledgements \u2018Teach the Teachers\u2019 courses were supported by educational grant by Pfizer Limited, Esaote S.p.A. and GE Healthcare Disclosure of Interest None Declared",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/3d87410c84dd1b4ddafa0b414698ed833d8ec441",
        "citation_count": 1
    },
    {
        "title": "Prototype Learning for Medical Time Series Classification via Human\u2013Machine Collaboration",
        "abstract": "Deep neural networks must address the dual challenge of delivering high-accuracy predictions and providing user-friendly explanations. While deep models are widely used in the field of time series modeling, deciphering the core principles that govern the models\u2019 outputs remains a significant challenge. This is crucial for fostering the development of trusted models and facilitating domain expert validation, thereby empowering users and domain experts to utilize them confidently in high-risk decision-making contexts (e.g., decision-support systems in healthcare). In this work, we put forward a deep prototype learning model that supports interpretable and manipulable modeling and classification of medical time series (i.e., ECG signal). Specifically, we first optimize the representation of single heartbeat data by employing a bidirectional long short-term memory and attention mechanism, and then construct prototypes during the training phase. The final classification outcomes (i.e., normal sinus rhythm, atrial fibrillation, and other rhythm) are determined by comparing the input with the obtained prototypes. Moreover, the proposed model presents a human\u2013machine collaboration mechanism, allowing domain experts to refine the prototypes by integrating their expertise to further enhance the model\u2019s performance (contrary to the human-in-the-loop paradigm, where humans primarily act as supervisors or correctors, intervening when required, our approach focuses on a human\u2013machine collaboration, wherein both parties engage as partners, enabling more fluid and integrated interactions). The experimental outcomes presented herein delineate that, within the realm of binary classification tasks\u2014specifically distinguishing between normal sinus rhythm and atrial fibrillation\u2014our proposed model, albeit registering marginally lower performance in comparison to certain established baseline models such as Convolutional Neural Networks (CNNs) and bidirectional long short-term memory with attention mechanisms (Bi-LSTMAttns), evidently surpasses other contemporary state-of-the-art prototype baseline models. Moreover, it demonstrates significantly enhanced performance relative to these prototype baseline models in the context of triple classification tasks, which encompass normal sinus rhythm, atrial fibrillation, and other rhythm classifications. The proposed model manifests a commendable prediction accuracy of 0.8414, coupled with macro precision, recall, and F1-score metrics of 0.8449, 0.8224, and 0.8235, respectively, achieving both high classification accuracy as well as good interpretability.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/3daeb3731a5412ec9740ca7176742b8b7f6ac08f",
        "citation_count": 2
    },
    {
        "title": "Engagement estimation of the elderly from wild multiparty human\u2013robot interaction",
        "abstract": "The use of social robots in healthcare systems or nursing homes to assist the elderly and their caregivers will be becoming common, where robots' understanding of engagement of the elderly is important. Traditional engagement estimation (EE) often requires expert involvement in a controlled dyadic interaction environment. In this article, we propose a supervised machine learning method to estimate the engagement state of the elderly in a multiparty human\u2013robot interaction (HRI) scenario from the real\u2010world video recording as input. The method is built upon the basic concept of engagement in geriatric psychiatry and HRI video representations. It adapts pretrained models to extract behavior, affective, and visual signals to form the multi\u2010modal features. These features are then fed into a neural network made of a self\u2010attention mechanism and average pooling for individual learning, a graph attention network for group learning and a fully connected layer to estimate the engagement. We tested the proposed method using 43 wild multiparty elderly robot interaction (ERI) videos. The experimental results show that our method is capable of detecting the key participants and estimating the engagement state of the elderly effectively. Also our study demonstrates the signals from side\u2010participants in the main interaction group considerably contribute to the EE of the elderly in the multiparty ERI.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3dde9cb8405abc091a15daf1756124723aeb2ebf",
        "citation_count": 6
    },
    {
        "title": "A Semi-supervised Approach for De-identification of Swedish Clinical Text",
        "abstract": "An abundance of electronic health records (EHR) is produced every day within healthcare. The records possess valuable information for research and future improvement of healthcare. Multiple efforts have been done to protect the integrity of patients while making electronic health records usable for research by removing personally identifiable information in patient records. Supervised machine learning approaches for de-identification of EHRs need annotated data for training, annotations that are costly in time and human resources. The annotation costs for clinical text is even more costly as the process must be carried out in a protected environment with a limited number of annotators who must have signed confidentiality agreements. In this paper is therefore, a semi-supervised method proposed, for automatically creating high-quality training data. The study shows that the method can be used to improve recall from 84.75% to 89.20% without sacrificing precision to the same extent, dropping from 95.73% to 94.20%. The model\u2019s recall is arguably more important for de-identification than precision.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/3de3a172d6ad69776276e11d2df799a0e9eb0a33",
        "citation_count": 2
    },
    {
        "title": "Genetic Algorithm-Based Feature Selection for Accurate Breast Cancer Classification",
        "abstract": "Breast cancer is a significant global healthcare challenge, particularly in developing and underdeveloped countries, with profound physical, emotional, and psychological consequences, including mortality. Timely diagnosis and accurate treatment are crucial in addressing this issue. We propose the utilization of a feature selection technique to identify the most relevant features from among all features for breast cancer diagnosis, and show that Genetic Algorithms are impressive for this task. The study compares the results of GA with no selection and an alternative method, Principle Component Analysis (PCA). Three machine learning models, all based on supervised learning with data split into training and test data, are employed for binary classification using the selected feature subset. The evaluation metrics employed encompass accuracy, precision, recall, and F1-score. Among the selected models, Random Forest demonstrates the most favorable outcomes, achieving an accuracy score of 0.96, precision score of 0.96, recall value of 0.98, and an F1-score of 0.97. These results underscore the effectiveness of GA in feature selection for breast cancer diagnosis. Consequently, the integration of Genetic Algorithms (GA) with Random Forest showcases the superior performance among the evaluated models.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3dfe30a9f65ea1419ef500b832ca3f0d2bf846fa",
        "citation_count": 8
    },
    {
        "title": "Supervised Machine Learning Models for Prediction of COVID-19 Infection using Epidemiology Dataset",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/3e6219db2f620a008fe9f47ffb390aaad6c5bab6",
        "citation_count": 222
    },
    {
        "title": "Unsupervised Domain Adaptation across FMCW Radar Configurations Using Margin Disparity Discrepancy",
        "abstract": "Commercial radar sensing is gaining relevance and machine learning algorithms constitute one of the key components that are enabling the spread of this radio technology into areas like surveillance or healthcare. However, radar datasets are still scarce and generalization cannot be yet achieved for all radar systems, environment conditions or design parameters. A certain degree of fine tuning is, therefore, usually required to deploy machine-learning-enabled radar applications. In this work, we consider the problem of unsupervised domain adaptation across radar configurations in the context of deep-learning human activity classification using frequency-modulated continuous-wave. For that, we focus on the theory-inspired technique of Margin Disparity Discrepancy, which has already been proved successful in the area of computer vision. Our experiments extend this technique to radar data, achieving a comparable accuracy to few-shot supervised approaches for the same classification problem.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3e75ab592c240ba951cba76551eebbf12180dc2e",
        "citation_count": 0
    },
    {
        "title": "Special Disease Prediction System Using Machine Learning",
        "abstract": "The wide variety of computer-based technologies within the healthcare industry has led to the gathering of electronic data. Due to the massive number of information, medical professionals are faced with the challenge of accurately diagnosing signs and figuring out diseases at an early stage. In medicine, misdiagnosis could be a major factor leading because of poor treatment and diagnosing the disease when it\u2019s serious. However, supervised machine learning techniques have demonstrated the potential to surpass conventional diagnostic procedures and assist medical professionals in diagnosing high-risk diseases. Mostly people feel lazy to visit a hospital, and concern a doctor for a minor complication. However, this small problem can pose significant medical risk. Since, online medical advice is readily available. The system evaluates the symptoms that person give as an input and gives the disease as an output. Naive Bayes Classifier is used in the system. Our system focuses on accuracy, the more numbers of a symptoms furnished by the person as a input the disorder prediction as a output will be better. Work can enhance the health care industry to zenith and give cure to world.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/3eb745a58c2ae478f132b75c7c09ca55fbf334b2",
        "citation_count": 4
    },
    {
        "title": "Development of a cloud-assisted classification technique for the preservation of secure data storage in smart cities",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/3f18b4e0a46a8b6cacf53bf1ee85510e92691d89",
        "citation_count": 17
    },
    {
        "title": "PREDICTION OF DISEASES USING SUPERVISED LEARNING",
        "abstract": "In healthcare industry and in various applications, data mining plays a basic role to forecast various diseases. For detection of various diseases patient need to go through various tests. But mining techniques can lower the number of trails. The downgraded tests play a key role in team behaviour. This requires proper paper studies of mining methods which is used for forecasting different diseases. In this paper Na\u00efve Bayes and Decision Tree method are described to envision various diseases. Facilities must be inventive so patient examination and cure can be done. Various machine learning algorithms can be beneficial to the medical purpose, the humans practice large and all-purpose medical datasets to analyse them for clinical insights. This can be used by physicians in various medical field which leads to satisfaction to large number of people when well accomplished. We are basically trying to contrivance functionalities of ML in a single system in a medical field. Instead of having diagnosis, diseases are predicted and executed using ML then the medical field would be smarter and more advanced. Some cases can happen when basic investigation of a disease is not in reach. Hence disease forecast can be accurately carried out.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/3f45a30934200808dda4f1274374d05835373fed",
        "citation_count": 0
    },
    {
        "title": "Machine learning-based prediction and classification of psychiatric symptoms induced by drug and plants toxicity",
        "abstract": "Psychiatric disorders induced by drug and plant toxicity represent a complex and underexplored area in medical research. Exposure to substances such as pharmaceuticals, illicit drugs, and environmental toxins can trigger a wide range of neuropsychiatric symptoms. This study proposes the development of a machine learning (ML) model to predict and classify these symptoms by analyzing open-access, de-identified datasets. Supervised and unsupervised learning techniques, including neural networks and algorithms like XGBoost, were applied to distinguish drug-induced psychiatric conditions from primary psychiatric disorders. The models were evaluated using metrics such as accuracy, precision, recall, and AUC-ROC. The XGBoost model demonstrated the best performance, achieving an AUC-ROC of 94.8%, making it a promising tool for clinical decision-support systems. This approach can improve early detection and intervention for psychiatric symptoms associated with drug toxicity, contributing to safer and more personalized healthcare.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/3f7d31e678bf95fca4e73f44e73ef9d6269920f3",
        "citation_count": 0
    },
    {
        "title": "Analysis of Supervised Machine Learning Algorithms for Heart Disease Prediction with Reduced Number of Attributes using Principal Component Analysis",
        "abstract": "research on causes of death due to heart disease has shown that it is the number one cause of death. If current trends are allowed to continue, 23.6 million people will die from heart disease in coming 2030. The healthcare industry gathers enormous amounts of heart disease data which unfortunately, are not \"mined\" to discover hidden information for effective decision making. In this paper, study of PCA has been done which finds the minimum number of attributes required to increase the accuracy of various supervised machine learning algorithms. The objective of this research is to analyze supervised machine learning algorithms to predict heart disease.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/40236facd357d3a67c40fa59ed458034dd8f5cd8",
        "citation_count": 32
    },
    {
        "title": "Attitudes towards mental health professionals in social media: infodemiology study.",
        "abstract": "BACKGROUND\nNegative perceptions of mental health professionals can deter individuals from seeking mental healthcare. Given the high burden of mental health globally, it is essential to understand attitudes towards mental health professionals. Social media platforms like Twitter/X provide valuable insights into the views of the general population.\n\n\nAIMS\nThis study aimed to use social media to investigate the (a) public perceptions (positive or negative) of mental health professionals, (b) changes in these perceptions over time and (c) engagement levels with tweets about mental health professionals over time.\n\n\nMETHOD\nWe collected all tweets posted in English between 2007 and 2023, containing key terms such as 'mental health', 'psychology', 'psychologist', 'psychiatry', 'psychiatrist', 'neurology' and 'neurologist'. A total of 1500 tweets were manually classified into categories, which were used in conjunction with semi-supervised machine learning to categorise a large data-set.\n\n\nRESULTS\nFor most key terms, there was a higher frequency of positive perceptions compared with negative, with this trend improving over time. However, tweets containing 'psychiatrist' exhibited a higher proportion of negative perceptions (n = 4872, 39.52% negative v. n = 1972, 15.99% positive before 2020). After 2020, the gap narrowed, yet negative perceptions continued to dominate (n = 5505, 36.10% negative v. n = 3472, 22.77% positive).\n\n\nCONCLUSIONS\nOverall, positive perceptions of mental health and mental health professionals increased over time. However, 'psychiatrist' had a consistently higher proportion of negative perceptions. This study underscores the need to improve public perception of psychiatrists, and demonstrates the potential of using Twitter/X to better understand public attitudes and reduce stigma associated with accessing mental health services.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/40462bd2e119af15a189cfa37c1e6dfbb9c36a7d",
        "citation_count": 0
    },
    {
        "title": "Machine learning applied to healthcare: a conceptual review",
        "abstract": "Abstract The technological inference in procedures applied to healthcare is frequently investigated in order to understand the real contribution to decision-making and clinical improvement. In this context, the theoretical field of machine learning has suitably presented itself. The objective of this research is to identify the main machine learning algorithms used in healthcare through the methodology of a systematic literature review. Considering the time frame of the last twenty years, 173 studies were mined based on established criteria, which allowed the grouping of algorithms into typologies. Supervised Learning, Unsupervised Learning, and Deep Learning were the groups derived from the studies mined, establishing 59 works employed. We expect that this research will stimulate investigations towards machine learning applications in healthcare.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/40620a51a19bb0cb61a27f920f3f9235c0b44b6b",
        "citation_count": 7
    },
    {
        "title": "Revisiting the need for the use of GPT in surgery and medicine",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/406f62d31694b8b93a6fd1c4fd195fe0c0fb8264",
        "citation_count": 1
    },
    {
        "title": "Theoretical Guidance in the Field of Health and Healing Using NLP",
        "abstract": "The majority of ailments are now treatable because of advances in medical science, and discoveries are paving the path for a more advanced future. Smart technology is already being applied to healthcare to enhance patient care. In this paper, natural language processing (NLP) is employed. To understand the content of text documents, machine learning (ML) for natural language processing (NLP) and text analytics requires the employment of machine learning algorithms and \u201cnarrow\u201d artificial intelligence (AI). Facebook displays a vehicle ad on your screen if you post a status update about buying a car. This is not a dark spell! Facebook is using this to offer you more relevant advertising. The attempt to provide the correct advertisement in the commercial above certainly failed. Recognizing the context in which a term has been used is much more crucial. This is a frequent issue in Natural Language Processing (NLP) activities. Homonyms are words that have the same spelling and sound but are used in different context, and calculating word representations might be a solution to the aforementioned issue. For word embedding and text categorization learning, Facebook's AI Research (FAIR) created the Fast Text package. This research work uses a model that enables the development of supervised or unsupervised word vector representation learning algorithms. For 294 languages, Facebook offers pre- trained models. Fast Text embeds words using a neural network. To locate the word vectors for this research work, this study focuses on the semantic terms with the standard treatment guidelines. This study has created a vector representation by visualizing the word embedding in the vector space after converting the word vectors into word embedding.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/40a9bc300672e1263497c79c0bcceea8f174a57b",
        "citation_count": 0
    },
    {
        "title": "Semantic body parts segmentation for quadrupedal animals",
        "abstract": "Although marker-less human pose estimation and tracking is important in various systems, nowadays many applications tend to detect animals while performing a certain task. These applications are multidisciplinary including robotics, computer vision, safety, and animal healthcare. The appearance of RGB-D sensors such as Microsoft Kinect and its successful applications in tracking and recognition made this area of research more active, especially with their affordable price. In this paper, a data synthesis approach for generating realistic and highly varied animal corpus is presented. The generated dataset is used to train a machine learning model to semantically segment animal body parts. In the proposed framework, foreground extraction is applied to segment the animal, dense representations are obtained using the depth comparison feature extractor and used for training a supervised random decision forest. An accurate pixel-wise classification of the parts will allow accurate joint localization and hence pose estimation. Our approach records classification accuracy of 93% in identifying the different body parts of an animal using RGB-D images.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/4123b7baacd416decefeb4dcde9c95b288a568f4",
        "citation_count": 22
    },
    {
        "title": "Predicting length of stay in hospitalized patients using SSL algorithms",
        "abstract": "Length of stay in hospitalized patients is acknowledged as a critical factor for healthcare policy planning that consequently affects the available human, technical and financial resources as well as facilities occupation. Over recent years, data mining and machine learning led to the development of several efficient and accurate models for predicting of how long a patient will stay in the hospital and support healthcare policy planning. As an alternative to traditional classification methods, semi-supervised learning algorithms have become a hot topic of significant research which exhibit remarkable performance over labeled data but lack the ability to be applied on large amounts of unlabeled data. In this work, we evaluate the performance of semi-supervised methods in predicting the length of stay of hospitalized patients. Our reported experimental results illustrate that a good predictive accuracy can be achieved using few labeled data in comparison to well known supervised learning algorithms.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/41e0dc839f5f00c34b9ce849b00ff018099af42b",
        "citation_count": 8
    },
    {
        "title": "ComplAI: Theory of A Unified Framework for Multi-factor Assessment of Black-Box Supervised Machine Learning Models",
        "abstract": "The advances in Artificial Intelligence are creating new opportuni-ties to improve people\u2019s lives around the world, from business to healthcare, from lifestyle to education. For example, some systems profile the users using their demographic and behavioral charac-teristics to make certain domain-specific predictions. Often, such predictions impact the user\u2019s life directly or indirectly (e.g., loan disbursement, determining insurance coverage, shortlisting applications, etc.). As a result, the concerns over such AI-enabled systems are also increasing. To address these concerns, such systems are mandated to be responsible: transparent, fair, and explainable to developers and end-users. In this paper, we present ComplAI, a unique framework to enable, observe, analyze and quantify explainability, robustness, performance, fairness, and model\u2019s behavior in drift scenarios, and to provide a single Trust Factor that evaluates different supervised Machine Learning models not just from their ability to make correct predictions but from overall responsibility perspective. The framework helps users to (a) connect their models and enable explanations, (b) assess and visualize different aspects of the model such as robustness, drift susceptibility, and fairness, and (c) compare different models (from different model families or obtained through different hyperparameter settings) from an overall perspective thereby facilitating actionable recourse for improvement of the models. ComplAI is model agnostic and works with different supervised machine learning scenarios (i.e., Binary Classification, Multi-class Classification, and Regression) and frameworks ( viz. scikit-learn, TensorFlow, etc.). It can be seamlessly integrated with any ML life-cycle framework. Thus, this already deployed framework aims to unify critical aspects of Responsible AI systems for regulating the development process of such real systems.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/420cdb2d244c85a75900dbe6bc1916a68d06c18e",
        "citation_count": 0
    },
    {
        "title": "IMPROVING THE PERFORMANCE OF HEART DISEASE CLASSIFICATION USING CHAOTIC TENT MAP BASED WHALE OPTIMIZER FOR FEATURE SELECTION WITH SVM ALGORITHM",
        "abstract": "Current computing technologies have simplified the collection and storage of medical data, which can be utilized to assist medical assessments. Initially, there is an essential for collecting as well as making patient\u201fs data in digitized form. Afterward, the composed data can be examined for diagnosis, detection and progress the treatment based on the patient\u201fs condition. Normally, human heart covers numerous disorders that effect the heart also it is the main focus of death worldwide in the past few eras. These diseases requires early diagnosis systems to get accurate, reliable and sensible detection to attain quick management of the disease that associates many risk factors on patient\u201fs health. In the healthcare domain, data mining and machine learning techniques are generally utilized for analyzing huge volume of data. Several researchers established the numerous data mining as well as machine learning methods to examine vast complex medical data for assisting healthcare specialists to diagnosis various heart diseases in existing system. In this research paper, many feature attributes associated to heart disease are utilized to develop the model that is based on supervised learning algorithm (SVM) and feature optimization (PSO, WOA and CTM-WOA) algorithms.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/42300fb746a085a1159377c0c072dd0302e63d32",
        "citation_count": 2
    },
    {
        "title": "PREDICTIVE MODELLING FOR DIABETES USING MACHINE LEARNING",
        "abstract": "Diabetes is a prevalent and long-lasting medical disorder that has significant consequences for health. It is important to diagnose diabetes promptly and accurately in order to effectively manage it. This study use machine learning algorithms to forecast the occurrence of diabetes by analyzing a dataset obtained from the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK). Important diagnostic characteristics such as the count of pregnancies, insulin levels, age, body mass index (BMI), and other health measurements are used. We utilize various supervised learning classification methods, including Logistic Regression, Support Vector Machines (SVM), Decision Trees, k-Nearest Neighbours (k- NN), and Random Forest, in order to create a reliable predictive model. The study entails thorough data preprocessing, meticulous feature selection, and rigorous model training to guarantee the precision and dependability of predictions. Performance indicators, such as accuracy, precision, recall, F1- score, and the Area Under the Receiver Operating Characteristic Curve (AUC), are employed to assess the efficacy of each algorithm. The objective of this research is to enhance the identification and treatment of diabetes at an early stage, hence enhancing the effectiveness of healthcare interventions. This effort aims to enhance predictive modelling in the field of diabetes using advanced machine learning techniques. Key Words: Diabetes Prediction, Machine Learning, Logistic Regression, Support Vector Machines, Decision Trees, k- Nearest Neighbours, Random Forest, Predictive Modelling, National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK)",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/423a700a236bf27825d14ed542f70a65cbf3ca43",
        "citation_count": 0
    },
    {
        "title": "Foundations of intelligent systems : 16th International Symposium, ISMIS 2006, Bari, Italy, September 27-29, 2006, proceedings",
        "abstract": "Invited Talks.- Lifecycle Knowledge Management: Getting the Semantics Across in X-Media.- Argument-Based Machine Learning.- Play It Again: A Case-Based Approach to Expressivity-Preserving Tempo Transformations in Music.- Active Media Human-Computer Interaction.- Decision Fusion of Shape and Motion Information Based on Bayesian Framework for Moving Object Classification in Image Sequences.- A Two-Stage Visual Turkish Sign Language Recognition System Based on Global and Local Features.- Speech Emotion Recognition Using Spiking Neural Networks.- Visualizing Transactional Data with Multiple Clusterings for Knowledge Discovery.- Computational Intelligence.- An Optimization Model for Visual Cryptography Schemes with Unexpanded Shares.- A Fast Temporal Texture Synthesis Algorithm Using Segment Genetic Algorithm.- Quantum-Behaved Particle Swarm Optimization with Immune Operator.- Particle Swarm Optimization-Based SVM for Incipient Fault Classification of Power Transformers.- AntTrend: Stigmergetic Discovery of Spatial Trends.- Genetic Algorithm Based Approach for Multi-UAV Cooperative Reconnaissance Mission Planning Problem.- Improving SVM Training by Means of NTIL When the Data Sets Are Imbalanced.- Evolutionary Induction of Cost-Sensitive Decision Trees.- Triangulation of Bayesian Networks Using an Adaptive Genetic Algorithm.- Intelligent Agent Technology.- Intelligent Agents That Make Informed Decisions.- Using Intelligent Agents in e-Government for Supporting Decision Making About Service Proposals.- A Butler Agent for Personalized House Control.- Incremental Aggregation on Multiple Continuous Queries.- Location-Aware Multi-agent Based Intelligent Services in Home Networks.- A Verifiable Logic-Based Agent Architecture.- Intelligent Information Retrieval.- Flexible Querying of XML Documents.- VIRMA: Visual Image Retrieval by Shape MAtching.- Asymmetric Page Split Generalized Index Search Trees for Formal Concept Analysis.- Blind Signal Separation of Similar Pitches and Instruments in a Noisy Polyphonic Domain.- Score Distribution Approach to Automatic Kernel Selection for Image Retrieval Systems.- Business Intelligence in Large Organizations: Integrating Which Data?.- Intelligent Infomation Systems.- Intelligent Methodologies for Scientific Conference Management.- The Consistent Data Replication Service for Distributed Computing Environments.- OntoBayes Approach to Corporate Knowledge.- About Inclusion-Based Generalized Yes/No Queries in a Possibilistic Database Context.- Flexible Querying of an Intelligent Information System for EU Joint Project Proposals in a Specific Topic.- Multi-expression Face Recognition Using Neural Networks and Feature Approximation.- A Methodology for Building Semantic Web Mining Systems.- Content-Based Image Filtering for Recommendation.- Knowledge Representation and Integration.- A Declarative Kernel for Concept Descriptions.- RDF as Graph-Based, Diagrammatic Logic.- A Framework for Defining and Verifying Clinical Guidelines: A Case Study on Cancer Screening.- Preferred Generalized Answers for Inconsistent Databases.- Representation Interest Point Using Empirical Mode Decomposition and Independent Components Analysis.- Integration of Graph Based Authorization Policies.- Knowledge Discovery and Data Mining.- Supporting Visual Exploration of Discovered Association Rules Through Multi-Dimensional Scaling.- Evaluating Learning Algorithms for a Rule Evaluation Support Method Based on Objective Rule Evaluation Indices.- Quality Assessment of k-NN Multi-label Classification for Music Data.- Effective Mining of Fuzzy Multi-Cross-Level Weighted Association Rules.- A Methodological Contribution to Music Sequences Analysis.- Towards a Framework for Inductive Querying.- Towards Constrained Co-clustering in Ordered 0/1 Data Sets.- A Comparative Analysis of Clustering Methodology and Application for Market Segmentation: K-Means, SOM and a Two-Level SOM.- Action Rules Discovery, a New Simplified Strategy.- Characteristics of Indiscernibility Degree in Rough Clustering Examined Using Perfect Initial Equivalence Relations.- Implication Strength of Classification Rules.- A New Clustering Approach for Symbolic Data and Its Validation: Application to the Healthcare Data.- Action Rules Discovery System DEAR_3.- Mining and Modeling Database User Access Patterns.- Logic for AI and Logic Programming.- Belief Revision in the Situation Calculus Without Plausibility Levels.- Norms, Institutional Power and Roles: Towards a Logical Framework.- Adding Efficient Data Management to Logic Programming Systems.- A Logic-Based Approach to Model Supervisory Control Systems.- SAT as an Effective Solving Technology for Constraint Problems.- Dependency Tree Semantics.- Machine Learning.- Mining Tolerance Regions with Model Trees.- Lazy Learning from Terminological Knowledge Bases.- Diagnosis of Incipient Fault of Power Transformers Using SVM with Clonal Selection Algorithms Optimization.- An Overview of Alternative Rule Evaluation Criteria and Their Use in Separate-and-Conquer Classifiers.- Learning Students' Learning Patterns with Support Vector Machines.- Practical Approximation of Optimal Multivariate Discretization.- Optimisation and Evaluation of Random Forests for Imbalanced Datasets.- Improving SVM-Linear Predictions Using CART for Example Selection.- Simulated Annealing Algorithm with Biased Neighborhood Distribution for Training Profile Models.- A Conditional Model for Tonal Analysis.- Hypothesis Diversity in Ensemble Classification.- Complex Adaptive Systems: Using a Free-Market Simulation to Estimate Attribute Relevance.- Text Mining.- Exploring Phrase-Based Classification of Judicial Documents for Criminal Charges in Chinese.- Regularization for Unsupervised Classification on Taxonomies.- A Proximity Measure and a Clustering Method for Concept Extraction in an Ontology Building Perspective.- An Intelligent Personalized Service for Conference Participants.- Contextual Maps for Browsing Huge Document Collections.- Web Intelligence.- Classification of Polish Email Messages: Experiments with Various Data Representations.- Combining Multiple Email Filters Based on Multivariate Statistical Analysis.- Employee Profiling in the Total Reward Management.- Mining Association Rules in Temporal Document Collections.- Self-supervised Relation Extraction from the Web.",
        "year": 2006,
        "url": "https://www.semanticscholar.org/paper/426a111bbff3039286e0782caa1955540a2b58ad",
        "citation_count": 0
    },
    {
        "title": "A Review Of The Issues And Challenges In IoT Security Using Machine Learning Techniques",
        "abstract": "In a typical IoT network, a sensor connects to a controller using a wireless connection. Controllers collect data from sensors and sends the data for storage and analysis[1]. These controllers work with actuators that translate an electrical input to a physical action. The internet of things (IoT), have found application in different areas of human endeavor including healthcare, government, supply chain, cities, manufacturing, etc. and it is estimated that the number of connected devices will reach 50 billion by 2020[2] With the increasing number of devices comes an increase in the the varying number of security threats to the IoT network [3]. To contain these threats, a secure-by-design approach should be adopted as this will help the IoT devices to anticipate and neutralize the ever changing nature of the threats as against older systems where security was handled as it presents itself [2] This paper x-rays the security challenges in IoT networks and the application of machine learning (Supervised learning, Unsupervised learning and Reinforcement learning) in tackling the security challenges",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/427dad56efd7d5d4ed5536ec0fee82afead3fb9a",
        "citation_count": 0
    },
    {
        "title": "Hidden Risks of Machine Learning Applied to Healthcare: Unintended Feedback Loops Between Models and Future Data Causing Model Degradation",
        "abstract": "There is much hope for the positive impact of machine learning on healthcare. In fact, several ML methods are already used in everyday clinical practice, but the e\ufb00ect of adopting imperfect predictions from an ML system on model performance over time is unknown. Clinicians changing their decisions based on an imperfect ML system changes the underlying probability distribution P ( Y ) of future data, where Y is the outcome. This e\ufb00ect has not been carefully studied to date. In this work we tackle the problem of model predictions in\ufb02uencing future labels (which we refer to as the feedback loop ) by considering several supervised learning scenarios, and show that unlike in the no-feedback-loop setting, if clinicians fully trust the model (100% adoption of the predicted label) the false positive rate (FPR) grows uncontrollably with the number of updates. We simulate the feedback loop problem on a real-world ICU data (MIMIC-IV v0.1) as the distribution shifts over time. Among our scenarios, we consider how the clinician\u2019s trust in the model over time impacts the magnitude of the FPR increase due to a feedback loop. Finally, we propose mitigating solutions to the observed model degradation using heuristics that discard potentially incorrectly labeled samples. We hope that our work draws attention to the existence of the feedback-loop problem resulting in both theoretical and practical advances for ML in healthcare.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/42a27d8f0e3384d8c99b49684c1cdf58376ef879",
        "citation_count": 34
    },
    {
        "title": "Identification of dyscalculia using supervised machine learning algorithms",
        "abstract": "Dyscalculia is a specific learning disability in which a person faces difficulty in comprehending mathematical concepts. People with dyscalculia tend to face constant difficulties in performing mathematical calculations which affects their daily life. Around 3-7% of the population globally are affected with dyscalculia. The process of diagnosis of dyscalculia has always been a tough task. Techniques such as machine learning are used to for prediction in various fields such as healthcare, education, etc. Subsequently those techniques can be used for diagnosis of dyscalculia. The current study aims to develop a diagnosis model using well known supervised machine learning algorithms such Support Vector Machines (SVM), Simple logistic regression, Naive bayes and Random Forest",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/43178e7cbf9f2387975e68ac517a3751cc4e0a1e",
        "citation_count": 2
    },
    {
        "title": "Knowledge Extraction and Retrieval for Domain-Specific Documents",
        "abstract": "With the overwhelming amount of textual data created by more and more domain based information systems, it has been a significant challenge to identify the precise piece of relevant knowledge \u201cnugget\u201d from the tremendous amount of noisy, relevant and irrelevant data, including techno-geek and gobbledygook. When dealing with domain-specific text, many existing text mining methods fail to produce satisfying results, because they are unable to handle complex domain languages, understand semantic meaning, model latent business processes, or leverage domain resources and expertise. This motivates us to develop novel, effective extraction models and analyses to identify desired information from domain-specific documents, as well as associated retrieval models and analyses. In the dissertation, we study this research topic in three different domains, and approach the challenges in domain-specific text mining from multiple perspectives.In an enterprise service center, accurate and timely delivery of knowledge to service representatives becomes the cornerstone for delivering efficient customer service. There are two main steps in achieving this objective. The first step concerns efficient text mining to extract information of interest from the very long service request (SR) documents in the historical database. The second step concerns matching new service requests with previously solved service requests. Both lead to efficiencies by minimizing time spent by service personnel in accessing knowledge. In this scenario we present our text analytics system, the Service Request Analyzer and Recommender (SRAR), which is designed to improve the productivity in an enterprise service center for computer networking diagnostics and support. SRAR unifies a text preprocessor, a hierarchical classifier, and a service request recommender, to deliver critical, pertinent, and categorized knowledge for improved service efficiency. The novel feature we report here is identifying the components of the diagnostic process underlying the creation of the original text documents. This identification is crucial in the successful design and prototyping of SRAR and its hierarchical classifier elements. Equally, the use of domain knowledge and human expertise to generate features are indispensable components in improving the accuracy of knowledge extraction and retrieval. The empirical evaluation demonstrates the effectiveness of our framework and algorithms. We observe significant improvements of service time responsiveness during knowledge extraction and retrieval in the networking service center context at Cisco.In the healthcare domain, crucial information on a patient\u2019s physical or mental conditions is provided by mentions of disorders in clinical notes. However, there are many surface forms of the same disorder concept documented in clinical text. Some are even recorded disjointedly, briefly, or intuitively. In this study, we propose a synergistic approach to extracting disorder concepts and variants. We exploit rich features to predict mention spans using supervised learning algorithms, including support vector machines (SVM). In addition to the explicit bag-of-words, orthographic, and morphologic features, we investigate semantic, syntactic, and sequential features for better capturing implicit relationships among words. More specifically, the two types of semantic features we propose based on medical ontology prove very effective. We supplement SVMs with a rule-based annotator and an unsupervised NLP system to improve the prediction accuracy and the generalization capability of the system. Ultimately, this synergistic system is able to produce state-of-the-art results on public challenge data sets.In the biomedical domain, we define the notion of concept, extract all types of concepts from biomedical documents, and design a concept-based information retrieval framework. Using this framework, we transform documents and queries from term space into concept space, perform semantic analysis among concepts, and estimate a concept-based relevance model for improved document retrieval. Our approach has three advantages. First, it only assumes independence between concepts, so is able to keep the strong dependencies between the words of a concept. Second, it unifies synonyms or different surface forms of a concept, leading to reduced dimensionality of the space, increased sample size of a concept, and consequently more accurate and reliable estimates of the relevance. Third, when domain resources are available, our approach enables the semantic analysis of query concepts, and thus identifies concepts related to the query, from which a more accurate distribution of relevance can be estimated. We compare our approach with three benchmark retrieval models on different types of data collections. The proposed approach demonstrates consistent and statistically significant improvements across collections, outperforming top benchmark conceptual language models by at least 9% and up to 20% on a number of metrics.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/431de4fc5647080278d3d31ed4ac9d75e300fda9",
        "citation_count": 1
    },
    {
        "title": "Bringing Innovations in Systems and Analytics to the Bedside : Design of the CompGen Machine",
        "abstract": "The use of *omics data is transforming the healthcare and lifesciences domains to become more precise, personalized and datadriven. The key challenge in realizing the potential is to effectively merge several different modalities of data (e.g., genomic, metabolomic, epigenetic, medical sensor and patient record data) to produce actionable intelligence that can be used in clinical therapeutic contexts. Further this data fusion and subsequent analytics must be done in a timeand cost-effective manner. This presents interesting analytics, algorithmic and computer-systems challenges dealing with computation and data storage. In this paper, we present an outline of the CompGen machine at the UIUC, which was built in collaboration with the Mayo Clinic and support from IBM. It addresses several problems at the intersection of healthcare data, novel analytical tools and methods, and novel computer system architecture and design. At it\u2019s core, the CompGen machine uses probablistic graphical models called factor graphs, along with supervised, unsupervised learning methods, as well as sequence data processing algorithms to fuse information from several sources to perform inference and prediction. The system uses a hardware-software co-design approach to significantly improve computational performance and energy consumption. Further, using factor graphs to model the performance of various components of the system, we are able to distribute computations effectively between our custom designed accelerators as well as, popularly available accelerators like GPUs and MICs. We demonstrate the efficacy of the approach in solving several important biological and medical problems: 1) Incidence of Diabetes in Populations, 2) Psychiatric Drug Response, and 3) Seizure Prediction and Localization. Figure 1 demonstrates the overarching design of the proposed proposed framework.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/436536870ad4a6d65767fdf296f8f0f082a562c8",
        "citation_count": 0
    },
    {
        "title": "A Healthcare System for Internet of Things (IoT) Application: Machine Learning Based Approach",
        "abstract": "Internet of things (IoT) has become an interesting topic in the field of technological research. It is basically interconnecting of devices with each other over the internet. Beside its general use in terms of autonomous cars and smart homes, but some of the best applications of IoT technology in fields of health care monitoring is worth mentioning. The main purpose of this research work is to provide comport services for patients. It can be used to promote basic nursing care by improving the quality of care and patient safety from patient home environment. Rural area of a country lacks behind the proper patient monitoring system. So, remote monitoring and prescribing by sharing medical information in an authenticated manner is very effective for betterment of medical facilities in rural area. We have proposed a healthcare system which can analyze ECG report using supervise machine learning techniques. Analyzing report can be stored in cloud platform which can be further used to prescribe by the experienced medical practitioner. For performance evaluation, ECG data is analyzed using six supervised machine learning algorithms. Data sets are divided into two groups: 75 percent data for training the model and rest 25 percent data for testing. To avoid any kind of anomalies or repetitions, cross validation and random train-test split was used to obtain the result as accurate as possible.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/43b76a1bfbdb0f0837a76aeeaa1a8e4e1801a4b1",
        "citation_count": 12
    },
    {
        "title": "Drug Prediction System Using Data Mining Techniques - A Survey",
        "abstract": "The thriving Medical applications of Data mining in the fields of Medicine and Public health has led to the popularity of its use in Knowledge Discovery in Databases (KDD). Data mining has revealed novel Biomedical and Healthcare acquaintances for Clinical decision making that has great potential to improve the treatment quality of hospitals and increase the survival rate of patients. Drug Prediction is one of the applications where data mining tools are establishing the successful results. Data mining intends to endow with a systematic survey of current techniques of Knowledge discovery in Databases using Data mining techniques that are in use in today\u2019s Medical research. To enable the drug retrieval and the breakthrough of hidden retrieval patterns from related databases, a study is made. Also, the use of data mining to discover such relationships as those between Supervised and Unsupervised are presented. This paper summarizes various Machine learning algorithms based on various Data mining techniques in learning strategies. It has also been targeted on contemporary research being done the usage of the Data mining strategies to beautify the retrieval manner. This research paper offers destiny developments of modern-day strategies of KDD, using data mining equipment for medicinal drug industry. It also confers huge troubles and demanding situations related to information mining and medication area. The research discovered a developing quantity of records mining packages, such as evaluation of drugs names for higher fitness policy-making, detection of accurate effects with outbreaks and preventable from misclassified drug names.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/43ecc4c5f58c17e0739da9ea42901aff514969d6",
        "citation_count": 0
    },
    {
        "title": "Identify Hidden Phenotypes in Electronic Health Records Using Machine Learning Technique",
        "abstract": "scientific information, such as EHRs, have become increasingly famous because of their comfort and price savings related to their use. On the side of providing an extra efficient manner of storing and reviewing affected person facts, using EHRs allows healthcare companies to study and examine healthcare tendencies and outcomes extra effectively. As the use of EHRs grows, so does the need for brand-new methods to perceive and extract medically helpful facts from the facts. Lately, there has been a growing frame of labor that uses device learning strategies to discover hidden phenotypes in EHRs. These hidden phenotypes are defined as \u201cinformation or characteristics that are not conveniently obvious from the raw EHRs information however, may be gleaned through automatic data mining and evaluation.\u201d This newsletter focuses on the various tactics used to pick out hidden phenotypes in EHRs through machine studying, natural language processing (NLP), deep gaining knowledge of, and supervised mastering techniques. It additionally gives an outline of the most promising algorithms and discusses the challenges and possibilities associated with the usage of this era.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/4470c80c8dbdf26e5920bcdb455f44db021930b1",
        "citation_count": 0
    },
    {
        "title": "Artificial Neural Networks in Biomedicine",
        "abstract": null,
        "year": 2000,
        "url": "https://www.semanticscholar.org/paper/4499a809b86e95e1b5efaf2755f5a24803c78c21",
        "citation_count": 92
    },
    {
        "title": "Towards the Application of Machine Learning in Emergency Informatics",
        "abstract": "Emergency care is one of the cornerstone parts of the world health organization's action plan. Rapid response and immediate care are considered in agile emergency care. Artificial intelligence (AI) and informatics have been applied to fulfill these requirements through automated emergency technology. Machine learning (ML) is one of the main parts of some of these proposed technologies. There are various ML algorithms and techniques which are potentially applicable for different purposes of emergency care. AI-based approaches using classification and clustering algorithms, natural language processing, and text mining are some of the possible techniques that could prove useful for investigating models of emergency prevention and management and proposing improved procedures for handling such critical situations. ML is known as a field of AI which attempts to automatically learn from data and applies that learning to make better decisions. Decision-support tools can apply the results of either supervised or various semi-supervised or unsupervised learning methods to tackle the how decisions about emergency situations are typically handled by the best professionals at the scene of an emergency, in the pre-hospital, and in healthcare facility settings. Enhanced and rapid communication at the moment of emergency, with the most effective decision making for triaging to estimate the acute nature of injuries and possible complications, how to keep a patient stable on the way to the care facility, and also avoiding adverse drug reactions, are some of the possible directions for exploring how ML can help to gather the data and to make emergency management more efficient and effective. The wide range of scenarios present in emergency situations and the complexity of different legal and ethical constraints on what responding personnel are allowed to perform on an injured subject before reaching a hospital makes for a most challenging set of problems for investigating the components of \"intelligent\" decision support that could help in these highly interactive and humanly tragic situations.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/44bb7590384e8b85b7cc69f61d62210b64d345ae",
        "citation_count": 1
    },
    {
        "title": "A Machine Learning Model for Healthcare Stocks Forecasting in the US Stock Market during COVID-19 Period",
        "abstract": "This paper study the nowcasting and forecasting for the healthcare stock price in the united states during the Covid-19 period including the google trend data information. The data is collected in monthly data from 2015 to 2020 which are five interested stock price indexes in the healthcare sector. Empirically, the finding reveals that the Bayesian structural time series analysis can be used to investigate the stock price indexes with the google trend data is becoming useful for the prediction in term of current movement. In term of the machine learning algorithms, the unsupervised learning k-Mean algorithm is employed to cluster the cycle regimes of the stock market which provided three regimes such as Bull market, Sideways and Bear market. There are twenty-nine months stand for bull market, thirty-seven months are predictively provided sideways market and five months are referred as the bear market. Additionally, the supervised learning algorithms by using the Linear Discriminant Analysis (LDA), k-Nearest Neighbors (kNN) and Support vector machine (SVM) are used to investigate the cycle regimes of healthcare stock in next five year. The results indicated that LDA is chosen by the highest coefficient validation which represented the the regimes of stock in the healcare sector of the unites states of America will stay on the sideways periods in the next five years. Thus, the finding in this paper can be the useful information for investor to manage their portfolio especially, in healthcare sector during the Covid-19 period.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/44dd048cfb52f31c91626ca52c8bb41388bb9fd6",
        "citation_count": 4
    },
    {
        "title": "Supervised Machine Learning Based Medical Diagnosis Support System for Prediction of Patients with Heart Disease",
        "abstract": "A R T I C L E I N F O A B S T R A C T Article history: Received: 20 July, 2020 Accepted: 01 September, 2020 Online: 17 September, 2020 Application in the field of medical development has always been one of the most important research areas. One of these medical applications is the early prediction system for heart diseases especially; coronary artery disease (CAD) also called atherosclerosis. The need for a medical diagnosis support system is to detect atherosclerosis at the earlier stages to optimize the diagnosis, avoid the advanced cases, and reduce treatment costs. Earlier, the datasets are collected from specific medical sources and have evaluated against computer applications. In this paper, a supervised machine learning medical diagnosis support system (MDSS) for atherosclerosis prediction is presented that able to obtain and learn automatically knowledge from each patient's clinical data. Therefore, we used three Machine Learning (ML) classifiers for the proposed MDSS for atherosclerosis. Thus, this work is accomplished using databases collected from the UCI repository (Cleveland, Hungarian) and Sani Z-Alizadeh dataset. The performance metrics were computed utilizing Accuracy, Recall and Precision. Furthermore, F1-score and Matthews\u2019s correlation coefficient these measures were also calculated to greatly increase the proposed system performance. Additionally, 10-fold cross-validation methods have been used for proposed model performance evaluation that achieved 94% as the best accuracy average. Consequently, the proposed model can be used to support healthcare and facilitate largescale clinical diagnostic of atherosclerosis diseases.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/457b58cee1f93c6123e43835cea3bf2c5a27d507",
        "citation_count": 37
    },
    {
        "title": "Factors associated with fall risk of community-dwelling older people: A decision tree analysis",
        "abstract": "Objective To examine the predictive attributes for accidental falls in community-dwelling older people in Hong Kong using decision tree analysis. Methods We recruited 1151 participants with an average age of 74.8 years by convenience sampling from a primary healthcare setting to carry out the cross-sectional study over 6 months. The whole dataset was divided into two sets, namely training set and test set, which respectively occupied 70% and 30% of the whole dataset. The training dataset was used first; decision tree analysis was used to identify possible stratifying variables that could help to generate separate decision models. Results The number of fallers was 230 with 20% 1-year prevalence. There were significant differences in gender, use of walking aids, presence of chronic diseases, and co-morbidities including osteoporosis, depression, and previous upper limb fractures, and performance in the Timed Up and Go test and the Functional Reach test among the baselines between the faller and non-faller groups. Three decision tree models for the dependent dichotomous variables (fallers, indoor fallers, and outdoor fallers) were generated, with overall accuracy rates of the models of 77.40%, 89.44% and 85.76%, respectively. Timed Up and Go, Functional Reach, body mass index, high blood pressure, osteoporosis, and number of drugs taken were identified as stratifying variables in the decision tree models for fall screening. Conclusion The use of decision tree analysis for clinical algorithms for accidental falls in community-dwelling older people creates patterns for decision-making in fall screening, which also paves the way for utility-based decision-making using supervised machine learning in fall risk detection.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/45d26202fe0d91232dcb14937c4dd21a8737e99f",
        "citation_count": 3
    },
    {
        "title": "Role of Machine Learning In Health Care System for The Prediction of Different Diseases",
        "abstract": "Machine Learning (ML) refers to a variety of statistical approaches that enable computers to learn from experience without being explicitly programmed. This learning generally manifests itself as modifications to how an algorithm operates. For physicians, predicting and identifying heart illness has always been a challenging and time-consuming task. Hospital and other institutions provide pricey operations and treatments to treat hearing issues. Early heart disease identification will help people all around the globe since it will enable them to get the proper care before it worsens. Overconsumption of alcohol, cigarette smoking, and inactivity have been the main contributors to heart disease in recent years. The healthcare industry has used machine learning to generate predictions and decisions from a significant quantity of data across time. The supervised machine learning techniques used in this prediction of coronary heart disease include artificial neural network (ANN), decision trees (DT), Random Forest (RF), support vector systems (SVM), nave Boltzmann (NB), and nearest neighbour algorithm. Additionally, a summary of the outcomes from several algorithms is provided.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/45d53bc85f043f26c5d89b7031c9c5d9b07a95a7",
        "citation_count": 13
    },
    {
        "title": "Diagnosis Of Heart Disease Using Datamining Algorithm",
        "abstract": "The diagnosis of heart disease is a significant and tedious task in medicine. The healthcare industry gathers enormous amounts of heart disease data that regrettably, are not \u201cmined\u201d to determine concealed information for effective decision making by healthcare practitioners. The term Heart disease encompasses the diverse diseases that affect the heart. Cardiomyopathy and Cardiovascular disease are some categories of heart diseases. The reduction of blood and oxygen supply to the heart leads to heart disease. In this paper the data classification is based on supervised machine learning algorithms which result in accuracy, time taken to build the algorithm. Tanagra tool is used to classify the data and the data is evaluated using 10-fold cross validation and the results are compared.",
        "year": 2010,
        "url": "https://www.semanticscholar.org/paper/45e97637d6ba9b306956e192bd4f96c2119fdd30",
        "citation_count": 137
    },
    {
        "title": "Does COVID-19 Clinical Status Associate with Outcome Severity? An Unsupervised Machine Learning Approach for Knowledge Extraction",
        "abstract": "Since the beginning of the COVID-19 pandemic, 195 million people have been infected and 4.2 million have died from the disease or its side effects. Physicians, healthcare scientists and medical staff continuously try to deal with overloaded hospital admissions, while in parallel, they try to identify meaningful correlations between the severity of infected patients with their symptoms, comorbidities and biomarkers. Artificial intelligence (AI) and machine learning (ML) have been used recently in many areas related to COVID-19 healthcare. The main goal is to manage effectively the wide variety of issues related to COVID-19 and its consequences. The existing applications of ML to COVID-19 healthcare are based on supervised classifications which require a labeled training dataset, serving as reference point for learning, as well as predefined classes. However, the existing knowledge about COVID-19 and its consequences is still not solid and the points of common agreement among different scientific communities are still unclear. Therefore, this study aimed to follow an unsupervised clustering approach, where prior knowledge is not required (tabula rasa). More specifically, 268 hospitalized patients at the First Propaedeutic Department of Internal Medicine of AHEPA University Hospital of Thessaloniki were assessed in terms of 40 clinical variables (numerical and categorical), leading to a high-dimensionality dataset. Dimensionality reduction was performed by applying a principal component analysis (PCA) on the numerical part of the dataset and a multiple correspondence analysis (MCA) on the categorical part of the dataset. Then, the Bayesian information criterion (BIC) was applied to Gaussian mixture models (GMM) in order to identify the optimal number of clusters under which the best grouping of patients occurs. The proposed methodology identified four clusters of patients with similar clinical characteristics. The analysis revealed a cluster of asymptomatic patients that resulted in death at a rate of 23.8%. This striking result forces us to reconsider the relationship between the severity of COVID-19 clinical symptoms and the patient\u2019s mortality.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/46105f340a30a406d8bce4e7bb49962a80f41a4f",
        "citation_count": 6
    },
    {
        "title": "Cloud based patient prioritization as service in public health care",
        "abstract": "This paper proposes and evaluates the performance of a Cyber-healthcare system which is aimed at providing patient prioritization over the cloud as a public health service for the rural and urban communities of the developing world. The underlying cloud-based Internet-of-Things (IoT-Cloud) infrastructure is aimed to be implemented in the city of Lubumbashi in the republic Democratic Republic of the Congo (DRC) with the objective of setting up a community health care network around a mesh of health kiosks. We propose a deployment model for the proposed Cyber-healthcare system, and describe a patient prioritization process as part of its situation awareness component. The results obtained from an experimental prototype reveal the field readiness of the off-the-shelf bio-sensor technology used by the system, the performance achieved when using a solar powered subsystem, the relative communication capabilities provided by its protocols and the network engineering feasibility of the planned community health care network. The relative efficiency of using supervised machine learning compared to unsupervised machine learning when performing patient prioritization, is also revealed through two popular algorithms: Multivariate linear regression (MLR) and K-means clustering (KMC).",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/46a8aa4e2609363a3dc870586e26c436829d3938",
        "citation_count": 37
    },
    {
        "title": "Human Digital Twin for Personal Conversation Automation Using Supervised Machine Learning Approaches",
        "abstract": "\u2014Digital Twin has emerged as a compelling research area, capturing the attention of scholars over the past decade. It \ufb01nds applications across diverse \ufb01elds, including smart manufacturing and healthcare, offering signi\ufb01cant time and cost savings. Notably, it often intersects with other cutting-edge technologies such as Data Mining, Arti\ufb01cial Intelligence, and Machine Learning. However, the concept of a Human Digital Twin (HDT) is still in its infancy and requires further demonstration of its practicality. HDT takes the notion of Digital Twin a step further by extending it to living entities, notably humans, who are vastly different from inanimate physical objects. The primary objective of this research was to create an HDT capable of automating real-time human responses by simulating human behavior. To achieve this, the study delved into various areas, including clustering, supervised classi\ufb01cation, topic extraction, and sentiment analysis. The paper successfully demonstrated the feasibility of HDT for generating personalized responses in social messaging applications. Notably, the proposed approach achieved an overall accuracy of 63%, a highly promising result that could pave the way for further exploration of the HDT concept. The methodology employed Random Forest for clustering the question database and matching new questions, while K-nearest neighbor was utilized for sentiment analysis",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/46ba273aee269b997d5943197ef008eae23ebf45",
        "citation_count": 0
    },
    {
        "title": "A Framework for Efficient Healthcare Resources Utilization using Semi-supervised Machine Learning Algorithm",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/46d0c09dc58890e1326ee24f4631d78929b93788",
        "citation_count": 0
    },
    {
        "title": "Selecting cardiac magnetic resonance images suitable for annotation of pulmonary arteries using an active-learning based deep learning model",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/47313f8af126a31a79e7163c5d48ff7880cfef85",
        "citation_count": 1
    },
    {
        "title": "Leveraging distant supervision and deep learning for twitter sentiment and emotion classification",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/4738c5ca7b630722a8b5a8ac2b9e4bd898a5b905",
        "citation_count": 6
    },
    {
        "title": "Decision Support System in Healthcare for Predicting Blood Pressure Disorders",
        "abstract": "Blood pressure problems including hypertension and hypotension are considered common among the elderly population, especially hypertension. Recently it started being common among younger adults due to many factors related to unhealthy lifestyles, stress, or genetic factors. Besides the fact of considering hypertension as a chronic disease, it is also considered a primary or contributing cause of complicated risky health issues such as strokes, heart diseases, and chronic kidney failure. In many cases, hypertensive patients may not be aware of their problem because they don't experience any symptoms or warning signs. For this reason, it is essential to build a decision support system to identify individuals at high risk of blood pressure problems including raised blood pressure and low blood pressure. This paper proposes a decision support model for predicting blood pressure disorders by using input variables such as sex, age, body mass index (BMI), cholesterol level, heart rate, and glucose level. The decision model helps in early warning of the potential risk of hypertension or hypotension. As a result, people under potential risk are advised to measure their blood pressure regularly and take the needed precautions or medications to avoid or control this health issue. The proposed decision support model is based on using supervised machine learning classification algorithms, mainly Random Forest, Decision Tree, and XGBoost. The experimental results show that the model achieved the best performance when implemented using a Random Forest classifier with a 10-fold cross-validation method, with an accuracy of 85.81%.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/4743225183f373fb50c79274747209435bd1b97c",
        "citation_count": 3
    },
    {
        "title": "A Comparative Study on Aspects Level Drug Reviews using Back Propagation Neural Networks",
        "abstract": "Several aspects, such as drug interactions and adverse effects, must be taken into account before prescribing a drug. The fact that some pharmacological qualities, such as side effects, are dependent on patient variables such as age and gender, complicates the procedure even further. Our goal is to create a platform that will aid doctors in prescription medications. This paper devises a method for searching for medications that meet a set of criteria based on drug attributes. Both healthcare professionals who prescribe and dispense pharmaceuticals, as well as drug users, should take several precautions when using pharmaceutical drugs. Prescription drug interactions, interactions with the patient\u2019s existing medicine, potential adverse effects, and contraindications must all be considered. Furthermore, patient characteristics such as age, gender, habits, and genetic profiles influence pharmacological attributes such as side effects and efficacy. The objective is to develop a system that will assist medical professionals and drug users in choosing and locating appropriate drugs. Users can select side effects and the approach answers to their needs. Data about drugs comes from a variety of places. Medicine data, on the other hand, is typically noisy and incomplete because it is either manually developed or mechanically retrieved from text resources like drug labels. Data science technology known as a supervised Machine learning algorithm can be used to analyze medications based on various aspects with better accuracy to deal with incomplete and noisy data.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/477316c25087653f9d6e094ab1995a59bde68884",
        "citation_count": 1
    },
    {
        "title": "Evaluating the Performance of Supervised Machine Learning Algorithms for Predicting Multiple Diseases: A Comparative Study",
        "abstract": "Machine learning has become one of the most popular and widely used techniques in various industries, especially in the healthcare sector. This paper focuses on examining the performance analysis of several machine learning algorithms and conducting a comparative analysis to determine which algorithm performs best in predicting six different diseases, such as cardiovascular, heart, stroke, Alzheimer, breast, and lung cancer, with various metrics. The Multi Disease Dataset was obtained from the UCI Machine Learning Repository and contains various instances and attributes. The proposed model involves two stages of data preprocessing, including missing value replacement and label encoding. Additionally, Six diverse supervised machine learning classification algorithms, including Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Logistic Regression (LR), Naive Bayes (NB), Random Forest (RF), and Decision Tree (DT), were analyzed. Also the AdaBoost and Soft voting classifier were analyzed and compared to the accuracy of all the algorithms. The comparative analysis showed that the Voting Classifier performed best in predicting most of the diseases, and Support Vector Machine and AdaBoost also performed well in terms of Precision, Sensitivity, and Specificity metrics. SVM achieved a classification accuracy of 91.9% for Alzheimer\u2019s Disease, 88.7% for Lung Cancer, while the Voting Classifier, which is an ensemble of the mentioned ML algorithms, achieved accuracy of 77% for Heart Disease, 78.2% for Cardiovascular Disease, 91.4% for Breast Cancer, and 95% for Stroke, outperforming the other machine learning algorithms. The classification accuracy of the Voting Classifier was similar to that of SVM and AdaBoost in multi-disease prediction",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/47f9e412e7151dd72492fa7aa7f03c826b765ad3",
        "citation_count": 4
    },
    {
        "title": "EpiBOX: An Automated Platform for Long-Term Biosignal Collection",
        "abstract": "Biosignals represent a first-line source of information to understand the behavior and state of human biological systems, often used in machine learning problems. However, the development of healthcare-related algorithms that are both personalized and robust requires the collection of large volumes of data to capture representative instances of all possible states. While the rise of flexible biosignal acquisition solutions has enabled the expedition of data collection, they often require complicated frameworks or do not provide the customization required in some research contexts. As such, EpiBOX was developed as an open-source, standalone, and automated platform that enables the long-term acquisition of biosignals, passable to be operated by individuals with low technological proficiency. In particular, in this paper, we present an in-depth explanation of the framework, methods for the evaluation of its performance, and the corresponding findings regarding the perspective of the end-user. The impact of the network connection on data transfer latency was studied, demonstrating innocuous latency values for reasonable signal strengths and manageable latency values even when the connection was unstable. Moreover, performance profiling of the EpiBOX user interface (mobile application) indicates a suitable performance in all aspects, providing an encouraging outlook on adherence to the system. Finally, the experience of our research group is described as a use case, indicating a promising outlook regarding the use of the EpiBOX framework within similar contexts. As a byproduct of these features, our hope is that by empowering physicians, technicians, and monitored subjects to supervise the biosignal collection process, we enable researchers to scale biosignal collection.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/481106f958bf9d2e0bcb06e25e3385c96419abcb",
        "citation_count": 5
    },
    {
        "title": "Predictive Incident Management Using Machine Learning",
        "abstract": ": One of the significant advances resulting from the ability to predict incidents is the emergence of predictive incident management as the critical capability for proactive monitoring and management of modern complex systems. This survey presents the complete picture of foretelling incident management based on machine learning techniques and the up - to - date advancement in this area. The primary issue is that the way incident management is done on emergency help is reactive and causes people to be delayed, services to be interrupted, and costs to go high. The manual gambling of computerized (hardware/software) failures is almost impossible in complex, highly dynamic systems with a large amount of monitoring data. Machine learning techniques are considered for implementing an automated disaster detection system that can be trained on observing data properties related to system features to forecast incidents before they occur. Applying models like regression and neural networks to supervised learning can help recognize imminent storm symptoms by referencing past antecedents. Another feature of unsupervised techniques such as clustering is that they can be used to identify anomalies witnessed, which gives the earliest indications that there could be emerging problems. Online education goes on to lead to the practicality of predictive software. This review studies the potential of predictive incident management applications in monitoring the IT system, industrial predictive maintenance, healthcare systems, fraud detection, and supply chain risk. The effect, therefore, is improved service quality and stability, diagnostics accuracy, and resource allocation optimization. The following steps are adding new data sources to predict further scenarios, distributed learning at scale, making AIs one step further explaining themselves, and preserving people's privacy while dealing with data. The preference for predictive incident management based on machine learning allows industry - wide organizations to go from reactive to proactive with machine - driven systems management throughout the economy .",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/4819d920de756413446f377146940384353636d5",
        "citation_count": 0
    },
    {
        "title": "Developing machine learning models to predict multi-class functional outcomes and death three months after stroke in Sweden",
        "abstract": "Globally, stroke is the third-leading cause of mortality and disability combined, and one of the costliest diseases in society. More accurate predictions of stroke outcomes can guide healthcare organizations in allocating appropriate resources to improve care and reduce both the economic and social burden of the disease. We aim to develop and evaluate the performance and explainability of three supervised machine learning models and the traditional multinomial logistic regression (mLR) in predicting functional dependence and death three months after stroke, using routinely-collected data. This prognostic study included adult patients, registered in the Swedish Stroke Registry (Riksstroke) from 2015 to 2020. Riksstroke contains information on stroke care and outcomes among patients treated in hospitals in Sweden. Prognostic factors (features) included demographic characteristics, pre-stroke functional status, cardiovascular risk factors, medications, acute care, stroke type, and severity. The outcome was measured using the modified Rankin Scale at three months after stroke (a scale of 0\u20132 indicates independent, 3\u20135 dependent, and 6 dead). Outcome prediction models included support vector machines, artificial neural networks (ANN), eXtreme Gradient Boosting (XGBoost), and mLR. The models were trained and evaluated on 75% and 25% of the dataset, respectively. Model predictions were explained using SHAP values. The study included 102,135 patients (85.8% ischemic stroke, 53.3% male, mean age 75.8 years, and median NIHSS of 3). All models demonstrated similar overall accuracy (69%\u201370%). The ANN and XGBoost models performed significantly better than the mLR in classifying dependence with F1-scores of 0.603 (95% CI; 0.594\u20130.611) and 0.577 (95% CI; 0.568\u20130.586), versus 0.544 (95% CI; 0.545\u20130.563) for the mLR model. The factors that contributed most to the predictions were expectedly similar in the models, based on clinical knowledge. Our ANN and XGBoost models showed a modest improvement in prediction performance and explainability compared to mLR using routinely-collected data. Their improved ability to predict functional dependence may be of particular importance for the planning and organization of acute stroke care and rehabilitation.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/481eac4ad67150ccfe399075acad7c56482f2d2d",
        "citation_count": 1
    },
    {
        "title": "Machine learning based approach for detecting Distributed Denial of Service attack",
        "abstract": "All elements of the IT industry are expanding, including bandwidth, storage, processing speed. As a result, there are now more cyber threats and attacks, necessitating a creative and predictive security approach that employs cutting-edge technology to combat the danger. The trends will be monitored, and adequate analysis from various sets of data will be utilized to build a model that is based on the information available. Distributed Denial of Service (DDoS) is one of the most prevalent dangers and attacks wreaking havoc on internet-connected computer equipment. This study compares the performance of several machine learning-based classifiers for detecting DDoS assaults before they occur. This experiment made use of data from the benchmark KDD-Cup-1999 DDoS attack. To choose essential characteristics in the context of DDoS detection, I created three distinct types of feature selection techniques. The findings revealed that feature selection approaches can assist domain specialists in understanding the intrusion system\u2019s hidden key patterns and features during DDoS detection. DNN-based deep learning and semi-supervised learning method were also compared with the ML-based classifiers output. The suggested model learns to recognize regular network traffic to detect ICMP, TCP, and UDP DDoS traffic as it arrives. Experiments show that machine learning algorithms may correctly classify the traffic into regular and DDoS. This discovery has long-term implications in a variety of sectors, including national defence, financial institutions, healthcare, and other businesses where sophisticated intrusion detection techniques are required. In the future, I would want to apply similar approaches to a variety of datasets.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/485a44f7e561ebaebbfc25b614370347a8986be7",
        "citation_count": 1
    },
    {
        "title": "Intelligence-Based Recommendation System for Critical Stroke Management in Intensive Care Units",
        "abstract": ": This work presents an integrated recommendation system capable of providing support in healthcare critical environments such as Intensive Care Units or Stroke Care Units using Machine Learning techniques. The system can manage several patients by reading monitoring hemodynamic data in real-time, presenting current death risk probability, and showing recommendations that would reduce such probability and, in some cases, avoid death. This system introduces a novel method to produce recommendations based on genetic models and supervised machine learning. The interface is built upon a web application where clinicians can evaluate recommendations and straightforwardly provide feedback.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/48b005c1798986a0ef086c5e6a3a1a8c5626c667",
        "citation_count": 0
    },
    {
        "title": "Machine Learning in Healthcare: A Deep Dive into Classification, Limitations, Prospects, And Hurdles",
        "abstract": "Recently, a range of advanced techniques, such as artificial intelligence and machine learning, have been used to analyse health-related data. Machine learning applications are helping medical practitioners become more proficient in diagnosing and treating patients. Numerous academics have used medical data to find trends and diagnose illnesses. There aren't many papers in the literature right now that discuss using machine learning algorithms to increase the efficiency and accuracy of healthcare data. We investigated how well time series healthcare parameters for heart rate data transfer (accuracy and efficiency) may be enhanced using machine learning methods. We explored a number of machine learning techniques for use in healthcare applications in this research. Following a thorough introduction and analysis of supervised and unsupervised machine learning algorithms.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/48d264ccc0dbf741a1de41fec22853258d05bd89",
        "citation_count": 0
    },
    {
        "title": "Assessment of beliefs and attitudes about electroconvulsive therapy posted on Twitter: An observational study",
        "abstract": "Abstract Background Electroconvulsive therapy (ECT) is an effective and safe medical procedure that mainly indicated for depression, but is also indicated for patients with other conditions. However, ECT is among the most stigmatized and controversial treatments in medicine. Our objective was to examine social media contents on Twitter related to ECT to identify and evaluate public views on the matter. Methods We collected Twitter posts in English and Spanish mentioning ECT between January 1, 2019 and October 31, 2020. Identified tweets were subject to a mixed method quantitative\u2013qualitative content and sentiment analysis combining manual and semi-supervised natural language processing machine-learning analyses. Such analyses identified the distribution of tweets, their public interest (retweets and likes per tweet), and sentiment for the observed different categories of Twitter users and contents. Results \u201cHealthcare providers\u201d users produced more tweets (25%) than \u201cpeople with lived experience\u201d and their \u201crelatives\u201d (including family members and close friends or acquaintances) (10% combined), and were the main publishers of \u201cmedical\u201d content (mostly related to ECT\u2019s main indications). However, more than half of the total tweets had \u201cjoke or trivializing\u201d contents, and such had a higher like and retweet ratio. Among those tweets manifesting personal opinions on ECT, around 75% of them had a negative sentiment. Conclusions Mixed method analysis of social media contents on Twitter offers a novel perspective to examine public opinion on ECT, and our results show attitudes more negative than those reflected in studies using surveys and other traditional methods.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/48e6fa1fe8dfa57b6202dc0154215996f06469e3",
        "citation_count": 13
    },
    {
        "title": "A Systematic Analysis for Cardiovascular Disease Classification Using Deep Learning",
        "abstract": "The processing of medical data has profited from automation and contemporary computing breakthroughs, which have given rise to several novel instructional approaches. In both traditional and cutting-edge disciplines, deep learning has emerged as a cutting-edge machine learning paradigm. Deep learning algorithms have developed into supervised, semi-supervised, and unsupervised modes for a variety of real-time applications. The technology has shown to be broadly applicable in image processing, computer vision, medical diagnostics, robotics, and control operation. Deep learning is essential in the field of medical science for recognizing various diseases and solving health issues. The deep learning revolution will significantly alter cardiovascular imaging within the next decade. To ensure that deep learning may meaningfully impact clinical practice, it is crucial for medical practitioners to stay up with these breakthroughs. This evaluation is intended to be a preliminary step in that process. In this study cardiovascular disease diagnosis and classification have been examined using different state-of-the-art deep learning approaches. Deep Neural Networks can be used to improve the classification of heart disease as a whole in a crucial field called heart illness. The classification process can be carried out using a variety of methods, such as DL, KNN, SVM, ANN Nave Bayes, Random Forest, SSD, DNN, and TDNN where DL exhibited maximum accuracy. Although deep learning-based automated cardiovascular classification algorithms have shown highly accurate results, they have not yet been widely used by healthcare professionals.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/4932b503d965b67e1cdec352e80581733bdadc2d",
        "citation_count": 0
    },
    {
        "title": "Evaluating GPT-4 as a Clinical Decision Support Tool in Ischemic Stroke Management",
        "abstract": "Cerebrovascular diseases are the second most common cause of death worldwide and one of the major causes of disability burden. Advancements in artificial intelligence (AI) have the potential to revolutionize healthcare delivery, particularly in critical decision-making scenarios such as ischemic stroke management. This study evaluates the effectiveness of GPT-4 in providing clinical decision support for emergency room neurologists by comparing its recommendations with expert opinions and real-world treatment outcomes. A cohort of 100 consecutive patients with acute stroke symptoms was retrospectively reviewed. The data used for decision-making included patients' history, clinical evaluation, imaging studies results, and other relevant details. Each case was independently presented to GPT-4, which provided a scaled recommendation (1-7) regarding the appropriateness of treatment, the use of tissue plasminogen activator (tPA), and the need for endovascular thrombectomy (EVT). Additionally, GPT-4 estimated the 90-day mortality probability for each patient and elucidated its reasoning for each recommendation. The recommendations were then compared with those of a stroke specialist and actual treatment decision. The agreement of GPT-4 recommendations with the expert opinion yielded an Area Under the Curve (AUC) of 0.85 [95% CI: 0.77-0.93], and with real-world treatment decisions, an AUC of 0.80 [0.69-0.91]. In terms of mortality prediction, out of 13 patients who died within 90 days, GPT-4 accurately identified 10 within its top 25 high-risk predictions (AUC = 0.89 [95% CI: 0.8077-0.9739]; HR: 6.98 [95% CI: 2.88-16.9]), surpassing supervised machine-learning models. This study demonstrates the potential of GPT-4 as a viable clinical decision support tool in the management of ischemic stroke. Its ability to provide explainable recommendations without requiring structured data input aligns well with the routine workflows of treating physicians. Future studies should focus on prospective validations and exploring the integration of such AI tools into clinical practice.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/493f3c86508c7d807c9f9e6153558d1fafe2ecf2",
        "citation_count": 0
    },
    {
        "title": "Biomedical literature mining: graph kernel-based learning for gene\u2013gene interaction extraction",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/496a6e53fa7930c69302913614910f60aed9fec9",
        "citation_count": 0
    },
    {
        "title": "From EHRs to Insights: How Machine Learning is Transforming Healthcare Data Management",
        "abstract": "The care industry is in the middle of a transformation because of the adoption of EHRs and the integration of ML into the framework of healthcare. This article also has the intention of discussing how ML assists in changing the management of healthcare information and, as such, indicates how the raw EHR data can be utilized. Some of the traditional challenges associated with handling immensely large, diverse and geographically distributed healthcare data have been solved by employments of Maxims and the use of intelligence algorisms to encompass data manipulation, pattern recognition and Information content anticipation. First of all, they have not only used the new opportunities to provide better, improved and more efficient services to the patients but also in the area of cost-cutting and introduction of the system of personalized medicine. In this paper, the author explored the place that ML occupies in consideration of the management of healthcare data with reference to techniques such as supervised learning, unsupervised learning, NLP and deep learning. They are then presented with regard to uses such as patient risk assessment, clinical decision-making, and population health. Furthermore, the paper also reveals that the challenges of \u2018bringing\u2019 ML into healthcare include the issues of data privacy and ethical questions regarding the data governance efforts needed. The study also proceeds further to talk about the future of ML in healthcare with regard to predictive and precision medicine. Some of the other interdisciplinary integration of ML is a combination of the technology with other currently dominant technologies like blockchain or IoT, where the integration of these two with ML is demonstrated, and other possibilities in the management of healthcare data are explored. In support of the said arguments the article gives instances of cases of the effective application of ML in the health sector as well as giving out tables and figures. To that end, it is important to assert that more research should be done. More monetary investment is made in the development of ML technologies so that these concepts can be better implemented and optimized. These two observations can become more fully realized in their potential to revolutionize the ways in which healthcare information is managed by healthcare providers, technologists and policymakers in the future and now.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/49ba531ec495691ab6624afaede9b7aa8a58de89",
        "citation_count": 0
    },
    {
        "title": "Predicting pregnancy loss and its determinants among reproductive-aged women using supervised machine learning algorithms in Sub-Saharan Africa",
        "abstract": "Background Pregnancy loss is a significant public health issue globally, particularly in Sub-Saharan Africa (SSA), where maternal health outcomes continue to be a major concern. Despite notable progress in improving maternal health, pregnancy-related complications, including s due to miscarriages, stillbirths, and induced abortions, continue to impact women's health, social wellbeing, and economic stability in the region. This study aims to identify the key predictors of pregnancy loss and develop effective predictive models for pregnancy loss among reproductive-aged women in SSA. Methods We derived the data for this cross-sectional study from the most recent Demographic and Health Survey of Sub-Saharan African countries. Python software was used to process the data, and machine learning techniques such as Random Forest, Decision Tree, Logistic Regression, Extreme Gradient Boosting, and Gaussian were applied. The performance of the predictive models was evaluated using several standard metrics, including the ROC curve, accuracy score, precision, recall, and F-measure. Result The final experimental results indicated that the Random Forest model performed the best in predicting pregnancy loss, achieving an accuracy of 98%, precision of 98%, F-measure of 83%, ROC curve of 94%, and recall of 77%. The Gaussian model had the lowest classification accuracy, with an accuracy of 92.64% compared to the others. Based on SHPY values, unmarried women may be more likely to experience pregnancy loss, particularly in contexts where premarital pregnancies are stigmatized. The use of antenatal care and family planning services can significantly impact the risk of pregnancy loss. Women from lower-income backgrounds may face challenges in accessing prenatal care or safe reproductive health services, leading to higher risks of loss. Additionally, higher levels of education are often correlated with increased awareness of family planning methods and better access to healthcare, which can reduce the likelihood of unintended pregnancy loss. Conclusion The Random Forest machine learning model demonstrates greater predictive power in estimating pregnancy loss risk factors. Machine learning can help facilitate early prediction and intervention for women at high risk of pregnancy loss. Based on these findings, we recommend policy measures aimed at reducing pregnancy loss Sub-Saharan African countries.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/49bcd3c2d736ec9c95c9abe14be417ef80e919df",
        "citation_count": 0
    },
    {
        "title": "Cold-Start Hospital Length of Stay Prediction Using Positive-Unlabeled Learning",
        "abstract": "Accurately predicting the in-hospital length of stay (LOS) at the time of admission can positively impact healthcare metrics. Machine learning (ML) techniques have been used to predict hospital patients\u2019 LOS based on their demographic and clinical characteristics. During the regular steady-state operation, traditional supervised-learning classification algorithms can be used for this purpose to inform hospital planning. However, when there are sudden changes to the admission and patient statistics, such as during the onset of a pandemic or the establishment of a new hospital, these approaches break down because reliable data for training ML models becomes available only gradually over time. This paper shows how LOS predictions can be improved during such a cold-start transition period by utilizing the positive-unlabelled (PU) learning techniques. Experimental results from using two PU learning algorithms with inpatient data from New York state hospitals support the proposed approach.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/49cca83e460c1e15647f1515e9aac75210f1dda2",
        "citation_count": 0
    },
    {
        "title": "Computational Intelligence in Gait Research: A Perspective on Current Applications and Future Challenges",
        "abstract": "Our mobility is an important daily requirement so much so that any disruption to it severely degrades our perceived quality of life. Studies in gait and human movement sciences, therefore, play a significant role in maintaining the well-being of our mobility. Current gait analysis involves numerous interdependent gait parameters that are difficult to adequately interpret due to the large volume of recorded data and lengthy assessment times in gait laboratories. A proposed solution to these problems is computational intelligence (CI), which is an emerging paradigm in biomedical engineering most notably in pathology detection and prosthesis design. The integration of CI technology in gait systems facilitates studies in disorders caused by lower limb defects, cerebral disorders, and aging effects by learning data relationships through a combination of signal processing and machine learning techniques. Learning paradigms, such as supervised learning, unsupervised learning, and fuzzy and evolutionary algorithms, provide advanced modeling capabilities for biomechanical systems that in the past have relied heavily on statistical analysis. CI offers the ability to investigate nonlinear data relationships, enhance data interpretation, design more efficient diagnostic methods, and extrapolate model functionality. These are envisioned to result in more cost-effective, efficient, and easy-to-use systems, which would address global shortages in medical personnel and rising medical costs. This paper surveys current signal processing and CI methodologies followed by gait applications ranging from normal gait studies and disorder detection to artificial gait simulation. We review recent systems focusing on the existing challenges and issues involved in making them successful. We also examine new research in sensor technologies for gait that could be combined with these intelligent systems to develop more effective healthcare solutions.",
        "year": 2009,
        "url": "https://www.semanticscholar.org/paper/4a0e2fc45a46df2b78f97ed36623ead212a0e567",
        "citation_count": 146
    },
    {
        "title": "A Hybrid Model for Detecting Insurance Fraud Using K-Means and Support Vector Machine Algorithms",
        "abstract": "Private stakeholders and governments across the globe are striving to improve the quality and access of healthcare services to citizens. The need to improve healthcare services, coupled with the increase in social awareness and improvement of people\u2019s living standards, has seen an increase in medical policyholders in the insurance industry. Even so, the healthcare sector is grappled with increased costs every other year, leading to revision of premiums and increased costs for the policyholders. One of the main factors contributing to the increased costs is fraudulent claims raised by the service providers and the policyholders, leading to unprecedented risks and losses for insurance firms. The insurance industry has set up fraud detection and mitigation systems to mitigate losses brought about by fraudulent claims, which come in two flavors: rule-based systems and expert claims analysis. With rule-based systems, conditions such as missing details, location of the claim vis a vis the location of the policyholder, among other rules, are evaluated by systems to assess the validity of the claims. On the other hand, insurance firms rely on the human intervention of experts using statistical analyses and artificial rules to detect fraudulent claims. The rule-based and expert analysis methods fail to detect patterns or anomalies in claims, which is central to efficient fraud detection. Data mining and machine learning techniques are being leveraged to detect fraud. This automation presents enormous opportunities for identifying hidden patterns for further analysis by insurance firms. This research aims to analyze a hybrid approach to detect medical insurance fraud using both K-Means (unsupervised) and Support Vector Machines (supervised) machine learning algorithms.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/4a6a23f5ad5cd808220379c3e69f54de3cc37033",
        "citation_count": 0
    },
    {
        "title": "IDENTIFICATION OF LIVER PATIENTS USING SUPERVISED LEARNING: A COMPARATIVE ANALYSIS",
        "abstract": ": Liver Failure is a serious condition and it affects the patient\u2019s life time. Disease identification is the most crucial task for treating any disease. Liver disease can be inherited genetically or caused by a variety of subjects that damage the liver. Machine learning technique is broadly used in various grounds of science and technology. They have been giving out meaningful information. It also explores in creation and study of algorithms which can learn from data. Data mining in healthcare is an evolving field of high importance for providing diagnosis and a deeper understanding of medical data. To build an effective disease management strategy, large amount of data should be analyzed for the early detection of the disease, assessment of the severity and early prediction of adverse events. This will impede the progression of the disease, will improve the quality of life of the patients and will reduce the associated medical costs. The aim of this research paper is to present the state-of-the-art of the machine learning methodologies applied for the prediction of liver failure. The main objective of this research work is to find the best classification algorithm in terms of precision, accuracy, specificity and sensitivity. Therefore, the present investigation was done to determine the relative performance of four classification algorithms namely, Support Vector machine (SVM), Logistic Regression, Random Forest and Decision Tree algorithm based on the available downloaded Indian Liver Patient Dataset(ILPD",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/4aa378d45e10d8c5e96635e4e9d5c10d020f86df",
        "citation_count": 0
    },
    {
        "title": "Roux-lette at \u201cDischarge Me!\u201d: Reducing EHR Chart Burden with a Simple, Scalable, Clinician-Driven AI Approach",
        "abstract": "Healthcare providers spend a significant amount of time reading and synthesizing electronic health records (EHRs), negatively impacting patient outcomes and causing provider burnout. Traditional supervised machine learning approaches using large language models (LLMs) to summarize clinical text have struggled due to hallucinations and lack of relevant training data. Here, we present a novel, simplified solution for the \u201cDischarge Me!\u201d shared task. Our approach mimics human clinical workflow, using pre-trained LLMs to answer specific questions and summarize the answers obtained from discharge summaries and other EHR sections. This method (i) avoids hallucinations through hybrid-RAG/zero-shot contextualized prompting; (ii) requires no extensive training or fine-tuning; and (iii) is adaptable to various clinical tasks.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/4b1224ffa9922689e1fcc6eb483feafd7b91eaed",
        "citation_count": 1
    },
    {
        "title": "Application of Machine Learning in Healthcare: An Analysis",
        "abstract": "Health care field is facing a lot of challenges due to the huge volume of people need medical support. The pandemic situation has created a lot of challenges to the healthcare field. This paper analyses how advancement in machine learning can be best utilized in improving health care services. Machine learning techniques are based on the idea of how systems can learn from the already existing data and can work with minimal human supervision. Thus machine learning has huge scope in healthcare. Machine learning algorithms can be effectively utilized for disease prediction, disease detection, providing personalized healthcare etc. These models can effectively predict the presence of diseases and also helps in detecting the diseases at earlier stage itself. Both supervised and unsupervised algorithms will be helpful in this field. Personalized healthcare applications aim to provide patient oriented healthcare services. Machine learning in combination with internet of things technologies made the personalized health care possible. The data collected from wearable devices and sensors can be effectively processed using machine learning algorithms and effective predictions can leads to quality of life improvements. In this chapter authors studies some of the existing applications of machine learning in healthcare field. Authors also propose a model that will add value to the existing applications.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/4b4eb05c5ec977105fa95f90cb44baa6a4f7aa60",
        "citation_count": 5
    },
    {
        "title": "A Review on Efficient Breast Cancer Diagnosis System Using Artificial Intelligence Tools",
        "abstract": "Artificial intelligence, in contrast to the natural intelligence of humans and animals involving consciousness and emotion, is a machine that shows intelligence. Artificial intelligence is a total notion utilized in medical treatment to explain the avail, survey, impression, or understanding of aggregate medical data, of machine learning algorithms and software or artificial intelligence (AI). Particularly; AI is the capability of computer algorithms to approach conclusions based exclusively on input data. In the contemporary scenario, artificial intelligence (AI) is going to switch almost all the areas of the healthcare field. The need is to study the study carried out in this technology and detect and diminish error in health reports in medical field\" have specified considerable applications of AI. Lastly, with an abstract, this paper describes ten major applications of artificial intelligence in the clinical field. Artificial intelligence takes a good clinical judgment to improve patient performance. Various deep learning technologies are approved and experienced with breast cancer diagnosed and minimizing mistakes in the medical field. The AI builds analytical algorithms of different characteristics of patient data, which is useful to provide information about the patient, survival time and disease levels. Its execution will be for digital supervision of hospitals in subsequent years in order to enhance patient safety.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/4bd05fc881fb9b80509efdd7ac403b0c00d18948",
        "citation_count": 0
    },
    {
        "title": "Designing Medical Interactive Systems Via Assessment of Human Mental Workload",
        "abstract": "In clinical settings, Human-computer systems need to be designed in a way that medical errors are reduced and patient care is enhanced. Inspection methods are usually employed in HCI to assess usability of interactive systems. However, they do not consider the state of the operator while executing a task, the surrounding environment and the task demands. It is argued that assessing performance of operators is fundamental for designing optimal systems with which healthcare can be effectively delivered. The aim of our solution is to assess performance of operators employing the notion of Mental Workload (MWL) this being a construct believed to strongly correlate with performance. The proposal is to develop a model for MWL assessment using supervised machine learning. This model will be evaluated via user studies involving clinicians and operators interacting with a set of medical systems. Assessments of MWL will be compared and validated with objective indexes of performance such as error rate and task execution time.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/4c7d68d64239d95e000089d2f1fd21e648a9dae8",
        "citation_count": 34
    },
    {
        "title": "AI-Driven Fraud Detection in Healthcare Payments: Reducing Financial Risks in Claims and Billing",
        "abstract": "Comprising billions of yearly expenses and heavily stressing healthcare systems financially, healthcare fraud is a major issue. Apart from increasing expenses, false claims, billing mistakes, and identity theft compromise the quality of therapy received. Dependent on human audit & the rule-based systems, traditional fraud detection techniques sometimes finds it difficult to adapt with the times to meet the advancing strategies of the fraudsters. Artificial intelligence (AI) & the machine learning (ML) greatly change the recognition & avoidance of the healthcare fraud. AI-powered fraud detection solutions using big datasets highlight trends and anomalies human auditors would overlook. All, supervised and unsupervised algorithms, predictive analytics, natural language processing, and machine learning models provide very accurate real-time fraud detection. Methods including network analysis, deep learning, and anomaly detection help to uncover dubious claims and raise attention to variances before financial damages are compensated for. Recent developments indicate that AI-powered systems could greatly reduce false positives while simultaneously increasing fraud detection rates, therefore saving billions of unlawful payments. By means of AI-driven fraud prevention, not only accomplishes financial resource protection but also enhances confidence of healthcare systems. Still, long-term success challenges including data privacy concerns, model interpretability, and the need of constant model revisions demand attention. The results show that artificial intelligence changes payment security for healthcare not only as a tool but also as a transforming agent. Since its versatility ensures that detection systems grow proportionately as fraudsters create ever more sophisticated strategies, artificial intelligence is an essential tool in avoiding healthcare fraud.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/4d1a5238140ed2ba8f22931031a8eb02bd1e76a1",
        "citation_count": 0
    },
    {
        "title": "Health Sensor Data Analysis for a Hospital and Developing Countries",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/4dc356dd9a1e60e1ec329dbcedda4a4086ee1e35",
        "citation_count": 0
    },
    {
        "title": "Penerapan dan Manfaat Machine Learning di Rumah Sakit",
        "abstract": "Machine learning is a highly useful method for solving various problems, streamlining task execution, and making significant contributions in various fields, including the healthcare industry. For instance, within the realm of hospitals or healthcare, the use of machine learning enables doctors to swiftly diagnose heart diseases, reducing the time required for the diagnostic process. This technology also has the capability to learn autonomously without the need for continuous supervision. However, like any other technology, machine learning has its strengths and weaknesses. Strengths of machine learning include efficient problem-solving, rapid data analysis, and autonomous learning capabilities. However, weaknesses encompass susceptibility to biased training data, lack of interpretability in complex models, and potential challenges in handling unforeseen scenarios. Balancing these aspects is crucial for maximizing the benefits of machine learning across diverse applications.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/4dd0a9c5a2f0853c16f31d6cb58dd21e7477de1e",
        "citation_count": 0
    },
    {
        "title": "Respiratory Rate Prediction Algorithm based on Pulse Oximeter",
        "abstract": "Respiratory rate (RR) is a physiological parameter typically used to monitor patient status in clinical settings. The goal of the Respiratory Rate Prediction Project is to use supervised machine learning techniques to estimate a person\u2019s respiratory rate using real-time, continuous Photoplethysmogram (PPG) and Electrocardiogram (ECG) and oximeter data. In addition, it is also our goal to investigate the feasibility of using such data to improve diagnostic processes in healthcare. It consists of a series of studies of different algorithms for respiratory rate estimation from clinical data and is complemented by the provision of publicly available datasets and resources.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/4e23b4ffb29a92b9f0bc4db6d656174d8f1dc231",
        "citation_count": 3
    },
    {
        "title": "Intelligent Target Coverage in Wireless Sensor Networks with Adaptive Sensors",
        "abstract": "Day by day innovation in wireless communications and micro-technology has evolved in the development of wireless sensor networks. This technology has applications such as healthcare supervision, home security, battlefield surveillance and many more. However, due to the use of small batteries with low power this technology faces the issue of power and target monitoring. There is much research done to overcome these issues with the development of different architecture and algorithms. In this paper, a scheduling machine learning algorithm called adaptive learning automata algorithm(ALAA) is used. It provides an efficient scheduling technique. Such that each sensor node in the network has been equipped with learning automata, and with this, they can select their proper state at any given time. The state of the sensor is either active or sleep. For the experiment, different parameters are used to check the consistency of the algorithm to schedule the sensor node such that it can cover all the targets with the use of less power. The results obtained from the experiments show that the proposed algorithm is an efficient way to schedule the sensor nodes to monitor all the targets with use of less power. On the whole, this paper manages to achieve its goal by contributing to the related research on wireless sensor networks with a new design of a learning automata scheduling algorithm. The ability of this proposed algorithm to use the minimum number of sensors to be in active state verified to reduce the use of power in the network. Thus, achieving the goal by enhancing the lifetime of wireless sensor networks.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/4e46ee66cb35a25bb2cb70571e9317e55ec8022c",
        "citation_count": 11
    },
    {
        "title": "Survey: Big Data Application in Biomedical Research",
        "abstract": "In recent years, the emergence of diverse applications created a plethora of data and immense sources that can be applied in varying areas of the industry worldwide escalating its capabilities including biomedicine. Subsequently, analytical tools loomed to leverage the availability of massive data to analyze and elicit meaningful information to improve biomedical research and enhance healthcare systems. Algorithms applied in these analytical tools supplements the prognosis of diseases and personalized treatment of fatal diseases. This survey will evaluate algorithms used in bio medical research for personalized precision medicine, dissect the characteristics that made breakthrough in improving the efficiency of the analytical tool and identify the possible applicability in other diseases. It will focus on the machine learning and deep learning algorithms, both supervised and unsupervised that is applied in terminal diseases.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/4e782caa179ba92d3f53a2841d2aa27f72b2113b",
        "citation_count": 2
    },
    {
        "title": "Using machine learning to improve patient outcomes in a mobile health system for persons with diabetes",
        "abstract": "Introduction \nmHealth or mobile health refers to the practice of medicine and public health supported by mobile phones and wireless devices. Over the past decade, many mHealth systems have been developed to provide a range of services targeting a wide range of health conditions. Mobile health has a tremendous potential to improve access to healthcare in developing countries due to mobile penetration rates. MediNet, a mobile health system developed at the University of the West Indies (Mohan and Sultan, 2010), provides remote monitoring services for persons suffering from diabetes and cardiovascular disease. In MediNet, data flows from measuring devices (e.g., blood glucose meter and blood pressure monitor) in a person\u2019s home or work environment to his/her mobile phone using Bluetooth. It then travels through a wireless telecommunications network to the Internet where it is stored securely on a Web server. The system successfully underwent small-scale testing in Trinidad and Tobago in 2009-2010. \n \nFeedback in a Mobile Health System \n \nIn a remote monitoring system such as MediNet, the data collected by the system is used to provide feedback to the person being monitored based on a set of rules. For example, if the person's blood glucose or blood pressure level is \u201ctoo high\u201d or \u201ctoo low\u201d, the system recommends certain courses of action to the person. If the person\u2019s blood glucose level is still outside the range after a certain timeframe, a message is sent to the person\u2019s health care provider so that an appropriate intervention can be made. In building the system, the values for \"too high\" and \"too low\" were assigned by a medical doctor based on medical practice and were applied across the board to all the patients participating in the study. However, results from the testing of MediNet indicate that the threshold levels for each person may differ for various reasons and may often differ by wide margins. Analysis of test data from the MediNet system also revealed some interesting insights. For example, the blood glucose levels of certain persons were often higher on weekends and on public holidays (Sultan and Mohan, 2013). \n \nData Stored in a Mobile Health System \n \nA mobile health system such as MediNet can generate and store a considerable amount of data over time. For example, persons with diabetes are expected to take two measurements each day; each measurement consists of a single value representing the person\u2019s blood glucose level. The system also records a person\u2019s blood pressure; each measurement consists of three values representing the systolic, diastolic, and pulse values. Other mHealth systems can generate even larger amounts of data. For example, Camara et al (2017) developed a system to screen persons for obstructive sleep apnea; this system collects data from a number of sources including a microphone, a pulse oximeter, and built-in smartphone sensors. Over time, the data in a mobile health system can become so large that it is termed \u201cbig data\u201d. It has been suggested that the application of big data analysis techniques to mHealth (e.g., machine learning) can bring value to patient outcomes (Weiler, 2016). \n \nPredictive Analysis Using Machine Learning \n \nWe are presently investigating how machine learning techniques can be used to analyze data stored in a mobile health monitoring system to improve patient outcomes. In particular, supervised learning is being used where data over a certain period (e.g., a year) together with additional input (e.g., whether additional treatment or a visit to a doctor was required) is used to train the system. When local highs or lows occur, the system does not go into \u201cemergency mode\u201d since it would have learned that such variations in the past were not cause for concern. If indeed, for a particular person, the highs or lows resulted in emergency treatment or a visit to a doctor, the system can advise the person beforehand to follow a certain diet or take appropriate exercise. The system is also trained with data obtained during weekends and public holidays. Based on the training data, the system can make predictions which can guide the feedback provided to users. For example, knowing that a particular person is not likely to submit readings over a weekend or knowing that a person\u2019s blood glucose may show certain patterns over a holiday period, the system can make appropriate recommendations before the event occurs. One caveat of this research is that the techniques being developed cannot be applied to real data until the mobile health system has been used for a sufficient period of time to generate the data which will be used to train and test the machine learning algorithms. \n \nReferences \n \nCamara, M.A., Castillo, Y., Blanco-Almazan, D., Estrada, L., and Raimon, J. (2017). mHealth Tools for Monitoring Obstructive Sleep Apnea Patients at Home: Proof-of-Concept. In Proc. 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC 2017), Seogwipo, South Korea, July 11-15, 2017, pp. 1555-1558. \nMohan, P., and Sultan, S. (2010). Staying Connected in a Mobile Healthcare System: Experiences from the MediNet Project. International Journal on Human Computer Interaction, 2, 6. \nSultan, S., and Mohan, P. (2013). Transforming Usage Data into a Sustainable Mobile Health Solution. Electronic Markets, 23, 1, pp. 63-72. \nWeiler A. (2016). mHealth and Big Data Will Bring Meaning and Value to Patient-reported Outcomes, mHealth, 2, 2.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/4e97b209a000a53f6ebddbb28d74d07520940f3e",
        "citation_count": 0
    },
    {
        "title": "Classification of patients with cardiac amyloidosis using machine learning models on Italian electronic clinical health records*",
        "abstract": "Amyloidosis refers to a range of medical conditions in which misshapen proteins accumulate in various organs and tissues, forming insoluble fibrils. Cardiac amyloidosis is frequently linked to the buildup of misfolded transthyretin (TTR) or immunoglobulin light chains (AL). Delayed diagnosis, due to lack of disease awareness, results in a poor prognosis, especially in patients with AL amyloidosis. Early identification is therefore a key factor to improve patient outcomes. This study investigates the use of supervised machine-learning algorithms to support clinicians in classifying amyloidosis and control subjects. The aim of this work is to foster model interpretability reporting the most important risk factors in predicting the presence of cardiac amyloidosis. We analyzed electronic health records (EHRs) of 418 participants acquired in a time window of 12 years as part of a case-control study conducted in Fondazione Toscana Gabriele Monasterio (Italy) clinical practice. This work paves the way for the creation of digital health solutions that can aid in amyloidosis screening. The effective handling, analysis, and interpretation of these solutions can have a transformative effect on modern healthcare, offering new opportunities for improved patient care.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/4ee3f606e5453ca419575adaf7a73ea05dbb446c",
        "citation_count": 0
    },
    {
        "title": "Comparison of Performance of Classification Algorithms Using Standard Deviation-based Feature Selection in Cyber Attack Datasets",
        "abstract": "Supervised machine learning techniques are commonly used in many areas like finance, education, healthcare, engineering, etc. because of their ability to learn from past data. However, such techniques can be very slow if the dataset is high-dimensional, and also irrelevant features may reduce classification success. Therefore, feature selection or feature reduction techniques are commonly used to overcome the mentioned issues. On the other hand, information security for both people and networks is crucial, and it must be secured without wasting the time. Hence, feature selection approaches that can make the algorithms faster without reducing the classification success are needed. In this study, we compare both the classification success and run-time performance of state-of-the-art classification algorithms using standard deviation-based feature selection in the aspect of security datasets. For this purpose, we applied standard deviation-based feature selection to KDD Cup 99 and Phishing Legitimate datasets for selecting the most relevant features, and then we run the selected classification algorithms on the datasets to compare the results. According to the obtained results, while the classification success of all algorithms is satisfying Decision Tree (DT) was the best one among others. On the other hand, while Decision Tree, k Nearest Neighbors, and Na\u00efve Bayes (BN) were sufficiently fast, Support Vector Machine (SVM) and Artificial Neural Networks (ANN or NN) were too slow.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/4efa0bf51a4ead0718788f2d24db3a94c298c1e1",
        "citation_count": 3
    },
    {
        "title": "Demystifying Supervised Learning in Healthcare 4.0: A New Reality of Transforming Diagnostic Medicine",
        "abstract": "The global healthcare sector continues to grow rapidly and is reflected as one of the fastest-growing sectors in the fourth industrial revolution (4.0). The majority of the healthcare industry still uses labor-intensive, time-consuming, and error-prone traditional, manual, and manpower-based methods. This review addresses the current paradigm, the potential for new scientific discoveries, the technological state of preparation, the potential for supervised machine learning (SML) prospects in various healthcare sectors, and ethical issues. The effectiveness and potential for innovation of disease diagnosis, personalized medicine, clinical trials, non-invasive image analysis, drug discovery, patient care services, remote patient monitoring, hospital data, and nanotechnology in various learning-based automation in healthcare along with the requirement for explainable artificial intelligence (AI) in healthcare are evaluated. In order to understand the potential architecture of non-invasive treatment, a thorough study of medical imaging analysis from a technical point of view is presented. This study also represents new thinking and developments that will push the boundaries and increase the opportunity for healthcare through AI and SML in the near future. Nowadays, SML-based applications require a lot of data quality awareness as healthcare is data-heavy, and knowledge management is paramount. Nowadays, SML in biomedical and healthcare developments needs skills, quality data consciousness for data-intensive study, and a knowledge-centric health management system. As a result, the merits, demerits, and precautions need to take ethics and the other effects of AI and SML into consideration. The overall insight in this paper will help researchers in academia and industry to understand and address the future research that needs to be discussed on SML in the healthcare and biomedical sectors.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/4f67cc883f007614fbd42dd4948b466c265e2938",
        "citation_count": 95
    },
    {
        "title": "Analyzing Perceived Intentions of Public Health-Related Communication on Twitter",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/4f7ddee41418a6c1ca7dd7200ed1b2a6c4dd722a",
        "citation_count": 6
    },
    {
        "title": "HUMAN SOUND-BASED DISEASE DETECTION SYSTEM USING MACHINE LEARNING",
        "abstract": ": : A human sound-based disease detecting system leveraging machine learning involves collecting diverse audio samples capturing specific human sounds related to diseases or health conditions. Through signal processing and feature extraction methods like spectrograms or MFCCs, meaningful features are derived from these audio signals. Supervised machine learning models, such as CNNs or RNNs, are trained on these extracted features to learn patterns and correlations between audio characteristics and particular diseases. After validation and performance assessment, the trained model is integrated into an application or system to analyze incoming audio input and predict potential diseases or health issues, and ethical use of health data remain pivotal throughout the development process. Employing signal processing techniques and feature extraction methods like spectrograms or MFCCs, the system abstracts meaningful patterns from the audio data. Through supervised learning algorithms such as CNNs or RNNs, the model learns to correlate these sound features with specific diseases during the training phase. Validation and fine-tuning ensure its accuracy and generalizability, following which it gets integrated into an interface for real-time audio input processing and disease prediction. Ethical considerations, data privacy, and collaboration among medical professionals and AI experts are essential throughout the development to responsibly deploy this system, potentially enabling early disease detection and remote healthcare accessibility.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/4f860c6727d1605e33108564d88ed16b26565f09",
        "citation_count": 0
    },
    {
        "title": "Accuracy-Rejection Curves (ARCs) for Comparing Classification Methods with a Reject Option",
        "abstract": "Data extracted from microarrays are now considered an important source of knowledge about various diseases. Several studies based on microarray data and the use of receiver operating characteristics (ROC) graphs have compared supervised machine learning approaches. These comparisons are based on classification schemes in which all samples are classified, regardless of the degree of confidence associated with the classification of a particular sample on the basis of a given classifier. In the domain of healthcare, it is safer to refrain from classifying a sample if the confidence assigned to the classification is not high enough, rather than classifying all samples even if confidence is low. We describe an approach in which the performance of different classifiers is compared, with the possibility of rejection, based on several reject areas. Using a tradeoff between accuracy and rejection, we propose the use of accuracy-rejection curves (ARCs) and three types of relationship between ARCs for comparisons of the ARCs of two classifiers. Empirical results based on purely synthetic data, semi-synthetic data (generated from real data obtained from patients) and public microarray data for binary classification problems demonstrate the efficacy of this method.",
        "year": 2009,
        "url": "https://www.semanticscholar.org/paper/4fbba1c182448ffd89babf81c88d8bec6b552525",
        "citation_count": 117
    },
    {
        "title": "For Acute Pancreatitis using Supervised Machine Learning Algorithms",
        "abstract": "The data present in healthcare industry is very huge and delicate which requires to be managed watchfully. There are multiple fatal diseases which grow rapidly all over the world pancreatitis is one among them. Medical professionals want a reliable prediction system to diagnose Pancreatitis. Getting useful information out of the data which has been examined using diverse perspective and various machine learning methods and grouping the required information is a bit difficult task. When various data mining methods are applied on a huge and accessible data which will definitely provide us with the required information to the users. Pancreatitis contributes to Infection, Kidney failure, Breathing problem, Diabetes, Malnutrition, Pancreatic cancer. So, mining the Pancreatitis data in efficient way is a crucial concern. An outcome feature has to be predicted using a dataset where the outcome may contain only two constants that is either 1 or 0. 0 refers to the sufferer having Acute Pancreatitis and 1 refers to the sufferer may have chronic pancreatitis. Thus, an outcome feature with exemplary accuracy has to be predicted using the test dataset and classification algorithms. In order to realize this data is very necessary and then diverse classification techniques can be experimented. Then a finest model can be preferred which gives the maximum accuracy among all others.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/50068b25d774e4abbb18a3d00cca0c3e7d0ef06d",
        "citation_count": 0
    },
    {
        "title": "Comparative Study of Breast Cancer Detection Using Histopathology Images",
        "abstract": "Breast cancer continues to be a major health issue, necessitating efficient and accurate diagnostic methods for early detection. Deep learning approaches have recently showed significant potential in improving the accuracy and efficiency of breast cancer detection, notably in histopathology image processing. This review provides a thorough analysis of existing research on deep and machine-learning applications in breast cancer detection, highlighting the diverse diagnostic setups utilized in various studies. Deep learning is particularly promising in the detection of breast cancer because of its ability to provide accurate, automated, and early detection of potential malignancies, ultimately contributing to better patient outcomes and more effective healthcare practices as a result. The paper explores the range of techniques employed, with a specific focus on different classifiers that works on supervised learning.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/500bc1eb0215af73a05af500e6a82ef16c7dcb39",
        "citation_count": 0
    },
    {
        "title": "Comparative Analysis of Feature Selection Based Machine Learning Methods for Heart Disease Prediction",
        "abstract": "Smart healthcare application is an advanced field in the era of Internet of Things (IoT) technology. Digitization in healthcare focuses on predicting the health status of a patient with the aid of IoT based application. Machine learning algorithms can be applied to develop a decision framework to investigate whether an individual is likely to have heart disease or not. In the proposed study, machine learning algorithms are used in the evaluation of heart disease prediction framework. Feature selection (FS) method plays a vital role in improving the quality of prediction. Proposed prediction framework is analyzed using three important feature selection methods (six techniques) and seven supervised machine learning algorithms. Comparative performance analysis of machine learning algorithm is evaluated using most significant parameter selected using feature selection. The experiments are carried out using data set retrieved from Cleveland data set from UCI repository. Results show that Random Forest, a hybrid machine learning algorithm with LASSO regularization method for feature selection approach gives the best performance. Each algorithm\u2019s performance is measured using accuracy, precision, recall and specificity. Feature selection has an impact on classifier\u2019s accuracy and data storage. This approach can be further used in building IoT based heart disease decision support system with minimum number of sensor nodes to record the health parameters. Medical experts can diagnose the heart patient competently with the help of proposed method.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/501920e0279a4e8916e5e4272ac3dea454b1c748",
        "citation_count": 0
    },
    {
        "title": "Cardiac Disease Prediction using Machine Learning Algorithms",
        "abstract": "The human heart is an important bodily organ. The death rate from heart disease is rising steadily in modern times. Due to several risk factors, detecting cardiovascular disease is extremely challenging such as abnormal pulse rate, high blood pressure, and many other factors. The healthcare sector now faces a problem in predicting cardiac disease. As a result, finding a trustworthy, accurate, and useful method to diagnose these illnesses in time for effective therapy is necessary. Large datasets generated by the healthcare sector employing machine learning algorithms, predictions and decision-making have been accomplished. The algorithms used are based on supervised learning. By using three algorithms of Machine Learning i.e., K-Nearest Neighbor, Decision Tree, Support Vector Machine and some of the results have been evaluated such as predicting the accuracy, confusion matrix, precision, and recall.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/50314c1fc1c4ab6ecdffe95f8a713a2817db3c45",
        "citation_count": 3
    },
    {
        "title": "Semantic Data Types in Machine Learning from Healthcare Data",
        "abstract": "Healthcare is particularly rich in semantic information and background knowledge describing data. This paper discusses a number of semantic data types that can be found in healthcare data, presents how the semantics can be extracted from existing sources including the Unified Medical Language System (UMLS), discusses how the semantics can be used in both supervised and unsupervised learning, and presents an example rule learning system that implements several of these types. Results from three example applications in the healthcare domain are used to further exemplify semantic data types.",
        "year": 2012,
        "url": "https://www.semanticscholar.org/paper/505fcb5090183b50ae1fea5ac967f3c07cc78f39",
        "citation_count": 9
    },
    {
        "title": "Optimized Heart Failure Prediction using Support Vector Machine Algorithms",
        "abstract": "Heart failure remains a leading cause of death globally, highlighting the importance of early intervention and accurate risk assessment. This research investigates the potential of Support Vector Machine (SVM) models, a supervised learning technique, in predicting heart failure. By utilizing a large dataset of clinical characteristics, the study demonstrates the SVM model\u2019s ability to accurately predict heart disease with a classification accuracy of 87.53%. The research highlights the importance of integrating multimodal data sources, including clinical biomarkers, imaging, lifestyle, and demographic information, to enhance prediction accuracy and enable preventive healthcare interventions. Wearable devices, the Internet of Things, and Electronic Health Records (EHRs) contribute to the availability of rich, longitudinal data streams for real-time monitoring and prediction. However, developing reliable and interpretable models for clinical use remains a challenge. Future research should focus on improving model generalization, data accuracy, and interpretability. By addressing these challenges and utilizing real-time data, machine learning and deep learning techniques can significantly advance predictive healthcare, reducing morbidity and mortality, and improving patient outcomes. This research highlights the promise of SVM models in heart failure prediction and underscores the continued need for research to maximize their practical application.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/50b0c34c17094be3578f92bb19eeb14e3b101f9e",
        "citation_count": 0
    },
    {
        "title": "Novel path: FINDing the way forward in screening for atrial fibrillation",
        "abstract": "Despite many advances in healthcare, mortality and morbidity related to undetected and hence untreated atrial fibrillation (AF) remain a major challenge. To reduce downstream consequences of AF, opportunistic screening for AF is recommended in persons older than 65 years, and systematic, invitationbased screening should be considered in older individuals (aged \u226575) or those at high risk. The prevalence of AF rises sharply with age, additional cardiovascular risk factors and cardiovascular disease. In line with this, large studies performed in younger individuals with low burden of comorbidities have shown a low yield of screening using consumer devices. Even though recommended in guidelines, yields have also been disappointingly low in opportunistic screening in older persons attending their general practitioner. This low yield may partly be due to insufficient monitoring for the arrhythmia since studies using intermittent or prolonged heart rhythm monitoring have demonstrated the large potential of AF screening. 5 However, even more important than identifying the appropriate screening methodology may be selecting the right individuals for screening. Risk scores have been developed to determine the risks for incident AF but are rarely used in the clinical setting due to their complexity, long time perspective and low discriminatory abilities. Most screening studies have used crude cutoffs to select individuals who might benefit from screening, commonly high age, enhanced with biomarkers or cardiovascular risk factors (figure 1). Despite these efforts, screening detects AF only in a fraction of those screened. Hence, a method to better identify individuals who would benefit from screening is greatly needed. With the ongoing digitalisation of healthcare and increased use of digital devices, more data are becoming available that might be used to provide better decisionmaking tools in addtion to more advanced statistical methods that can process the data. In the Future Innovations inNovel Detection of Atrial Fibrillation (FINDAF) study by Dr Nadarajah, electronic health record entries from more than two million patients in UK primary care between 1998 and 2018 were used to predict the risk of developing AF within 6 months. Data on age, sex, ethnicity and over 70 comorbidities were fed into a supervised machine learning model using random samples split into training and test sets. The population studied was quite young and healthy at an average age of 50 years, and a low proportion developed AF (0.4%). Still, the model classified approximately 20% of individuals as high risk, with the risk of AF in those being 20fold higher compared with individuals classified as low risk. Overall, more than 20% of individuals who developed AF and approximately 4% of all individuals classified as high risk were younger than 65 years old, and the vast majority of these had a CHA2DS2VASc score of at least 1. The model outperformed prior risk scores used to identify persons at risk of AF or stroke following AF diagnosis. At the optimal cutoff, the sensitivity was 78% and the specificity was 73%. The authors point to the simplicity of the input data as a strength because of the implied feasibility; hence, the algorithm can easily be incorporated into general practice in the UK and elsewhere without spending resources on measurement of biomarkers. Studies to externally validate and prospectively test the methodology are under way and necessary. Another advantage is that the algorithm uses a short time to predict AF incidence, making it potentially useful for screening purposes. Certainly, patients developing AF over a course of only 6 months may have suffered from it before but remained at a subclinical stage, making them ideal candidates for AF screening. In addition, the model seems to improve the identification of young individuals at risk of AF. The latter may be important as asymptomatic AF in the young, although being rare is not unthinkable, and stroke rates have reportedly increased more in this age group than in older people. As the authors acknowledge, the study is limited by using International Classification of Diseases (ICD)coded outcomes which cannot necessarily be used to infer yield of screening for an asymptomatic condition. This may partly explain the relatively large proportion of young patients with AF compared with screening studies, as older individuals may remain asymptomatic and may not seek healthcare. On the other hand, the study confirmed that age is by far the most important predictor of AF with limited impact of additional \u2018oldfashioned\u2019 risk factors. In the future, biomarkers such as natriuretic peptides or left atrial anatomy or function may become more easily measured and available for incorporation into screening algorithms. Consumerdriven screening and heart rhythm monitoring are increasingly being implemented in society. This may have contributed to why randomised trials failed to demonstrate significant yield by",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/50c81ede189273a8bca20d4a686db01cc375e431",
        "citation_count": 1
    },
    {
        "title": "Improved Prediction of Diabetes Mellitus using Machine Learning Based Approach",
        "abstract": "The diabetes is one of the most commonly occurring chronic diseases in human being. Statistical models are availabel for prediction of diabetes but these provide poor performance. This article proposed machine learning based model for prediction of diabetes disease. Three supervised machine learning algorithms namely K-NN, Linear SVM and Random Forest have been chosen for diabetes prediction for early diagnosis. The area under the curve and accuracy of each of these models have been obtained using PIMA Indian Diabetes dataset from UCI repository. The comparative results demonstrate that among these three algorithms random forest is the best model in terms of accuracy of 78.57 and AUC of 95.08 for diabetes risk prediction. The contribution of this article will help the healthcare professionals for the early prediction of the disease and taking appropriate treatment. The proposed approach can be applied for detection of other diseases.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/50e0dd1bcbf77f7e27ce401ce515ff53e7e7efe1",
        "citation_count": 8
    },
    {
        "title": "Empowering big data analytics through machine learning: Applications, challenges, and future directions",
        "abstract": "Abstract. This paper explores the transformative role of machine learning (ML) methodologies in big data analytics, highlighting supervised learning, unsupervised learning, and deep neural networks' contributions to diverse sectors. Supervised learning, with regression analysis at its core, provides accurate forecasting in finance and healthcare by modeling relationships between variables. Unsupervised learning, through techniques like k-means and hierarchical clustering, uncovers patterns within data, offering insights for retail and biological analysis. Deep learning, particularly Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM), excel in complex tasks like image recognition and sequential data processing, driving advances in fields from autonomous driving to language translation. The application of ML in enhancing business intelligence, innovating fintech, and advancing healthcare analytics is discussed, alongside the challenges of data privacy, security, ethical considerations, and the skills gap. This paper underscores the need for advanced cryptographic techniques, bias mitigation strategies, and education to address these challenges. It concludes by emphasizing the importance of interdisciplinary education and AI advancements in bridging the skills gap, ensuring the ethical use of ML, and making these technologies accessible for future innovations.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/50e93ba72b4a6090643f51e20f719cc198f5bb29",
        "citation_count": 0
    },
    {
        "title": "Learning Algorithms Made Simple",
        "abstract": "In this paper, we discuss learning algorithms and their importance in different types of applications which includes training to identify important patterns and features in a straightforward, easy-to-understand manner. We will review the main concepts of artificial intelligence (AI), machine learning (ML), deep learning (DL), and hybrid models. Some important subsets of Machine Learning algorithms such as supervised, unsupervised, and reinforcement learning are also discussed in this paper. These techniques can be used for some important tasks like prediction, classification, and segmentation. Convolutional Neural Networks (CNNs) are used for image and video processing and many more applications. We dive into the architecture of CNNs and how to integrate CNNs with ML algorithms to build hybrid models. This paper explores the vulnerability of learning algorithms to noise, leading to misclassification. We further discuss the integration of learning algorithms with Large Language Models (LLM) to generate coherent responses applicable to many domains such as healthcare, marketing, and finance by learning important patterns from large volumes of data. Furthermore, we discuss the next generation of learning algorithms and how we may have an unified Adaptive and Dynamic Network to perform important tasks. Overall, this article provides brief overview of learning algorithms, exploring their current state, applications and future direction.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5185926230dd025e5389f7330cea0d370c2d5936",
        "citation_count": 0
    },
    {
        "title": "Random Forest Ensemble Machine Learning Model for Early Detection and Prediction of Weight Category",
        "abstract": "The number of insurgents in our nation today is significantly rising each day, and the majority of those affected are living as Internally Displayed Persons (IDP) in various IDP camps. These people experience a variety of health problems as a result of numerous factors. Due to financial difficulties and a lack of accessibility to healthcare facilities and medical professionals, these health risk factors may occasionally go undetected for long periods. BMI excesses, such as those in the underweight, overweight, and obese categories, are linked to several health issues, including low birth weight, poor quality of life, diabetes mellitus, cardiovascular diseases, and higher mortality. In the context of this paper, identifying the health status of IDPs depends critically on human body weight. For people living in IDP camps, early detection of the weight categories like underweight, overweight, and obese people is crucial because if not, they will be an early death or other health complications. To reduce mortality rates and other health complications that may result from improper and lately identifying underweight, overweight, and obese members in IDP camps, the researcher collect Datasets from the IDP camps, trained, and developed a Random Forest ensemble model of supervised learning that will aids the medical practitioner in early detection and prediction of the weight category of IDPs. After hyper-parameter tuning and feature selection, the Random forest machine learning algorithms identify three significant parameters from the dataset's original 10 parameters to use as the model parameter. The highest accuracy obtained was 92% on the test dataset and 96% on the training dataset for the Random Forest (RF) Classifier using 3 features, while the accuracy of 83% was obtained on the test dataset and 87% on the training dataset for the RF Classifier using 10 features.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/519664a59a56f0f9f884f589bdb4b16d1e83e3b8",
        "citation_count": 3
    },
    {
        "title": "Medicare Fraud Detection Using Machine Learning Methods",
        "abstract": "Healthcare is an integral component in people\u2019s lives, especially for the rising elderly population, and must be affordable. Medicare is one such healthcare program. Claims fraud is a major contributor to increased healthcare costs, but its impact can be lessened through fraud detection. In this paper, we compare several machine learning methods to detect Medicare fraud. We perform a comparative study with supervised, unsupervised, and hybrid machine learning approaches using four performance metrics and class imbalance reduction via oversampling and an 80-20 undersampling method. We group the 2015 Medicare data into provider types, with fraud labels from the List of Excluded Individuals/Entities database. Our results show that the successful detection of fraudulent providers is possible, with the 80-20 sampling method demonstrating the best performance across the learners. Furthermore, supervised methods performed better than unsupervised or hybrid methods, but these results varied based on the class imbalance sampling technique and provider type.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/521bc9c1ce7f229526022e8b1fd8d8c2ee194349",
        "citation_count": 75
    },
    {
        "title": "A Comparative Study of Selected Supervised Machine Learning Algorithms for Detecting Child Mortality",
        "abstract": "The World Health Organization (WHO) defines under-five mortality rate as the probability that a child born in a specified year will die before reaching the age of five. It is a key metric for determining the quality of a country's healthcare system.In many parts of the world, under-five mortality is still a big concern, according to the World Health Organization (WHO). Under-five mortality has been a major issue in emerging nations. Even though the number of childhood deaths worldwide has significantly decreased, under-five mortality is still a significant public health concern in Nigeria. Nigeria now has the second-highest number of under-five deaths globally, after India, and the highest recorded number of under-five deaths in Africa (WHO, 2022). In Nigeria, around one million children under the age of five pass away each year, with over 60% of these deaths taking place between the ages of one and fifty-nine. According to data from the Nigeria Demographic and Health Surveys (NDHS), the under-five mortality rate increased from 157 per 1000 live births in 2008 to 138.8 per 1000 live births in 2020. This showed that the rate is still high, and the Millennium Development Goal (MDG) calls for reducing under-five mortality to 25 per 1,000 live births by 2030. The study's precise goals are to use supervised machine learning classification algorithms to predict mortality among children under five using nationally representative data on children under five and the specific objectives are, to predict under five mortality using machine learning classification models,to compare the performance of the supervised machine learning Classification models and lastly to apply the study's conclusions to improve and enhance relevant government policies and intervention plans. The study utilized secondary data from the 2018 Nigeria demographic and health survey data (NDHS). The 2018 NDHS is a nationally probability sample survey with approximately 42,000 households (NDHS 2018). The unit of analysis include children under-five years with total sample size of 33924 selected from 1389 clusters across Nigeria. The (2018 NDHS) dataset was downloaded from www.dhsprogram.com website, SPSS version 23 was used to open the data set and R programming Language is used to perform data analysis and processing. In this study, the outcome\u201d variable was under-five \u201cmortality measured as a binary outcome, under-five mortality measured as being alive (coded as 0) or dead (coded as 1)\u201d.Twenty seven(27)predictors (features) used in this study are mother\u2019s age at birth, highest educational level, mother\u2019s body mass index (BMI), Currently breastfeeding, Child alive, whether the child was wanted, sex of the child, birth order, child is twin, age in five years, given child anything other than breast, Birth weight in kg, Current age of child, Size of child at birth, source of drinking water, toilet facility, household wealth index, marital status, place of residence type, region, Native language ,religion, antenatal care visit, Delivery by caesarean, place of delivery, covered by health insurance and Number of antenatal care visit. The study used 2018 demographic and health survey data to investigate the factors linked to under-five mortality in Nigeria. Four distinct classification techniques for supervised machine learning were compare. Support Vector Machine (SVM) and Na\u00efve Bayes emerged as the top performers among the four evaluated models based on their accuracy followed by Artificial Neural Network and lastly Linear Discriminant Analysis(LDA) models with accuracy values reaching 62.48%. This indicates their strong ability to correctly identify cases where a child is not alive while maintaining a moderate level of sensitivity 62.74% for detecting cases where a child is alive and Lastly Support vector machine model outperformed all other models by achieving perfect scores across all metrics, suggesting that it can accurately classify every instance in the dataset",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/527949de761cf22e7bc92aa8bda1194cccb735b0",
        "citation_count": 0
    },
    {
        "title": "Design and Experimentation of Causal Relationship Discovery among Features of Healthcare Datasets",
        "abstract": "Causal relationships in a data play vital role in decision making. Identification of causal association in data is one of the important areas of research in data analytics. Simple correlations between data variables reveal the degree of linear relationship. Partial correlation explains the association between two variables within the control of other related variables. Partial association test explains the causality in data. In this paper a couple of causal relationship discovery strategies are proposed using the design of partial association tree that makes use of partial association test among variables. These decision trees are different from normal decision trees in terms of construction, scalability, interpretability and the ability of identifying causality in data. Normal Decision Trees are supervised machine learning approach to classify data based on a labeled attribute values. Variants of partial association trees are constructed as a part of analytics on a number of healthcare datasets. The applicability of design variants are carefully analyzed through this experimentation. In the above said experimentation it is found that the causation in data is not existed in data in some situations and sometimes the existing causality cannot be extracted where low associated dimensions are involved in data and hiding the underlying causality. One of the variants of proposed algorithms which was named dimensionality reduced partial association tree, did well in extracting causal association in case of a hidden causality in data.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/52dce4c47e6cb2241583aab604a5e87ac9fd080f",
        "citation_count": 0
    },
    {
        "title": "NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning",
        "abstract": "Deployment of machine learning models in real high-risk settings (e.g. healthcare) often depends not only on the model's accuracy but also on its fairness, robustness, and interpretability. Generalized Additive Models (GAMs) are a class of interpretable models with a long history of use in these high-risk domains, but they lack desirable features of deep learning such as differentiability and scalability. In this work, we propose a neural GAM (NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that scale well and perform better than other GAMs on large datasets, while remaining interpretable compared to other ensemble and deep learning models. We demonstrate that our models find interesting patterns in the data. Lastly, we show that we improve model accuracy via self-supervised pre-training, an improvement that is not possible for non-differentiable GAMs.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/531a8c8455ffee00fa9ae68fd4bfe3f680f824f2",
        "citation_count": 73
    },
    {
        "title": "Study of PET Image Classification Methods to the Preliminary Diagnosis of Alzheimer's Disease",
        "abstract": "Thailand has been undergoing a transition into a completely developed elderly society. The sign is becoming more apparent in the last few years, when a ratio between the number of children and mature adults has been dramatically decreasing. In additional to prevailing measures the government has to take, healthcare service for elderly people has to be readily prepared. Among diseases from which the elderly people are suffered are high blood pressure, high cholesterol and dementia. Age related dementia are gradually developed. Alzheimer's disease is however another more serious type of dementia that often drastically affect not only the patient but also their caretaker. Early diagnosis of the symptom could well enable therapeutic measures that improve their quality of life. This can be done in several ways, e.g., by medical survey and medical imaging. This paper therefore presents a robust PET image classification methods for diagnosing Alzheimer's disease in a samples drawn from Thai population. The proposed process adopted K-means clustering and Gabor Wavelet for brain segmentation and image feature extraction, respectively. To reduce the dimensions of data involved, only mean and standard deviation of pixels were extracted as features. The disease was finally classified by using a supervised machine learning in turn. Specifically, four classification methods were considered, i.e., Eigenface, Support Vector Machine, Convolutional Neural Network and proposed method. The experimental results indicated the accuracy of proposed method was up to 87%. It was appropriate to identify Alzheimer's patients from normal controls and the proposed SVM outperformed the rest.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/532a92de5a0da16a76cdd6bb8ae5dc29205b952e",
        "citation_count": 0
    },
    {
        "title": "Triplet-based Domain Adaptation (Triple-DARE) for Lab-to-field Human Context Recognition",
        "abstract": "Human Context Recognition (HCR) from smart-phone sensor data is an essential task in Context-Aware (CA) systems including those targeting healthcare and security. Two types of smartphone HCR studies (and datasets) have become popular for training HCR models: a) scripted and b) Unscripted/In-the-wild. Supervised machine learning HCR models can achieve good performance on scripted datasets due to their high quality labels but such models generalize poorly to in-the-wild datasets which are more representative of real-world scenarios. In-the-wild datasets are often imbalanced, have missing or wrong labels, with a diversity of phone placements and smartphone models. Lab-to-field approaches try to train HCR models to learn a robust data representation from a high-fidelity, scripted dataset that is used to improve performance on noisy in-the-wild datasets that have similar labels without having to incur the high expense of gathering high-quality labeled dataset. In this paper, leveraging coincident datasets with the same HCR labels collected in separate scripted and unscripted studies, we propose Triplet-based Domain Adaptation for context REcognition (Triple-DARE), a novel lab-to-field neural networks method with three key components: 1) a domain alignment loss to learn domain-invariant embeddings, 2) a classification loss to maintain task-discriminative features, 3) a joint fusion triplet loss designed to increase intra-class compactness and inter-class separation in the embedding space of multi-labeled datasets. In rigorous evaluation, Triple-DARE improved on the F1-score and classification accuracy of state-of-the-art HCR baselines by 6.3% and 4.5%, respectively, and on HCR models with no adaptation by 44.6% and 10.7%, respectively.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/532ee34b1dc1aa5576f38d7cb11e86f3d925c344",
        "citation_count": 3
    },
    {
        "title": "Predicting Extravascular Hemolysis in Paroxysmal Nocturnal Hemoglobinuria",
        "abstract": "\n \n Introduction\n Paroxysmal Nocturnal Hemoglobinuria (PNH) is a life-threatening blood disorder characterized by the destruction of red blood cells due to complement system dysregulation. The advent of C5 complement inhibitors has markedly improved the outlook for PNH patients by mitigating intravascular hemolytic crises and thrombotic events. However, many patients undergoing C5-inhibitor treatment experience C3-mediated extravascular hemolysis (EVH), which can lead to transfusion dependence, lower quality of life, and poorer health outcomes. The development of proximal complement inhibitors has heightened the need to identify patients at high risk for EVH resulting from C5 inhibitor therapy. Predictive models that identify these high-risk PNH patients could enable personalized, physician-supervised treatment selection, improving clinical outcomes and reducing healthcare costs. We describe a machine learning model, trained on demographic, laboratory, and Next-Generation Sequencing (NGS) data, designed to predict the risk of EVH in PNH patients.\n Methods\n We analyzed the medical records of 172 PNH patients treated between 2000 and 2022 at the University of Texas Southwestern and Cleveland Clinic Foundation. The dataset included clinical, laboratory, and NGS sequencing information, with specific clinical variables such as the type and duration of complement inhibitor(s) used, PNH clone size and distribution, EVH occurrence, antecedent aplastic anemia, and laboratory markers of hemolysis. Laboratory markers included lactate dehydrogenase (LDH), hemoglobin, absolute reticulocyte count and percentage, total bilirubin, d-dimer, AST, ALT, direct antiglobulin test (DAT), WBC, MCV, and platelet count. Missing data were imputed using the K-Nearest Neighbors algorithm (K=10). Feature selection through a Random Forest algorithm identified 23 significant clinical markers. A 5-layer multilayer perceptron classification algorithm trained using Leave-One-Out Cross Validation (LOOCV), achieved 87% sensitivity, 75% specificity, and an Area Under the Curve (AUC) of 0.80.\n Results\n Out of the 172 patients, 104 started on C5 complement inhibitors, while one began on a C3 inhibitor; eventually, nine were on a C3 inhibitor. About 26% of patients (n=27) were tested for EVH based on persistent anemia, with 15 testing positive for C3 complement activation at DAT evaluation. Of these, 71% were treated with eculizumab, and 28% with ravulizumab. Significant differences in clinical markers, such as Type II RBC levels (predictive score of 0.72), hemoglobin levels (predictive score of 0.42), LDH levels (predictive score of 0.50), and reticulocyte counts (predictive score of 0.46), were observed between EVH-positive and EVH-negative patients.\n Discussion\n Our findings are promising, demonstrating a machine learning model capable of predicting EVH with high accuracy. Given the recent approval of C3 and factor B inhibitors and ongoing development of proximal complement inhibitors, predicting EVH in PNH patients on C5 inhibitor therapy is increasingly relevant. Our model represents a significant advancement in identifying the risk of EVH at the time of diagnosis using accessible clinical variables. This predictive capability could enhance treatment monitoring, personalize treatment strategies based on patient risk profiles, and reduce healthcare costs. Future retrospective cohort studies to validate our model on patient data from other institutions would be valuable.\n",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/53503286d580e9e641357d4e7e5615b56811442d",
        "citation_count": 0
    },
    {
        "title": "P203 Unsupervised one-class classification and anomaly detection of stress echocardiograms with deep denoising spatio-temporal autoencoders",
        "abstract": "\n \n \n The combination of medical knowledge, experience and AI algorithms have supported the advancement of patient care and the lowering of healthcare costs. Machine and deep learning methods enable the extraction of meaningful patterns that remain beyond human perception. Numerous computer-aided diagnosis and detection systems have been developed to assist in the assessment of stress echocardiograms. However, issues are encountered when facing imbalanced, limited, and unannotated datasets. Learning from imbalanced medical datasets impairs diagnostic accuracy due to classifier bias and overfitting. Furthermore, datasets comprising of all existing abnormal classes are impossible to obtain, hence supervised algorithms would fail to generate predictions for classes devoid of training samples. Moreover, reliance on prior knowledge in the form of expert annotation and anatomical region extraction impairs scalability, as these procedures are time-consuming, computationally expensive, and limited to specific tasks.\n \n \n \n We aimed to perform one-class classification and anomaly detection of stress echocardiograms using unsupervised deep learning techniques to discriminate between normal and abnormal videos as well as to localise wall motion abnormalities within individual frames.\n \n \n \n Deep denoising spatio-temporal autoencoder networks were employed to learn visual and motion representations from multiple echocardiographic cross-sections and stress stages. Extracted middle layer features were modelled by one-class support vector machines to discriminate between regular and irregular echocardiograms despite the absence of abnormal training samples. Reconstruction errors allowed for direct visualisation and localisation of anomalous cardiac regions, without the need for annotated training data or segmentation of structures.\n \n \n \n 2D B-mode stress echocardiograms acquired from 36 patients were classified as normal or abnormal based on patient reports and served as the ground truth. Results revealed that learnt features extracted from spatio-temporal autoencoders trained solely on normal data can be utilised to classify abnormal echocardiograms with a high level of accuracy, sensitivity and specificity. In addition to that, as validated by an expert reader, spatio-temporal autoencoder reconstruction errors were capable of detecting and localising wall motion abnormalities in specific cardiac regions without prior knowledge of abnormal segments.\n \n \n \n The trained model enables the classification and detection of spatio-temporal abnormalities in stress echocardiograms. Therefore, the proposed networks have the potential of assisting in the global and regional assessment of stress echocardiograms.\n",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/53861957f939f61278bacd25d3227dfca73f6c5d",
        "citation_count": 3
    },
    {
        "title": "Machine Learning Applications in Studying Mental Health Among Immigrants and Racial and Ethnic Minorities: A Systematic Review",
        "abstract": "Background: The use of machine learning (ML) in mental health (MH) research is increasing, especially as new, more complex data types become available to analyze. By systematically examining the published literature, this review aims to uncover potential gaps in the current use of ML to study MH in vulnerable populations of immigrants, refugees, migrants, and racial and ethnic minorities. Methods: In this systematic review, we queried Google Scholar for ML-related terms, MH-related terms, and a population of a focus search term strung together with Boolean operators. Backward reference searching was also conducted. Included peer-reviewed studies reported using a method or application of ML in an MH context and focused on the populations of interest. We did not have date cutoffs. Publications were excluded if they were narrative or did not exclusively focus on a minority population from the respective country. Data including study context, the focus of mental healthcare, sample, data type, type of ML algorithm used, and algorithm performance was extracted from each. Results: Our search strategies resulted in 67,410 listed articles from Google Scholar. Ultimately, 12 were included. All the articles were published within the last 6 years, and half of them studied populations within the US. Most reviewed studies used supervised learning to explain or predict MH outcomes. Some publications used up to 16 models to determine the best predictive power. Almost half of the included publications did not discuss their cross-validation method. Conclusions: The included studies provide proof-of-concept for the potential use of ML algorithms to address MH concerns in these special populations, few as they may be. Our systematic review finds that the clinical application of these models for classifying and predicting MH disorders is still under development.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/538ef52a81131871f88e393132aca6b7e08516b1",
        "citation_count": 1
    },
    {
        "title": "Analyzing and Predicting the Impact of COVID-19 on Online Pharmaceuticals Sectors and Pathological Services in India",
        "abstract": "The novel coronavirus disease 2019 (COVID-19) is a worldwide pandemic that has impacted the healthcare industry. While retail pharmaceutical and medical stores were classified as vital services, online pharmacies emerged as one of the most significant benefactors of India\u2019s pandemic-induced lockdown, as consumers decided to buy medications online to lessen the risk of contamination. The wide-ranging consequences of the COVID-19 outbreak have also prompted healthcare providers to embrace new methods and techniques that allow for at-home lab testing. We conducted a research study and analysis to determine if online pharmacies and at-home lab tests would continue to develop rapidly and become increasingly digital post-COVID pandemic considering that it has been fuelled by the current pandemic crisis and changing customer needs and requirements. The research was carried out considering the factors such as \"Gender, Age-group, how often they use online pharmacies, rating their online pharmacy experiences, how often they purchased medicines online before and during COVID, have they used at-home lab testing services, and rating the quality, discounts, safety, genuineness and time taken for at-home lab testing\". Based on these factors, in this paper, we have built two prediction models that use supervised learning which would predict how likely a person will utilize online pharmacies and at-home lab tests post COVID 19 pandemic. It consists of 5 probabilities i.e. very likely to use it, likely use it, moderately use it, less likely to use it, and rarely use it. The various classification algorithms employed in the study were logistic regression, decision trees, random forest, support vector machines, and Gradient booster classification algorithm The model\u2019s results are based on the previous data that was collected by asking around 250 individuals. Accuracies obtained for predicting how likely a person will use online pharmacies post COVID are as follows, by gradient booster model the accuracy is ~85%, the accuracy obtained by decision tree classifier is ~71%, by logistic regression model the accuracy is ~85% and accuracy obtained by random forest model is ~78%. Accuracies obtained for predicting how likely a person will use at-home lab tests post COVID are as follows, by decision tree classifier accuracy is ~78%, the accuracy obtained by logistic regression is ~50% and the accuracy obtained by support vector machines is ~64%.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/53949d5f557c38d11dc2582ba4056f3c727894e4",
        "citation_count": 2
    },
    {
        "title": "The role of artificial neural network and machine learning in utilizing spatial information",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/53ae0c6fd08a668c6b524d0e99de23b5103af0af",
        "citation_count": 89
    },
    {
        "title": "Annotating and detecting topics in social media forum and modelling the annotation to derive directions-a case study",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/53f0e07d4bcf3e0a9f3e4a8a01f71f8c60551448",
        "citation_count": 5
    },
    {
        "title": "Annotating and Detecting Topics from Social Media Forum and Modelling the Annotation to Derive Directions-A Case Study (Preprint)",
        "abstract": "\n BACKGROUND\n Widespread influence on social media has its ramifications on all walks of life over the last few decades. Interestingly enough, the healthcare sector is a significant beneficiary of the reports and pronouncements that appear on social media. Although medics and other health professionals are the final decision-makers, advice or recommendations from kindred patients has consequential role. In full appreciation of the current trend, the present paper explores the topics pertaining to the patients, diagnosed with breast cancer as well as the survivors, who are discussing on online fora.\n \n \n OBJECTIVE\n The study examines the online forum of Breast Cancer.org (BCO), automatically maps discussion entries to formal topics, and proposes a machine learning model to characterize the topics in the health-related discussion, so as to elicit meaningful deliberations. Therefore, the study of communication messages draws conclusions about what matters to the patients.\n \n \n METHODS\n Manual annotation was made in the posts of a few randomly selected forums. To explore the topics of breast cancer patients and survivors, 736 posts are selected for semantic annotation. The entire process was automated using machine learning model falling into category of supervised learning algorithms. The effectiveness of those algorithms used for above process has been compared.\n \n \n RESULTS\n The method could classify following 8-high level topics, such as writing medication reviews, explaining the adverse effects of medication, clinician knowledge, various treatment options, seeking and supporting various matters, diagnostic procedures, financial issues and implications in everyday life. The model viz. Ensembled Neural Network (ENN) achieved a promising predicted score of 83.4 % F1-score among four different models.\n \n \n CONCLUSIONS\n The research was able to segregate and name the posts all into a set of 8 classes and supported by the efficient scheme for encoding text to vectors, the current machine learning models are shown to give impressive performance in modelling the annotation process.\n",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5401615a58100f835cd8d04c0efca5234b5b2d67",
        "citation_count": 0
    },
    {
        "title": "Analysis and prediction of unplanned intensive care unit readmission using recurrent neural networks with long short-term memory",
        "abstract": "Background Unplanned readmission of a hospitalized patient is an extremely undesirable outcome as the patient may have been exposed to additional risks. The rates of unplanned readmission are, therefore, regarded as an important performance indicator for the medical quality of a hospital and healthcare system. Identifying high-risk patients likely to suffer from readmission before release benefits both the patients and the medical providers. The emergence of machine learning to detect hidden patterns in complex, multi-dimensional datasets provides unparalleled opportunities to develop efficient discharge decision-making support system for physicians. Methods and Findings We used supervised machine learning approaches for ICU readmission prediction. We used machine learning methods on comprehensive, longitudinal clinical data from the MIMIC-III to predict the ICU readmission of patients within 30 days of their discharge. We have utilized recent machine learning techniques such as Recurrent Neural Networks (RNN) with Long Short-Term Memory (LSTM), by this we have been able incorporate the multivariate features of EHRs and capture sudden fluctuations in chart event features (e.g. glucose and heart rate) that are significant in time series with temporal dependencies, which cannot be properly captured by traditional static models, but can be captured by our proposed deep neural network based model. We incorporate multiple types of features including chart events, demographic, and ICD9 embeddings. Our machine learning models identifies ICU readmissions at a higher sensitivity rate (0.742) and an improved Area Under the Curve (0.791) compared with traditional methods. We also illustrate the importance of each portion of the features and different combinations of the models to verify the effectiveness of the proposed model. Conclusion Our manuscript highlights the ability of machine learning models to improve our ICU decision making accuracy, and is a real-world example of precision medicine in hospitals. These data-driven results enable clinicians to make assisted decisions within their patient cohorts. This knowledge could have immediate implications for hospitals by improving the detection of possible readmission. We anticipate that machine learning models will improve patient counseling, hospital administration, allocation of healthcare resources and ultimately individualized clinical care.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/5436a29ca04fb35fa338a3d86d9c1c7ceac8001e",
        "citation_count": 142
    },
    {
        "title": "Design of Carryable Respiratory Training System Using Learning-Based Waveform Classification",
        "abstract": "Spirometry is a crucial assessment for detecting respiratory obstructive diseases such as chronic obstructive pulmonary disease (COPD). While there are several respiratory trainers and spirometers available on the market, incorrect blowing techniques may render key metrics like forced vital capacity (FVC), forced expiratory volume in first second (FEV1), and Peak Expiratory Flow (PEF) unreliable, necessitating supervised testing by healthcare professionals in hospital settings. Our system integrates the functionalities of a spirometer and respiratory trainer. After conducting pulmonary function tests using the App, users' blowing waveforms are measured with an airflow sensor. The App provides guidance for lung capacity tests and a gaming interface for respiratory training, storing all data in a MySQL database. This study categorizes common blowing waveforms into six types using machine learning models and dynamic time warping (DTW) distance calculations. Based on the classification results, users are directed to appropriate respiratory training sessions to help them master correct testing techniques. Analysis of the results indicates that using Mel Frequency Cepstral Coefficients (MFCC) feature extraction with Random Forest for classification yields optimal outcomes.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/55040e57575037cb799e05f28564bb4d30d7debf",
        "citation_count": 0
    },
    {
        "title": "A STUDY ON SUPERVISED MACHINE LEARNING ALGORITHMS WITH RESPECT TO PERFORMANCE ANALYSIS IN LIVER DISEASE DETECTION",
        "abstract": ": Machine learning has a great potential in healthcare industry in various tasks ranging from diagnosis to decision making. There are several machine learning algorithms available which are suitable for various tasks but selecting the best one is a challenge. For selecting the best algorithm, we conducted a study on supervised machine learning algorithms for detecting liver disease in patients. In this paper, we have discussed various supervised machine learning algorithms and analyzed performance of those algorithms for liver disease detection for Indian liver patient records. To implement the algorithms, Indian liver patient records data set was used with 583 instances with 10 attributes as independent variables and one as dependent variable for the analysis. From this research study, the results show that SVM gives the best results in liver disease detection as compared to Logistic Regression, K-Nearest Neighbours, Naive Bayes (NB), Random Forest and Neural Network algorithm .",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5507fd4558528d1b4f1fb03ed1486e3cd62d75a7",
        "citation_count": 1
    },
    {
        "title": "Machine Learning Approaches on India's Health Insurance Market using Data Analytics",
        "abstract": "Data has grown in significance in the digital realm with the development of computer technology. Information gathering is crucial when it comes to data analytics. Every industry uses data analytics, from banking to retail, and the importance of data analytics in healthcare is on the rise.This research mainly seeks to categorize and predict healthcare data using data mining tools and machine learning (supervised) approaches. We need to build a sophisticated model (using machine learning) to filter through all the data in our databases since there is so much of it. The amount of data stored exceeds the speed at which human beings can analyze it. This categorization becomes even more significant since classified healthcare data may help with patient identification, diagnosis, and treatment. The huge, complicated, and varied nature of healthcare data is driving the need for data mining tools for classification and forecasting. Machine learning has emerged as a crucial tool for healthcare researchers to quickly, accurately, and efficiently resolve complex classification problems. Although researchers are aware of the problem, premature birth (PTB) continues to go unaddressed, despite the fact that it is a huge public health concern with far-reaching negative consequences for families and communities. The first goal of implementing a model based on machine learning is to predict cases of TB. Decision Tree (DT), Logistic Regression (RR), and Support Vector Machine (SVM) are three learner classifiers utilized for this purpose, in addition to Minimum Information Loss (MIL) discretization.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/556f2baa40b6c85b1e3916e6676c5c68ba2569b3",
        "citation_count": 0
    },
    {
        "title": "Effective Prognosis of Heart Attack Using Supervised Machine Learning Algorithms",
        "abstract": "Early identification of heart attack is essential and predicting it using clinical data is a complex process due to the multifaceted nature of the disease and the diverse range of contributing factors. Machine Learning (ML) algorithms are powerful tools for predicting heart disease by analyzing patient healthcare data. This paper explores the predictive analysis of heart attack using supervised ML algorithms: Adaptive Boosting (AdaBoost), Classification and Regression Tree (CART), and Random Forest (RF) algorithms. AdaBoost is a simple ensemble algorithm that improves the performance of weak learners by focusing on misclassified instances. CART is highly interpretable and efficient in handling non-linear data relationships. Random Forest is a robust algorithm that aggregates the predictions of multiple decision trees to produce accurate predictions. A comprehensive dataset comprising various cardiovascular health indicators is used to evaluate these algorithms. Simulation results demonstrate that the proposed algorithms significantly enhance prediction accuracy upto 96%.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5570202126f348384fa222a84851f0362c14bb83",
        "citation_count": 0
    },
    {
        "title": "Diabetes Prognosis - A Supervised Learning Approach",
        "abstract": "Diabetes is a major public health challenge that requires prevention, management, and treatment. It is incurable, but it is essential to identify and detect diabetes in patients at the earliest. Therefore, researchers in the healthcare sector are applying several machine-learning techniques that would help diagnose and detect diabetic patients. In this study, diabetes was prognosticated using machine learning approaches like the AdaBoost Classifier, Logistic Regression Classifier, Gaussian Naive Bayes Classifier, KNN Classifier, and the MLP Classifier with K-Fold Cross-Validation. The proposed DPM-Diabetes Prognosis model achieved the highest AUC (by up to 72.66%) for the AdaBoost Classifier.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/5575322a6f50cc2d5eccea6df2987cadf688b2d7",
        "citation_count": 0
    },
    {
        "title": "Monitoring System for Sickle Cell Disease Patients by Using Supervised Machine Learning",
        "abstract": "Recently, the need for a real-time healthcare monitoring system that able to offer remote and personal health-care services has increased. The patients with Sickle Cell Disease (SCD) require continuous services of testing, following-up and monitoring. Offering these services to patients smoothly at any time needs to integrated healthcare system. The recent development in information systems and technologies facilitate introducing such healthcare systems. This paper proposed an integrated system model, which offers the services of testing, following-up and monitoring patients with (SCD). The proposed system uses support vector machine SVM, which is supervised machine learning approach to analyze the collected data of a specific patient and takes the appropriate action such as send alert message to the healthcare staff. To perform the classification process, four methods are applied with SVM algorithm, which are Sequential Minimal Optimization SMO, Rules JRIP, Tree Decision Stump and Naive Bays for comparative analysis. In this paper, many experiments were implemented based on the four machine learning algorithms to determine patients of SCD from normal patients. The results were promising as they show 99% classifications were accurate when using SMO algorithm.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/55774006d3e54923399e300bfe09da628493f80f",
        "citation_count": 10
    },
    {
        "title": "Monitoring Lung Mechanics during Mechanical Ventilation using Machine Learning Algorithms",
        "abstract": "Evaluation of lung mechanics is the primary component for designing lung protective optimal ventilation strategies. This paper presents a machine learning approach for bedside assessment of respiratory resistance (R) and compliance (C). We develop machine learning algorithms to track flow rate and airway pressure and estimate R and C continuously and in real-time. An experimental study is conducted, by connecting a pressure control ventilator to a test lung that simulates various R and C values, to gather sensor data for validation of the devised algorithms. We develop supervised learning algorithms based on decision tree, decision table, and Support Vector Machine (SVM) techniques to predict R and C values. Our experimental results demonstrate that the proposed algorithms achieve 90.3%, 93.1%, and 63.9% accuracy in assessing respiratory R and C using decision table, decision tree, and SVM, respectively. These results along with our ability to estimate R and C with 99.4% accuracy using a linear regression model demonstrate the potential of the proposed approach for constructing a new generation of ventilation technologies that leverage novel computational models to control their underlying parameters for personalized healthcare and context-aware interventions.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/5602191a63a4218458726cc51816437050944199",
        "citation_count": 10
    },
    {
        "title": "Semi-supervised learning methods for large scale healthcare data analysis",
        "abstract": "With the development of information technology in healthcare industry, more and more data has been generated and stored electronically. To fully exploit the information and knowledge, data mining and machine learning methods have been developed and studied. We notice that a large body of healthcare data are lack of supervised information which requires expense human efforts in labelling or scoring them so as to be analysed in a data mining model. In this article, we address the problem of making use of unlabeled or un-scored data, together with only a few supervised data, to improve the performance of analysis model for healthcare decision making. This kind of paradise is called semi-supervised learning in machine learning literatures. We focus on semi-supervised kernel learning and propose to apply the learned kernel in two algorithms, i.e., support vector machine SVM and kernel regularised least squares KRLS. The evaluation results on two publicly available healthcare dataset illustrate the effectiveness of the proposed framework.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/563972ce25ce634c34c55c98f22167c909305440",
        "citation_count": 9
    },
    {
        "title": "Cardiac Arrhythmia Classification Using Advanced Deep Learning Techniques on Digitized ECG Datasets",
        "abstract": "ECG classification or heartbeat classification is an extremely valuable tool in cardiology. Deep learning-based techniques for the analysis of ECG signals assist human experts in the timely diagnosis of cardiac diseases and help save precious lives. This research aims at digitizing a dataset of images of ECG records into time series signals and then applying deep learning (DL) techniques on the digitized dataset. State-of-the-art DL techniques are proposed for the classification of the ECG signals into different cardiac classes. Multiple DL models, including a convolutional neural network (CNN), a long short-term memory (LSTM) network, and a self-supervised learning (SSL)-based model using autoencoders are explored and compared in this study. The models are trained on the dataset generated from ECG plots of patients from various healthcare institutes in Pakistan. First, the ECG images are digitized, segmenting the lead II heartbeats, and then the digitized signals are passed to the proposed deep learning models for classification. Among the different DL models used in this study, the proposed CNN model achieves the highest accuracy of \u223c92%. The proposed model is highly accurate and provides fast inference for real-time and direct monitoring of ECG signals that are captured from the electrodes (sensors) placed on different parts of the body. Using the digitized form of ECG signals instead of images for the classification of cardiac arrhythmia allows cardiologists to utilize DL models directly on ECG signals from an ECG machine for the real-time and accurate monitoring of ECGs.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/56415f49c3e8bd42def94cfd113db8cdecf93696",
        "citation_count": 4
    },
    {
        "title": "Artificial Intelligence for Nursing Practice and Management",
        "abstract": "KEY POINTS With the advancement of available clinical and health data as well as the growth of big data in different healthcare disciplines, artificial intelligence is becoming a prevalent emerging technology to predict disease risks, disease diagnoses, courses of illness, and treatments. A simplified meaning of artificial intelligence, machine learning, and deep learning methods is illustrated for future nursing informatics research. Current use ofmachine learning and deep learning in nursing education is described and research and recommendations for future use are presented. ARTIFICIAL INTELLIGENCE Artificial intelligence (AI) has been defined as an area of study in computer science concerned with the ability to make computers do things that would require intelligence if done by humans. Artificial intelligence is a new-old science. Artificial intelligence concepts were presented in the 1950s; however, due to the scarcity of electronic data, at that time, its use for further discovery was still immature. Nowadays, with the growth of electronic data, AI is growing in importance in many disciplines. In healthcare and nursing science, with widespread implementation of electronic health records and electronic documentation, big data in terms of large volume, variety, velocity, and veracity of data aremore available. Large warehouses of structured and unstructured nursing data will enhance the use of AI technology to create more meanings that can be used in research to improve nursing practice and management. Artificial intelligence is the ability to use machine learning to imitate humans' cognitive abilities by using numerous statistical and algorithmic calculations in understanding, problem solving, and decision making. Artificial intelligence is a broad concept under which are machine learning and deep learning (Figure 1). Machine learning (Table 1) has three subfields; each uses different assumptions and mathematical frameworks for how data are ingested and how learning occurs within the algorithm. The subfields of machine learning are (1) supervised learning; (2) unsupervised learning; and (3) reinforcement learning (semisupervised learning). Supervised learning requires labeled data sets, which is the process of attaching meaning to different types of digital data such as text, audio files, images, videos and more. This environment includes a known data domain and known response (labeled) set. Therefore, a supervised learning model and an algorithm deal with an environment where the given",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/566b1eedcbd12287f4a1eaedd91358bda4eb93cc",
        "citation_count": 8
    },
    {
        "title": "TECHNOLOGY DIAGNOSING DIABETES USING DATA MINING TECHNIQUES",
        "abstract": "Diabetes Mellitus (DM) is an important health problem that affects many people including teenagers who get affected by it due to their sedentary lifestyle and food habits. Prevention or controlling diabetes is a big challenge as faced by diabetologists world over. Data mining is an important technique which can be used to find so far unpredicted pattern among huge heath care databases in a very effective and efficient manner. In fact, data mining is applied in many fields like education, retail, finance, healthcare, and many such fields. In this paper the rule based method named as PDC (Potential Diabetic Classifier) was used to diagnose diabetes from the healthcare database and it also diagnoses the type of diabetes from the diabetes dataset. Standard supervised machine learning algorithms like Naive Bayes, SVM, Ada Boost, bagging, Decision Tree and Simple Cart were also used for diagnosing diabetes and also for predicting the type of diabetes like Gestational Diabetic Mellitus, Type-1 or Type-2 Diabetes. This paper compares the result of the standard classification methods with the PDC method and it was found that the PDC method gives better results when compared to other classification methods applied.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/5693b636603778f6a2d02dddc7e8f93ade9fb489",
        "citation_count": 0
    },
    {
        "title": "Gesture recognition for Healthcare 4.0: a machine learning approach to reduce clinical infection risks",
        "abstract": "The management and monitoring of diagnostic routines for the active surveillance of colonization of antibiotic-resistant bacteria require the use of advanced data drivers based on field sensors that characterize various phases of hospital processes. To this aim, this study describes the proof of concept of an integrated system exploiting smart field sensors and a digital management system that utilizes flow diagrams and business process models and notation (BPMN) to optimize hospital processes. The focus is on the development and validation of the smart field sensor based on a vision system, which extensively leverages machine learning algorithms for real-time identification of hand-washing procedures. The novelty of this research is twofold: hands joints are extracted and processed frame-by-frame to extract relevant geometric features, which are the input of three independent Random Forests. Then, the output of the three Random Forests composes the input for a final supervisor classifier (a simple Artificial Neural Network). The overall system prediction accuracy is of 73.3%, which is an encouraging result given the complexity of such gestures and the simplicity of the algorithms adopted. Therefore, the proposed method demonstrates the capability of field sensors to facilitate novel real-time management models in the healthcare sector, aligning with the principles of the Healthcare 4.0 paradigm.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/56ab7be56a51e8947a057b58915cd3b92b0298b1",
        "citation_count": 1
    },
    {
        "title": "Rat Swarm Optimizer based Transform for Performance Improvement of Machine Learning Classifiers in Diagnosis of Lung Cancer",
        "abstract": "Usage of Machine Learning algorithms for assisting healthcare providers is increasing day by day. But the performance and robustness of the machine learning algorithms are the main concerns while implementing them for critical healthcare applications such as detection of cancer. This work concentrates on the performance improvement of supervised classifiers through the feature transform based on Rat Swarm Optimizer in diagnosing lung cancer using histopathological images. Rat Swarm Optimizer used for the transformation of features. These transformed features are more capable of providing better classification accuracy when compared to normal features. The dataset is downloaded from the publicly available website and three classes are present: normal, lung squamous cell carcinomas, and lung adenocarcinomas. In each class, 1000 histopathological images are considered. Four supervised classifiers namely Histogram-Gradient boosting classifier, Random forest classifier, K-Nearest Neighbor classifier, and Linear Discriminant Analysis classifiers are tested. The highest accuracy of 90.66% is offered by Histogram-Gradient boosting classifier and this is increased to 95.82% when Rat Swarm Optimizer is used as transform before classification.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/56ce8a83857a7103c3caa73d23818878a732f173",
        "citation_count": 0
    },
    {
        "title": "Robots in the home",
        "abstract": "Robots are coming, but what does this mean for ordinary folks? First of all, don\u2019t believe all the hype. Lots of hobbyists and small ventures would have you believe that robots are already here, capable of a wide variety of interactions, including healthcare and monitoring medication compliance, security monitoring, education, errands, and entertainment. Robots are, of course, used in manufacturing, in search-and-rescue missions, and in the military. But when we get away from industry and the military and discuss machines that are reasonably priced, most of these so-called applications are more imagination than reality, with unreliable mechanisms barely able to get through demonstrations. For everyday home applications, the use of robots is restricted to entertainment, vacuum cleaners, and lawn mowers. Note, however, that the definition of \u201crobot\u201d varies widely, often being used for anything mobile, even though controlled by a human. Personally, I would classify intelligent home appliances as robots: my coffee maker, microwave oven, dishwasher, and clothes washer and dryer have more intelligence and actuators than robot vacuum cleaners\u2014and they are also a lot more expensive. But they don\u2019t move around the room, which for many people disqualifies them from the label of \u201crobot.\u201d Given that any successful product for the home must be affordable, reliable, safe, and usable by everyday people, what might a home robot do? And what would it look like? In the home, form probably will follow function. A kitchen robot might be built into the counter space, with dishwasher, pantry, coffee maker, and cooking units all arranged so that they can communicate with one another and pass items readily back and forth. An entertainment robot might take on a humanoid appearance (as in Wow Wee\u2019s Robosapien), or an animal-like one (as in Sony\u2019s Aibo). And robots that vacuum or mow lawns will look like, well, vacuum cleaners and lawn mowers. Making robots work well is incredibly difficult. Their sensory apparatus is limited because sensors are expensive and interpretation (especially commonsense knowledge) is still more suited for research than deployment. Robotic arms are expensive to build and not very reliable. This limits the range of possibilities. Mowing and vacuuming? Sure. Sorting laundry? Hard, but do-able. Picking up dirty items around the home? Doubtful. How about assistants for the elderly or those who need medical supervision? This is a booming area of exploration, but I am skeptical. Today\u2019s devices are not reliable, versatile, or intelligent enough-not yet, anyway. Moreover, the social aspects of the interaction are far more complex than the technical ones, something the technology-driven enthusiasts typically fail to recognize. Three likely directions for the future are entertainment, home appliances, and education. We can start with today\u2019s existing devices and slowly add on intelligence, manipulative ability, and function. Start small and build. The market for robots that entertain by being cute and cuddly is already well established. The second generation of vacuum cleaners is smarter than the first. Sony\u2019s dog gets smarter and less expensive with each new version. We don\u2019t yet think of washing machines, microwave ovens, and coffee makers as robots, but why not? They don\u2019t move around the house, but they are getting better and smarter every year. And when the coffee maker is connected to the pantry and dishwasher, that will be a home robot worthy of the name\u2014same for the coupling of sorting, washing, drying, and storing clothes. Education is a powerful possibility. There is already a solid basis of educational devices that aid learning. Today\u2019s robots can read aloud in engaging voices. They can be cute and lovable-witness the responses to the multiple quasi-intelligent animals on the toy market. A robot could very well interact with a child, offering educational benefits as well. Why not have the robot help the child learn the alphabet, teach reading, vocabulary, pronunciation, basic arithmetic, maybe basic reasoning? Why not music and art, geography and history? And why restrict it to children? Adults can be willing and active learners. Now this is a direction worthy of exploration: robot as teacher. Not to replace school, not to replace human contact and interaction, but to supplement them. The beauty here is that these tasks are well within the abilities of today\u2019s devices. They don\u2019t require much mobility or sophisticated manipulators. Many technologists dream of implementing Neil Stephenson\u2019s children\u2019s tutor in his novel The Diamond Age: Or, A Young Lady\u2019s Illustrated Primer. Why not? Here is a worthy challenge. T H E W A Y I S E E IT",
        "year": 2005,
        "url": "https://www.semanticscholar.org/paper/577363b3f2e593b349f409a8c6996b8359dfcf3c",
        "citation_count": 14
    },
    {
        "title": "Detection and Analysis of Cardiovascular Diseases using Machine Learning Techniques",
        "abstract": "The detection and analysis of cardiovascular diseases is a critical study field within the medical field. Cardiovascular diseases are one of the leading causes of mortality globally, and timely identification is vital to forego adverse effects and improve outcomes for patients with these conditions. The incorporation of machine learning technologies to forecast onset of cardiovascular diseases and analyzing their progression has shown promising results. This paper demonstrates the machine learning models that can provide near-accurate predictions and help identify the right data set based on accuracy. The choice of the best-fitting algorithm has been made by a comparative study and with the inclusion of K-fold cross-validation. We infer that the Random Forest algorithm is the best algorithm for detection and K-Nearest Neighbor Algorithm for the analysis of prominent heart diseases like Stable Angina, ST-elevated myocardial infarction, and non-ST elevated myocardial infarction which will serve as a direction to further diagnosis. Overall, the potential for machine learning to improve early detection and treatment of Cardiovascular Diseases, which could ultimately save lives and reduce healthcare costs, has been recognized. Index Terms\u2014Artificial intelligence, Machine learning, Supervised learning, Unsupervised learning, Accuracy",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/57baa3c42a9b95fed10cf854a15669120e14b28f",
        "citation_count": 0
    },
    {
        "title": "Offenders and non-offenders with schizophrenia spectrum disorders: the crime-preventive potential of sufficient embedment in the mental healthcare and support system",
        "abstract": "Background Suffering from schizophrenia spectrum disorder (SSD) has been well-established as a risk factor for offending. However, the majority of patients with an SSD do not show aggressive or criminal behavior. Yet, there is little research on clinical key features distinguishing offender from non-offender patients. Previous results point to poorer impulse control, higher levels of excitement, tension, and hostility, and worse overall cognitive functioning in offender populations. This study aimed to detect the most indicative distinguishing clinical features between forensic and general psychiatric patients with SSD based on the course of illness and the referenced hospitalization in order to facilitate a better understanding of the relationship between violent and non-violent offenses and SSD. Methods Our study population consisted of forensic psychiatric patients (FPPs) with a diagnosis of F2x (ICD-10) or 295.x (ICD-9) and a control group of general psychiatric patients (GPPs) with the same diagnosis, totaling 740 patients. Patients were evaluated regarding their medical (and, if applicable, criminal) history and the referenced psychiatric hospitalization. Supervised machine learning (ML) was used to exploratively evaluate predictor variables and their interplay and rank them in accordance with their discriminative power. Results Out of 194 possible predictor variables, the following 6 turned out to have the highest influence on the model: olanzapine equivalent at discharge from the referenced hospitalization, a history of antipsychotic prescription, a history of antidepressant, benzodiazepine or mood stabilizer prescription, medication compliance, outpatient treatment(s) in the past, and the necessity of compulsory measures. Out of the seven algorithms applied, gradient boosting emerged as the most suitable, with an AUC of 0.86 and a balanced accuracy of 77.5%. Discussion Our study aimed to identify the most influential illness-related predictors, distinguishing between FPP and GPP with SSD, thus shedding light on key differences between the two groups. To our knowledge, this is the first study to compare a homogenous sample of FPP and GPP with SSD regarding their symptom severity and course of illness using highly sophisticated statistical approaches with the possibility of evaluating the interplay of all factors at play.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/57c000b26e917b5cbb8fd918ebb449db28daf820",
        "citation_count": 3
    },
    {
        "title": "Let's Grab a Drink: Teacher-Student Learning for Fluid Intake Monitoring using Smart Earphones",
        "abstract": "This paper shows the feasibility of fluid intake estimation using earphone sensors, which are gaining in popularity. Fluid consumption estimation has a number of healthcare-related applications in tracking dehydration and overhydration which can be connected to issues in fatigue, irritability, high blood pressure, kidney stones, etc. Therefore, accurate tracking of hydration levels not only has direct benefits to users in preventing such disorders but also offers diagnostic information to healthcare providers. Towards this end, this paper employs a voice pickup microphone that captures body vibrations during fluid consumption directly from skin contact and body conduction. This results in the extraction of stronger signals while being immune to ambient environmental noise. However, the main challenge for accurate estimation is the lack of availability of large-scale training datasets to train machine learning models (ML). To address the challenge, this paper designs robust ML models based on techniques in data augmentation and semi-supervised learning. Extensive user study with 12 users shows a per-swallow volume estimation accuracy of 3.35 mL (\u2248 19.17% error) and a cumulative error of 3.26% over an entire bottle, while being robust to body motion, container type, liquid temperature, sensor position, etc. The ML models are implemented on smartphones with low power consumption and latency.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/58331034d1a52bfd4a6afc5f7dc1a6c308b301a1",
        "citation_count": 4
    },
    {
        "title": "Time Series Data Analysis using Machine Learning-(ML) Approach",
        "abstract": "Healthcare benefits related to continuous monitoring of human movement and physical activity can potentially reduce the risk of accidents associated with elderly living alone at home. Based on the literature review, it is found that many studies focus on human activity recognition and are still active towards achieving practical solutions to support the elderly care system. The proposed system has introduced a joint approach of machine learning and signal processing technology for the recognition of human's physical movements using signal data generated by accelerometer sensors. The framework adopts the concept of DSP to select very descriptive feature sets and uses ML-based supervised learning techniques for effective classification. The simulation result demonstrates the efficiency of the proposed system regarding the prediction of human movement based on sensor signals. Keywords-Machine Learning, Security, Support Vector Machine, Neural Network, Signal Processing, Huma movement Detection",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/5859625be1df2874742999bb48363328acefa61c",
        "citation_count": 0
    },
    {
        "title": "Interpretable Classifier Models for Decision Support Using High Utility Gain Patterns",
        "abstract": "Ensemble models such as gradient boosting and random forests are proven to offer the best predictive performance on a wide variety of supervised learning problems. The high performance of these black box models, however, comes at a cost of model interpretability. They are also inadequate to meet regulatory demands and explainability needs of organizations. The model interpretability in high performance black-box models is achieved with the help of post-hoc explainable models such as Local Interpretable Model-agnostic Explanations (LIME) and SHapley Additive exPlanations (SHAP). This paper presents an alternate intrinsic classifier model that extracts a class of higher order patterns and embeds them into an interpretable learning model. More specifically, the proposed model extracts novel High Utility Gain (HUG) patterns that capture higher order interactions, transforms the model input data into a new space, and applies interpretable classifier methods on the transformed space. We conduct rigorous experiments on forty benchmark binary and multi-class classification datasets to evaluate the proposed model against the state-of-the-art ensemble and interpretable classifier models. The proposed model was comprehensively assessed on three key dimensions: 1) quality of predictions using classifier measures such as accuracy, $F_{1}$ , AUC, H-measure, and logistic loss, 2) computational performance on large and high-dimensional data, and 3) interpretability aspects. The HUG-based learning model was found to deliver performance comparable to that of the state-of-the-art ensemble models. Our model was also found to achieve 2-40% (45%) prediction quality (interpretability) improvements with significantly lower computational requirements over other interpretable classifier models. Furthermore, we present case studies in finance and healthcare domains and generate one- and two-dimensional HUG profiles to illustrate the interpretability aspects of our HUG models. The proposed solution offers an alternate approach to build high performance and transparent machine learning classifier models. We hope that our ML solution help organizations meet their growing regulatory and explainability needs.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/58655e4baac405193f8958b5e71a252865dbcaad",
        "citation_count": 0
    },
    {
        "title": "Machine Learning Techniques for Wireless-Powered Ambient Backscatter Communications: Enabling Intelligent IoT Networks in 6G Era",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/587f59303202e60ac8ce69bb871ec33a25e8f27d",
        "citation_count": 17
    },
    {
        "title": "Artificial Intelligence, Machine Learning and Deep Learning in Ophthalmology: Current Clinical Relevance",
        "abstract": "With the advent of computer graphic processing units, improvement in mathematical models and availability of big data, artificial intelligence (AI) using machine learning (ML) and deep learning (DL) techniques have achieved robust performance for potential application across many industries, including social-media, the internet of things, the automotive industry and healthcare. DL systems provide capability in image, speech and motion recognition as well as in natural language processing. In medicine, most of the progress of AI, ML and DL systems has been demonstrated in image-centric specialties such as radiology, dermatology and pathology. There is increasing interest in AI in ophthalmology. New studies, including pre-registered prospective clinical trials, have shown DL systems are effective in detecting diabetic retinopathy (DR), glaucoma, age-related macular degeneration, retinopathy of prematurity, refractive error and in identifying cardiovascular risk factors and diseases, using image based data such as fundus photographs and optical coherence tomography. Additionally, the application of ML to Humphrey visual fields may be useful in detecting glaucoma progression. There are fewer studies that incorporate clinical data in AL algorithms and no prospective studies to demonstrate that AI algorithms can predict the development of eye disease. This article describes the current global eye disease burden, clinical unmet needs and selected common ophthalmic conditions of public health importance for which AI and DL systems may be applicable. Technical and clinical aspects to build a DL system to address those gaps, and the potential challenges for clinical adoption are discussed. AI, ML and DL likely will play a crucial role in clinical ophthalmology practice, with implications for screening, diagnosis and follow up of the major causes of vision impairment, in the setting of the ageing population globally. Introduction With the advent of graphic processing units (GPUs), advances in mathematical models, the availability of big datasets and low cost sensors, artificial intelligence (AI) using machine learning (ML) techniques initially and deep learning (DL) techniques subsequently, has sparked tremendous interest in many industries. These include application of AI in social-media, the internet of things, finance and banking, the automotive industry and healthcare. AI systems can be designed not only for image, speech and motion recognition, but also in natural language processing. In medicine, the most robust AI algorithms have been demonstrated in image-centric specialties, including radiology, dermatology, pathology and increasingly so in ophthalmology. For example, Lakhani et al demonstrated excellent performance in detecting pulmonary tuberculosis from chest radiographs, while Esteva et al was able to differentiate malignant melanoma from benign lesions on skin photographs. In ophthalmology, there have been two major areas in which AI and new DL systems have been applied. First, AI systems have been shown in new studies, including preregistered prospective clinical trials, to accurately detect diabetic retinopathy (DR), 13 glaucoma, age-related macular degeneration (AMD), retinopathy of prematurity (ROP), and refractive error, from digital fundus photographs. A range of cardiovascular risk factors have also been accurately predicted from fundus photographs. Second, several retinal conditions [e.g., neovascular AMD, earlier stages of AMD, and diabetic macular edema (DME)] has also be detected accurately using optical coherence tomography (OCT). There are relatively fewer AI studies using other data, such as studies which show good performance in detecting glaucoma progression from serial Humphrey visual fields (HVFs). However, there are fewer studies that incorporate clinical and imaging data in AL algorithms, and no prospective studies to demonstrate that AI algorithms can predict the development of eye diseases over time. Furthermore, the implementation and adoption of AI into routine clinical care remains extremely challenging. These remain significant goals of AI research in ophthalmology This article describes basic concepts of AI, ML and DL and how such systems might address some of the global burdens created by common eye conditions. Furthermore, the technical and clinical aspects of developing and validating an AI/DL system, potential challenges and future directions are also discussed in this article. Artificial Intelligence, Machine Learning and Deep Learning AI was conceptualized in 1956, after a workshop at Dartmouth College (Figure 1). In the workshop, many AI groups showed promising results in computer learning of checkers strategies, solving word problems in algebra and proving logical theorems. These tasks involved mostly pattern recognition and computational learning. All AI systems were designed to execute and maximise its chance of \u2018winning\u2019 within a constructed environment. The term \u2018machine learning\u2019 (ML) was subsequently coined by Arthur Samuel in 1959 and stated that \u201cthe computer should have the ability to learn using various statistical techniques, without being explicitly programmed\u201d. Using ML, the algorithm can learn and make predictions based on the data that has been fed into the training phase, using either a supervised or unsupervised approach. ML has been widely adopted in applications such as computer vision and predictive analytics using complex mathematical models. In supervised learning, the computer is trained with labelled examples, also known as ground truth, whereas for unsupervised learning, no labelling is required for the algorithm to find its own structure in the input. The majority of AI application in biomedical research uses supervised learning. DL utilizes multiple processing layers to learn representation of data with multiple levels of abstraction. Although some forms of deep neural networks have already been investigated in the past, the advent of graphic processing units (GPU) with improved processing power, larger annotated datasets, and other factors, have recently boosted its diagnostic performance in many domains. Using learning approaches such as backpropagation, a ML or DL system is able to discover intricate structure in large data sets, then changing its internal parameters that are used to compute the representation in each layer from the previous one. These approaches permit the use of regional samples to allow the network to learn to detect biomarkers; furthermore these approaches use complete images, and associate the entire image with a diagnostic output, thereby eliminating the use of \u201chand-engineered\u201d image features. Given the much improved performance, DL has been widely adopted in image recognition, speech recognition and natural language processing. General Approach in Building a Robust AI system This section explains some common terminologies, software framework, network architectures, datasets selection, assistive vs. autonomous AI system, consideration factors to ensure the robustness of these algorithms (Table 1). In order to build a robust DL system, it is important to have 2 main components \u2013 the \u2018brain\u2019 (technical networks \u2013 Convolutional Neural Network (CNN) and the \u2018dictionary\u2019 (the datasets). 1. What is a CNN? A CNN is a deep neural network consisting of a cascade of processing layers that resemble the biological processes of the animal visual cortex. It transforms the input volume into an output volume via a differentiable function. Inspired by Hubel and Weisel, each neuron in the visual cortex will respond to the stimulus that is specific to a region within an image, similar to how the brain neuron would respond to the visual stimuli, that will activate a particular region of the visual space, known as the receptive field. These receptive fields are tiled together to cover the entire visual field. Two classes of cells are found in this region \u2013 simple vs complex cells. The simple cells active when they detect edge-like patterns, while the more complex cells activate when they have a larger receptive field and are invariant to the position of the pattern. Broadly, the CNN can be divided into the input, hidden (also known as featureextraction layers) and output layers (Figure 2A). The hidden layers usually consist of convolutional, pooling, fully connected and normalization layers, and the number of hidden layers will differ for different CNNs. The input layer specifies the width, height and the number of channels (usually 3 channels \u2013 red, green and blue). The convolutional layer is the core building block of a CNN, transforming the input data by applying a set of filters (also known as kernels) that acts as the feature detectors. The filter will slide over the input image to produce a feature map (as the output). A CNN learns the values of these filters weights on its own during the training process, although the specific parameters such as number of filters, filter size, network architecture still need to be set prior to that. Additional operations called activations (for example ReLU or Rectified Linear Unit) are used after every convolution operation. For pooling, the aim is to reduce the dimensionality of each feature map and make it somewhat spatially invariant, and retain the most important information. Pooling can be divided into different types: maximum, average and minimum. In the case of maximum pooling, the largest element from the rectified feature map will be taken (Figure 2B). The output from the convolutional and pooling layers represent the high-level features of the input image. The purpose of the fully connected layer is to use these high-level features to classify the input image into various classes based on the training dataset. Following which, backpropagation is conducted to compute the network weights and uses the gradient descent to update all filters and parameter values to minimize the output error. T",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/5881fb094b08dfbc93bea2a226040877f4535792",
        "citation_count": 0
    },
    {
        "title": "Efficient Domain Adaptation of Multimodal Embeddings using Constrastive Learning",
        "abstract": "Recent advancements in machine learning (ML), natural language processing (NLP), and foundational models have shown promise for real-life applications in critical, albeit compute-constrainted fields like healthcare. In such areas, combining foundational models with supervised ML offers potential for automating tasks like diagnosis and treatment planning, but the limited availability of onsite computational resources pose significant challenges before applying these technologies effectively: Current approaches either yield subpar results when using pretrained models without task-specific adaptation, or require substantial computational resources for fine-tuning, which is often a barrier to entry in such environments. This renders them inaccessible in applications where performance and quality standards are high, but computational resources are scarce. To bridge the gap between best-in-class performance and accessibility, we propose a novel method for adapting foundational, multimodal embeddings to downstream tasks, without the need of expensive fine-tuning processes. Our method leverages frozen embeddings from Large Language Models (LLMs) and Vision Models, and uses contrastive learning to train a small, task-specific nonlinear projection that can be used in the downstream task, without having to fine-tune the original foundational models. We show that this efficient procedure leads to significant performance improvements across various downstream tasks, and perhaps more importantly with minimal computational overhead, offering a practical solution for the use of advanced, foundational ML models in resource-constrained settings.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/58a8412206676666e04bc52794fbf786269b4386",
        "citation_count": 0
    },
    {
        "title": "A Review on Machine Learning Strategies for Real-World Engineering Applications",
        "abstract": "Huge amounts of data are circulating in the digital world in the era of the Industry 5.0 revolution. Machine learning is experiencing success in several sectors such as intelligent control, decision making, speech recognition, natural language processing, computer graphics, and computer vision, despite the requirement to analyze and interpret data. Due to their amazing performance, Deep Learning and Machine Learning Techniques have recently become extensively recognized and implemented by a variety of real-time engineering applications. Knowledge of machine learning is essential for designing automated and intelligent applications that can handle data in fields such as health, cyber-security, and intelligent transportation systems. There are a range of strategies in the field of machine learning, including reinforcement learning, semi-supervised, unsupervised, and supervised algorithms. This study provides a complete study of managing real-time engineering applications using machine learning, which will improve an application's capabilities and intelligence. This work adds to the understanding of the applicability of various machine learning approaches in real-world applications such as cyber security, healthcare, and intelligent transportation systems. This study highlights the research objectives and obstacles that Machine Learning approaches encounter while managing real-world applications. This study will act as a reference point for both industry professionals and academics, and from a technical standpoint, it will serve as a benchmark for decision-makers on a range of application domains and real-world scenarios.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/58b43268380002b916457746d9863b55c23e62c4",
        "citation_count": 39
    },
    {
        "title": "Personalized Nutrition\u2014Genes, Diet, and Related Interactive Parameters as Predictors of Cancer in Multiethnic Colorectal Cancer Families",
        "abstract": "To personalize nutrition, the purpose of this study was to examine five key genes in the folate metabolism pathway, and dietary parameters and related interactive parameters as predictors of colorectal cancer (CRC) by measuring the healthy eating index (HEI) in multiethnic families. The five genes included methylenetetrahydrofolate reductase (MTHFR) 677 and 1298, methionine synthase (MTR) 2756, methionine synthase reductase (MTRR 66), and dihydrofolate reductase (DHFR) 19bp, and they were used to compute a total gene mutation score. We included 53 families, 53 CRC patients and 53 paired family friend members of diverse population groups in Southern California. We measured multidimensional data using the ensemble bootstrap forest method to identify variables of importance within domains of genetic, demographic, and dietary parameters to achieve dimension reduction. We then constructed predictive generalized regression (GR) modeling with a supervised machine learning validation procedure with the target variable (cancer status) being specified to validate the results to allow enhanced prediction and reproducibility. The results showed that the CRC group had increased total gene mutation scores compared to the family members (p < 0.05). Using the Akaike\u2019s information criterion and Leave-One-Out cross validation GR methods, the HEI was interactive with thiamine (vitamin B1), which is a new finding for the literature. The natural food sources for thiamine include whole grains, legumes, and some meats and fish which HEI scoring included as part of healthy portions (versus limiting portions on salt, saturated fat and empty calories). Additional predictors included age, as well as gender and the interaction of MTHFR 677 with overweight status (measured by body mass index) in predicting CRC, with the cancer group having more men and overweight cases. The HEI score was significant when split at the median score of 77 into greater or less scores, confirmed through the machine-learning recursive tree method and predictive modeling, although an HEI score of greater than 80 is the US national standard set value for a good diet. The HEI and healthy eating are modifiable factors for healthy living in relation to dietary parameters and cancer prevention, and they can be used for personalized nutrition in the precision-based healthcare era.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/58f5be2ad4c12284bd8db53d4661ce853d849248",
        "citation_count": 27
    },
    {
        "title": "Personal View: Learning from the Russians",
        "abstract": "Liz sneezed again and Alexandr's worried countenance became almost panicky. He summoned his secretary into the office who, in response to a few barked commands, adopted the same anxious look and hurriedly ushered Liz out of the room. It was our first full day in Russia and we did not want to appear rude or lacking in diplomacy, but we were worried by the apparent abduction of our colleague. The interpreter laughed and explained to us that Liz had been taken downstairs to the \u201csalt cave\u201d for treatment of her cold. \n \nWe had been sent from the United Kingdom to conduct a review of the Podmoskovny Lyceum, a charity-funded boarding school near Moscow. The lyceum provides top quality care, education, and accommodation free of charge for a specially selected group of children who come from disadvantaged backgrounds, have been victims of terrorism, have lived in areas of conflict, or whose parents serve in the Russian Border Guards in remote corners of the country. The school had approached a charitable foundation in the UK for funding, and the foundation had set up a review team of advisers to visit the school and make recommendations. Details sent with the funding requests included paying full time salaries for four doctors, a dentist, and two nurses to serve a population of only 136 children, so there was no argument with the suggestion that a doctor be part of the review team. \n \n \nAll food served is first tasted by a doctor \n \n \nMy first impression was one of pure astonishment at the medical facilities with which the school had been equipped. There were consulting rooms, treatment rooms, and isolation rooms, spinal stretching beds designed to treat minor spinal misalignments and mild scoliosis, inhalators and ultraviolet lamps to treat colds and runny noses, heat therapy, ultrasound therapy, magnet therapy, laser therapy\u2014\u201cLasers can treat everything\u201d was the repeated refrain of the senior doctor\u2014a visual biofeedback machine to correct squints, and of course the aforementioned salt cave. The salt cave is a small room with the walls, floor, and ceiling covered in salt; salt dust is fanned into the darkened room while the patient lies on a deckchair listening to classical music and looking at soothing coloured lights. It is used to treat coughs and chesty colds and also for a number of skin conditions. At the lyceum they believe that if all the children spend prophylactic time in the salt cave, it will reduce the overall number of colds suffered, so each child receives a total of 10 hours of salt cave therapy in a year. \n \nPerhaps the most striking feature for me, and that for which I was least prepared, was the cultural difference in healthcare attitudes. I have heard it described as Russian health paranoia but I think this is inaccurate. Of course it sounded extreme to learn that term time interaction with children from outside (such as in sports matches) is discouraged for fear of bringing infections in; that at the first signs of a cold a child is isolated from his or her peers for two to five days; that all kitchen staff undergo a daily medical examination; that all food preparation is supervised by either a doctor or nurse; and that all food served is first tasted by a doctor. However, despite the lack of evidence for many of these interventions, there is perhaps a lot to be learnt from such an attitude. \n \nWhile at such an institution in the UK we would think, \u201cWhat do the children need in terms of health care?\u201d at the lyceum they think, \u201cWhat more can we provide?\u201d The medical team are fully involved in the daily life of the lyceum and are able to take a holistic approach to the health of the children. This includes attention to diet, physical exercise (a doctor can \u201cprescribe\u201d physical exercise for children in addition to their normal fitness programmes), hygiene and sanitation (the doctors conduct weekly inspections of the living accommodation), and health education delivered either individually or in small groups. \n \nVisiting this Russian institution has given me a new perspective regarding primary care and public health in the UK. How many doctors in this country wish they had more power to control the diet, physical lifestyles, and living environments of their patients? \n \nAs for the salt cave, there is some evidence for its role in respiratory medicine though I could find none regarding dermatology or resistance to viral infections (Allergy 2006;61: 605-10 [PubMed] and Journal of Aerosol Medicine 1995;8: 221-32 [PubMed]). I did, however, expose myself to a short treatment and found that the soothing combination of classical music, coloured lights, and comfortable deckchair left me with a tremendous feeling of wellbeing. I imagine for the children it is a greatly appreciated break from the general hustle of a busy boarding school, and I only wish I could afford the $10 000 (\u00a35,400; \u20ac7,800) to have one installed in my own home.",
        "year": 2006,
        "url": "https://www.semanticscholar.org/paper/591af68545560d3835f1b770d5b2fc6910022bc3",
        "citation_count": 0
    },
    {
        "title": "AI Ethics Journal",
        "abstract": "Machine learning algorithms have been shown to be capable of diagnosing cancer, Alzheimer\u2019s disease and even selecting treatment options. However, the majority of machine learning systems implemented in the healthcare setting tend to be based on the supervised machine learning paradigm. These systems tend to rely on previously collected data annotated by medical personnel from specific populations. This leads to \u2018learnt\u2019 machine learning models that lack generalizability. In other words, the machine\u2019s predictions are not as accurate for certain populations and can disagree with recommendations of medical experts who did not annotate the data used to train these models. With each human-decided aspect of building supervised machine learning models, human bias is introduced into the machine\u2019s decision-making. This human bias is the source of numerous ethical concerns. In this article, we describe and discuss three challenges to generalizability which affect real world deployment of machine learning systems in clinical practice. First, there is bias which occurs due to the characteristics of the population from which data was collected. Second, the bias which occurs due to the prejudice of the expert annotator involved. And third, the bias by the timing of when A.I. processes start training themselves. We also discuss the future implications of these biases. More importantly, we describe how responsible data sharing can help mitigate the effects of these biases \u2013 and allow for the development of novel algorithms which may be able to train in an unbiased manner. We discuss environmental and regulatory hurdles which hinder the sharing of data in medicine \u2013 and discuss possible updates to current regulations that may enable ethical data sharing for machine learning. With these updates in mind, we also discuss emerging algorithmic frameworks being used to create medical machine learning systems, which can eventually learn to be free from population-and expert-induced bias. These models can then truly be deployed to clinics worldwide, making medicine both cheaper and more accessible for the world at large.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/59396284de350e3efbb8549bf46d5fcb6b860624",
        "citation_count": 4
    },
    {
        "title": "Computer-aided automated detection of kidney disease using supervised learning technique",
        "abstract": "In this paper, we propose an efficient home-based system for monitoring chronic kidney disease (CKD). As non-invasive disease identification approaches are gaining popularity nowadays, the proposed system is designed to detect kidney disease from saliva samples. Salivary diagnosis has advanced its popularity over the last few years due to the non-invasive sample collection technique. The use of salivary components to monitor and detect kidney disease is investigated through an experimental investigation. We measured the amount of urea in the saliva sample to detect CKD. Further, this article explains the use of predictive analysis using machine learning techniques and data analytics in remote healthcare management. The proposed health monitoring system classified the samples with an accuracy of 97.1%. With internet facilities available everywhere, this methodology can offer better healthcare services, with real-time decision support in remote monitoring platform.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/593ac25b704afb53c240d96c299568f0fc229d82",
        "citation_count": 3
    },
    {
        "title": "Predictive Modelling of Stroke Occurrence among Patients using Machine Learning",
        "abstract": "Stroke is a global public health concern with severe consequences. Early detection and accurate prediction of stroke occurrence are crucial for effective prevention and targeted interventions. This study proposes a machine learning-based approach to predict the likelihood of stroke among patients. A comprehensive dataset encompassing demographic, clinical, and lifestyle factors of a large patient cohort was employed. Variables such as age, gender, hypertension, diabetes, smoking status, BMI, and medical history were considered. Advanced machine learning algorithms, including logistic regression, decision trees, random forests, and support vector machines, were utilized to analyses the dataset and develop a predictive model. The results demonstrate that the machine learning-based approach achieved high predictive accuracy in identifying individuals at risk of stroke. The model exhibited excellent sensitivity and specificity, enabling effective stratification of patients based on their stroke likelihood. Developing an accurate stroke prediction model using machine learning holds immense potential for proactive healthcare strategies and personalized patient care. Early identification of high-risk patients enables timely intervention and implementation of preventive measures, potentially reducing the burden of stroke-related complications. This study showed that the supervised K-Nearest Neighbors Algorithm (K-NN) model outperforms the other methods, with an accuracy of 95% compared with other models.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/59bfad03365fec7fb08677034d9da3a0907afc45",
        "citation_count": 0
    },
    {
        "title": "Personalized Machine Learning-Based Prediction of Wellbeing and Empathy in Healthcare Professionals",
        "abstract": "Healthcare professionals are known to suffer from workplace stress and burnout, which can negatively affect their empathy for patients and quality of care. While existing research has identified factors associated with wellbeing and empathy in healthcare professionals, these efforts are typically focused on the group level, ignoring potentially important individual differences and implications for individualized intervention approaches. In the current study, we implemented N-of-1 personalized machine learning (PML) to predict wellbeing and empathy in healthcare professionals at the individual level, leveraging ecological momentary assessments (EMAs) and smartwatch wearable data. A total of 47 mood and lifestyle feature variables (relating to sleep, diet, exercise, and social connections) were collected daily for up to three months followed by applying eight supervised machine learning (ML) models in a PML pipeline to predict wellbeing and empathy separately. Predictive insight into the model architecture was obtained using Shapley statistics for each of the best-fit personalized models, ranking the importance of each feature for each participant. The best-fit model and top features varied across participants, with anxious mood (13/19) and depressed mood (10/19) being the top predictors in most models. Social connection was a top predictor for wellbeing in 9/12 participants but not for empathy models (1/7). Additionally, empathy and wellbeing were the top predictors of each other in 64% of cases. These findings highlight shared and individual features of wellbeing and empathy in healthcare professionals and suggest that a one-size-fits-all approach to addressing modifiable factors to improve wellbeing and empathy will likely be suboptimal. In the future, such personalized models may serve as actionable insights for healthcare professionals that lead to increased wellness and quality of patient care.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/59dd8b75d851e89ed2c2f6a5f4d8cce3af7b07db",
        "citation_count": 2
    },
    {
        "title": "Using NASA Satellite Data Sources and Geometric Deep Learning to Uncover Hidden Patterns in COVID-19 Clinical Severity",
        "abstract": "As multiple adverse events in 2021 illustrated, virtually all aspects of our societal functioning -- from water and food security to energy supply to healthcare -- more than ever depend on the dynamics of environmental factors. Nevertheless, the social dimensions of weather and climate are noticeably less explored by the machine learning community, largely, due to the lack of reliable and easy access to use data. Here we present a unique not yet broadly available NASA's satellite dataset on aerosol optical depth (AOD), temperature and relative humidity and discuss the utility of these new data for COVID-19 biosurveillance. In particular, using the geometric deep learning models for semi-supervised classification on a county-level basis over the contiguous United States, we investigate the pressing societal question whether atmospheric variables have considerable impact on COVID-19 clinical severity.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/59ed2eb96d169f297fcf26f977472b5772b94cf2",
        "citation_count": 1
    },
    {
        "title": "Analysis of classification based predicted disease using machine learning and medical things model",
        "abstract": "Health diseases have been issued seriously harmful in human life due to different dehydrated food and disturbance of working environment in the organization. Precise prediction and diagnosis of disease become a more serious and challenging task for primary deterrence, recognition, and treatment. Thus, based on the above challenges, we proposed the Medical Things (MT) and machine learning models to solve the healthcare problems with appropriate services in disease supervising, forecast, and diagnosis. We developed a prediction framework with machine learning approaches to get different categories of classification for predicted disease. The framework is designed by the fuzzy model with a decision tree to lessen the data complexity. We considered heart disease for experiments and experimental evaluation determined the prediction for categories of classification. The number of decision trees (M) with samples (MS), leaf node (ML), and learning rate (I) is determined as MS=20, ML=3, I=0.1, then mean test score(m) is 20.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/5a2f722504a5d9ef56974d9abc16d685b08729ca",
        "citation_count": 0
    },
    {
        "title": "FRAUDULENT HEALTH INSURANCE CLAIMS DETECTION USING MACHINE LEARNING",
        "abstract": ": Health insurance fraud harm the integrity and long-term viability of global healthcare systems. With the expanding use of digital technology and electronic health records, there is a greater need for effective fraud detection tools to defend against financial losses and assure the quality of service. This review paper provides a comprehensive summary of current research on detecting false health insurance claims utilising machine learning approaches. This paper discusses a variety of methodology, including supervised and unsupervised learning algorithms, feature engineering techniques, anomaly detection methods, and ensemble learning approaches. It examines the issues of imbalanced datasets, noisy data, and model interpretability, as well as techniques for overcoming them.This research also assesses the effectiveness of machine learning models in detecting false health insurance claims utilizing real-world datasets and performance measurements such as accuracy, precision, recall, and F1 score. We hope that this poll will provide useful insights into the present status of research in this subject, as well as indicate future research directions to improve healthcare fraud detection systems.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/5b3344c9a9d9ebe1fb24fa652d34890e0d915887",
        "citation_count": 0
    },
    {
        "title": "Classification of Electromyographic Hand Gesture Signals Using Modified Fuzzy C-Means Clustering and Two-Step Machine Learning Approach",
        "abstract": "Understanding and classifying electromyogram (EMG) signals is of significance for dexterous prosthetic hand control, sign languages, grasp recognition, human-machine interaction, etc.. The existing research of EMG-based hand gesture classification faces the challenges of unsatisfied classification accuracy, insufficient generalization ability, lack of training data and weak robustness. To address these problems, this paper combines unsupervised and supervised learning methods to classify an EMG dataset consisting of 10 classes of hand gestures. To lessen the difficulty of classification, clustering methods including subtractive clustering and fuzzy c-means (FCM) clustering algorithms are employed first to obtain the initial partition of the inputs. In particular, modified FCM algorithm is proposed to accustom the conventional FCM to the multi-class classification problem. Based on the grouping information obtained from clustering, a type of two-step supervised learning approach is proposed. Specifically, a top-classifier and three sub-classifiers integrated with windowing method and majority voting are employed to accomplish the two-step classification. The results demonstrate that the proposed method achieves 100% test accuracy and the strongest robustness compared to the conventional machine learning approaches, which shows the potential for industrial and healthcare applications, such as movement intention detection, grasp recognition and dexterous prostheses control.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5b6a4fbc195d21c3c3d59821eeb0053d8c204745",
        "citation_count": 34
    },
    {
        "title": "Detecting Arrhythmia Heart Condition using Supervised Machine Learning Algorithms",
        "abstract": "\u2015 Arrhythmia is a common heart condition commonly due to irregular heartbeats, which can have serious implications and significant threats on a person's health. The heart can beat excessively quickly, too slowly, or irregularly as a result of disturbances in the electrical impulses that regulate heart contractions, which is known as an arrhythmia. For effective medical intervention it is crucial to detect and diagnose arrhythmia at an early stage. Machine learning algorithms have shown positive results in automating the arrhythmia detection process in recent years. The advantages of using Machine Learning algorithms include accuracy in handling and analyzing complex ECG patterns, early arrhythmia detection, personalized real-time monitoring, reduced human error, efficient big data handling and resource optimization. Machine learning algorithms can provide clinicians with additional information and insights to aid in their decisionmaking process. This can facilitate more informed treatment plans and interventions. In order to achieve accurate detection rates, this research investigates the use of different machine learning algorithms on the MIT-BIH Arrhythmia Database. With a primary focus on accuracy, precision, recall, and F1-Score, this study compares multiple algorithms in detail, including Random Forest (RF) Classification, Support Vector Machines (SVM), K-Nearest Neighbor (KNN), and Decision Tree Classification using the CART (Classification and Regression Trees) algorithm. For the automated strategy Random Forest Classifier can predict unexpected sudden cardiac death with an average accuracy of 98.91%. Our results demonstrate the potential of machine learning techniques in providing valuable assistance to healthcare professionals in diagnosing arrhythmia effectively and leading to more effective treatment approaches. They also contribute to research, innovation and continuous improvement in patient health care.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/5b92aad8cd297be1315efff63fe36fa60324b881",
        "citation_count": 0
    },
    {
        "title": "Comparative Machine Learning Approach in Dementia Patient Classification using Principal Component Analysis",
        "abstract": ": Dementia is one of the brain diseases that were significantly affecting the global population. Mainly it is exposed to older people with an association of memory loss and thinking ability. Unfortunately, there are no proper medications for dementia prevention. Doctors are suggesting that early prediction of this disease can somehow help the patient by slowdown the dementia progress. Nowadays, many computer scientists were using machine learning (ML) algorithms and data-mining operations in the healthcare environment for predicting and diagnosing diseases. The current study designed to develop an ML model for better classification of patients associated with dementia. For that, we developed a feature extraction method with the involvement of three supervised ML techniques such as support vector machines (SVM), K-nearest neighbor (KNN), and logistic regression (LR). Principal component analysis (PCA) was selected to extract relevant features related to the targeted outcome. Performance measures were assessed with accuracy, precision, recall, and AUC values. The accuracy of SVM, LR, and KNN was found as 0.967, 0.983, and 0.976, respectively. The AUC of LR (0.997) and KNN (0.966) were recorded the highest values. With the highest AUC values, KNN and LR were considered optimal classifiers in dementia prediction.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5c0c5bb4e11debad108c591237858784529e74d1",
        "citation_count": 10
    },
    {
        "title": "Facial Emotional Recognition With Deep Learning On Pepper Robot",
        "abstract": "Author Mengge Hu Title Facial Emotional Recognition With Deep Learning On Pepper Robot Year 2019 Language English Pages 59 Name of Supervisor Yang Liu There are millions of people in the world, who suffer from life-threatening diseases each year. It has been reported that the magnitude of the disparities of healthcare quality worldwide is still significant. In particular, things can lead to high mortality, such as inadequate doctor-patient ratio and lack of intelligent medical facilities. This situation, however, has been largely alleviated by the rapid developments in fields of Computer Aided Design (CAD) and Robotics. For example, the computeraided machine can help doctors analyze radiological images and make diagnosis more quickly and accurately; the medical automatic system offers patients a broad and wide access to medical resources in a more effective way. This project is the use of robots for capturing and identifying the patient's expression, through the deep learning of the computer to determine the patient's mental state. The main research works concludes six contents, face detected by photos, resolved by Open Source Computer Vision Library (OpenCV), facial dataset, resolved by Kaggle\u2019s Fer2013, the processing training and testing the facial dataset, resolved by the model Convolutional Neural Network (CNN), showing the result by a bar chart is the next one, resolved by Matplotlib and taking pictures for patients, resolved by one of Pepper\u2019s modules, ALPhotoCapture and face detected by the robot, resolved by one of Pepper\u2019s modules, ALFaceDetection.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/5c1d24cd2dd06e8e09826d8afca43a5a0e21bc0a",
        "citation_count": 1
    },
    {
        "title": "Deep Learning Approaches for Clustering Source Code by Functionality",
        "abstract": "With the rise of artificial intelligence, applications for machine learning can be found in nearly every aspect of modern life, from healthcare and transportation to software services like recommendation systems. Consequently, there are now more developers engaged in the field than ever with the number of implementations rapidly increasing by the day. In order to meet the new demands, it would be useful to provide services that allow for an easy orchestration of a large number of repositories. Enabling users to easily share, access and search for source code would be beneficial for both research and industry alike. A first step towards this is to find methods for clustering source code by functionality. The problem of clustering source code has previously been studied in the literature. However, the proposed methods have so far not leveraged the capabilities of deep neural networks (DNN). In this work, we investigate the possibility of using DNNs to learn embeddings of source code for the purpose of clustering by functionality. In particular, we evaluate embeddings from Code2Vec and cuBERT models for this specific purpose. From the results of our work we conclude that both Code2Vec and cuBERT are capable of learning such embeddings. Among the different frameworks that we used to fine-tune cuBERT, we found the best performance for this task when fine-tuning the model under the triplet loss criterion. With this framework, the model was capable of learning embeddings that yielded the most compact and wellseparated clusters. We found that a majority of the cluster assignments were semantically coherent with respect to the functionalities implemented by the methods. With these results, we have found evidence indicating that it is possible to learn embeddings of source code that encode the functional similarities among the methods. Future research could therefore aim to further investigate the possible applications of the embeddings learned by the different frameworks. Sammanfattning Djupinl\u00e4rningsmetoder f\u00f6r gruppering av k\u00e4llkod efter funktionalitet Med den avsev\u00e4rda \u00f6kningen av anv\u00e4ndandet av artificiell intelligens g\u00e5r det att finna till\u00e4mpningar f\u00f6r maskininl\u00e4rningsalgoritmer i n\u00e4stan alla aspekter av det moderna livet, fr\u00e5n sjukv\u00e5rd och transport till mjukvarutj\u00e4nster som rekommendationssystem. Till f\u00f6ljd av detta s\u00e5 \u00e4r det fler utvecklare \u00e4n n\u00e5gonsin engagerade inom omr\u00e5det, d\u00e4r antalet nya implementationer \u00f6kar f\u00f6r var dag. F\u00f6r att m\u00f6ta de nya kraven skulle det vara anv\u00e4ndbart att kunna tillhandah\u00e5lla tj\u00e4nster som m\u00f6jligg\u00f6r en enkel hantering av ett stort antal kodf\u00f6rr\u00e5d. Att g\u00f6ra det m\u00f6jligt f\u00f6r anv\u00e4ndare att enkelt dela, komma \u00e5t och s\u00f6ka efter k\u00e4llkod skulle vara till nytta inom b\u00e5de forskning och industri. Ett f\u00f6rsta steg mot detta \u00e4r att hitta metoder som g\u00f6r det m\u00f6jligt att klustra k\u00e4llkod med avseende p\u00e5 funktionalitet. Problemet med klustring av k\u00e4llkod \u00e4r n\u00e5got som har tidigare studerats. De f\u00f6reslagna metoderna har dock hittils inte utnyttjat kapaciteten hos djupa neurala n\u00e4tverk (DNN). I detta arbete unders\u00f6ker vi m\u00f6jligheten att anv\u00e4nda DNN f\u00f6r inl\u00e4rning av inb\u00e4ddningar av k\u00e4llkod i syfte att klustra med avseende p\u00e5 funktionalitet. I synnerhet s\u00e5 utv\u00e4rderar vi inb\u00e4ddningar fr\u00e5n Code2Vecoch cuBERT-modeller f\u00f6r detta specifika \u00e4ndam\u00e5l. Fr\u00e5n resultatet av v\u00e5rt arbete drar vi slutsatsen att b\u00e5de Code2Vec och cuBERT har kapacitet f\u00f6r att l\u00e4ra sig s\u00e5dana inb\u00e4ddningar. Bland de olika ramverken som vi unders\u00f6kte f\u00f6r att finjustera cuBERT, fann vi att modellen som finjusterades under triplet-f\u00f6rlustkriteriet var b\u00e4st l\u00e4mpad f\u00f6r denna uppgift. Med detta ramverk kunde modellen l\u00e4ra sig inb\u00e4ddningar som resulterade i de mest kompakta och v\u00e4l separerade klusterna, d\u00e4r en majoritet av klustertilldelningarna var semantiskt sammanh\u00e4ngande med avseende p\u00e5 funktionaliteten som metoderna implementerade. Med dessa resultat har vi funnit bel\u00e4gg som tyder p\u00e5 att det \u00e4r m\u00f6jligt att l\u00e4ra sig inb\u00e4ddning av k\u00e4llkod som bevarar och \u00e5tger funktionella likheter mellan metoder. Framtida forskning kan d\u00e4rf\u00f6r syfta till att ytterligare unders\u00f6ka de olika m\u00f6jliga anv\u00e4ndningsomr\u00e5dena f\u00f6r de inb\u00e4ddningar som l\u00e4rts in inom de olika ramverken. Acknowledgements First I would like to express my deepest gratitude to my supervisor Amir H. Payberah for providing me with the opportunity to take part in the project at RISE and for his continuous and invaluable guidance throughout this semester. I want to direct special thanks to Francisco J. Pe\u00f1a, for his feedback and our many long and interesting conversations, ranging from concepts of deep learning to simple friendly banter. Furthermore, I would like to express my gratitude to Sepideh Pashami and Ahmad Al-Shishtawy at RISE for the help and suggestions that has gotten me through this project. I also want to thank my examiner Martina Scolamiero for her continuous encouragement and feedback. She has been a much needed voice of reason in this project. Last but certainly not least, I would like to extend a most heartfelt thank you to my friends and family that have given me an unwavering support throughout the years. Marcus H\u00e4gglund Stockholm, May 2021",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/5c533caffc5f44ef91e69ec8fced19ffff60f5fb",
        "citation_count": 0
    },
    {
        "title": "Supervised Learning Methods for Fraud Detection in Healthcare Insurance",
        "abstract": null,
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/5c637753bdbc642fb375364713bc7aa5e24f58f4",
        "citation_count": 25
    },
    {
        "title": "Reimagining Human-Machine Interactions through Trust-Based Feedback",
        "abstract": "Intelligent machines, and more broadly, intelligent systems, are becoming increasingly common in the everyday lives of humans. Nonetheless, despite significant advancements in automation, human supervision and intervention are still essential in almost all sectors, ranging from manufacturing and transportation to disaster-management and healthcare. These intelligent machines interact and collaborate with humans in a way that demands a greater level of trust between human and machine. While a lack of trust can lead to a human's disuse of automation, over-trust can result in a human trusting a faulty autonomous system which could have negative consequences for the human. Therefore, human trust should be calibrated to optimize these human-machine interactions. This calibration can be achieved by designing human-aware automation that can infer human behavior and respond accordingly in real-time.In this dissertation, I present a probabilistic framework to model and calibrate a human's trust and workload dynamics during his/her interaction with an intelligent decision-aid system. More specifically, I develop multiple quantitative models of human trust, ranging from a classical state-space model to a classification model based on machine learning techniques. Both models are parameterized using data collected through human-subject experiments. Thereafter, I present a probabilistic dynamic model to capture the dynamics of human trust along with human workload. This model is used to synthesize optimal control policies aimed at improving context-specific performance objectives that vary automation transparency based on human state estimation. I also analyze the coupled interactions between human trust and workload to strengthen the model framework. Finally, I validate the optimal control policies using closed-loop human subject experiments. The proposed framework provides a foundation toward widespread design and implementation of real-time adaptive automation based on human states for use in human-machine interactions.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5c70ff02ae491801cb661507a3d016675b99e5f5",
        "citation_count": 1
    },
    {
        "title": "Dynamic Ensemble Modelling for Prediction of Influenza Like Illnesses: A Framework",
        "abstract": "One of the advantages we have today in the fight against coronavirus (COVID-19) that wasn\u2019t as advanced in the SARS outbreak of 2003 is big data analytics and the major advancements in machine intelligence and artificial intelligence technologies. The United States of America\u2019s statistical surveillances have listed pneumonia/influenza as the seventh leading cause of death. Severe influenza seasons can result in more than 60,000 excess deaths and more than 200,000 hospitalizations. US witnessed fifty-five-thousand deaths (55,000 people) caused by pneumonia/ influenza among total number of nine-hundred-thousand deaths (900,000 people) (%6.0)-during Influenza outbreak in 2018. Patients aged 65 years or older are at particular risk for death from viral pneumonia as well as from influenza not complicated by pneumonia. Deaths in these patients account for 89% of all pneumonia and/or influenza deaths. The healthcare industry needs researchers who are interested in applying machine learning for surveillance, prediction and diagnosis of diseases. Many healthcare-related researches, states that machine learning (ML) is the lifesaving technology that will renovate healthcare services. This technology challenges the traditional reactive approach to healthcare. It is the predictive, proactive, and preventive life-saving qualities that make it a critically essential capability in every health system. In order to help in the prediction of pneumonia/influenza outbreaks, regression and classification techniques such as Ridge, Decision Tree Regression/Classification, Multiple Linear Regression, Logistic Regression Classification, K-Nearest Neighbor and Support Vector Machine Regression can be applied to predict forthcoming instances based on a trustworthy training and validation datasets. Accurate predictions will help healthcare stakeholders and governments to address the medical and physical needs during outbreak season. In this paper we exploit a methodology for predicting the number of deaths due to Influenza and Pneumonia in USA Cities using different machine supervised learning algorithms. Each algorithm is implemented, fitted to training dataset, validated by the validation dataset, and evaluated by means of Root Mean Square Error (RMSE) and R2 metric. KNN is the most fitted to the dataset by giving 92.6% accuracy. The least fitted algorithm is Logistic Regression by giving 51% accuracy. The remaining tested algorithms give accuracy levels from 80% to 92%. Evaluation Metrics, R2, and RMSE are obtained both analytically and programmatically using Python-based simulation. Results from both methods are well-matched. The promising results encourage the idea of enhancing the performance of the predictor. A new predictor (KMR-Stack) is implemented by integration of the best three fitted algorithms (KNN, Multiple Linear Regression, Ridge) in one stack. KMR-Stack exceeded KNN accuracy ratio by giving 94.9% accuracy. In KMR,\u00a0Stack, another improvement was made in comparison with other stacking models introduced in the literature. The improvement included in the dynamicity of choosing the base-model regressors Hence, the stacked-integrated use of different machine learning algorithms showed increased prediction accuracies compared to the use of each individual algorithm, therefore improves influenza surveillance and potentially contributes in developing a robust defence strategy, which will collectively enhance human health.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5c8e3b8c5a5f94c9794087af38e365f4b5dd5b60",
        "citation_count": 1
    },
    {
        "title": "Predicting adverse pregnancy outcome in Rwanda using machine learning techniques",
        "abstract": "Background Adverse pregnancy outcomes pose significant risk to maternal and neonatal health, contributing to morbidity, mortality, and long-term developmental challenges. This study aimed to predict these outcomes in Rwanda using supervised machine learning algorithms. Methods This cross-sectional study utilized data from the Rwanda Demographic and Health Survey (RDHS, 2019\u20132020) involving 14,634 women. K-fold cross-validation (k = 10) and synthetic minority oversampling technique (SMOTE) were used to manage dataset partitioning and class imbalance. Descriptive and multivariate analyses were conducted to identify the prevalence and risk factors for adverse pregnancy outcomes. Seven machine learning algorithms were assessed for their accuracy, precision, recall, F1 score, and area under the curve (AUC). Results Of the pregnancies analyzed, 93.4% resulted in live births, while 4.5% ended in miscarriage, and 2.1% in stillbirth. Advanced maternal age(>30 years),women aged 30\u201334 years (adjusted odds ratio [AOR] = 5.755; 95% confidence interval [CI] = 3.085\u201310.074; p < 0.001), 35\u201339 years (AOR = 8.458; 95% CI = 4.507\u201310.571; p < 0.001), 40\u201344 years (AOR = 11.86; 95% CI = 6.250\u201321.842; p < 0.001), and 45\u201349 years (AOR = 14.233; 95% CI = 7.359\u201325.922; p < 0.001), compared to those aged 15\u201319 years, and multiple unions (polyandry) (AOR = 1.320; 95% CI = 1.104\u20131.573, p = 0.002), and women not visited by healthcare provider during pregnancy (AOR = 1.421; 95%CI = 1.300\u20131.611, p<0.001) were factors associated with an increased risk of adverse pregnancy outcomes. In contrast, being married (AOR = 0.894; 95% CI = 0.787\u20130.966) and attending at least two antenatal care (ANC) visits (AOR = 0.801; 95% CI = 0.664\u20130.961) were linked to reduced risk. The K-nearest neighbors (KNN) model outperformed other ML Models in predicting adverse pregnancy outcomes, achieving 86% accuracy, 89% precision, 97% recall, 93% F1 score, and an area under the curve (AUC) of 0.842. The ML models constantly highlighted that woman with advanced maternal age, those in multiple unions, and inadequate ANC were more susceptible to adverse pregnancy outcomes. Conclusions Machine learning algorithms, particularly KNN, are effective in predicting adverse pregnancy outcomes, facilitating early intervention and improved maternal and neonatal care.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5c9e942a8e116a3f2ea1754e9ae2ec5029b9d3d0",
        "citation_count": 1
    },
    {
        "title": "Cyber-Healthcare Kiosks for Healthcare Support in Developing Countries",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/5cc5cb6e69a4db40ff643267ee29242bf9b7128f",
        "citation_count": 13
    },
    {
        "title": "Unveiling the Power of Data: A Journey Through Machine Learning Techniques",
        "abstract": "Machine Learning Techniques: Unveiling the Power of Data-Driven Solutions\nMachine learning (ML) has become a transformative force across disciplines, revolutionizing how computers extract knowledge from data and tackle complex tasks without explicit programming. This research paper delves into the core principles of machine learning, exploring its fundamental techniques and their far-reaching applications. We embark on a journey through the two main paradigms that govern learning: supervised and unsupervised. Supervised learning equips algorithms to make informed predictions based on labeled data, encompassing tasks like spam filtering, disease diagnosis, and stock market forecasting. The algorithm ingests this data, which includes both the input features and the corresponding desired output, and learns the intricate relationships between them. This empowers it to generalize this knowledge to unseen data, enabling accurate predictions.\nUnsupervised learning, in contrast, thrives on unlabeled data, where the data points lack predefined categories or target variables. Here, the objective is to uncover the inherent structures or patterns within the data itself. Unsupervised learning techniques are invaluable for tasks like data clustering, where similar data points are grouped together to reveal underlying relationships. Additionally, they play a crucial role in dimensionality reduction, a process of compressing high-dimensional data into a lower-dimensional space for efficient processing and analysis. This is particularly beneficial when dealing with massive datasets that may overwhelm traditional computational methods.\nBeyond these fundamental paradigms, the landscape of machine learning extends further. Deep learning, a subfield inspired by the structure and function of the human brain, utilizes artificial neural networks with multiple layers. These complex networks are adept at learning intricate patterns from vast amounts of data, achieving remarkable success in areas like computer vision, natural language processing, and speech recognition. Deep learning models, for instance, power facial recognition technology, enabling our devices to identify individuals with exceptional accuracy. In the realm of natural language processing, deep learning algorithms fuel machine translation systems, allowing seamless communication across languages.\nReinforcement learning presents another powerful approach. Here, an agent interacts with an environment, learning through trial and error. The agent receives rewards for desired actions and penalties for undesired ones, constantly refining its decision-making process. This approach has applications in robotics, where robots can learn to navigate complex environments and perform tasks with increasing autonomy. Reinforcement learning is also used in game playing, where AI agents can learn optimal strategies through self-play and achieve superhuman levels of performance.\nAs machine learning continues its exponential growth, ethical considerations become paramount. Potential biases within the training data can lead to discriminatory outcomes in areas like loan approvals or facial recognition software. Additionally, the explainability and transparency of complex models, particularly deep learning models, raise concerns. To ensure responsible development and deployment of ML, addressing these issues is crucial. The field requires robust methodologies to mitigate bias in training data and develop techniques that make complex models interpretable, allowing us to understand the rationale behind their predictions.\nLooking towards the horizon, the future of machine learning is brimming with potential. From personalized healthcare with tailored treatment plans to self-driving cars that navigate roads with exceptional precision, ML promises to revolutionize various aspects of our lives. Continuous research and development will enhance the capabilities and robustness of machine learning models, further expanding their reach and impact. By harnessing the power of data and fostering responsible development practices, machine learning will undoubtedly play a pivotal role in shaping a more intelligent and data-driven future",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5ce6e2e05f57d04fa925cfcba1b24f2751601992",
        "citation_count": 0
    },
    {
        "title": "A Comparitive Study on Liver Disease Prediction using Supervised Learning Algorithms with Hyperparameter Tuning",
        "abstract": "The World Health Organization estimates that liver disease or liver cancer results in one million deaths annually, and that ten new cases of hepatitis B and C are diagnosed each day. Given the challenges and expenses associated with diagnosing liver disease, this study aims to evaluate the effectiveness of a range of Supervised Machine Learning algorithms in predicting and detecting the disease, with the objective of reducing healthcare costs. To achieve this goal, the Indian Liver Patient Dataset from UCI (University of California Irvine) repository is used. The study employs various classification algorithms, including Random Forest, Decision Tree, Decision Tree SMOTE, Support Vector Classifier, K-Nearest Neighbour, AdaBoost, Stochastic Gradient Descent, and Artificial Neural Network. The study shows that ANN is the most effective algorithm, achieving an impressive margin of 87 percent over the other algorithms.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/5ce9d1b280d297ac270e0a9506e5a5795ae98207",
        "citation_count": 7
    },
    {
        "title": "Supervised machine learning algorithms to predict the duration and risk of long-term hospitalization in HIV-infected individuals: a retrospective study",
        "abstract": "Objective The study aimed to use supervised machine learning models to predict the length and risk of prolonged hospitalization in PLWHs to help physicians timely clinical intervention and avoid waste of health resources. Methods Regression models were established based on RF, KNN, SVM, and XGB to predict the length of hospital stay using RMSE, MAE, MAPE, and R2, while classification models were established based on RF, KNN, SVM, NN, and XGB to predict risk of prolonged hospital stay using accuracy, PPV, NPV, specificity, sensitivity, and kappa, and visualization evaluation based on AUROC, AUPRC, calibration curves and decision curves of all models were used for internally validation. Results In regression models, XGB model performed best in the internal validation (RMSE = 16.81, MAE = 10.39, MAPE = 0.98, R2 = 0.47) to predict the length of hospital stay, while in classification models, NN model presented good fitting and stable features and performed best in testing sets, with excellent accuracy (0.7623), PPV (0.7853), NPV (0.7092), sensitivity (0.8754), specificity (0.5882), and kappa (0.4672), and further visualization evaluation indicated that the largest AUROC (0.9779), AUPRC (0.773) and well-performed calibration curve and decision curve in the internal validation. Conclusion This study showed that XGB model was effective in predicting the length of hospital stay, while NN model was effective in predicting the risk of prolonged hospitalization in PLWH. Based on predictive models, an intelligent medical prediction system may be developed to effectively predict the length of stay and risk of HIV patients according to their medical records, which helped reduce the waste of healthcare resources.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5d099caa3904b6832e81f99d7eb8af01afd52f68",
        "citation_count": 1
    },
    {
        "title": "An Intrusion Detection System for Healthcare Applications using Machine Learning",
        "abstract": "The Internet of Things (IoT) is an extension of the current Internet to all objects that can communicate, directly or indirectly, with electronic equipment that is connected to the Internet. IoT offers services in many areas related to human life such as health, transport, home, smart cities, etc. The security of these components and data transfers is a major issue. In the field of healthcare, a medical staff submits requests to the Internet of Medical Things (IoMT) for tasks execution. Intruders can submit false requests to disrupt the operation of these devices. The detection of these attacks requires the development of a reliable security system capable of detecting any intrusion during all phases of the execution process. In this work we propose a supervised Machine Learning based Intrusion Detection System (IDS) for Internet of Medical Things (IoMT), in which we have adopted a Features Selection approach to improve the proposed system performance. This ML-based IDS has been designed to detect suspicious or malicious activities in IoMT, thereby contributing to preventing privacy breaches and security attacks.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/5d48d1403612abf26bcd5441c50a6c7d623f65df",
        "citation_count": 0
    },
    {
        "title": "A proposed technique for predicting heart disease using machine learning algorithms and an explainable AI method",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5d7e35750e437f31da56ef83055a9808bf70b253",
        "citation_count": 5
    },
    {
        "title": "EDGE: Evolutionary Directed Graph Ensembles",
        "abstract": "Classi\ufb01cation tasks are being tackled in a plethora of scienti\ufb01c \ufb01elds, such as astronomy, \ufb01nance, healthcare, human mobility, and pharmacology, to name a few. Classi\ufb01cation is de\ufb01ned as a supervised learning approach that uses labeled data to assign instances to classes. A common approach to tackle these tasks are ensemble methods. These are methods that employ a set of models, instead of just one and combine the predictions of every model to obtain the prediction of the whole. Common obstacles in ensemble learning are the choice of base models to use and how best to aggregate the predictions of each individual to produce the ensemble\u2019s prediction. It is also expected to mitigate the weaknesses of its members while pooling their strengths together. It is in this context that Evolutionary Directed Graph Ensembles (EDGE) thrives. EDGE is a machine learning tool based on social dynamics and modeling of trust in human beings using graph theory. Evolutionary Algorithms are used to evolve ensembles of models that are arranged in a directed acyclic graph structure. The connections in the graph map the trust of each node in its predecessors. The novelty in such an approach stems from the fusion of ensemble learning with graphs and evolutionary algorithms. A limitation of EDGE is that it focuses only on changing the topology of the graph ensembles, with the authors of hypothesizing about using the learned graphs for other tasks. with gains as substantial as 30 percentage points. The bootstrap was shown to be effective in improving the prediction power, with the exploitation of previous runs improved the results on 19 out of 21 datasets. The contributions can be summarized as a novel way to evolve graph ensembles, by also evolving the weights between nodes of the graphs, coupled with the idea of bootstrapping any dataset using previous runs from other datasets. The analysis of dataset choice for the bootstrapping lead to the proposal of a similarity metric between datasets that can be used to facilitate the choice for bootstrapping, without exhaustive or random search in the available datasets. uma m\u00e9trica de semelhan\u00e7a que pode ser utilizada em vez de uma pesquisa exaustiva nos conjuntos de dados dispon\u00edveis.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/5d84278e37ae5e9e0a4f74f57e6e9a37a7937acd",
        "citation_count": 2
    },
    {
        "title": "Crowd Opinion Mining And Scoring",
        "abstract": "A system and method are disclosed for mining and rating one or more crowd opinions. The system uses a machine learning approach for crowd opinion mining and scoring. The machine learning algorithm creates and updates concepts of the target query in the server by simultaneously mining the web to update opinion scores. A search interface is provided to find concepts and opinions on the targets. Based on the search, the system retrieves the target-related opinions from the server. The system sends crowd-sourced opinions or answers to users. Crowd knowledge is utilized to find opinions and the scores are displayed in a central place. Biasing of community-based opinions is mitigated. BACKGROUND People generally require opinions and scores/ratings on a day-to-day basis on products or services. For example, opinions may provide insight into quality of services by a healthcare provider, or on usability of a product or feedback relating on a trip to a specific resort. Conventionally, people rely on their community for such opinions. Currently, they use reviews, web searches, forums and other available means to gather such opinions, as well as manual review-gathering sites functioning at a very low scale. It may be challenging to obtain trustworthy opinions on every possible concept, product or service. Also, community-based opinions may, at times, be biased. DESCRIPTION A system and method are disclosed that enable mining and rating of one or more crowd opinions. The system uses a machine-learning approach for crowd opinion mining and to process the information. The machine learning approach is considered with the following high level 2 Abolhassani: Crowd Opinion Mining And Scoring Published by Technical Disclosure Commons, 2017 steps. The machine learning algorithm creates and updates concepts that are targets for opinions. It simultaneously mines the web for the concepts and updates opinion scores. It then provides a search mechanism to find concepts and opinions on the targets. It provides a web service to query opinion scores from third party applications and services. The system sends crowd-sourced opinions or answers to users as shown in FIG. 1. FIG. 1: Method to provide crowd-sourced opinion mining and scoring The machine learning algorithm creates and updates concepts that are targets for opinions. Knowledge base resources are available that represent facets and relationships. For creating and updating a concept in the knowledge base, the following information may be stored: name, including alternate names (e.g. synonyms or names in other languages), category (e.g. product, resort or hotel) or facets (e.g. for a product it may be price, size, lifetime, etc.). A similar approach is followed to create and update the available knowledge-based resources for a vast majority of concepts. The machine learning approach continuously mines the web for concepts and updates 3 Defensive Publications Series, Art. 490 [2017] http://www.tdcommons.org/dpubs_series/490 opinion scores. A spectrum for opinions (i.e. classes) are considered. For instance, the opinions may include a spectrum that ranges from \u201chorrible\u201d, to \u201cvery bad\u201d, to \u201cbad\u201d, to \u201cneutral\u201d,to \u201cgood\u201d, to \u201cvery good\u201d,to \u201cexcellent\u201d. A semi-supervised learning approach is taken to mine opinions which may include training a set of opinions that are labeled with values from the aforementioned spectrum. A training example may include natural language statements describing opinions by humans about the concept that may be carefully labeled by an expert using one of the values from the above spectrum. A neural network may be trained based on the training set and it may be used to find important phrases and words separating one class from the others. The core set of words and phrases is expanded by an approach similar to query the expansion used by search engines. The words and phrases are further expanded by similar words and phrases from other human languages. A set of words and phrases is created that is useful to categorize statements representing an opinion to one of the classes. This set is updated periodically. A larger neural network is created with this set and an opinion that is given (in natural language statements) is classified into one of the aforementioned categories. This classifier crawls the web and gathers opinions and stores opinions in a data store keyed by concepts and their facets. For each opinion, the source authority is also computed and stored. The machine-learning algorithm provides a search mechanism to find concepts and opinions on the target query. The data store enables the user to avail a free-form search facility, for example \u201cBrand X price\". A result displays a summarized score such as \u201cBad\u201d and optionally provides further details. For example, the user may further select to view opinions in a given category. For example, if they want to further read opinions within the \"Good\" category, results 4 Abolhassani: Crowd Opinion Mining And Scoring Published by Technical Disclosure Commons, 2017 ranked by any or multiple source\u2019s authorities are shown. The following formula is used to compute the summarized score: SCORE = Round to a category (AVERAGE over all stored opinions (opinion category* source authority)). The machine learning algorithm may provide a web service to query opinion scores from third party applications and services. The service may be called from any services that need to show opinions to users. For example, a hotel search service might use this service to show a total score for the hotel to the user. The system and method to provide crowd opinion mining and scoring provides dynamic updates using web scale to find opinions. The query is not limited to a human language. It is a general framework for solving the problem. Crowd knowledge is utilized to find opinions and the scores are displayed in a central place. The system and method also prevents biasing caused by review-gathering sites. 5 Defensive Publications Series, Art. 490 [2017] http://www.tdcommons.org/dpubs_series/490",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/5d979baf05407a3e4960e781a5dee5bef6f6e5df",
        "citation_count": 0
    },
    {
        "title": "Statistical Machine Learning for Agriculture and Human Health Care Based on Biomedical Big Data",
        "abstract": null,
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/5da1bc99c799018a4cf9fdea0d3a1847a9d4f8cf",
        "citation_count": 0
    },
    {
        "title": "What Do Patients Care About? Mining Fine-grained Patient Concerns from Online Physician Reviews Through Computer-Assisted Multi-level Qualitative Analysis",
        "abstract": "Online physician review (OPR) websites have been increasingly used by healthcare consumers to make informed decisions in selecting healthcare providers. However, consumer-generated online reviews are often unstructured and contain plural topics with varying degrees of granularity, making it challenging to analyze using conventional topic modeling techniques. In this paper, we designed a novel natural language processing pipeline incorporating qualitative coding and supervised and unsupervised machine learning. Using this method, we were able to identify not only coarse-grained topics (e.g., relationship, clinic management), but also fine-grained details such as diagnosis, timing and access, and financial concerns. We discuss how healthcare providers could improve their ratings based on consumer feedback. We also reflect on the inherent challenges of analyzing user-generated online data, and how our novel pipeline may inform future work on mining consumer-generated online data.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5dad0c81fc334cc0759abe53528e75fe3e084e5c",
        "citation_count": 10
    },
    {
        "title": "Bone Age Assessment Empowered with Deep Learning: A Survey, Open Research Challenges and Future Directions",
        "abstract": "Deep learning is a quite useful and proliferating technique of machine learning. Various applications, such as medical images analysis, medical images processing, text understanding, and speech recognition, have been using deep learning, and it has been providing rather promising results. Both supervised and unsupervised approaches are being used to extract and learn features as well as for the multi-level representation of pattern recognition and classification. Hence, the way of prediction, recognition, and diagnosis in various domains of healthcare including the abdomen, lung cancer, brain tumor, skeletal bone age assessment, and so on, have been transformed and improved significantly by deep learning. By considering a wide range of deep-learning applications, the main aim of this paper is to present a detailed survey on emerging research of deep-learning models for bone age assessment (e.g., segmentation, prediction, and classification). An enormous number of scientific research publications related to bone age assessment using deep learning are explored, studied, and presented in this survey. Furthermore, the emerging trends of this research domain have been analyzed and discussed. Finally, a critical discussion section on the limitations of deep-learning models has been presented. Open research challenges and future directions in this promising area have been included as well.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5db4d6b26c0adf1c9b0a83a228f404caa0e3bfd6",
        "citation_count": 41
    },
    {
        "title": "Predicting incident heart failure from population-based nationwide electronic health records: protocol for a model development and validation study",
        "abstract": "Introduction Heart failure (HF) is increasingly common and associated with excess morbidity, mortality, and healthcare costs. Treatment of HF can alter the disease trajectory and reduce clinical events in HF. However, many cases of HF remain undetected until presentation with more advanced symptoms, often requiring hospitalisation. Predicting incident HF is challenging and statistical models are limited by performance and scalability in routine clinical practice. An HF prediction model implementable in nationwide electronic health records (EHRs) could enable targeted diagnostics to enable earlier identification of HF. Methods and analysis We will investigate a range of development techniques (including logistic regression and supervised machine learning methods) on routinely collected primary care EHRs to predict risk of new-onset HF over 1, 5 and 10 years prediction horizons. The Clinical Practice Research Datalink (CPRD)-GOLD dataset will be used for derivation (training and testing) and the CPRD-AURUM dataset for external validation. Both comprise large cohorts of patients, representative of the population of England in terms of age, sex and ethnicity. Primary care records are linked at patient level to secondary care and mortality data. The performance of the prediction model will be assessed by discrimination, calibration and clinical utility. We will only use variables routinely accessible in primary care. Ethics and dissemination Permissions for CPRD-GOLD and CPRD-AURUM datasets were obtained from CPRD (ref no: 21_000324). The CPRD ethical approval committee approved the study. The results will be submitted as a research paper for publication to a peer-reviewed journal and presented at peer-reviewed conferences. Trial registration details The study was registered on Clinical Trials.gov (NCT 05756127). A systematic review for the project was registered on PROSPERO (registration number: CRD42022380892).",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5df565c2711d4d29eff320b2c6708c10e42cf9c3",
        "citation_count": 0
    },
    {
        "title": "Integrating Co-Clustering and Interpretable Machine Learning for the Prediction of Intravenous Immunoglobulin Resistance in Kawasaki Disease",
        "abstract": "Identifying intravenous immunoglobulin-resistant patients is essential for the prompt and optimal treatment of Kawasaki disease, suggesting the need for effective risk assessment tools. Data-driven approaches have the potential to identify the high-risk individuals by capturing the complex patterns of real-world data. To enable clinically applicable prediction of intravenous immunoglobulin resistance addressing the incompleteness of clinical data and the lack of interpretability of machine learning models, a multi-stage method is developed by integrating data missing pattern mining and intelligible models. First, co-clustering is adopted to characterize the block-wise data missing patterns by simultaneously grouping the clinical features and patients to enable (a) group-based feature selection and missing data imputation and (b) patient subgroup-specific predictive models considering the availability of data. Second, feature selection is performed using the group Lasso to uncover group-specific risk factors. Third, the Explainable Boosting Machine, which is an interpretable learning method based on generalized additive models, is applied for the prediction of each patient subgroup. The experiments using real-world Electronic Health Records demonstrate the superior performance of the proposed framework for predictive modeling compared with a set of benchmark methods. This study highlights the integration of co-clustering and supervised learning methods for incomplete clinical data mining, and promotes data-driven approaches to investigate predictors and effective algorithms for decision making in healthcare.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5e14ec7582bc918345b8dc9c51d5d9a77c8ab44c",
        "citation_count": 23
    },
    {
        "title": "A Systematic Study About Chronic Disease Prediction Strategies using Artificial Intelligence based Algorithms",
        "abstract": "The challenge of chronic diseases will take its deserved place among the top global health issues, mainly because they account for 74% of deaths every year, as reported by the WHO. This systematic review will discuss possible applications of machine learning and AI techniques to predict, diagnose, and treat CDs such as diabetes, cancer, cardiovascular diseases, and liver disease. Integration of ML algorithms: RF, SVM, DT, ANN, and boosting techniques has transformed healthcare by improving the quality of predictive information for potential cases, reducing healthcare costs, and contributing to innovative clinical decision support systems. The research focuses on several approaches of ML, namely supervised and unsupervised learning, for predicting patient-specific treatment regimens and hence better outcomes in chronic disease management. Another discussion from the study is on how to apply ML on large, structured and unstructured datasets collected from the healthcare system about the predictive powers of AI-based models in order to be able to address complications arising from CD. Research aims at providing a comprehensive overview of the understanding of predictive models (PMs) under one heading, making an amalgamation of the desired workings of PMs for chronic disease prediction, useful for knowledge collection for future reference. The paper also provides a descriptive analysis of data sources, methodologies, and algorithms adopted, accompanied by a tabular representation of previous studies to avoid redundancy and enhance accuracy.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5e1e3fb1d06895ef76ee5ad692adc5a0b63d3440",
        "citation_count": 0
    },
    {
        "title": "Performance Accuracy between Classifiers in Sustain of Disease Conversion for Clinical Trial Tuberculosis Data : Data Mining Approach",
        "abstract": "Data mining has been used intensively and extensively by many organizations. In healthcare, data mining is becoming increasingly popular, if not increasingly essential. Data mining applications can greatly benefit all parties involved in the healthcare industry. For example, data mining can help physicians to identify risk factors, effective treatments and best practices in health care industry which helps patients to receive better and affordable healthcare services. The huge amounts of data generated by healthcare transactions are too complex and voluminous to be processed and analyzed by traditional methods. Data mining provides the methodology and technology to transform these mounds of data into useful information for decision making. This work will explore data mining applications within healthcare in one of the major area such as the evaluation of treatment effectiveness as well as disease conversion in tuberculosis patients; it aims to compare various classification techniques and its performance accuracy to build a predictive modelling with controlled clinical trial tuberculosis (TB) data. The classification of tuberculosis patients is of substantial importance in TB disease conversion. During the last few years, many algorithms have been proposed for this task. In this paper, we review different supervised machine learning techniques and its performance accuracy for classification with an original dataset and carry out a methodological comparison using \u201cWEKA\u201d software (Wang, 2010). We used the C4.5 (J48) tree classifier, Iterative Dichotomiser3 (ID3), a Multilayer Perceptron (MLP) and a naive Bayes 7classifier over a large set of TB data. It is found that Multilayer Perceptron achieves a competitive performance than naive Bayes, and when the number of features to be classified is reduced naive bayes performs well.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/5e1e9cb390ebc9ec2aa1750e8e41d2e04e06aafd",
        "citation_count": 2
    },
    {
        "title": "Justification-Based Reliability in Machine Learning",
        "abstract": "With the advent of Deep Learning, the field of machine learning (ML) has surpassed human-level performance on diverse classification tasks. At the same time, there is a stark need to characterize and quantify reliability of a model's prediction on individual samples. This is especially true in applications of such models in safety-critical domains of industrial control and healthcare. To address this need, we link the question of reliability of a model's individual prediction to the epistemic uncertainty of the model's prediction. More specifically, we extend the theory of Justified True Belief (JTB) in epistemology, created to study the validity and limits of human-acquired knowledge, towards characterizing the validity and limits of knowledge in supervised classifiers. We present an analysis of neural network classifiers linking the reliability of its prediction on a test input to characteristics of the support gathered from the input and hidden layers of the network. We hypothesize that the JTB analysis exposes the epistemic uncertainty (or ignorance) of a model with respect to its inference, thereby allowing for the inference to be only as strong as the justification permits. We explore various forms of support (for e.g., k-nearest neighbors (k-NN) and \u2113p-norm based) generated for an input, using the training data to construct a justification for the prediction with that input. Through experiments conducted on simulated and real datasets, we demonstrate that our approach can provide reliability for individual predictions and characterize regions where such reliability cannot be ascertained.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/5e218b936bb95482e6fc5fe9825bc77850ecb2c3",
        "citation_count": 18
    },
    {
        "title": "Predicting Postoperative Length of Stay for Isolated Coronary Artery Bypass Graft Patients Using Machine Learning",
        "abstract": "Purpose Predictive analytics (PA) is a new trending approach in the field of healthcare that uses machine learning to build a prediction model using supervised learning algorithms. Isolated coronary artery bypass grafting (iCABG), an open-heart surgery, is commonly performed in the treatment of coronary heart disease. Aim The aim of this study was to develop and evaluate a model to predict postoperative length of stay (PLoS) for iCABG patients using supervised machine learning techniques, and to identify the features with the highest contribution to the model. Methods This is a retrospective study that uses historic data of adult patients who underwent isolated CABG (iCABG). After initial data pre-processing, data imputation using the kNN method was applied. The study used five prediction models using Na\u00efve Bayes, Decision Tree, Random Forest, Logistic Regression and k Nearest Neighbor algorithms. Data imbalance was managed using the following widely used methods: oversampling, undersampling, \u201cBoth\u201d, and random over-sampling examples (ROSE). The features selection process was conducted using the Boruta method. Two techniques were applied to examine the performance of the models, (70%, 30%) split and cross-validation, respectively. Models were evaluated by comparing their performance using AUC and other metrics. Results In the final dataset, six distinct features and 621 instances were used to develop the models. A total of 20 models were developed using R statistical software. The model generated using Random Forest with \u201cBoth\u201d resampling method and cross-validation technique was deemed the best fit (AUC=0.81; F1 score=0.82; and recall=0.82). Attributes found to be highly predictive of PLoS were pulmonary artery systolic, age, height, EuroScore II, intra-aortic balloon pump used, and complications during operation. Conclusion This study demonstrates the significance and effectiveness of building a model that predicts PLoS for iCABG patients using patient specifications and pre-/intra-operative measures.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/5e657c75f1a1e605a248de0bbcc4856cae1eda54",
        "citation_count": 13
    },
    {
        "title": "Model Evaluation of Various Supervised Machine Learning Algorithm for Heart Disease Prediction",
        "abstract": "Machine Learning (ML) is a type of Artificial Intelligence (Al) that allows the machine to learn from data and become more accurate in predicting outcomes without human intervention. The fundamental idea of machine learning is to mimic the way our brain works. In a variety of application domains, including medicine and healthcare, ML techniques have demonstrated strong prediction abilities. This study evaluated and compared several popular supervised machine learning techniques for predicting heart diseases using medical records from the UCI Machine learning repository. The performance of different models, including Support Vector Machines (SVM), K-Nearest Neighbor (KNN), and Logistic Regression models, is examined in this paper. The performance of these algorithms was analyzed based on the (Area Under ROC Curve) AUC score. AUC is an evaluation metric that helps us validate our machine learning algorithm how good it is, and the decision is made to implement if the AUC score is more significant than 0.5. The trial result verifies that the Logistic regression algorithm has achieved the highest AUC score of 0.87 compared to other ML algorithms.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/5eb4ea0f9c474548248df0b432869bcc23d80a4e",
        "citation_count": 6
    },
    {
        "title": "Machine Learning Approaches in Alzheimer\u2019s Disease: Early Diagnosis, Prognosis, and Treatment Optimization",
        "abstract": "Alzheimer's disease (AD) is a progressive neurodegenerative disorder that has emerged as a significant global health challenge, affecting millions worldwide. It is characterised by cognitive decline, memory loss, and behavioural changes, significantly burdening patients, caregivers, and healthcare systems. Early diagnosis and effective intervention remain critical yet challenging due to the complex nature of the disease and its heterogeneous progression. Traditional diagnostic methods rely on invasive, expensive, and often time-consuming procedures, underscoring the urgent need for innovative diagnostic and therapeutic strategies.Machine learning (ML), a subset of artificial intelligence, has revolutionised the field of medical research by enabling the analysis of complex and high-dimensional datasets. In Alzheimer\u2019s research, ML has shown immense potential in enhancing.diagnostic accuracy, predicting disease progression, and personalising treatment plans. ML models leverage data from various sources, including neuroimaging, genomics, biomarkers, and clinical records, to identify subtle patterns and accurately predict outcomes. Applying supervised learning, deep learning techniques like convolutional neural networks (CNNs) for imaging data, and unsupervised clustering algorithms for patient stratification have significantly advanced the field.This paper focuses on three critical areas: (1) early diagnosis of AD through ML-based analysis of neuroimaging and biomarkers, (2) prediction of disease progression using longitudinal data and predictive models, and (3) optimisation of treatment plans and personalised care through reinforcement learning and predictive analytics. The study also explores the challenges associated with ML applications, such as data heterogeneity, interpretability, and ethical concerns, and discusses potential solutions to address these barriers.In conclusion, machine learning represents a transformative tool in Alzheimer\u2019s research. It promises to improve early detection, enhance disease management, and pave the way for precision medicine. Its integration into clinical practice can potentially significantly mitigate the global burden of AD.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5ec047ff78d62f24f911f7fd77204120a695baf0",
        "citation_count": 0
    },
    {
        "title": "SYMPTOM-BASED DISEASE PREDICTION SYSTEM USING MACHINE LEARNING",
        "abstract": "Healthcare has been an important industry from then till now, and it is said to be one of the sectors which plays a critical role in preventing the increasing number of a particular disease. In this era of new technology, machine learning has been used in a lot of industries, and one would be the healthcare industry. In the healthcare field, machine learning contributes significantly to predicting a disease as to simplify the process of the manual disease diagnosis and bring convenience to both the doctor and patient. In this paper, a disease prediction system will be implemented with the use of supervised learning algorithm to allow patient in identifying disease themselves based on their symptoms. Few supervised learning algorithms are being trained and tested in terms of their accuracy, and the algorithm with the highest accuracy is used for the prediction. The chosen supervised learning algorithms to be tested include Bernoulli Na\u00efve Bayes, Decision Tree, and Support Vector Machine.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/5ec6fe45df8da42c41afe20fa1aab5c46619376c",
        "citation_count": 1
    },
    {
        "title": "Explainable Neural Rule Learning",
        "abstract": "Although neural networks have achieved great successes in various machine learning tasks, people can hardly know what neural networks learn from data due to their black-box nature. The lack of such explainability is one of the limitations of neural networks when applied in domains, e.g., healthcare and finance, that demand transparency and accountability. Moreover, explainability is beneficial for guiding a neural network to learn the causal patterns that can extrapolate out-of-distribution (OOD) data, which is critical in real-world applications and has surged as a hot research topic. In order to improve the explainability of neural networks, we propose a novel method\u2014Explainable Neural Rule Learning (denoted as ENRL), with the aim to integrate the expressiveness of neural networks and the explainability of rule-based systems. Specifically, we first design several operator modules and guide them to behave as certain relational operators via self-supervised learning. With input feature fields and learnable context values serving as arguments, these operator modules are used as predicates to constitute the atomic propositions. Then we employ neural logical operations to combine atomic propositions into a collection of rules. Finally, we design a voting mechanism for these rules so that they collaboratively make up our predictive model. Thus, rule learning is transformed to neural architecture search, that is, to choose the appropriate arrangements of feature fields and operator modules. After searching for a specific architecture and learning the involved modules, the resulting neural network explicitly expresses some rules and thus possesses explainability. Therefore, we can predict for each input instance according to rules it satisfies, which at the same time explains how the neural network makes that decision. We conduct a series of experiments on both synthetic and real-world datasets to evaluate ENRL. Compared with conventional neural networks, ENRL achieves competitive in-distribution performance while providing the extra benefits of explainability. Meanwhile, ENRL significantly alleviates performance drop on OOD test data, implying the effectiveness of rule learning. Codes are provided at https://github.com/Shuriken13/ENRL.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/5ee7b59c9d5a6611ddad2aec21702ae43c56c4ce",
        "citation_count": 4
    },
    {
        "title": "Intelligent Threat Detection And Response Systems For Safeguarding Cloud-Hosted Electronic Health Records From Cyber Attacks",
        "abstract": "As more people use cloud-based electronic health record (EHR) systems, they make healthcare better, but they also make it easier for cybercriminals to attack. This article describes a system that uses artificial intelligence (AI) and machine learning (ML) to intelligently watch cloud-hosted EHR environments for bad behaviour, find cyberattacks, and automatically take the right steps to stop them. Using supervised machine learning models that have been trained on known threat indicators, the suggested framework constantly looks at log and system data. As soon as an attack is found, established containment and mitigation steps are carried out naturally to lower the harm. The test results show that the framework can correctly identify common EHR attack methods like ransomware and data theft, as well as quickly and effectively protect private patient data",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5ee8bc4190d3b242627dfccbe7d99d54d5917cb0",
        "citation_count": 0
    },
    {
        "title": "Image Classification Based On CNN: A Survey",
        "abstract": "Computer vision is one of the fields of computer science that is one of the most powerful and persuasive types of artificial intelligence. It is similar to the human vision system, as it enables computers to recognize and process objects in pictures and videos in the same way as humans do. Computer vision technology has rapidly evolved in many fields and contributed to solving many problems, as computer vision contributed to self-driving cars, and cars were able to understand their surroundings. The cameras record video from different angles around the car, then a computer vision system gets images from the video, and then processes the images in real-time to find roadside ends, detect other cars, and read traffic lights, pedestrians, and objects. Computer vision also contributed to facial recognition; this technology enables computers to match images of people\u2019s faces to their identities. which these algorithms detect facial features in images and then compare them with databases. Computer vision also play important role in Healthcare, in which algorithms can help automate tasks such as detecting Breast cancer, finding symptoms in x-ray, cancerous moles in skin images, and MRI scans. Computer vision also contributed to many fields such as image classification, object discovery, motion recognition, subject tracking, and medicine. The rapid development of artificial intelligence is making machine learning more important in his field of research. Use algorithms to find out every bit of data and predict the outcome. This has become an important key to unlocking the door to AI. If we had looked to deep learning concept, we find deep learning is a subset of machine learning, algorithms inspired by structure and function of the human brain called artificial neural networks, learn from large amounts of data. Deep learning algorithm perform a task repeatedly, each time tweak it a little to improve the outcome. So, the development of computer vision was due to deep learning. Now we'll take a tour around the convolution neural networks, let us say that convolutional neural networks are one of the most powerful supervised deep learning models (abbreviated as CNN or ConvNet). This name ;convolutional ; is a token from a mathematical linear operation between matrixes called convolution. CNN structure can be used in a variety of real-world problems including, computer vision, image recognition, natural language processing (NLP), anomaly detection, video analysis, drug discovery, recommender systems, health risk assessment, and time-series forecasting. If we look at convolutional neural networks, we see that CNN are similar to normal neural networks, the only difference between CNN and ANN is that CNNs are used in the field of pattern recognition within images mainly. This allows us to encode the features of an image into the structure, making the network more suitable for image-focused tasks, with reducing the parameters required to set-up the model. One of the advantages of CNN that it has an excellent performance in machine learning problems. So, we will use CNN as a classifier for image classification. So, the objective of this paper is that we will talk in detail about image classification in the following sections.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/5f233f3de3667147b711b735cf97c498c74488f5",
        "citation_count": 50
    },
    {
        "title": "Artificial Intelligence in Pediatric Critical Care Medicine: Are We (Finally) Ready?",
        "abstract": "Unauthorized reproduction of this article is prohibited Pediatric Critical Care Medicine www.pccmjournal.org 997 In this issue of Pediatric Critical Care Medicine, a timely work by Alexander et al (1) and a multidisciplinary team aimed to develop a methodology to predict extended cardiac ICU length of stay following surgery for congenital heart disease in order to optimize hospital resource utilization. The study by Alexander et al (1) employed a multivariable logistic regression methodology of predictive factors in a retrospective analysis with a model that was built to predict the outcome postoperative ICU length of stay greater than 7 days; an additional model was built with inclusion of intraoperative factors. Although this academic effort is laudable for its efforts to espouse the significance of assessing value of critical care delivery, the \u201ctop-down\u201d selection of variables as well as methodology used (logistic regression) that is most likely in the realm of advanced biostatistics or simple supervised machine learning is perhaps becoming out-of-date. It is time for all of us in clinical medicine to consider an entirely different paradigm of data analysis leading to information and knowledge: deployment of newer methodologies of machine and deep learning or artificial intelligence (AI) and a \u201cbottom-up\u201d approach in step with the expression \u201cwith enough data, let the data speak for themselves\u201d (2). This shift in AI adoption to better reflect its advances is demonstrated in the Medical Information Mart for Intensive Care III database and its myriad of publications summarized in a recent article (3). One new methodology is deep reinforcement learning, which was successful in the form of the program \u201cAlphaGo\u201d in defeating the human Go champion in a series of matches 2 years ago (4). In this reinforcement type of deep learning, there is a goal-oriented algorithm especially designed for game situations like Go as well as real-life, real-time complex decisions like those in the ICU setting. In addition, deep learning methodology coupled with raw electronic medical records based on the Fast Healthcare Interoperability Resources format is capable of outperforming the traditional predictive models that have preselected variables like the present article (1) as the new methodology will have the ability of learning many more key factors from the data itself (5). We need innovative solutions to this healthcare data conundrum. First, we need an AI-focused solution to the volume of data by applying this technology at the point of data acquisition and collection (the so-called \u201cinternet of everything\u201d). Second, a disruptive technology such as blockchain can perhaps provide the public and clinicians healthcare data access while concomitantly assure patients of data security. Third, we need large common repositories (data reservoirs) that share storage and agility characteristics, so that every stakeholder can work on the data. Fourth, we need much better data infrastructures that is organized, complete, and therefore AI friendly. Last, a graph database format with its elements that are more flexible for healthcare data would be a good forward-thinking solution to the present-day relational database format. All of these aforementioned changes can lead to a biomedical data nirvana: a federated or virtual software-defined meta-database architecture for all of medicine in a dynamic hybrid cloud with real-time analytic processing to provide an AI-in-medicine-as-a-service (\u201cAIMedaas\u201d) for any patient at anytime and anywhere. It is close to 40 years since the ubiquitous personal computer era began with all its astonishing dividends; in AI, we have the wondrous opportunity of another such technological advance that can be of benefit for everyone. AI in the form of convolutional neural network and deep learning is now increasingly adopted in the medical image-focused subspecialties such as radiology, cardiology, pathology, dermatology, and ophthalmology. Similarly, the data-rich clinical milieu of the ICU setting is ideal for a new AI-centric approach to data, information, and knowledge (6) with new AI tools and data strategies. This is therefore another clarion call for ICU physicians and caretakers to embrace this new AI in medicine paradigm: machine intelligence + clinician intelligence = medical intelligence (7).",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/5f33a18045b7149ee18506f32e3da38a6556c1bc",
        "citation_count": 3
    },
    {
        "title": "Machine Learning Side Effect Trend Predictions and the SIDER Database",
        "abstract": "In the Pharmaceutical and Healthcare industries, understanding medications is key in the treatment of patients. Worldwide, there are hundreds of thousands of medications available, classified in categories related to medication therapy and the remediation that they provide. With so many different types of medication, medical doctors and pharmacists need to determine what kinds of drugs to provide to patients with specific medical needs. New medication studies necessitate careful analysis of available medication data during clinical trials, prior to production of new medications, and through the course of prescribed medication therapy. he use of medication therapy is not justified if the number of side effects outweighs the remedial benefits. Therefore, not all medications are deemed medically safe for all patients. Supervised machine learning techniques assist scientists with predicting side effects of medications that are under development. Prediction techniques aid future development of medications based on the properties of current medication data models.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/5f7b6c6814c83b2f9bf183229bc8987266f31700",
        "citation_count": 0
    },
    {
        "title": "SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training",
        "abstract": "Tabular data underpins numerous high-impact applications of machine learning from fraud detection to genomics and healthcare. Classical approaches to solving tabular problems, such as gradient boosting and random forests, are widely used by practitioners. However, recent deep learning methods have achieved a degree of performance competitive with popular techniques. We devise a hybrid deep learning approach to solving tabular data problems. Our method, SAINT, performs attention over both rows and columns, and it includes an enhanced embedding method. We also study a new contrastive self-supervised pre-training method for use when labels are scarce. SAINT consistently improves performance over previous deep learning methods, and it even outperforms gradient boosting methods, including XGBoost, CatBoost, and LightGBM, on average over a variety of benchmark tasks.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/5fa2103e36b3e76e49edb8433a1206a6b25e3ead",
        "citation_count": 274
    },
    {
        "title": "Machine Learning Based Healthcare System for Investigating the Association Between Depression and Quality of Life",
        "abstract": "New technological innovations are changing the future of healthcare system. Identification of factors that are responsible for causing depression may lead to new experiments and treatments. Because depression as a disease is becoming a leading community health concern worldwide. Using machine learning techniques this article presents a complete methodological framework to process and explore the heterogenous data and to better understand the association between factors related to quality of life and depression. Subsequently, the experimental study is mainly divided into two parts. In the first part, a data consolidation process is presented. The relationship of data is formed and to uniquely identify each relation in data the concept of the Secure Hash Algorithm is adopted. Hashing is used to locate and index the actual items in the data. The second part proposed a model using both unsupervised and supervised machine learning techniques. The consolidation approach helped in providing a base for formulation and validation of the research hypothesis. The Self organizing map provided 08 cluster solution and the classification problems were taken from the clustered data to further validate the performance of the posterior probability multi-class Support Vector Machine. The expectations of the importance sampling resulted in factors responsible for causing depression. The proposed model was adopted to improve the classification performance, and the result showed classification accuracy of 91.16%.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/5ff1df7a1ebfa20423c73e0864859559573e0ef7",
        "citation_count": 18
    },
    {
        "title": "Performance Evaluation of Cardiovascular Disease Prediction Using Supervised Machine Learning Algorithms",
        "abstract": "Cardiovascular disease has emerged as a very critical and intricate condition on a global scale. Healthcare practitioners have long faced substantial challenges in predicting and identifying heart disease. Medical and other healthcare facilities provide costly treatments and surgical procedures for cardiovascular conditions. People throughout the globe would benefit from early heart disease prediction since it would allow them to take action before the issue worsens. These days, heart disease is a major concern, and the primary causes of this illness include things like smoking, excessive alcohol use, and not getting enough exercise. Based on the extensive dataset that the healthcare industry has produced over time, machine learning has proven effective in decisions and forecasts. Logistic regression, Decision- Trees, Naive-Bayes, Random-Forest, and SVM are among the supervised machine learning algorithms that may anticipate the occurrence of heart illness. A synopsis of the algorithm\u2019s performance assessment is also included. A comparison of five models showed that the Decision Tree and Random Forest models were better at predicting heart disease than the others. Also, these models were very accurate, with a 98.5% success rate.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/602e94c4e02fbe738df3eb1b7f77731fd1523b57",
        "citation_count": 0
    },
    {
        "title": "Cancer Prognosis Using Artificial Intelligence-Based Techniques",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/602fa606683b65ea3ddc5a992a62c6060e4aa9ff",
        "citation_count": 21
    },
    {
        "title": "Cluster-Then-Classify Methodology for the Identification of Pain Episodes in Chronic Diseases",
        "abstract": "Chronic diseases benefit of the advances on personalize medicine coming out of the integrative convergence of significant developments in systems biology, the Internet of Things and Artificial Intelligence. 70% to 80% of all healthcare costs in the EU and US are currently spent on chronic diseases, leading to estimated costs of ${\\rm C}\\!\\!\\!\\!\\!\\!\\!=$700 billion and ${\\$}$3.5 trillion respectively. The management of symptomatic pain crises in chronic diseases is based on general clinical guidelines that do not take into account the singularities of the crises, such as their intensity or duration, so that the pain of those particular crises may cause the medication to be ineffective and lead the patient to overmedication. Knowing in detail the characteristics of the pain would help the physician to objectively prescribe personalized treatments for each patient and crisis. In this manuscript, we make a step further on the prediction of symptomatic crisis from ambulatory collected data in chronic diseases. We propose a categorization of pain types according to subjective symptoms of real patients. Our approach has been evaluated in the migraine disease. The migraine is one of the most disabling neurological diseases that affects over 12% of the population worldwide and leads to high economic costs for private and public health systems. This study aims to classify pain episodes by the characterization of pain curves reported by patients in real time. Pain curves have been described as a set of morphological features. With these features the pain episodes are clustered then classified by unsupervised and supervised machine learning models. It is shown that the evolution of different pain episodes in chronic diseases can be modeled and clustered. Over a population of 51 migraine patients, it has been found that there are 4 clusters of pain types that can be classified using 4 morphological features with an accuracy of 99.0% using a Logistic Model Tree algorithm.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/60560b27fc3139711d336a052a2ba98af4e2a2d4",
        "citation_count": 8
    },
    {
        "title": "Happy Healthing - Daily Health Reading Visualization and Disease Prediction",
        "abstract": "\u2014 The Happy healthing is a system that will help to predict disease using Machine Learning. Happy Healthing processes the symptoms provided by the user as input and gives the output as the prediction of the disease. A supervised machine learning algorithm called the Naive Bayes classifier is used in the prediction of the disease. The prediction is calculated by the Naive Bayes algorithm. With an increase in biomedical and healthcare data, accurate analysis of medical data benefits early disease detection and patient care.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/60600f349dbd1bddc311259ef79d4c31a6c21899",
        "citation_count": 0
    },
    {
        "title": "Intrusion detection in healthcare domain using machine learning",
        "abstract": "Intrusion detection system is considered as one of the main sources for protection of important information and communication technologies especially in healthcare networks. Intrusion detection system must be updated frequently because of intrusions that improves periodically. Due to particular limitations such as resource-constrained devices, limited memory and battery capacity of nodes, and unique protocol stacks, traditional intrusion detection algorithms must be updated and improved for application to the Internet of Things. To address this issue, a lightweight attack detection approach based on supervised machine learning\u2013based FIDS (Frothy Disturbance Intrusion Detection System) was developed to detect an adversary attempting to inject unneeded data into the network. FIDS can play an important role in intrusion detection. The proposed model was trained with KDD (Knowledge Discovery in Database) dataset using SVM (Support Vector Machine) algorithm. AODV (Ad-hoc- on-demand Distance Vector) routing protocol was used for routing to make it more energy efficient since the energy usable was limited. The process of packet transmission was done with the help of clustering algorithm to separate the sensors into groups with each group containing a cluster head.\u00a0 \n\u00a0",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/606df17e7b577cae0db12c1dd59a30c6700cbe30",
        "citation_count": 0
    },
    {
        "title": "Convolutional Neural Networks based Liver Tumor Classification",
        "abstract": "The most common and widespread disease among today's population is liver disease, which is caused by excessive alcohol consumption, polluted gas produced by various chemical factories, drugs, spoiled or tainted food, and obesity. Liver is the most important body organ as it performs the detoxification process. As a result, early disease detection plays a crucial role in the disease diagnosis and recovery process. Early prediction of liver disease has been made possible with the introduction of machine learning technology. This technology provides significant benefits to the healthcare sector by developing new ways to deploy early disease prediction system even in a remote location. SVM, KNN, K-Mean clustering, neural networks, decision trees, and other machine learning techniques are used to implement liver disease diagnosis in order to provide varying levels of accuracy, precision and sensitivity. Unsupervised learning, supervised learning, semi-supervised learning, and reinforcement learning can also be used. This research study intends to compare all the machine learning algorithms to investigate and predict the liver disease and the resultant performance is evaluated based on sensitivity, relevance, accuracy, and precision.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/607d3f7182aa6abb187636c2b7cf31ae6f69108b",
        "citation_count": 2
    },
    {
        "title": "Electronic Health Records Based Prediction of Future Incidence of Alzheimer\u2019s Disease Using Machine Learning",
        "abstract": "Background Accurate prediction of future incidence of Alzheimer\u2019s disease may facilitate intervention strategy to delay disease onset. Existing AD risk prediction models require collection of biospecimen (genetic, CSF, or blood samples), cognitive testing, or brain imaging. Conversely, EHR provides an opportunity to build a completely automated risk prediction model based on individuals\u2019 history of health and healthcare. We tested machine learning models to predict future incidence of AD using administrative EHR in individuals aged 65 or older. Methods We obtained de-identified EHR from Korean elders age above 65 years old (N=40,736) collected between 2002 and 2010 in the Korean National Health Insurance Service database system. Consisting of Participant Insurance Eligibility database, Healthcare Utilization database, and Health Screening database, our EHR contain 4,894 unique clinical features including ICD-10 codes, medication codes, laboratory values, history of personal and family illness, and socio-demographics. Our event of interest was new incidence of AD defined from the EHR based on both AD codes and prescription of anti-dementia medication. Two definitions were considered: a more stringent one requiring a diagnosis and dementia medication resulting in n=614 cases (\u201cdefinite AD\u201d) and a more liberal one requiring only diagnostic codes (n=2,026; \u201cprobable AD\u201d). We trained and validated a random forest, support vector machine, and logistic regression to predict incident AD in 1,2,3, and 4 subsequent years using the EHR available since 2002. The length of the EHR used in the models ranged from 1,571 to 2,239 days. Model training, validation, and testing was done using iterative (5 times), nested, stratified 5-fold cross validation. Results Average duration of EHR was 1,936 days in AD and 2,694 days in controls. For predicting future incidence of AD using the \u201cdefinite AD\u201d outcome, the machine learning models showed the best performance in 1 year prediction with AUC of 0.781; in 2 year, 0.739; in 3 year, 0.686; in 4 year, 0.662. Using \u201cprobable AD\u201d outcome, the machine learning models showed the best performance in 1 year prediction with AUC of 0.730; in 2 year, 0.645; in 3 year, 0.575; in 4 year, 0.602. Important clinical features selected in logistic regression included hemoglobin level (b=-0.902), age (b=0.689), urine protein level (b=0.303), prescription of Lodopin (antipsychotic drug) (b=0.303), and prescription of Nicametate Citrate (vasodilator) (b=-0.297). Conclusion This study demonstrates that EHR can detect risk for incident AD. This approach could enable risk-specific stratification of elders for better targeted clinical trials. Key Points Question Can machine learning be used to predict future incidence of Alzheimer\u2019s disease using electronic health records? Findings We developed and validated supervised machine learning models using the HER data from 40,736 South Korean elders (age above 65 years old). Our model showed acceptable accuracy in predicting up to four year subsequent incidence of AD. Meaning This study shows the potential utility of the administrative EHR data in predicting risk for AD using data-driven machine learning to support physicians at the point of care.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/60a615f6f3937acea3e38fc48ccd1af1a2ede607",
        "citation_count": 16
    },
    {
        "title": "Supervised And Unsupervised Neural Network Deep Analysis For Facial Recognition",
        "abstract": "In this technological era automation is playing a vital role in making things faster. Face Recognition is one of the examples of automation. Facial Recognition is categorized as a biometric method alongside fingerprint scan and iris scan. Back in the days facial recognition is only limited for safety and security purposes but nowadays it is widely used in various industries like Banking, Healthcare, and many more. One such industry is the educational industry. Various universities around the globe have already implemented biometrics through facial recognition not only for the staff but also for recording the student's attendance. Currently available Facial Recognition systems are able only able to track one person at an instance. The constructed system must track the individual attendance while he/she being recorded in a live video or while they were in a group photo using machine learning techniques. The system must analyze each individual in a group using the image provided and mark the individual's basic information like name, class, section, etc. In general, the system is trained with each individual's 180-degree facial view with the help of convolutional neural networks. And to improve accuracy the system must be trained using deep learning and deploying with a huge and distinct dataset. For achieving this we have conducted a study comparing five well-established algorithms to know which algorithm is reliable",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/60d9bbcfdec324d9680440f9f842bd174ead5d20",
        "citation_count": 0
    },
    {
        "title": "Method for Classifying Schizophrenia Patients Based on Machine Learning",
        "abstract": "Schizophrenia is a chronic and severe mental disorder that affects individuals in various ways, particularly in their ability to perceive, process, and respond to stimuli. This condition has a significant impact on a considerable number of individuals. Consequently, the study, analysis, and characterization of this pathology are of paramount importance. Electroencephalography (EEG) is frequently utilized in the diagnostic assessment of various brain disorders due to its non-intrusiveness, excellent resolution and ease of placement. However, the manual analysis of electroencephalogram (EEG) recordings can be a complex and time-consuming task for healthcare professionals. Therefore, the automated analysis of EEG recordings can help alleviate the burden on doctors and provide valuable insights to support clinical diagnosis. Many studies are working along these lines. In this research paper, the authors propose a machine learning (ML) method based on the eXtreme Gradient Boosting (XGB) algorithm for analyzing EEG signals. The study compares the performance of the proposed XGB-based approach with four other supervised ML systems. According to the results, the proposed XGB-based method demonstrates superior performance, with an AUC value of 0.94 and an accuracy value of 0.94, surpassing the other compared methods. The implemented system exhibits high accuracy and robustness in accurately classifying schizophrenia patients based on EEG recordings. This method holds the potential to be implemented as a valuable complementary tool for clinical use in hospitals, supporting clinicians in their clinical diagnosis of schizophrenia.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/6154acf631d4299e206f2edf104e383781ca58ed",
        "citation_count": 6
    },
    {
        "title": "Advancements and challenges in the application of artificial intelligence in civil engineering: a comprehensive review",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/61825acd9fa38dc03181a000a36a88fd54d81f87",
        "citation_count": 14
    },
    {
        "title": "Intelligent Microfluidics for Plasma Separation: Integrating Computational Fluid Dynamics and Machine Learning for Optimized Microchannel Design",
        "abstract": "Efficient separation of blood plasma and Packed Cell Volume (PCV) is vital for rapid blood sensing and early disease detection, especially in point-of-care and resource-limited environments. Conventional centrifugation methods for separation are resource-intensive, time-consuming, and off-chip, necessitating innovative alternatives. This study introduces \u201cIntelligent Microfluidics\u201d, an ML-integrated microfluidic platform designed to optimize plasma separation through computational fluid dynamics (CFD) simulations. The trifurcation microchannel, modeled using COMSOL Multiphysics, achieved plasma yields of 90\u201395% across varying inflow velocities (0.0001\u20130.05 m/s). The input fluid parameters mimic the blood viscosity and density used with appropriate boundary conditions and fluid dynamics to optimize the designed microchannels. Eight supervised ML algorithms, including Artificial Neural Networks (ANN) and k-Nearest Neighbors (KNN), were employed to predict key performance parameters, with ANN achieving the highest predictive accuracy (R2 = 0.97). Unlike traditional methods, this platform demonstrates scalability, portability, and rapid diagnostic potential, revolutionizing clinical workflows by enabling efficient plasma separation for real-time, point-of-care diagnostics. By incorporating a detailed comparative analysis with previous studies, including computational efficiency, our work underscores the superior performance of ML-enhanced microfluidic systems. The platform\u2019s robust and adaptable design is particularly promising for healthcare applications in remote or resource-constrained settings where rapid and reliable diagnostic tools are urgently needed. This novel approach establishes a foundation for developing next-generation, portable diagnostic technologies tailored to clinical demands.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/61e0ba69085ec86d57a2f048c9c38a6c79cf1e03",
        "citation_count": 0
    },
    {
        "title": "Monitoring Human Attention with a Portable EEG Sensor and Supervised Machine Learning",
        "abstract": "For several healthcare applications, it is important to monitor the attention level of people, especially in the fields of rehabilitation and psychology. The recent availability of cheap and portable EEG readers has enabled continuous and unobtrusive acquisition of EEG signals. Those signals may be preprocessed and analysed with machine learning algorithms to estimate the attention level of people without interfering with their current activities. In this paper, we report our experience with attention level estimation using two kinds of devices: an off-the-shelf portable EEG headset, and a more sophisticated",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/61f43e3378e918c1ab3af0f80af8c6b19cfdae01",
        "citation_count": 2
    },
    {
        "title": "Use of Classification Algorithms in Health Care",
        "abstract": "A detailed description will be provided of all the classification algorithms that have been widely used in the domain of medical science. The foundation will be laid by giving a comprehensive overview pertaining to the background and history of the classification algorithms. This will be followed by an extensive discussion regarding various techniques of classification algorithm in machine learning (ML) hence concluding with their relevant applications in data analysis in medical science and health care. To begin with, the initials of this chapter will deal with the basic fundamentals required for a profound understanding of the classification techniques in ML which will comprise of the underlying differences between Unsupervised and Supervised Learning followed by the basic terminologies of classification and its history. Further, it will include the types of classification algorithms ranging from linear classifiers like Logistic Regression, Naive Bayes to Nearest Neighbour, Support Vector Machine, Tree-based Classifiers, and Neural Networks, and their respective mathematics. Ensemble algorithms such as Majority Voting, Boosting, Bagging, Stacking will also be discussed at great length along with their relevant applications. Furthermore, this chapter will also incorporate comprehensive elucidation regarding the areas of application of such classification algorithms in the field of biomedicine and health care and their contribution to decision-making systems and predictive analysis. To conclude, this chapter will devote highly in the field of research and development as it will provide a thorough insight to the classification algorithms and their relevant applications used in the cases of the healthcare development sector.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/62146bc93794b0dfac7ae15a0bf8dca87666b328",
        "citation_count": 8
    },
    {
        "title": "Machine Learning and Knowledge Discovery in Databases",
        "abstract": null,
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/622cdfe99533de280a2a069af462fe066c6258d0",
        "citation_count": 1
    },
    {
        "title": "Healthcare Prognosis Using Machine Learning: A Review",
        "abstract": ": Diseases tracing plays important role in daily life. Everyone cares about their health. According to some social study, a lot of people spends their time online searching for health-related issues. By browsing they get a lot of information about medical concepts and health-related issues. Normally, people use Google to search their queries and that search engine responds to them with the answer but that answer is in scattered format. User does not get the exact answer to their queries. From previous work, there have been vital work on the information needs of health seekers in terms of questions and then select those that ask for a possible disease of their manifested symptoms for further analysis. To resolve such issues an extensive experiment on a real-world dataset labeled by online doctors show significant performance. This paper discussed the techniques for further restructuring of the question and the answer has been done to get the exact answer of the query. A tag mining framework for health seekers will be proposed; aim to identify discriminant features for each specific disease. In this paper, going to use one of the most famous algorithms of machine learning that is the decision tree. It is a type of supervised learning algorithm that is mostly used for classification problems. Surprisingly, it works for both categorical and continuous dependent variables. In this algorithm, split the population into two or more homogeneous sets. This is done based on the most significant attributes independent variables to make as distinct groups as possible.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/624c008f8ce16fbdf506b52aa9283b140f868d8f",
        "citation_count": 0
    },
    {
        "title": "Privacy Protected Medical Data Classification in precision medicine using an Ontology-based Support Vector Machine in the Diabetes Management System",
        "abstract": "Diabetes is a serious health issue across the globe. As stated by the International Diabetes Foundation, currently 425 million people live with diabetes globally, and another 300 million people are expecting to be at higher risk of diabetes in the year 2030.Hence, there is an urgent clinical need for an early prognosis, diagnosis, and management of diabetes and its complications. In this context, numerous intelligent machine learning and data mining approaches including Support vector machine (SVM) have been exploited for diabetes management.SVM is a prevailing supervised and discriminative data classifier which assists the healthcare and biomedical professionals to ascertain unknown data patterns by training a large volume of real-time data. Since this database is the private asset, the sensitive information should be safeguarded without compromising the utility. Even though SVM is a fast and accurate machine learning technique, it does not have the capacity to represent semantically the classification and reasoning rules which can enable more precise classification. Therefore, the objective of this research is three-fold. Firstly, in order to protect sensitive clinical data, we introduce the Kronecker product and Crow Search Algorithm (CSA) based coefficient generation technique. Secondly, we design diabetes ontology to define domain concepts and relationships and allow medical datamining. Finally, we implement the Ontology-based Support Vector Machine (Ont-SVM) classifier by assimilating privacy protection, ontology, and SVM-based classifier for the diagnosis of diabetes.The experimental results on a real-world dataset, the Pima Indian database at the UCI repository, illustrate that the proposed Ont-SVM outperforms other existing approaches in terms of privacy, accuracy, specificity, and sensitivity.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/6256a0929ef703d0fd6b50b512ad944ed7306ad2",
        "citation_count": 1
    },
    {
        "title": "A Survey on Machine Learning Techniques for the Diagnosis of Liver Disease",
        "abstract": "Suffering from liver disease has been rapidly increasing due to excessive drink of alcohol, inhale polluted gas, drugs, contamination food and packing food pickle, so the medical expert system will help a doctor to automatic prediction. With the repeated development in machine learning technology, early prediction of liver disease is possible so that people can easily diagnosis the deadly disease in the early stage. This will give more useful in the Healthcare department and also a medical expert system can be used in a remote area. The liver plays a very important role in life which supports the removal of toxins from the body. So early prediction is very important to diagnosis the disease and recovers. Different types of machine learning, Supervised, Unsupervised and Semi- Supervised, Reinforcement Learning for diagnosis of liver disease such as SVM, KNN, K-Mean clustering, neural network, Decision tree etc and give difference accuracy, precision, sensitivity. The motive of this paper is to give a survey and comparative analysis of the entire machine learning techniques for diagnosis and prediction of liver disease in the medical area, which has already been used for the prediction of liver disease by various authors and the analysis are based on Accuracy, Sensitivity, Precision, and Specificity.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/625df05e59d41ed9d67904229be7743debcde0e0",
        "citation_count": 0
    },
    {
        "title": "Bayesian Filtering Methods For Dynamic System Monitoring and Control",
        "abstract": "of a dissertation at the University of Miami. Dissertation supervised by Professor Ramin Moghaddas. No. of pages in text. (175) Real-time system monitoring and control represent two of the most important issues that characterize modern industries in critical areas of civilian and military interest, including power grid, energy, healthcare, aerospace, and infrastructure. During the past decade, there has been a rapid development of robust dynamic system monitoring and control methods for fault diagnosis and failure prognosis. Among various monitoring and control policies, condition-based maintenance (CBM) has been studied by many researchers due to its ability to enable a large amount of monitoring data for real-time diagnostics and prognostics. A considerable amount of literature has been published on the subject, providing a large volume of dynamic system control methods. Previously published studies are limited by assumptions that can generally be distinguished into three main categories: i) predefined system failure thresholds, ii) simplified latent dynamics, and iii) unrealistic parametric forms that describe the evolution of system dynamics through time. This thesis provides an array of solution approaches that overcomes the aforementioned assumptions in a smart and effective way by introducing novel quantitative frameworks for real-time monitoring, control, and decision-making for dynamic systems. The proposed frameworks are categorized into two main phases of a comprehensive framework. The first phase contains two original Bayesian filtering methods for condition monitoring and control of systems with either linear or non-linear degradation dynamics. The former is designed only for systems with linear latent and observable dynamics and utilizes Kalman filtering for state-parameter inference. It considers a failure process that is purely stochastic and is based on logistic regression. This process is directly affected by the latent system dynamics, therefore avoiding the need for a priori failure thresholds. The latter takes into consideration multiple levels of system dynamics that evolve either linearly or non-linearly. A hybrid particle filter is developed for state-parameter inference, while an Extreme Learning Machine artificial neural network is utilized to relate sensor observations to latent system dynamics. Both frameworks are tested and validated on synthetic and real-world time-series datasets. The second phase of this thesis introduces an original method for optimal control and decision-making that employs Bayesian filtering-based deep reinforcement learning with fully stochastic environments. Sets of deep reinforcement learning agents were trained to develop control policies. Bayesian filtering methods from the first phase were utilized to provide environment states that use the estimates from latent system dynamics. This method is used in two different applications for maintenance cost minimization and estimating remaining useful life of a system under condition monitoring. Results obtained from applying the framework on simulated and realworld time-series data suggest that the proposed Bayesian filtering-based deep reinforcement learning algorithm can be trained even with limited data, which can be useful for real-time control and decision making for many dynamic systems. Dedicated to my fantastic parents, Gordios and Vasiliki, for providing me with every opportunity and encouragement in life",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/6273eecc2aa48d93804ee26ed745b91b59885e42",
        "citation_count": 0
    },
    {
        "title": "Machine learning for healthcare with a focus on the early diagnosis of epilepsy and brain tumor detection",
        "abstract": "Machine learning (ML) techniques have evolved rapidly in recent years and have shown impressive capabilities in feature extraction, pattern recognition, and causal inference. There has been an increasing attention to applying ML to medical applications, such as medical diagnosis, drug discovery, personalized medicine, and numerous other medical problems. ML-based methods have the advantage of processing vast amounts of data. With an ever increasing amount of medical data collection and large, inter-subject variability in the medical data, automated data processing pipelines are very much desirable since it is laborious, expensive, and error-prone to rely solely on human processing. ML methods have the potential to uncover interesting patterns, unravel correlations between complex features, learn patient-specific representations, and make accurate predictions. Motivated by these promising aspects, in this thesis, I present studies where I have implemented deep neural networks for the early diagnosis of epilepsy based on electroencephalography (EEG) data and brain tumor detection based on magnetic resonance spectroscopy (MRS) data. In the project for early diagnosis of epilepsy, we are dealing with one of the most common neurological disorders, epilepsy, which is characterized by recurrent unprovoked seizures. It can be triggered by a variety of initial brain injuries and manifests itself after a time window which is called the latent period. During this period, a cascade of structural and functional brain alterations takes place leading to an increased seizure susceptibility. The development and extension of brain tissue capable of generating spontaneous seizures is defined as epileptogenesis (EPG). Detecting the presence of EPG provides a precious opportunity for targeted early medical interventions and, thus, can slow down or even halt the disease progression. In order to study brain signals in this latent window, animal epilepsy models are used to provide valuable data as it is extremely difficult to obtain this data from human patients. The aim of this study is to discover biomarkers of EPG using animal models and then to find the equivalent and counterparts in human patients' data. However, the EEG features for EPG are not well-understood and there is not a sufficiently large amount of annotated data for ML-based algorithms. To approach this problem, firstly, I utilized the timestamp information of the recorded EEG from an animal epilepsy model where epilepsy is induced by an electrical stimulation. The timestamp serves as a form of weak supervision, i.e., before and after the stimulation. Secondly, I implemented a deep residual neural network and trained it with a binary classification task to distinguish the EEG signals from these two phases. After obtaining a high discriminative ability on the binary classification task, I proposed to divide further the time span after the stimulation for a three-class classification, aiming to detect possible stages of the progression of the latent EPG phase. I have shown that the model can distinguish EEG signals at different stages of EPG with high accuracy and generalization ability. I have also demonstrated that some of the learned features from the network are clinically relevant. In the task of detecting brain tumors based on MRS data, I first proposed to apply a deep neural network on the MRS data collected from over 400 patients for a binary classification task. To combat the challenge of noisy labeling, I developed a distillation step to filter out relatively ``cleanly'' labeled samples. A mixing-based data augmentation method was also implemented to expand the size of the training set. All the experiments were designed to be conducted with a leave-patient-out scheme to ensure the generalization ability of the model. Averaged across all leave-patient-out cross-validation sets, the proposed method performed on par with human neuroradiologists, while outperforming other baseline methods. I have demonstrated the distillation effect on the MNIST data set with manually-introduced label noise as well as providing visualization of the input influences on the final classification through a class activation map method. Moreover, I have proposed to aggregate information at the subject level, which could provide more information and insights. This is inspired by the concept of multiple instance learning, where instance-level labels are not required and which is more tolerant to noisy labeling. I have proposed to generate data bags consisting of instances from each patient and also proposed two modules to ensure permutation invariance, i.e., an attention module and a pooling module. I have compared the performance of the network in different cases, i.e., with and without permutation-invariant modules, with and without data augmentation, single-instance-based and multiple-instance-based learning and have shown that neural networks equipped with the proposed attention or pooling modules can outperform human experts.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/628fe0bc212fae7308c761e8fd0b10c293f29103",
        "citation_count": 0
    },
    {
        "title": "Multi-view versus single-view machine learning for diseasediagnosis in primary healthcare",
        "abstract": "The work presented in this report considers and compares two different approaches of machine learning towards solving the problem of disease diagnosis prediction in primary healthcare: single-view and multi-view machine learning. In particular, the problem of disease diagnosis prediction refers to the issue of predicting a (possible) diagnosis for a given patient based on her past medical history. The problem area is extensive, especially considering the fact that there are over 14,400 unique possible diagnoses (grouped into 22 high level categories) that can be considered as prediction targets. The approach taken in this work considers the high-level categories as prediction targets and attempts to use the two different machine learning techniques towards getting close to an optimal solution of the issue. The multi-view machine learning paradigm was chosen as an approach that can improve predictive performance of classifiers in settings where we have multiple heterogeneous data sources (different views of the same data), which is exactly the case here. In order to compare the single-view and multi-view machine learning paradigms (based on the concept of supervised learning), several different experiments are devised which explore the possible solution space under each paradigm. The work closely touches on other machine learning concepts such as ensemble learning, stacked generalization and dimensionality reduction-based learning. As we shall see, the results show that multiview stacked generalization is a powerful paradigm that can significantly improve the predictive performance in a supervised learning setting. The different models performance was evaluated using F1 scores and we have been able to observe an average increase of performance of 0.04 and a maximum increase of 0.114 F1 score points. The findings also show that approach of multi-view stacked ensemble learning is particularly well suited as a noise reduction technique and works well in cases where the feature data is expected to contain a notable amount of noise. This can be very beneficial and of interest to projects where the features are not manually chosen by domain experts.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/62c380024a8fa447df829d2a1317fc06eac100f3",
        "citation_count": 1
    },
    {
        "title": "\u2018Without data, you\u2019re just another person with an opinion\u2019",
        "abstract": "ABSTRACT Introduction: Given the recent impressive digital transformation worldwide, the importance of data has reached a new dimension. It is, therefore, provocative to ask whether data can save healthcare systems from bankruptcy. Areas covered: We reviewed published examples in the search for the evidence on how the growing amount of data could change the way we used to assess the value of healthcare technologies, ensuring a more holistic approach in the decision-making process while reducing the waste in the healthcare. Expert opinion: The growing amount of data will continue to provide a multitude of valuable insights that can save healthcare systems from bankruptcy. Electronic medical records, IoT, wearables, and mobile applications generate constant data streams that can be utilized endlessly thanks to methodological advancements such as SNA, unsupervised and supervised machine learning, and natural language programming. However, interoperability across these multiple data sources still pose a challenge for the future development of data-driven healthcare. Already today however, decision makers can utilize Big Data to develop conditional coverage schemes for very expensive and complicated health technologies suitable for personalized healthcare. More advanced payers may utilize even data analytics even further and develop AI-based pricing schemes.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/62db45580c4114d2a23d2424b0050810aeb59395",
        "citation_count": 13
    },
    {
        "title": "Sensor-Based Human Activity Recognition for Smart Healthcare: A Semi-supervised Machine Learning",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/62edb597b772d881fe945e3c745a6b6a66242cec",
        "citation_count": 41
    },
    {
        "title": "ILIME: Local and Global Interpretable Model-Agnostic Explainer of Black-Box Decision",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/631451e06de57013cccb4fba2f8a72cfe7c8fcde",
        "citation_count": 27
    },
    {
        "title": "Dynamic Neural Graphs Based Federated Reptile for Semi-Supervised Multi-Tasking in Healthcare Applications",
        "abstract": "AI healthcare applications rely on sensitive electronic healthcare records (EHRs) that are scarcely labelled and are often distributed across a network of the symbiont institutions. It is challenging to train the effective machine learning models on such data. In this work, we propose dynamic neural graphs based federated learning framework to address these challenges. The proposed framework extends Reptile, a model agnostic meta-learning (MAML) algorithm, to a federated setting. However, unlike the existing MAML algorithms, this paper proposes a dynamic variant of neural graph learning (NGL) to incorporate unlabelled examples in the supervised training setup. Dynamic NGL computes a meta-learning update by performing supervised learning on a labelled training example while performing metric learning on its labelled or unlabelled neighbourhood. This neighbourhood of a labelled example is established dynamically using local graphs built over the batches of training examples. Each local graph is constructed by comparing the similarity between embedding generated by the current state of the model. The introduction of metric learning on the neighbourhood makes this framework semi-supervised in nature. The experimental results on the publicly available MIMIC-III dataset highlight the effectiveness of the proposed framework for both single and multi-task settings under data decentralisation constraints and limited supervision.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/63ff101ed58cb0ef833a37d020c925aa4a2f6f82",
        "citation_count": 23
    },
    {
        "title": "Unlocking LLMs: Addressing Scarce Data and Bias Challenges in Mental Health",
        "abstract": "Large language models (LLMs) have shown promising capabilities in healthcare analysis but face several challenges like hallucinations, parroting, and bias manifestation. These challenges are exacerbated in complex, sensitive, and low-resource domains. Therefore, in this work we introduce IC-AnnoMI, an expert-annotated motivational interviewing (MI) dataset built upon AnnoMI by generating in-context conversational dialogues leveraging LLMs, particularly ChatGPT. IC-AnnoMI employs targeted prompts accurately engineered through cues and tailored information, taking into account therapy style (empathy, reflection), contextual relevance, and false semantic change. Subsequently, the dialogues are annotated by experts, strictly adhering to the Motivational Interviewing Skills Code (MISC), focusing on both the psychological and linguistic dimensions of MI dialogues. We comprehensively evaluate the IC-AnnoMI dataset and ChatGPT's emotional reasoning ability and understanding of domain intricacies by modeling novel classification tasks employing several classical machine learning and current state-of-the-art transformer approaches. Finally, we discuss the effects of progressive prompting strategies and the impact of augmented data in mitigating the biases manifested in IC-AnnoM. Our contributions provide the MI community with not only a comprehensive dataset but also valuable insights for using LLMs in empathetic text generation for conversational therapy in supervised settings.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/6416ee691fd651671e4d578b5d254c7d8d684b44",
        "citation_count": 0
    },
    {
        "title": "Comparative assessment of machine learning algorithms to predict severity of disease in COVID-19 patients based on eight cofactors",
        "abstract": "Machine learning is one of the important tools to diagnose and predict the diseased state accurately and effectively. The COVID-19 pandemic caused due to severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has become one of the most researched healthcare topics worldwide. Machine learning algorithms can find efficient and reliable ways to predict the COVID-19 from vast amounts of existing health care data, allowing faster, effective, and more accurate diagnosis with lower risk based on the symptoms. Based on the countrywide data published by the Israeli Ministry of Health, we propose a system that detects COVID-19 instances using simple variables. The COVID-19 dataset used in the study consisted of 278848 patients samples with five different symptoms, namely cough, fever, sore throat, shortness of breath, and headache, apart from other basic information like age, gender, and test indication excluding confirmed COVID-19 result. The data was analyzed using traditional supervised machine learning algorithms namely, Decision tree, Support vector machine, Random Forest, Logistic regression, k-nearest neighbor, and Naive Bayes based on eight cofactors with high accuracy rate (\u2265 0.9450). Apart from Support vector machine, all other algorithms displayed better performance based on the AUC score calculated using the receiver operator characteristic (ROC) curve. This study also highlights the significant differences between precision, recall and accuracy for each model. Graphical Abstract",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/641a657d54bfa72cfb402381098d1bae661aaf98",
        "citation_count": 0
    },
    {
        "title": "GUI BASED PREDICTION OF HEART STROKE STAGES BY SUPERVISED MACHINE LEARNING ALGORITHM",
        "abstract": "Heart attacks diseases are considered as the most Prevalent. Stroke Prediction using patient treatment history and health data by applying data mining and machine learning techniques is ongoing struggle for the past decades. The traditional prescient models or methods are as yet not powerful enough in catching the hidden information since it is unequipped for reproducing the multifaceted nature on include portrayal of the therapeutic issue space. In existing system, Vascular state is determined by measuring changes in the pressure wave forms induced through intentional variation in the device generated blood flow.To overcome this problem, predictive analytical techniques for heart stroke using machine learning model applied on given hospital data set. The performance from the given hospital data set with evaluation of classification report and identify the confusion matrix. Focuses on the design of a graphical user interface (GUI) for the prediction of stroke using risk parameters. Data collected from Kaggle data set was successfully trained and tested using Supervised machine learning algorithm.To propose a machine learning-based method to accurately predict the heart stroke by given attributes in the form of best accuracy from comparing supervised classification machine learning algorithms. Additionally, to compare and discuss the performance of various machine learning algorithms from the given healthcare department data set with evaluation classification report, identify the confusion matrix . Result shows that the effectiveness of GUI based the proposed machine learning algorithm technique can be compared with best accuracy with precision, Recall and F1 Score.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/646ffbe45797c650f59210ee7cb8da281139f5ce",
        "citation_count": 1
    },
    {
        "title": "Machine Learning in Healthcare: A Comprehensive Review of Predictive Models for COVID-19 Transmission among Vaccinated Individuals",
        "abstract": "This review provides an in-depth exploration of machine learning (ML) applications in healthcare, focusing specifically on predictive models for COVID-19 transmission among vaccinated individuals. It underscores the pivotal role of ML in disease forecasting and prognosis, showcasing its potential to enhance healthcare outcomes in pandemic contexts. Key challenges of COVID-19, such as the high transmission rate of asymptomatic carriers and the effectiveness of containment strategies, are analyzed to highlight areas where ML can offer significant advantages. The study aims to develop an advanced forecasting model for COVID-19 transmission using diverse supervised ML regression techniques, including linear regression, LASSO, support vector machine, and exponential smoothing, applied to an extensive COVID-19 patient dataset. The insights generated from this review support efforts to combat COVID-19 and improve public health strategies, demonstrating ML's vital contribution to pandemic management and healthcare resilience.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/649ecc1f05c7957a70403368d9f10eeb95834dce",
        "citation_count": 0
    },
    {
        "title": "Supervised machine learning tools: a tutorial for clinicians",
        "abstract": "In an increasingly data-driven world, artificial intelligence is expected to be a key tool for converting big data into tangible benefits and the healthcare domain is no exception to this. Machine learning aims to identify complex patterns in multi-dimensional data and use these uncovered patterns to classify new unseen cases or make data-driven predictions. In recent years, deep neural networks have shown to be capable of producing results that considerably exceed those of conventional machine learning methods for various classification and regression tasks. In this paper, we provide an accessible tutorial of the most important supervised machine learning concepts and methods, including deep learning, which are potentially the most relevant for the medical domain. We aim to take some of the mystery out of machine learning and depict how machine learning models can be useful for medical applications. Finally, this tutorial provides a few practical suggestions for how to properly design a machine learning model for a generic medical problem.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/64e76a22692fa6f5761a70adbc58f44e9078520e",
        "citation_count": 94
    },
    {
        "title": "A Web-scrapped Skin Image Database of Monkeypox, Chickenpox, Smallpox, Cowpox, and Measles",
        "abstract": "Monkeypox has emerged as a fast-spreading disease around the world and an outbreak has been reported in 42 countries so far. Although the clinical attributes of Monkeypox are similar to that of Smallpox, skin lesions and rashes caused by Monkeypox often resemble that of other pox types, e.g., Chickenpox and Cowpox. This scenario makes an early diagnosis of Monkeypox challenging for the healthcare professional just by observing the visual appearance of lesions and rashes. The rarity of Monkeypox before the current outbreak further created a knowledge gap among healthcare professionals around the world. To tackle this challenging situation, scientists are taking motivation from the success of supervised machine learning in COVID-19 detection. However, the lack of Monkeypox skin image data is making the bottleneck of using machine learning in Monkeypox detection from skin images of patients. Therefore, in this project, we introduce the Monkeypox Skin Image Dataset (MSID), the largest of its kind so far. We used web-scrapping to collect Monkeypox, Chickenpox, Smallpox, Cowpox and Measles infected skin as well as healthy skin images to build a comprehensive image database and made it publicly available. We believe that our database will facilitate the development of baseline machine learning algorithms for early Monkeypox detection in clinical settings. Our dataset is available at the following Kaggle link: https://www.kaggle.com/datasets/arafathussain/monkeypox-skin-image-dataset-2022.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/6539643d5475a50823903842d8c05fd40fb5b307",
        "citation_count": 24
    },
    {
        "title": "Exploring the Growth of COVID-19 Cases using Exponential Modelling Across 42 Countries and Predicting Signs of Initial Containment using Machine learning",
        "abstract": "COVID-19 pandemic disease spread by SARS-COV-2 single-strand structure RNA virus belongs to the 7th generation of the coronavirus family. Following an unusual replication mechanism, its extreme ease of transmissibility has put many counties under lockdown. With a cure for the infection uncertain in the near future, the pressure currently lies in the current healthcare infrastructure, policies, government activities, and behaviour of the people to contain the virus. This research seeks to understand the spreading patterns of the COVID-19 virus through exponential growth modelling and identifies countries that have showed an initial sign of containment until 26th March 2020. Post identification of countries that have shown an initial sign of containment, predictive supervised machine learning models were built with infrastructure, environment, policies, and infection related independent variables. For the purpose, COVID-19 infection data across 42 countries were used. Logistic regression results shows a positive significant relationship of healthcare infrastructure and lockdown policies on the sign of early containment in countries. Machine learning models based on logistic regression, decision tree, random forest, and support vector machines were developed and are seen to have accuracies between 76.2% to 92.9% to predict early sign of infection containment. Other policies and activities taken by countries to contain the infection are also discussed.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/658e52a958a390ad7f754d0399c59c3792ec2404",
        "citation_count": 1
    },
    {
        "title": "Screening For Childhood Autism Spectrum Disorder Using Machine Learning",
        "abstract": "Autism Spectrum Disorder (ASD) affects\ncommunication, behavior, and social interactions, and\nearly detection is crucial for intervention. Current\ndiagnostic method sare subjective and prone to delays or\nmisdiagnosis. This project explores machine learning\n(ML) to automate ASD screening using behavioral data,\ndiagnostic questionnaires, and developmental milestones.\nSupervised learning algorithms classify children into\nASD or non-ASD categories with high accuracy. The\napproach aims to assist clinicians in early identification\nand intervention. It offers a scalable, efficient, and\nobjective screening tool for ASD in clinical and\neducational settings.\nKey Words: Autism Spectrum Disorder (ASD),\nMachine Learning, Early Detection, Screening,\nBehavioral Data, Supervised Learning, Diagnostic Tools,\nDevelopmental Milestones, Classification, Intervention,\nArtificial Intelligence, Predictive Modeling, Child\nDevelopment, Healthcare Technology, Autism\nDiagnosis.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/65ef38b71ad3d0c2c05940cbf68913a7bd9ab866",
        "citation_count": 0
    },
    {
        "title": "Supervised Learning Framework for Healthcare Fraud Detection System with Excluded Provider Labels",
        "abstract": "With the overall increase in the elderly population comes additional, necessary medical needs and costs. Medicare is a U.S. healthcare program that provides insurance, primarily to individuals 65 years or older, to offload some of the financial burden associated with medical care. Even so, healthcare costs are high and continue to increase. Fraud is a major contributor to these inflating healthcare expenses. Our paper provides a comprehensive study leveraging machine learning methods to detect fraudulent Medicare providers. We use publicly available Medicare data and provider exclusions for fraud labels to build and assess three different learners. In order to lessen the impact of class imbalance, given so few actual fraud labels, we employ random under sampling creating four class distributions. Our results show that the C4.5 decision tree and logistic regression learners have the best fraud detection performance, particularly for the 80:20 class distribution with average AUC scores of 0.883 and 0.882, respectively, and low false negative rates. We successfully demonstrate the efficacy of employing machine learning with random under sampling to detect Medicare fraud.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/663d788cb98b6fa5a4c3719a3b41f7a91555c134",
        "citation_count": 1
    },
    {
        "title": "A Systematic Evaluation of Recurrent Neural Network Models for Edge Intelligence and Human Activity Recognition Applications",
        "abstract": "The Recurrent Neural Networks (RNNs) are an essential class of supervised learning algorithms. Complex tasks like speech recognition, machine translation, sentiment classification, weather prediction, etc., are now performed by well-trained RNNs. Local or cloud-based GPU machines are used to train them. However, inference is now shifting to miniature, mobile, IoT devices and even micro-controllers. Due to their colossal memory and computing requirements, mapping RNNs directly onto resource-constrained platforms is arcane and challenging. The efficacy of edge-intelligent RNNs (EI-RNNs) must satisfy both performance and memory-fitting requirements at the same time without compromising one for the other. This study\u2019s aim was to provide an empirical evaluation and optimization of historic as well as recent RNN architectures for high-performance and low-memory footprint goals. We focused on Human Activity Recognition (HAR) tasks based on wearable sensor data for embedded healthcare applications. We evaluated and optimized six different recurrent units, namely Vanilla RNNs, Long Short-Term Memory (LSTM) units, Gated Recurrent Units (GRUs), Fast Gated Recurrent Neural Networks (FGRNNs), Fast Recurrent Neural Networks (FRNNs), and Unitary Gated Recurrent Neural Networks (UGRNNs) on eight publicly available time-series HAR datasets. We used the hold-out and cross-validation protocols for training the RNNs. We used low-rank parameterization, iterative hard thresholding, and spare retraining compression for RNNs. We found that efficient training (i.e., dataset handling and preprocessing procedures, hyperparameter tuning, and so on, and suitable compression methods (like low-rank parameterization and iterative pruning) are critical in optimizing RNNs for performance and memory efficiency. We implemented the inference of the optimized models on Raspberry Pi.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/666db56c696aa81debe0db37c77680ca62df9763",
        "citation_count": 6
    },
    {
        "title": "The use of generative artificial intelligence in surgical education: a narrative review",
        "abstract": "The introduction of generative artificial intelligence (AI) has revolutionized healthcare and education. These AI systems, trained on vast datasets using advanced machine learning (ML) techniques and large language models (LLMs), can generate text, images, and videos, offering new avenues for enhancing surgical education. Their ability to produce interactive learning resources, procedural guidance, and feedback post-virtual simulations makes them valuable in educating surgical trainees. However, technical challenges such as data quality issues, inaccuracies, and uncertainties around model interpretability remain barriers to widespread adoption. This review explores the integration of generative AI into surgical training, assessing its potential to enhance learning and teaching methodologies. While generative AI has demonstrated promise for improving surgical education, its integration must be approached cautiously, ensuring AI input is balanced with traditional supervision and mentorship from experienced surgeons. Given that generative AI models are not yet suitable as standalone tools, a blended learning approach that integrates AI capabilities with conventional educational strategies should be adopted. The review also addresses limitations and challenges, emphasizing the need for more robust research on different AI models and their applications across various surgical subspecialties. The lack of standardized frameworks and tools to assess the quality of AI outputs in surgical education necessitates rigorous oversight to ensure accuracy and reliability in training settings. By evaluating the current state of generative AI in surgical education, this narrative review highlights the potential for future innovation and research, encouraging ongoing exploration of AI in enhancing surgical education and training.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/667444386ba11d204061b0eb31081deeee65908e",
        "citation_count": 0
    },
    {
        "title": "Prediction Analysis of Preterm Neonates Mortality using Machine Learning Algorithms via Python Programming",
        "abstract": "Prediction analysis of preterm neonate mortality is necessary and significant for benchmarking and evaluating healthcare services in Hospitals and other medical centers. Application of artificial intelligence and machine learning models, which is a hot topic in medicine/healthcare and engineering, may improve physicians\u2019 skill to predict the preterm neonatal deaths. The main purpose of this research article is to introduce a preterm neonatal mortality risk prediction by means of machine learning/ML predictive models to survive infants using supervised ML models if possible. Moreover, this paper presents some effective parameters and features which affect to survive the infants directly. It means, the obtained model has an accuracy of about 91.5% to predict the status of infant after delivery. After recognizing the critical status for an infant, physicians and other healthcare personnel can help to infant for possible surviving using special medical NICU cares. It has been tried to get some suitable models with high accuracy and comparing the results. In a word, a survival prediction analysis of preterm neonate mortality has been carried out using machine learning methods via Python programming (possible surviving infants after delivery in the hospital).",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/66c47718a71eabae877ee52fd5c7e6ade1885b79",
        "citation_count": 1
    },
    {
        "title": "Early Detection of Lung Cancer with Accuracy Monitoring using Logistic Regression Algorithm",
        "abstract": ": The early detection of lung cancer is vital for enhancing patient prognosis, as early-stage diagnosis leads to more effective treatment options and improved survival rates. Logistic regression, a supervised machine learning algorithm, has demonstrated significant potential in identifying early-stage lung cancer by processing clinical, demographic, and radiological data. This method assigns probabilities to various patient outcomes, making it possible to predict the likelihood of lung cancer based on specific risk factors. Logistic regression is favored for its simplicity and interpretability, providing clear insights into which factors are most influential in cancer prediction. Accuracy monitoring plays a crucial role in the deployment of logistic regression for lung cancer detection. Through continuous assessment of model performance using key metrics like accuracy, sensitivity, specificity, and area under the curve (AUC), the system ensures reliability in real-world clinical environments. This iterative process allows for the adjustment and refinement of the model as new data becomes available, improving its predictive capacity. The combination of logistic regression with accuracy monitoring enables healthcare providers to make informed, timely decisions in lung cancer detection, potentially reducing mortality rates.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/66f0ad9740f991d186b85c3bb18205ecbc0160d1",
        "citation_count": 0
    },
    {
        "title": "Could Machine Learning be used to address Africa\u2019s Challenges?",
        "abstract": "Machine Learning can be both experience and supervised based learning. Machine learning would help in designing system that can be able to take decisions in a more optimized form and also help them to work in most efficient method. In the field of machine learning one considers the important question of how to make machines able to \u201clearn\u201d. Learning in this context is understood as inductive inference, where one observes examples that represent incomplete information about some \u201cstatistical phenomenon\u201d. Advanced economies are already using machine learning to solve problems like medical diagnosis, Improving Ecommerce Conversion Rates, traffic congestion, saving cows from bad drivers and improving healthcare, while Africa lags conspicuously behind. African leaders may be aware of this. Whether they possess the foresight to see and take people through is however debatable. This paper discusses how machine learning could be used to address Africa\u2019s challenges by highlighting how some of major challenges can be solved using certain machine learning techniques. Major challenges to Africa continent are identified and machine learning techniques",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/6742fab307b32bb48fba49b67e658aa4d35c7d27",
        "citation_count": 6
    },
    {
        "title": "SMS Spam Filteration Using Text Features and Supervised Machine Learning Algorithms",
        "abstract": "Over time, technological advancements have had an immense effect on every aspect of life, including travel, office work, music, healthcare, and communication. In the past, people communicated using telephone lines. With far more functionality than telephone cable technology, wireless technology already prevails. SMS is mostly used by spammers and advertising firms to communicate with the general public and distribute company pamphlets. This explains why over 60% of spam SMS are sent and received every day. Although these spam communications irritate users and occasionally con unsuspecting users, the spammers and ad businesses benefit handsomely from them. This paper suggested a method for categorizing ham and spam SMS using supervised machine learning approaches. Features are extracted from data using feature extraction techniques like bag-of- words and Term Frequency-Inverse Document Frequency (TF-IDF). The imbalance in the SMS dataset we used was addressed by applying both oversampling and under sampling techniques. The support vector classifier, gradient boosting machine, random forest, Gaussian Naive Bayes, and logistics regression are implemented on the using spam SMS and ham SMS data sets, evaluated by F1 score, accuracy, precision and recall are used to assess performance. According to the experiment's findings, the random forest diagnoses spam and ham SMS more precisely-99% of the time.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/6797346a7cdf889648319f733ae815a40e546dcc",
        "citation_count": 0
    },
    {
        "title": "CLM SAPP Feature Extraction SVM Comfort / Discomfort Viola-Jones Face Detector Discomfort Detection Single Frame Face Detection Video Skin Color Face Detector",
        "abstract": "Automatic discomfort detection for infants is important in healthcare, since infants have no ability to express their discomfort. We propose a video analysis system, based on supervised learning and classifying previously unseen infants from the testing set in a fully automated way. The first stage of our system consists of fame-based face detection, and then fit a face shape to the detected face area by using a Constrained Local Model (CLM). In the second stage, we analyze expression features by using Elongated Local Binary Patterns (ELBP), and classify expression features with an Support Vector Machine (SVM) for discomfort detection. The key contribution of our system is that the face model is infantindependent by employing a Constrained Local Model without prior knowledge about previously unseen infants. The system detects discomfort with an accuracy of 84.3%, a sensitivity of 82.4%, and specificity of 84.9% on the testing set containing videos of 11 infants. In addition, in order to increase the robustness of the system to head rotation, we introduce a face recovery method based on the symmetry of the face. With this step, the previous performance parameters increase by 3.1\u2212 3.8% tested with videos of 2 infants containing 2, 010 frames.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/67c583c684371110772ef21ecd7b40649c27f347",
        "citation_count": 0
    },
    {
        "title": "Exploring a Gradient-based Explainable AI Technique for Time-Series Data: A Case Study of Assessing Stroke Rehabilitation Exercises",
        "abstract": "Explainable artificial intelligence (AI) techniques are increasingly being explored to provide insights into why AI and machine learning (ML) models provide a certain outcome in various applications. However, there has been limited exploration of explainable AI techniques on time-series data, especially in the healthcare context. In this paper, we describe a threshold-based method that utilizes a weakly supervised model and a gradient-based explainable AI technique (i.e. saliency map) and explore its feasibility to identify salient frames of time-series data. Using the dataset from 15 post-stroke survivors performing three upper-limb exercises and labels on whether a compensatory motion is observed or not, we implemented a feed-forward neural network model and utilized gradients of each input on model outcomes to identify salient frames that involve compensatory motions. According to the evaluation using frame-level annotations, our approach achieved a recall of 0.96 and an F2-score of 0.91. Our results demonstrated the potential of a gradient-based explainable AI technique (e.g. saliency map) for time-series data, such as highlighting the frames of a video that therapists should focus on reviewing and reducing the efforts on frame-level labeling for model training.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/68490ca23c555c19e065f2f9d3c89cc58c11d23b",
        "citation_count": 3
    },
    {
        "title": "A Proficient Framework for Coronary Artery Disease Prediction using Logistic Regression",
        "abstract": "The healthcare industry is actively researching heart disease prediction to identify people who have a higher likelihood of developing this condition. Due to the increasing prevalence of heart disease, it is vital to accurately identify and treat people at risk for it. Machine learning-based techniques offer potential benefits in the early detection and prevention of heart disease, but developing such methods is a complex task. Many countries lack the necessary cardiovascular expertise, and there is a significant number of misdiagnosed cases. Accurate and efficient prediction of heart disease at an early stage is essential for managing and treating the condition effectively, and digital patient records can support clinical decision-making. The ultimate goal is to reduce the incidence and mortality rates associated with heart disease. In this research, several supervised machine-learning algorithms have been developed and compared for their effectiveness in predicting heart disease, including Logistic Regression, Decision Tree, Na\u00efve Bayes, KNN, and Xtreme Gradient Boosting (XGB). Among these models, Logistic Regression has demonstrated an accuracy of 0.86 and precision of 0.90, making it a promising approach for heart disease prediction.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/686393ed752cffe0549e3e3bbc8ac7ec1b92960f",
        "citation_count": 1
    },
    {
        "title": "Supervised and Unsupervised Machine Learning for Cancer Classification: Recent Development",
        "abstract": "This is models with the ability to detect and classify cancer is important in the industrial of healthcare. The most difficult aspect for such model is the classification of cancer, which can be addressed using machine learning methods. The methods are used to improve classification accuracy between system output and test data. The classification process becomes more difficult due to vast data information. This paper presents an overview on current development of cancer classification techniques using machine learning methods, which have received increasing attention within the area of healthcare. This review will mainly focus on the development of machine learning methods for classification of cancer diseases. Recently, there are various researchers proposed different kinds of methods for cancer classification. The results show that the successful of cancer classification is dependent on the machine learning models. Besides, various types of healthcare data used in the experiments would also be discussed in this paper. The development of many optimization methods for cancer classification has brought a lot of improvement in the healthcare field. There is demand for further improvements in optimization methods to develop better machine learning models for cancer classification.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/68cb616996f48c91120450b437b0c772813be02c",
        "citation_count": 1
    },
    {
        "title": "Supervised Machine Learning Algorithms Using Patient Related Factors to Predict in-Hospital Mortality Following Acute Myeloid Leukemia Therapy",
        "abstract": "Background:\n Despite careful patient selection and improved supportive care over recent years, chemotherapy for acute myeloid leukemia (AML) is still associated with a significant risk for treatment-related mortality (5-20%), resulting from an interplay of multiple patient and disease-related factors. Tools to better identify candidates suitable for intensive chemotherapy are much needed. In this analysis, using a large administrative database, we evaluate the potential of machine learning (ML) algorithms trained using factors available at the time of admission for AML therapy to predict death during the hospitalization.\n Methods:\n We utilized the State Inpatient Database (SID) for years 2008-2014, which holds one of the largest collections of inpatient discharges incorporating all payers from community hospitals in the United States and is part of Healthcare Cost and Utilization Project (HCUP). Data from following states was obtained for analysis: Arizona, Florida, New York, Maryland, Washington, and New Jersey. Our cohort included adult (age >17) patients diagnosed with AML (ICD-9 codes 205.XX, 206.XX, and 207.XX) and receipt of any type of chemotherapy on same admission confirmed by ICD-9 diagnosis code (V581, V5811, and V5812) or ICD-9 procedure code of 9925. The primary objective was to predict inpatient mortality in AML patients undergoing chemotherapy using covariates that were present prior to chemotherapy initiation. Features included age, race, emergency room use, year of admission, number of days from admission to chemotherapy, comorbid conditions present at the time of admission, and procedures performed on or before the day of administration of chemotherapy. The main cohort was split into training (80%) and test (20%) sets. We compared several supervised machine learning classification algorithms including logistic regression (LR), decision trees (DT) and random forests (RF). Algorithms were trained using 5-fold cross validation with hyperparameters selected via grid search to prevent overfitting. Model performance on the test set was accessed using area under the receiver operating characteristic curve (AUC, ROC). True positive rate (TPR), true negative rate (TNR) and positive predictive value (PPV) were assessed at multiple thresholds. SAS 9.4 and Python libraries were utilized for all analysis.\n Results:\n A total of 29613 subjects with AML were included in final analysis each associated with 4177 features after including indicators to capture missing categorical variables. Median age was 58.9(18-101) years. 13689 (53.7%) were males and 20203 (69%) were Caucasian. Each subject underwent some form of chemotherapy. Mean time from admission to starting chemotherapy was 3 days (95%CI, 2.9-3.1). Among all subjects, 2682 (9.1%) died during the hospitalization following chemotherapy administration. Figure 1 shows the ROC curve comparing all algorithms. Both LR and RF achieved an AUC score of 0.78 while DT achieved 0.70 AUC. In comparison, a baseline LR model with age as the sole predictor yielded 0.62 AUC. Table 1 provides TPR, TNR and PPV for each algorithm at varying decision boundary thresholds.\n Discussion:\n The strength of this machine learning approach is the applicability of using readily-accessible personalized variables to predict inpatient mortality of any patient on track for chemotherapy to treat AML, without incorporating performance status or any laboratory information. Using a threshold of 0.7, our trained RF model achieves TNR of 99.2%, TPR of 8.6 % and PPV of 57.3%. If this threshold is used to select patients suitable for chemotherapy, 51 out of 587 total deaths that occurred in our test set of 5923 could have avoided treatment related mortality while 38 would not have received chemotherapy as they will be falsely flagged. Our study supports the use of supervised machine learning algorithms on large administrative databases to create healthcare solutions. One limitation is that this dataset is not able to differentiate discharges following induction therapy in newly diagnosed patients from those following consolidation. Next steps would be to validate on larger cohorts with more detailed therapy information. Ultimately, estimating inpatient mortality at the time of hospitalization may prove useful in helping clinicians identify high-risk patients for whom alternative treatment options would have better outcomes than chemotherapy.\n \n \n \n No relevant conflicts of interest to declare.\n",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/68cc33d922fbcc422ca55d06d09ce76b87defa43",
        "citation_count": 4
    },
    {
        "title": "CNN-Based Medical Device Design for the Smart Pillbox With Face Recognition",
        "abstract": "This study aims to assist elders with chronic diseases living in healthcare centers or a big family. In the era of AI, designers are not only to design product forms and functions, but the computer vision technique of AI can be used to help them. Based on the convolutional neural network (CNN) technology (as a supervised learning), three different types of optimizers of MobileNet V2 for training the best model accuracy, which is applied to a gerontechnological pillbox device with face recognition. In addition, the MobileNet V2 model proposed is imported into the JETSON edge machine that can identify different faces and then emit different sounds with its corresponding name and the quantity of medications. The smart pillbox device can improve the compliance and safety of elderly people when taking medicine.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/693dc5fcc2da35d436fc9b58921b90fd11d2b896",
        "citation_count": 1
    },
    {
        "title": "Prediction Methods of Common Cancers in China Using PCA-ANN and DBN-ELM-BP",
        "abstract": "Accurate prediction of cancer cases is crucial for diagnosis of cancer at an early stage because a long-lasting chronic disease is harmful to both physical and mental health. While medical data about healthcare and health obtained from questionnaire, the true positive rate of cancers predicted by traditional methods is low. Machine learning can provide a pattern for classification for types of cancer (mainly including lung cancer, liver cancer, upper gastrointestinal cancer, lower gastrointestinal cancer and breast cancer) using instances of early questionnaire screening. The screening covered 3411 respondents in this study. Principal component analysis (PCA) is used to generate attributes, coupled with artificial neural network (ANN) technology to conduct cancer prediction by providing 28 attributes into models. While deep belief network (DBN) is used for unsupervised training and extracting relevant attributes. Extreme learning machine (ELM) optimizes DBN and conducts supervised classification. Back propagation (BP) algorithm conducts supervised fine tuning. Finally, PCA-ANN and DBN-ELM-BP common cancers prediction models are established. The training set and testing set of PCA-ANN model gives 35.29% and 37.5% sensitivity, 98.36% and 98.33% specificity, 97.01% and 97.85% accuracy, an area under the receiver operating characteristic curve (AUC) 0.7245 and 0.7221, respectively. While the training set and testing set of DBN-ELM-BP model gives 58.83% and 62.5% sensitivity, 98.31% and 98.52% specificity, 98.03% and 98.24% accuracy, AUC 0.7747 and 0.7238, respectively. The results show that DBN-ELM-BP model can provide a method to predict the possibility of common cancers, which is non-invasive and economical for clinicians to make diagnostic decisions.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/694e3d1e2a4e53a6e50abad885347c2f7ab911c4",
        "citation_count": 11
    },
    {
        "title": "BIM-GIS ORIENTED INTELLIGENT KNOWLEDGE DISCOVERY",
        "abstract": "Abstract. Urban and population growth results in increasing pressure on the public utilities like transport, energy, healthcare services, crime management and emergency services in the realm of smart city management. Smart management of these services increases the necessity of dealing with big data which is come from different sources with various types and formats like 3D city information, GPS, traffic, mobile, Building Information Model (BIM), environmental, social activities and IoT stream data. Therefore, an approach to mine/analysis/interpret these data and extract useful knowledge from this diverse big data sources emerges in order to extract the hidden pattern of data using computational algorithms from statistics, machine learning and information theory. However, inconsistency, duplication and repetition and misconducting with the different type of discrete and continuous data can cause erroneous decision-making. This paper focuses on providing a rules extraction and supervised-decision making methods for facilitating the fusion of BIM and 2D and 3D GIS-based information coupling with IoT stream data residing in a spatial database and 3D BIM data. The proposed methods can be used in those applications like Emergency Response, Evacuation Planning, Occupancy Mapping, and Urban Monitoring to Smart Multi-Buildings so that their input data mostly come from 2D and 3D GIS, BIM and IoT stream. This research focus on proposing the unified rules extraction and decision engine to help smart citizens and managers using BIM and GIS data to make smart decision rather than focus on applications in certain field of BIM and GIS.\n",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/6950b2fb9b1f2114338face84c6564b5b8c30f2a",
        "citation_count": 4
    },
    {
        "title": "Identification of Medical Outliers with the use of Machine Learning",
        "abstract": "Machine learning has the potential to not only improve outcomes in healthcare data, but also to lessen the burden on healthcare workers. This algorithm has the potential to aid in the resolution of problems and the identification of new information crucial to the development of medical data. As part of our study, we provide a novel method for identifying outliers across many data sets. if one considers the possibility that information gleaned from medical records might shed light on the dynamics at play in an illness or person\u2019s way of life. The presented approach uses a combination of supervised and unsupervised learning to achieve its goals. It\u2019s probable that this programme might detect any discrepancies in the patient\u2019s medical file. How well regional and international data sources cooperate to detect anomalies in medical records in real time. The model is used here regardless of whether or not it was trained and verified using actual patient data. The cleaning method takes full use of all the advantages of analogous processes. The utilisation of medical data sets in research is common. The arithmetical results demonstration that the machine learning-based approach to outlier identification is more accurate.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/696439f354884b90fce1cbedeb7f7481439c8580",
        "citation_count": 0
    },
    {
        "title": "An Intelligent Image-based Colourimetric Test Framework for Diagnosis",
        "abstract": "The global imbalance between the healthcare provider and patient ratio, an increasingly elderly population and resource-limited settings have triggered the demand for point-of-care (POC) platforms, prompting the growth of personalised healthcare and homecare solutions. This thesis presents an investigation into an AI-enabled image-based system to perform automatic colourimetric tests in real-time. The case study of wet-chemical-based enzyme-linked immunosorbent assay (ELISA) and dry-chemical-based lateral flow assay (LFA) were utilised to design and develop an intelligent framework for chromaticity analysis with minimal user intervention or additional hardware attachments. \nThe proposed system was designed by exploring state-of-the-art solutions for each component of an image-based colourimetric test, trial and error, and domain knowledge. At first, a reaction phase and time-dependent approach was proposed to track the dynamic changes in a colourimetric reaction by calculating the Euclidean distances. Subsequently, the final static stage of the reactions were considered and the images were pre-processed and segmented before applying vigorous noise removal techniques. The 10-fold cross-validated classifiers were trained with the optimum number of features using supervised machine learning. A completely separate testing dataset was utilised while testing the model. Additionally, a pre-trained model of deep learning was deployed to determine the type of colourimetric test, which can be integrated into the system where feasible. \nBased on our study, the reaction phase and time-dependent scheme was found to be more suitable for wet-chemical-based assays, particularly for low concentration samples. In addition to classification, the approach can assist in optimising the reaction time. However, due to the requirement of significant memory space by the video frames, the final system consisted of an alternative approach - considering only the reaction phase and time-independent scheme. On an ideal condition, the later approach provided more than 98% accuracy for colourimetric decision. Furthermore, the exploration of a pre-trained deep learning model revealed its strength in the test-type detection, instead providing the colourimetric classification. Therefore, deep learning was deployed to initiate the system based on the assay type (i.e. ELISA or LFA), which provided 100% accuracy. \nThe system we demonstrated complies with the ASSURED criteria. As compared to the existing systems, the proposed intelligent and robust system with real-time processing capabilities has experienced a more extensive course of validation to enumerate the reliability of the system. Unlike most of the works in the literature, the proposed system provided the colourimetric prediction without any opto-mechanical attachment. Such an easy-to-use and computationally efficient system can be integrated into a server or deployed on a mobile platform to create better harmony between biochemical and computational complexity and eliminate the subjectivity of interpretation.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/699fe22ed4567d7c1b5c4aebdd3c95fde0a80774",
        "citation_count": 2
    },
    {
        "title": "A Machine Learning Analysis of Impact of the Covid-19 Pandemic on Alcohol Consumption Habit Changes Among Healthcare Workers in the U.S",
        "abstract": "In this paper, we discuss the impact of the Covid-19 pandemic on alcohol consumption habit changes among healthcare workers in the United States. We utilize multiple supervised and unsupervised machine learning methods and models such as Decision Trees, Logistic Regression, Naive Bayes classifier, k-Nearest Neighbors, Support Vector Machines, Multilayer perceptron, XGBoost, CatBoost, LightGBM, Chi-Squared Test and mutual information method on a mental health survey data obtained from the University of Michigan Inter-University Consortium for Political and Social Research to find out relationships between COVID-19 related negative effects and alcohol consumption habit changes among healthcare workers. Our findings suggest that COVID-19-related school closures, COVID-19-related work schedule changes and COVID-related news exposure may lead to an increase in alcohol use among healthcare workers in the United States.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/69e2a683e15a06858550db59357526991aa6b775",
        "citation_count": 0
    },
    {
        "title": "Obesity Guard: Machine Learning for Early Detection and Preventioning",
        "abstract": "Obesity has become a global health concern, with its prevalence reaching alarming levels in recent year. Obesity Guard is an innovative idea aimed at addressing the pressing global issue of obesity through the application of machine learning technology. Obesity poses significant health risks and is a growing concern worldwide, affecting millions of individuals and straining healthcare systems. Early detection and prevention are crucial in combating this epidemic, and Obesity Guard offers a proactive solution leveraging advanced machine learning algorithms. This revolves around the development of a comprehensive system capable of detecting early signs of obesity and providing personalized prevention strategies. Machine learning algorithms are at the core of Obesity Guard, enabling the system to process vast amounts of data efficiently and extract actionable insights. These algorithms utilize predictive analytics to identify patterns and trends indicative of obesity risk factors. By employing techniques such as classification, regression, and clustering, Obesity Guard can generate personalized recommendations tailored to each user's specific needs and goals. The implementation of Obesity Guard has the potential to revolutionize obesity management by shifting the focus from reactive treatments to proactive prevention. By empowering individuals with actionable insights and support, Obesity Guard aims to reduce the burden of obesity-related diseases and improve overall health outcomes. Obesity Guard represents a novel approach to addressing the obesity epidemic through the application of machine learning and personalized healthcare technologies. Obesity Guard represents a significant advancement in the field of preventive healthcare, offering a proactive approach to addressing the global obesity epidemic. By harnessing the power of machine learning and wearable technology, this has the potential to empower individuals to take control of their health, reduce obesity rates, and improve overall well-being. In our proposed work, we compare four supervised ML classifiers i.e. support Vector Machine, Decision Tree, Random Forest, Logistic Regression. Further ensemble learning technique is used to develop a hybrid model for obesity prediction. After analysis, the Random Forest (RF) model has achieved 100% accuracy than other models.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/6a060e06a28c577a927f21d09fac33206cb0f421",
        "citation_count": 0
    },
    {
        "title": "Application of Machine Learning for Diagnosis of Head and Neck Cancer in Primary Healthcare Organisation",
        "abstract": "Head and neck cancers (HNC) are indicated when cells grow abnormally.\u00a0 The disturbing rate of morbidity and mortality of patients with HNC due to late presentation is on the increase especially in Africa (developing countries). There is need to diagnose head and neck cancer early if patients present so that prompt referral could be facilitated.\u00a0 The collected data consists of 1473 instances with 18 features. The dataset was divided into training and test data.\u00a0 Two supervised learning algorithms were deployed for the study namely: Decision Tree (C4.5) and k-Nearest Neighbors (KNN). It showed that Decision Tree outperformed with accuracy of 91.40% while KNN had accuracy of 88.24%. Hence, machine learning algorithm like Decision Tree can be used for diagnosis of HNC in healthcare organisations.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/6a079ac7b1081dc019b1cc977ac380c191e5a6fa",
        "citation_count": 1
    },
    {
        "title": "Machine learning-based prediction models for home discharge in patients with COVID-19: Development and evaluation using electronic health records",
        "abstract": "Objective This study aimed to develop and validate predictive models using electronic health records (EHR) data to determine whether hospitalized COVID-19-positive patients would be admitted to alternative medical care or discharged home. Methods We conducted a retrospective cohort study using deidentified data from the University of Florida Health Integrated Data Repository. The study included 1,578 adult patients (\u226518 years) who tested positive for COVID-19 while hospitalized, comprising 960 (60.8%) female patients with a mean (SD) age of 51.86 (18.49) years and 618 (39.2%) male patients with a mean (SD) age of 54.35 (18.48) years. Machine learning (ML) model training involved cross-validation to assess their performance in predicting patient disposition. Results We developed and validated six supervised ML-based prediction models (logistic regression, Gaussian Na\u00efve Bayes, k-nearest neighbors, decision trees, random forest, and support vector machine classifier) to predict patient discharge status. The models were evaluated based on the area under the receiver operating characteristic curve (ROC-AUC), precision, accuracy, F1 score, and Brier score. The random forest classifier exhibited the highest performance, achieving an accuracy of 0.84 and an AUC of 0.72. Logistic regression (accuracy: 0.85, AUC: 0.71), k-nearest neighbor (accuracy: 0.84, AUC: 0.63), decision tree (accuracy: 0.84, AUC: 0.61), Gaussian Na\u00efve Bayes (accuracy: 0.84, AUC: 0.66), and support vector machine classifier (accuracy: 0.84, AUC: 0.67) also demonstrated valuable predictive capabilities. Significance This study\u2019s findings are crucial for efficiently allocating healthcare resources during pandemics like COVID-19. By harnessing ML techniques and EHR data, we can create predictive tools to identify patients at greater risk of severe symptoms based on their medical histories. The models developed here serve as a foundation for expanding the toolkit available to healthcare professionals and organizations. Additionally, explainable ML methods, such as Shapley Additive Explanations, aid in uncovering underlying data features that inform healthcare decision-making processes.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/6a4d1ebb22b82a399f834d8ffd1a257ebc5f4f31",
        "citation_count": 3
    },
    {
        "title": "Special issue on deep interpretation of deep learning: prediction, representation, modeling and utilization",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/6a4e3b5ece2afe161dbcf4dd1023ae145fb8abf2",
        "citation_count": 1
    },
    {
        "title": "Data Security Mechanisms, Approaches, and Challenges for e-Health Smart Systems",
        "abstract": "In the new era, the trend of using wearable devices and smart accessories gained considerable popularity and become a necessity utility for human life due to their major role to keep monitoring health conditions and providing healthcare services. The combination of IoT networks with edge computing paradigms develops an intelligent e-health system that aims to monitor different real-time scenarios. The deployment of an e-health system exposes several challenges regarding the security and privacy aspects, particularly in the case of dealing with an enormous quantity of medical data and the risk presented by exchanging operations with external entities. In this paper a comprehensive presentation covered the basic topics of e-health system layers thus the advantages and limitations in terms of existing challenges has been mentioned, subsequently, adapted to the exposed cyber risk through the traditional systems in exchanging medical data, a discussion of the blockchain technology come over for new application opportunities, where this approach efficiently ensure the security of data transactions over the network, in addition, an overview outlined the main research works related to this technology. Therefore, a presentation study of diverse works reveals different security framework solutions related to e-health system\u2019s layers, furthermore, uncovering the benefits of integrating intelligent technologies such as Machine Learning (supervised, and unsupervised types), Deep Learning, and Reinforcement Learning as well as introducing a comparison analysis of multiple AI algorithm models based on their efficiency for future deployment related security purposes to provide a smart healthcare monitoring system that meets patient needs. The end of this review highlighted further research directions and the actual open challenges regarding the e-Health system\u2019s limitations.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/6a8c8f58247b2471d8f15853d54e4d5e511f1dfe",
        "citation_count": 8
    },
    {
        "title": "Decision Tree-based Modelling for Identification of Predictors of Blood Loss and Transfusion Requirement After Adult Spinal Deformity Surgery",
        "abstract": "ABSTRACT Background Multilevel fusions and complex osteotomies to restore global alignment in adult spinal deformity (ASD) surgery can lead to increased operative time and blood loss. In this regard, we assessed factors predictive of perioperative blood product transfusion in patients undergoing long posterior spinal fusion for ASD. Methods A single-institution retrospective review was conducted on 909 patients with ASD, age\u2009>\u200918 years, who underwent surgery for ASD with greater than 4 levels fused. Using conditional inference tree analysis, a machine learning methodology, we sought to predict the combination of variables that best predicted increased risk for intraoperative percent blood volume lost and perioperative blood product transfusion. Results Among the 909 patients included in the study, 377 (41.5%) received red blood cell (RBC) transfusion. The conditional inference tree analysis identified greater than 13 levels fused, American Society of Anesthesiologists (ASA) score\u2009>\u20091, a history of hypertension, 3-column osteotomy, pelvic fixation, and operative time\u2009>\u20098 hours, as significant risk factors for perioperative RBC transfusion. The best predictors for the subgroup with the highest risk for intraoperative percent blood volume lost (subgroup mean: 53.1%\u2009\u00b1\u200942.9%) were greater than 13 levels fused, ASA score\u2009>\u20091, preoperative hemoglobin\u2009<\u200913.6 g/dL, 3-column osteotomy, posterior column osteotomy, and pelvic fixation. Patients who underwent major blood transfusion intraoperatively had significantly longer length of stay (8.5 days) versus those who did not (6.1 days) (P\u2009<\u2009.0001). The overall 90-day complication rate in patients who underwent major blood transfusion intraoperatively was 49%, compared with 19% in those who did not (P\u2009<\u2009.0001). By multivariate regression analysis, patients with a preoperative hemoglobin\u2009>\u200913.0 were less likely to require major blood transfusion (odds ratio: 0.52, P\u2009=\u2009.046). Conclusions Using a supervised learning technique, this study demonstrates that greater than 13 levels fused, ASA score\u2009>\u20091, 3-column osteotomy, and pelvic fixation are consistent risk factors for increased intraoperative percent blood volume lost and perioperative RBC transfusion. The addition of having a preoperative hemoglobin\u2009<\u200913.6 g/dL or undergoing a posterior column osteotomy conferred the highest risk for intraoperative blood loss. This information can assist spinal deformity surgeons in identifying at-risk individuals and allocating healthcare resources. Level of Evidence 3.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/6ac72f3b13b7696b00e77340e15a41b3cfcf623d",
        "citation_count": 21
    },
    {
        "title": "What Are Management Information Systems",
        "abstract": "MIS 6009 Information Systems Internship (0 semester credit hours) Student gains experience and improves skills through appropriate developmental work assignments in a real business environment. Student must identify and submit specific business learning objectives at the beginning of the semester. The student must demonstrate exposure to the managerial perspective via involvement or observation. At semester end, student prepares an oral or poster presentation, or a written paper reflecting on the work experience. Student performance is evaluated by the work supervisor. Pass/Fail only. Prerequisites: (MAS 6102 or MBA major) and department consent required. (0-0) S MIS 6204 Information Technology for Management (2 semester credit hours) Necessary background to understand the role of information technology and Management Information Systems in today's business environment. Topics include: strategic role of information, organization of information, information decision making requirements, telecommunications and networking, managing information resources, cloud computing distributed processing, and current information systems/technology issues. (2-0) S MIS 6302 (ACCT 6349) Managing Digital Strategy (3 semester credit hours) This course explores the strategic management issues associated with the transformation of all businesses into digital businesses. It focuses on developing an understanding of how to develop a business models to implement strategies that are based on digital systems across different industries. This includes understanding how to develop business plans, how to align the business architecture with the digital systems architecture, and appropriately managing the digital systems to maximize business value. The course will deal with assessing and developing business strategies by harnessing contemporary phenomena in the digital world, such as the Internet of Things, Mobility strategies, and include applications of emerging techniques based on machine learning, artificial intelligence and semantic analysis to craft appropriate business strategies for firms. Credit cannot be received for both ACCT 6349 and MIS 6302. (3-0) Y MIS 6305 (HMGT 6334) Healthcare Analytics (3 semester credit hours) The healthcare industry is yet to find ways to make best use of existing data to improve care, reduce costs, and provide more accessible care. This course introduces the use of business intelligence and decision sciences in healthcare industry. Students will develop a conceptual understanding of data mining techniques and decision analysis and hands-on experience with several analytics software which may include coding in R, Rattle, and WEKA (as needed and depending on availability). Prerequisite: OPRE 6301 or SYSM 6303. (3-0) Y MIS 6308 (ACCT 6340) System Analysis and Project Management (3 semester credit hours) Provides the student with an in-depth knowledge of object oriented systems analysis and design procedures. Software project management techniques will be introduced. At the end of the course, the student will be able to analyze business solutions and design computer based information systems using object-oriented methodologies. Prerequisite or Corequisite: MIS 632 0 or MIS 6326. (3-0) R MIS 6309 (ACCT 6309) Business Data Warehousing (3 semester credit hours) This course provides the student with in depth knowledge of data warehousing principles, data warehouse techniques, and business intelligence systems. The course introduces the topics of data warehouse design, Extract-Transform-Load (ETL), data cubes, and data marts. Students will create business intelligence using data warehouses with several OLAP and analytical tools. SAP, Business Objects, Cognos, or other data warehousing tools will be used to illustrate data warehousing concepts. (3-0) Y",
        "year": 2000,
        "url": "https://www.semanticscholar.org/paper/6acd1801cbec863d723ace3ff8053de284417d8e",
        "citation_count": 0
    },
    {
        "title": "Emotion recognition using voice characteristics of speech recordings",
        "abstract": "Nowadays, emotion recognition system is one of the most active research topics with a large variety of real-life applications. These applications are diverse, including robotics, education, healthcare, etc. Emotion recognition can be done using different supports such as voice/speech, facial expression, text. These sources can be used separately or together, depending on the cases (e.g., using text and speech to recognize the different emotions expressed by two people during a conversation). This paper deals with the classification of eight different emotions and the classification of one emotion against all the others using speech recordings only. The models have been evaluated using the RAVDESS English database. Supervised machine learning algorithms were used, mainly the cubic SVM algorithm which gives the best results, and global features. An attempt to reduce the number of features using PCA and MRMR algorithm was also made. For the classification of eight emotions, the cubic SVM model keeping the top 200 features using the MRMR algorithm has a weighted average accuracy of 72.1%, achieving the best result.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/6b0d5bc97bb848ab3168d8c9fb753ad43b90c912",
        "citation_count": 0
    },
    {
        "title": "Sensor-Based Human Activity Mining Using Dirichlet Process Mixtures of Directional Statistical Models",
        "abstract": "We have witnessed an increasing number of activity-aware applications being deployed in real-world environments, including smart home and mobile healthcare. The key enabler to these applications is sensor-based human activity recognition; that is, recognising and analysing human daily activities from wearable and ambient sensors. With the power of machine learning we can recognise complex correlations between various types of sensor data and the activities being observed. However the challenges still remain: (1) they often rely on a large amount of labelled training data to build the model, and (2) they cannot dynamically adapt the model with emerging or changing activity patterns over time. To directly address these challenges, we propose a Bayesian nonparametric model, i.e. Dirichlet process mixture of conditionally independent von Mises Fisher models, to enable both unsupervised and semi-supervised dynamic learning of human activities. The Bayesian nonparametric model can dynamically adapt itself to the evolving activity patterns without human intervention and the learning results can be used to alleviate the annotation effort. We evaluate our approach against real-world, third-party smart home datasets, and demonstrate significant improvements over the state-of-the-art techniques in both unsupervised and supervised settings.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/6b46c8a01f438ef71dec87c248653b0a8dd238d9",
        "citation_count": 0
    },
    {
        "title": "On the Homogenization of Heterogeneous Inertial-Based Databases for Human Activity Recognition",
        "abstract": "In the last years supervised machine learning techniques are largely employed for automatic Human Activity Recognition (HAR) using inertial sensors, such as accelerometer and gyroscope. HAR has many applications in several domains such as, for example, healthcare, sport, and entertainment. Machine learning scientists made available to the community a plenty of labeled databases for benchmarking that, unfortunately, are not consistent, both syntactically (e.g., different sampling frequency) and semantically (e.g., labels with different meanings). Commonly, due to this inconsistency, scientists evaluate their progress on individual databases separately, which corresponds to training and testing using the same database. Coherent merging of existing databases would enable: 1) evaluation of generalization capabilities of methods across databases; 2) use of deep learning techniques that, unlike traditional ones, require much more labeled data for the training process. Moreover, the growth in the daily use of wearable devices will produce a big amount of inertial data which, if not correctly labeled, cannot be efficiently exploited for the study of automatic HAR. In this paper we propose a semi-automatic procedure to coherently merge existing databases based on signal and word similarity. Preliminary experiments demonstrates the effectiveness of the proposed procedure.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/6bb898fb2de619cabe8a8d5dec4458fe40f07e46",
        "citation_count": 8
    },
    {
        "title": "Diagnosing hospital bacteraemia in the framework of predictive, preventive and personalised medicine using electronic health records and machine learning classifiers",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/6cdc3976d6be010b55197f3b26ce944e3279e9e0",
        "citation_count": 16
    },
    {
        "title": "Anomaly detection in IoT-based healthcare: machine learning for enhanced security",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/6ce36067a576742038e6026a52a0c7735552200a",
        "citation_count": 28
    },
    {
        "title": "Hyper Parameter Tuned Ensemble Approach for Gestational Diabetes Prediction",
        "abstract": "Diabetes Mellitus is commonly found in human beings around the world and this is one of the serious diseases which causes boundless suffering among patients. There are numerous reasons for the prevalence of this disease. It would be better to consider the predictions carried out earlier in this respect, since diabetes is a non - communicable disease and makes a great impact on the health condition of people nowadays. This is the reason why the existing medicinal practices in most hospitals are collecting patients' life history or the record of the disease. This is done for diagnosing diabetes using various medical tests followed by proper treatment for the disease. Machine learning provides an immense contribution to the sector of healthcare. For this research, Pima Indians Diabetes Dataset, obtained from the University of California, Irvine (UCI) machine learning source that included 768 patients' details along with nine attributes had been chosen for a comprehensive investigation of this grave and widespread problem in the health sector. Eventually, an adequate perfect outcome could be achieved and some effective and transparent conclusions were made. Among 768 diabetics, 500 were recognized as positive for the disease while 268 were recognized as negative. Besides, the recorded facts were put into particular supervised machine learning techniques such as Support Vector Machine (SVM), Na\u00efve Bayes (NB), Decision Tree (DT), Artificial Neural Networks (ANN), Linear Discriminant Analysis (LDA), Logistic Regression (LR) and k-nearest neighbors (k-NN). Along with this, bagging and boosting techniques like Random Forest (RF), Extreme Gradient Boosting (XGBoost), LightGBM, and CatBoost too were taken into consideration. In addition, by considering classifiers with the highest accuracies, the final ensemble model was developed with the adaption of SVM, CatBoost and RF to predict the diabetes mellitus. Thus, the model resulted in an accuracy of 86.15%.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/6d316c7b198c21f436b0141ecd0fa35de81548cf",
        "citation_count": 3
    },
    {
        "title": "Interpretable Machine Learning Methods for Stroke Prediction",
        "abstract": "Machine learning has long been touted as the next big tool, revolutionizing scientific endeavors as well as impacting industries like retail and finance. Naturally, there is much interest in the potential of next improving healthcare. However, using traditional machine learning approaches in this domain has many difficulties, chief among which is the issue of interpretability. We focus on the medical condition of stroke, a particularly desirable problem to target because it is one of the most prevalent and yet preventable conditions affecting Americans today. In this thesis, we apply novel interpretable prediction techniques to the problem of predicting stroke presence, location, acuity, and mortality risk for patient populations at two different hospital systems. We show that using an interpretable, optimal tree-based approach is roughly as effective if not better than black-box approaches. Using the clinical learnings from these studies, we explore new interpretable methodologies designed with medical applications and their unique challenges in mind. We present a novel regression algorithm to predict outcomes when the population is comprised of notably different subpopulations, and demonstrate that this gives comparable performance with improved interpretability. Finally, we explore new natural language processing techniques for machine learning from text. We propose an alternate endto-end framework for going from unprocessed textual data to predictions, with an interpretable linguistics-based approach to model words. Altogether, this work demonstrates the promise that new parsimonious, interpretable algorithms have in the domain of stroke and broader healthcare problems. Thesis Supervisor: Prof. Dimitris Bertsimas Boeing Professor of Operations Research",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/6dcaf8ea23e82668c586d7c61c85b06e35ae80d4",
        "citation_count": 3
    },
    {
        "title": "An Interpretable Deep Classifier for Counterfactual Generation",
        "abstract": "Counterfactual explanation has been the core of interpretable machine learning, which requires a trained model to be able to not only infer but also justify its inference. This problem is crucial in many fields, such as fintech and the healthcare industry, where accurate decisions and their justifications are equally important. Many studies have leveraged the power of deep generative models for counterfactual generation. However, most focus on vision data and leave the latent space unsupervised. In this paper, we propose a new and general framework that uses a supervised extension to the Variational Auto-Encoder (VAE) with Normalizing Flow (NF) for simultaneous classification and counterfactual generation. We show experiments on two tabular financial data-sets, Lending Club (LCD) and Give Me Some Credit (GMC), which show that the model can achieve a state-of-art level prediction accuracy while also producing meaningful counterfactual examples to interpret and justify the classifier\u2019s decision.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/6dd16c86a1a242426c33a7a2af79d5624e309ef6",
        "citation_count": 3
    },
    {
        "title": "FADE: Forecasting for Anomaly Detection on ECG",
        "abstract": "Cardiovascular diseases, a leading cause of noncommunicable disease-related deaths, require early and accurate detection to improve patient outcomes. Taking advantage of advances in machine learning and deep learning, multiple approaches have been proposed in the literature to address the challenge of detecting ECG anomalies. Typically, these methods are based on the manual interpretation of ECG signals, which is time consuming and depends on the expertise of healthcare professionals. The objective of this work is to propose a deep learning system, FADE, designed for normal ECG forecasting and anomaly detection, which reduces the need for extensive labeled datasets and manual interpretation. FADE has been trained in a self-supervised manner with a novel morphological inspired loss function. Unlike conventional models that learn from labeled anomalous ECG waveforms, our approach predicts the future of normal ECG signals, thus avoiding the need for extensive labeled datasets. Using a novel distance function to compare forecasted ECG signals with actual sensor data, our method effectively identifies cardiac anomalies. Additionally, this approach can be adapted to new contexts through domain adaptation techniques. To evaluate our proposal, we performed a set of experiments using two publicly available datasets: MIT-BIH NSR and MIT-BIH Arrythmia. The results demonstrate that our system achieves an average accuracy of 83.84% in anomaly detection, while correctly classifying normal ECG signals with an accuracy of 85.46%. Our proposed approach exhibited superior performance in the early detection of cardiac anomalies in ECG signals, surpassing previous methods that predominantly identify a limited range of anomalies. FADE effectively detects both abnormal heartbeats and arrhythmias, offering significant advantages in healthcare through cost reduction or processing of large-scale ECG data.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/6dfe900818228d34961f525b63e25989a1724570",
        "citation_count": 0
    },
    {
        "title": "LEVERAGING UNLABELED DATA TO ENHANCE UPLIFT META-LEARNERS: A GENERAL APPROACH FOR S-LEARNER AND T-LEARNER",
        "abstract": ". The application of machine learning methods to estimate treatment effects has gained significant attention in recent years, particularly in domains such as healthcare, marketing, and social science. Uplift modeling focuses on identifying subpopulations most influenced by a specific treatment. Meta-learners, including the widely adopted S-Learner and T-Learner frameworks, have become essential tools for estimating treatment heterogeneity. However, these models often require large quantities of labeled data to perform effectively, posing challenges in scenarios with limited or partially labeled datasets. Semi-supervised learning (SSL) enables the use of both labeled and unlabeled data, thus addressing data sparsity while enhancing model performance. This article presents a general approach for integrating SSL methods into the training of S-Learner and T-Learner meta-learners. The proposed approach is designed to be adaptable to any SSL technique, providing a flexible solution for uplift modeling in data-constrained environments. To demonstrate the practicality and effectiveness of this general methodology, we conduct experiments using the RESSEL semi-supervised learning method as a case study. RESSEL leverages relationships within unlabeled data to augment labeled information, improving the predictive accuracy of uplift models. Through experimentation on dataset, we validate the utility of the proposed framework. The results demonstrate that the integration",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/6e27d80f4f8d2c470921ed8b87c953816bc66c98",
        "citation_count": 0
    },
    {
        "title": "Pressure Mapping Using Nanocomposite-Enhanced Foam and Machine Learning",
        "abstract": "Pressure mapping has garnered considerable interest in the healthcare and robotic industries. Low-cost and large-area compliant devices, as well as fast and effective computational algorithms, have been proposed in the last few years to facilitate distributed pressure sensing. One approach is to use electrical impedance tomography (EIT) to reconstruct the contact pressure distribution of piezoresistive materials. While tremendous success has been demonstrated, conventional algorithms may be unsuitable for real-time monitoring due to its computational demand and runtime. Moreover, the low resolution of reconstructed images is a well-known issue related to the regularization strategies typically employed for traditional EIT methods. Therefore, in this study, two different supervised machine learning (ML) approaches, namely, radial basis function networks and deep neural networks, were employed to efficiently solve the inverse EIT problem and improve the resolution of reconstructed pressure maps. The demonstration of high-resolution pressure mapping, specifically, for identifying pressure hotspots, was achieved using a carbon nanotube-based thin film integrated with foam.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/6e7d5fc1c1a2b5cc918b4124b52df87c984cfd0a",
        "citation_count": 8
    },
    {
        "title": "Preface",
        "abstract": "This proceedings consists of the peer-reviewed papers from the 2nd International Conference on Robotics, Intelligent Automation and Control Technologies (RIACT 2021), which was organized by the School of Mechanical Engineering at Vellore Institute of Technology, Chennai, India on September from 23rd to 25th, 2021. However, due to the COVID 19 pandemic the conference was held Online. The main objective of RIACT 2021 is to provide a platform for researchers and practitioners from both academic institutions and industries to meet and share cutting-edge developments in the areas of Robot Design, Development and Control, Rehabilitation Robots and Devices, Intelligent Automation and Fault Diagnosis, Agricultural Robots, Underwater Robots, Development of Drones, Control and Supervision Systems, Vision Systems, Actuators and Sensors, Mechatronics Systems, System Interface and Control, Sustainable Technologies and associated disciplines. This conference also provided an opportunity to exchange research evidence and innovative ideas and also the issues related to Robotics and Automation. This proceeding will include presentations on the latest research areas such as Agriculture Drones, Bio Mechanisms for rehabilitation applications and Deep learning in robotics. This conference had gathered an excellent group of keynote speakers from around the globe on different topics such as Engineering Challenges of the AI-Enabled Automation and Process Optimisation for Healthcare and Business Domain, Upcoming future of robotics in protected horticulture, Intelligent Systems: From Smart Manufacturing and Network Perspectives, High-performance surgical and wearable robots for translational medicine, Challenges in Rover Mission, Two-Degree-of-Freedom Control of Flexible Manipulator, Manipulator Rule Generation from Table Data Sets and Its Application, Enduruns: Long-endurance sea surveying autonomous unmanned vehicle with gliding capability powered by hydrogen fuel cell, Bio-Inspired Swarm Intelligence with Engineering Applications, K-Learn for Robotics: Kinesthetic and STREMS, Embedded Machine Learning for Decentralized Automation, Real-time decentralized control: Design guidelines and applications, Whole-Body Optimization using Differential Dynamic Programming for Humanoid Robot Applications and How Business Technology Platform Accelerates Your Innovation. List of Advisory Committee, Technical Review Committee, Program Committee Members, Organizing Committee Members, Co-Convenor, Convenor are available in this pdf.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/6e8ccf86b299f3ababde51ece0ae3964d13ef874",
        "citation_count": 0
    },
    {
        "title": "Classification of Hospital of the Future Applications using Machine Learning",
        "abstract": "Effective health management is critical to ensure patients have access to necessary healthcare services. There are a number of challenges that can limit the provision of medical treatment, including a shortage of healthcare professionals, limited resources, and geographical barriers. Hospital of the Future (HoF) incorporates a number of technologies and innovations to improve the delivery of healthcare services and support effective health management. 5G network slicing has the potential to greatly enhance the capabilities of hospitals and the delivery of healthcare services. The network can be sliced into three main services; eMBB, mMTC, and URLLC. This paper presented a comparison of various supervised machine learning models in predicting the three network services. The classification for the slices is based on HoF applications\u2019 requirements. Deep learning model has the highest accuracy of 100% with total runtime of 85.7s and lowest standard deviation value. In comparison with other machine learning models, deep learning is the best model in predicting 5GHoF slices.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/6fb896edd24fd3b3f8cf7c8fe86be5fc61b60e99",
        "citation_count": 0
    },
    {
        "title": "Understanding the State of Bacterial Systems with Machine Learning-Enabled Interpretation of Surface Enhanced Raman Scattering Spectra Produced by Novel Nanomanufacturing",
        "abstract": "Author(s): Thrift, William John | Advisor(s): Ragan, Regina | Abstract: Surface enhanced Raman scattering (SERS) spectroscopy is a powerful tool for identifying and quantifying complex mixtures of small molecules, such as the metabolites that indicate the state of a bacterial system. SERS frequently takes advantage of metal nanoparticles to confine light onto their surface, increasing the local electric field. This field enhancement massively increases Raman scattering, and can enable single molecule detection. In this thesis, I introduce a new nanomanufacturing technique called 2-dimensional physically activated chemical self-assembly (2PAC). The focus of 2PAC is to manufacture extremely powerful and uniform SERS sensors, with a SERS enhancement factor of 109 that has a relative standard deviation of 10% over a 1 mm x 1 mm area. This technique is characterized by electron microscopy and Raman spectroscopy to elucidate its physical origin. I show that SERS sensor\u2019s field enhancement can be further increased by 3-fold by taking advantage of Rayleigh\u2019s anomaly using electron beam manufactured optical gratings. While SERS enables fantastic chemical sensing, it also increases the complexity of analyzing spectra. This is because the ligands involved in 2PAC produce their own spectral signature, and the nanostructures produce a field enhancement that decays rapidly from the hotspot in withhin gaps between nanoparticles. In order to address this complexity, I have developed machine learning techniques that greatly improve analyte concentration regressions. Using a convolutional neural network, I demonstrate quantitative sensing down to 10 fM, well into the single molecule detection regime. I use these methods to address another complex problem, identifying the state of a bacterial system through its metabolome. First, I show that by tracking pyocyanin, a metabolite of Psuedomonas aeruginosa (PA), PA can be monitored as it forms a biofilm. PA is detected in just 6 hours, well before it becomes resistant to antibiotics. Then, I demonstrate a semi-supervised method of antimicrobial susceptibility testing (AST) using SERS. This method identifies which antibiotics a bacterium is susceptible to with minimal 24-hour cell culture. AST of PA is performed in just 30 minutes with over 99% accuracy. In sum, this thesis points a way forward to better healthcare through nanotechnology and machine learning.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/6fd2a054aa8abf8219b49b26183982754c88a423",
        "citation_count": 0
    },
    {
        "title": "Information, communication and computing technologies as enablers of advancements in modern information society",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7015c4ca5afaa594cf670599fe000cbd0499a502",
        "citation_count": 2
    },
    {
        "title": "Active learning for medical code assignment",
        "abstract": "Machine Learning (ML) is widely used to automatically extract meaningful information from Electronic Health Records (EHR) to support operational, clinical, and financial decision-making. However, ML models require a large number of annotated examples to provide satisfactory results, which is not possible in most healthcare scenarios due to the high cost of clinician-labeled data. Active Learning (AL) is a process of selecting the most informative instances to be labeled by an expert to further train a supervised algorithm. We demonstrate the effectiveness of AL in multi-label text classification in the clinical domain. In this context, we apply a set of well-known AL methods to help automatically assign ICD-9 codes on the MIMIC-III dataset. Our results show that the selection of informative instances provides satisfactory classification with a significantly reduced training set (8.3\\% of the total instances). We conclude that AL methods can significantly reduce the manual annotation cost while preserving model performance.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/70a60fa9f95f4ceb8997af4bd1fefd4595f1aa27",
        "citation_count": 2
    },
    {
        "title": "Enhancing Semi-Supervised Learning With Concept Drift Detection and Self-Training: A Study on Classifier Diversity and Performance",
        "abstract": "Machine learning algorithms that assist in decision-making are becoming crucial in several areas, such as healthcare, finance, marketing, etc. Algorithms exposed to a larger and more relevant amount of training data tend to perform better. However, the availability of labeled data without human expert intervention is a challenging task, especially in data stream learning with concept drifts, where data is generated rapidly, in real-time, with the possibility of changes in the data distribution. Concept drift occurs in supervised, semi-supervised and unsupervised learning environments, and is addressed through different approaches such as statistics, machine learning, among others. Currently, the use of drift detectors with base classifiers in semi-supervised learning is uncommon. Semi-supervised classifiers often consume a lot of memory and run-time, and the addition of a detection mechanism increases the computational cost. Furthermore, classification in semi-supervised environments can lead to problems related to labeling data to training: an error in this process can negatively impact model performance. This article investigates the use of supervised concept drift detectors in semi-supervised learning problems, highlighting how the detectors can improve the performance of classification. It also explores the influence of diversity in classifier ensembles, showing that increased diversity contributes to enhanced accuracy and robustness of models in concept drift scenarios. Additionally, it introduces a self-training approach to provide more labels and optimize model learning and adaptation. This research also details updates in the Massive Online Analysis (MOA) framework, that supports the simulation of semi-supervised scenarios. The experiments conducted to test the proposed approach used Hoeffding Tree (HT) and Naive Bayes (NB) as base classifiers, which were also employed as members of the ensembles used in this research. These classifiers were combined with several detectors and tested on a total of 84 artificial and five real-world datasets. The experiments were conducted with 15% and 30% of labeled data, the main percentages addressed in this research, while 100% was used to provide additional grounding in some cases. The results indicate that detectors created for supervised learning can be effectively used in semi-supervised environments. Furthermore, the tests using the introduced self-training approach demonstrates that the inclusion of additional labels significantly improves the performance of the classifiers. These findings may lead to a paradigm shift for future research, as many researchers have not considered concept drift detectors as a viable alternative due to the limited presence of labels in most real-world data streams.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/70a7658942a3985c6ff40070c34d46d26a672139",
        "citation_count": 0
    },
    {
        "title": "BIOCAD: Bio-Inspired Optimization for Classification and Anomaly Detection in Digital Healthcare Systems",
        "abstract": "The modern smart digital healthcare system (SDHS) is leaning towards automation of patient disease monitoring and treatment with the advent of wireless body sensor networks (WBSN) and the internet of medical things (IoMT). However, the open communication network for sensitive medical data transfer is giving rise to vulnerabilities and security concerns. To prevent adversarial manipulation of sensor measurements, SDHS IoMT controllers leverage anomaly detection systems on top of the disease classification systems. Machine learning (ML) is one of the most effective techniques for providing experience-based automated decision-making models. These models generalize well to produce the expected output for the unseen inputs from the learned patterns. Therefore, ML-based models are currently being adopted to automate the anomaly detection and disease classification tasks of SDHS. In this work, we consider a SDHS that uses supervised ML models for patient status/disease classification and unsupervised ML models for anomaly detection. However, the performance of the ML models largely depends on hyper-parameter tuning. Finding the optimal hyper-parameter is a challenging task, and it becomes more difficult and time-consuming in high-dimensional feature space. In this work, we propose BIOCAD, a comprehensive bio-inspired optimization framework for SDHS data classification and anomaly detection. The framework leverages a novel fitness function for unsu-pervised anomaly detection ML models. We experiment with state-of-the-art datasets - the Pima Indians diabetes dataset, the Parkinson dataset, and the University of Queensland vital signs (UQVS) dataset for validating our proposed strategy.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/70eaa1cf005b6e63bfe61f037bdcd887a681bd74",
        "citation_count": 7
    },
    {
        "title": "Leaving No Stone Unturned: Using Machine Learning Based Approaches for Information Extraction from Full Texts of a Research Data Warehouse",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/70f6b92d861b87fe4253e6bb430438bab9746368",
        "citation_count": 5
    },
    {
        "title": "Thai Handwritten Character Recognition Using Deep Convolutional Neural Network",
        "abstract": "A handwritten character recognition is a key for many applications that rely on digital documents, such as healthcare, insurance, and banking sectors. Deep learning is an innovative way of carrying out the handwritten character recognition that is typically performed by humans. This research discusses supervised deep learning using teachable machine, web-based tool, as a tool to train, evaluate and test a convolutional neural network (CNN) model for 44 Thai handwritten consonants. The best model is selected to apply in web and mobile application for practicing writing Thai consonants. A pre-trained model, Mobilenet, is used in the training. The Burapha-TH Thai handwriting dataset is used to train, evaluate and test the model. The experimental results show that the number of epochs and the number of images in dataset affects model accuracy. The dataset that has the maximum number of images, achieves the highest training accuracy, 99.53%, at 60 epochs and 0.001 learning rate and achieves the highest testing accuracy, 83.43%, at 70 epochs and 0.0001 learning rate.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/715ca0a6c2d5c0434019e139411e5c18a5d4c91c",
        "citation_count": 1
    },
    {
        "title": "Multilayer Perceptron Artificial Neural Networks and Tree Models as Multifactorial Binary Predictors of Heart Disease and Failure",
        "abstract": "BACKGROUND: Cardiovascular diseases (CVDs) are a significant global health concern, causing an estimated 17.9 million deaths annually, which represents 31% of worldwide deaths. A significant proportion of CVD deaths are due to heart attacks and strokes, with one-third of these deaths occurring prematurely in individuals under 70 years old. Heart failure is a notable event within CVDs and emerges when the heart cannot efficiently pump blood to fulfill the body's requirements. This complex syndrome's origins are multifactorial and often arise from conditions such as hypertension, diabetes, and hyperlipidemia. Large datasets with multiple features offer an opportunity for machine learning to aid in the early detection and prediction of heart failure.\nMETHODS: The study employed an unmatched case-control retrospective design. Supervised machine learning models were utilized, notably Multilayer Perceptron Artificial Neural Networks (MLP-ANNs) and decision tree-based models, to predict heart failure disease using data from 918 patients. The open licensed dataset, a combination from five independent heart datasets, comprises 11 demographic and clinical features related to patient status. The MLP-ANN, equipped with a hidden layer and a hyperbolic tangent activation function, was trained on 70% of the data and tested on the remaining 30%. Additionally, the study evaluated the decision tree model's performance through split-sample validation and 10-fold cross-validation.\nRESULTS: The ANN model demonstrated an accuracy of 88.10% in predicting heart disease (AUROC = 0.942) based on six factors and five covariates. The cross-validated tree model achieved an overall predictive accuracy of 84.3%. In contrast, the split-sample validated tree model, which used a balanced 50-50 data split for training and testing, attained an accuracy of 82.0%. OldPeak (ST depression induced by exercise relative to rest) had the highest normalized importance calculated from the MLP ANN model.\nCONCLUSION: Machine learning predictions have gained importance in healthcare, presenting potential benefits in early detection and intervention, leading to improved patient outcomes and reduced healthcare expenses. The study revealed that ANNs outperform decision tree models in accuracy for the dataset in use. Furthermore, the research emphasized the significance of the clinical feature \"Oldpeak\" in predicting heart failure through ANNs. ANNs can discern intricate relationships between variables and recognize non-linear interactions, a capability sometimes missed by decision tree models. However, the efficacy of machine learning models remains dependent on the quality and volume of the available data.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/717a613d68a0f6903007743841961f69e01f4e13",
        "citation_count": 0
    },
    {
        "title": "Uncertainty Estimation with Data Augmentation for Active Learning Tasks on Health Data",
        "abstract": "Supervised machine learning (ML) is revolutionising healthcare, but the acquisition of reliable labels for signals harvested from medical sensors is usually challenging, manual, and costly. Active learning can assist in establishing labels on-the-fly by querying the user only for the most uncertain \u2013and thus informative\u2013 samples. However, current approaches rely on naive data selection algorithms, which still require many iterations to achieve the desired accuracy. To this aim, we introduce a novel framework that exploits data augmentation for estimating the uncertainty introduced by sensor signals.Our experiments on classifying medical signals show that our framework selects informative samples up to 50% more diverse. Sample diversity is a key indicator of uncertainty, and our framework can capture this diversity better than previous solutions as it picks unlabelled samples with a higher average point distance during the first queries compared to the baselines, which pick samples that are closer together. Through our experiments, we show that augmentation-based uncertainty makes better decisions, as the more informative signals are labelled first and the learner is able to train on samples with more diverse features earlier on, thus enabling the potential expansion of ML in more real-life healthcare use cases.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/71df2c5d7fc8a1f63345f443ae44bcad97da2493",
        "citation_count": 0
    },
    {
        "title": "AI-Powered Disease Diagnosis: Evaluating the Effectiveness of Machine Learning Algorithms",
        "abstract": "The integration of Artificial Intelligence (AI) and Machine Learning (ML) in healthcare has revolutionized disease diagnosis, offering the potential for early detection, improved accuracy, and personalized treatment. This paper evaluates the effectiveness of various ML algorithms in diagnosing a wide range of diseases, including cardiovascular conditions, cancer, neurological disorders, and infectious diseases. By analyzing key supervised and unsupervised learning algorithms such as Support Vector Machines, Random Forests, Neural Networks, and K-means Clustering, this study explores their applications, strengths, and limitations in clinical settings. Evaluation metrics including accuracy, precision, recall, and AUC are used to assess the performance of these algorithms. The paper also highlights significant challenges in AI-powered diagnostics, such as data quality, interpretability of models, ethical considerations, and integration into clinical workflows. Finally, it examines the future prospects of AI in disease diagnosis, emphasizing advances in deep learning, personalized medicine, and AI-human collaborative models. The findings underscore the transformative role of AI in enhancing diagnostic efficiency while acknowledging the need for further research, ethical oversight, and regulatory frameworks to ensure safe and equitable implementation.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/71fa6cde501c0ad17105cee7a025a3623e24413e",
        "citation_count": 1
    },
    {
        "title": "Considerations for the implementation of machine learning into acute care settings.",
        "abstract": "INTRODUCTION\nManagement of patients in the acute care setting requires accurate diagnosis and rapid initiation of validated treatments; therefore, this setting is likely to be an environment in which cognitive augmentation of the clinician's provision of care with technology rooted in artificial intelligence, such as machine learning (ML), is likely to eventuate.\n\n\nSOURCES OF DATA\nPubMed and Google Scholar with search terms that included ML, intensive/critical care unit, electronic health records (EHR), anesthesia information management systems and clinical decision support were the primary sources for this report.\n\n\nAREAS OF AGREEMENT\nDifferent categories of learning of large clinical datasets, often contained in EHRs, are used for training in ML. Supervised learning uses algorithm-based models, including support vector machines, to pair patients' attributes with an expected outcome. Unsupervised learning uses clustering algorithms to define to which disease grouping a patient's attributes most closely approximates. Reinforcement learning algorithms use ongoing environmental feedback to deterministically pursue likely patient outcome.\n\n\nAREAS OF CONTROVERSY\nApplication of ML can result in undesirable outcomes over concerns related to fairness, transparency, privacy and accountability. Whether these ML technologies irrevocably change the healthcare workforce remains unresolved.\n\n\nGROWING POINTS\nWell-resourced Learning Health Systems are likely to exploit ML technology to gain the fullest benefits for their patients. How these clinical advantages can be extended to patients in health systems that are neither well-endowed, nor have the necessary data gathering technologies, needs to be urgently addressed to avoid further disparities in healthcare.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/722011a4f89e41eeddbe6159213bd196cba07514",
        "citation_count": 1
    },
    {
        "title": "Leveraging metabolic modeling to identify functional metabolic alterations associated with COVID-19 disease severity",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/723f8f6858fbf79cabda359e11d575a192b1805e",
        "citation_count": 2
    },
    {
        "title": "Proteomics and Machine Learning Approaches Reveal a Set of Prognostic Markers for COVID-19 Severity With Drug Repurposing Potential",
        "abstract": "The pestilential pathogen SARS-CoV-2 has led to a seemingly ceaseless pandemic of COVID-19. The healthcare sector is under a tremendous burden, thus necessitating the prognosis of COVID-19 severity. This in-depth study of plasma proteome alteration provides insights into the host physiological response towards the infection and also reveals the potential prognostic markers of the disease. Using label-free quantitative proteomics, we performed deep plasma proteome analysis in a cohort of 71 patients (20 COVID-19 negative, 18 COVID-19 non-severe, and 33 severe) to understand the disease dynamics. Of the 1200 proteins detected in the patient plasma, 38 proteins were identified to be differentially expressed between non-severe and severe groups. The altered plasma proteome revealed significant dysregulation in the pathways related to peptidase activity, regulated exocytosis, blood coagulation, complement activation, leukocyte activation involved in immune response, and response to glucocorticoid biological processes in severe cases of SARS-CoV-2 infection. Furthermore, we employed supervised machine learning (ML) approaches using a linear support vector machine model to identify the classifiers of patients with non-severe and severe COVID-19. The model used a selected panel of 20 proteins and classified the samples based on the severity with a classification accuracy of 0.84. Putative biomarkers such as angiotensinogen and SERPING1 and ML-derived classifiers including the apolipoprotein B, SERPINA3, and fibrinogen gamma chain were validated by targeted mass spectrometry-based multiple reaction monitoring (MRM) assays. We also employed an in silico screening approach against the identified target proteins for the therapeutic management of COVID-19. We shortlisted two FDA-approved drugs, namely, selinexor and ponatinib, which showed the potential of being repurposed for COVID-19 therapeutics. Overall, this is the first most comprehensive plasma proteome investigation of COVID-19 patients from the Indian population, and provides a set of potential biomarkers for the disease severity progression and targets for therapeutic interventions.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/726b187fe36eb208466fec285e920e0cf24be525",
        "citation_count": 52
    },
    {
        "title": "Prostate Cancer Prediction Using Healthcare Utilization Patterns",
        "abstract": "Early cancer detection is crucial for improved patient outcomes, as evidenced by research on major cancer types emphasizing the impact of timely treatment initiation. This study focuses on identifying pre-diagnosis patterns in prostate cancer, utilizing supervised machine learning to build predictive models analyzing patients' medical activities one year before diagnosis. The dataset, sourced from the All of Us Research Program, specifically targets prostate cancer cases diagnosed between 2010 and 2019. By grouping CPT4 codes in clinically significant categories and employing the XGBoost model in machine learning, the study achieved superior performance with accuracy and area under the curve (AUC) of 0.94 for predicting cancer one month prior to diagnosis and 0.76 five months before diagnosis. In addition, the top important features derived from the model were surgical pathology procedure, cardiac stress tests, hospital inpatient, number of total visits, and diagnostic ultrasound of the head and neck. Despite a decline in accuracy when predicting 5 months and 1 year ahead, this research lays the groundwork for personalized and timely interventions, advancing cancer diagnostics and early intervention strategies.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/72dcfa5a5f83c58690996a9f16359a47cc45fde9",
        "citation_count": 0
    },
    {
        "title": "A Robust Chronic Kidney Disease Classifier Using Machine Learning",
        "abstract": "Clinical support systems are affected by the issue of high variance in terms of chronic disorder prognosis. This uncertainty is one of the principal causes for the demise of large populations around the world suffering from some fatal diseases such as chronic kidney disease (CKD). Due to this reason, the diagnosis of this disease is of great concern for healthcare systems. In such a case, machine learning can be used as an effective tool to reduce the randomness in clinical decision making. Conventional methods for the detection of chronic kidney disease are not always accurate because of their high degree of dependency on several sets of biological attributes. Machine learning is the process of training a machine using a vast collection of historical data for the purpose of intelligent classification. This work aims at developing a machine-learning model that can use a publicly available data to forecast the occurrence of chronic kidney disease. A set of data preprocessing steps were performed on this dataset in order to construct a generic model. This set of steps includes the appropriate imputation of missing data points, along with the balancing of data using the SMOTE algorithm and the scaling of the features. A statistical technique, namely, the chi-squared test, is used for the extraction of the least-required set of adequate and highly correlated features to the output. For the model training, a stack of supervised-learning techniques is used for the development of a robust machine-learning model. Out of all the applied learning techniques, support vector machine (SVM) and random forest (RF) achieved the lowest false-negative rates and test accuracy, equal to 99.33% and 98.67%, respectively. However, SVM achieved better results than RF did when validated with 10-fold cross-validation.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/72e303e9119ba8d3b1731e5ea5f9a7322d08e4ca",
        "citation_count": 47
    },
    {
        "title": "An Ontology Alignment based on Machine learning for Integration of Patient Health Data",
        "abstract": ": The integration of patient data is crucial in healthcare informatics. It involves organizing and integrating heterogeneous health data from various Electronic Health Records (EHRs). Attribute alignment is a fundamental step in data integration. It involves mapping data attributes across di ff erent datasets. Most of the data maintained in EHRs does not follow standard terminologies in healthcare. Therefore, it becomes di ffi cult to integrate patient health data from diverse data sources for generating historic medical records. The research work carried out overcomes this problem by developing a vital sign ontology using OpenEHR health standards. It helps to map the vital signs observations of the patients from its proprietary sources uniformly. The work also leverages the power of supervised learning algorithms to automate the mapping of di ff erent health datasets to the proposed ontology. The approach is evaluated on patient health datasets, considering both standard and non-standard datasets. The research work employs di ff erent machine learning algorithms, such as Support Vector Machine (SVM), Naive Bayes, Logistic Regression, k-nearest neighbor (KNN), AdaBoost, and Neural network, in order to evaluate the best algorithm for the proposed approach. The evaluation results conclude that Naive Bayes exhibits the highest accuracy, with minimum misclassification rate, in both the training and validation phases for automatically mapping the health datasets with the proposed ontology.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/73988dda54bac688765eaefdfd191f5f1629ef84",
        "citation_count": 0
    },
    {
        "title": "Development and Internal Validation of an Interpretable Machine Learning Model to Predict Readmissions in a United States Healthcare System",
        "abstract": "(1) One in four hospital readmissions is potentially preventable. Machine learning (ML) models have been developed to predict hospital readmissions and risk-stratify patients, but thus far they have been limited in clinical applicability, timeliness, and generalizability. (2) Methods: Using deidentified clinical data from the University of California, San Francisco (UCSF) between January 2016 and November 2021, we developed and compared four supervised ML models (logistic regression, random forest, gradient boosting, and XGBoost) to predict 30-day readmissions for adults admitted to a UCSF hospital. (3) Results: Of 147,358 inpatient encounters, 20,747 (13.9%) patients were readmitted within 30 days of discharge. The final model selected was XGBoost, which had an area under the receiver operating characteristic curve of 0.783 and an area under the precision-recall curve of 0.434. The most important features by Shapley Additive Explanations were days since last admission, discharge department, and inpatient length of stay. (4) Conclusions: We developed and internally validated a supervised ML model to predict 30-day readmissions in a US-based healthcare system. This model has several advantages including state-of-the-art performance metrics, the use of clinical data, the use of features available within 24 h of discharge, and generalizability to multiple disease states.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/73f0de5a2b99b5487600c1eba78d57b669d11681",
        "citation_count": 1
    },
    {
        "title": "New horizons in prediction modelling using machine learning in older people\u2019s healthcare research",
        "abstract": "Abstract Machine learning (ML) and prediction modelling have become increasingly influential in healthcare, providing critical insights and supporting clinical decisions, particularly in the age of big data. This paper serves as an introductory guide for health researchers and readers interested in prediction modelling and explores how these technologies support clinical decisions, particularly with big data, and covers all aspects of the development, assessment and reporting of a model using ML. The paper starts with the importance of prediction modelling for precision medicine. It outlines different types of prediction and machine learning approaches, including supervised, unsupervised and semi-supervised learning, and provides an overview of popular algorithms for various outcomes and settings. It also introduces key theoretical ML concepts. The importance of data quality, preprocessing and unbiased model performance evaluation is highlighted. Concepts of apparent, internal and external validation will be introduced along with metrics for discrimination and calibration for different types of outcomes. Additionally, the paper addresses model interpretation, fairness and implementation in clinical practice. Finally, the paper provides recommendations for reporting and identifies common pitfalls in prediction modelling and machine learning. The aim of the paper is to help readers understand and critically evaluate research papers that present ML models and to serve as a first guide for developing, assessing and implementing their own.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/74231c03d120c9f2c46fb07dd8da5771d7636f15",
        "citation_count": 1
    },
    {
        "title": "Artificial Intelligence in Medicine for Chronic Disease Classification Using Machine Learning",
        "abstract": "Artificial intelligence (AI) systems in medicine are one of the most important modern trends in global healthcare. Artificial intelligence technologies are fundamentally changing the global healthcare system, making it possible to radically rebuild the system of medical diagnostics while reducing healthcare costs. AI is actively used in research to develop methods for diagnosing coronary heart disease (CHD). There are different types of CHD. Before treating a disease, it is necessary to determine which class of diseases it belongs to. Based on the feature space of the disease, it is possible to classify the type of CHD. Machine learning algorithms can solve this problem. The k-nearest neighbors (KNN) algorithm is a simple, easy-to-implement supervised machine learning algorithm that can be used to solve classification problems. The dataset is the more important part of the supervised machine learning algorithm for training. Gathering data is the most important step in solving any supervised machine learning problem. But choosing more important part from the collected data is one of the tasks to be solved. The main purpose of this study is to select more useful parametric attributes from the dataset to obtain a high F1-score of CHD classification.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/74332d7c15ad4133593b074371335be9b89742fa",
        "citation_count": 6
    },
    {
        "title": "Anonymization of Sensitive Data in the Diabetes Prediction using Private Bayesian Networks",
        "abstract": "In the modern era of automated learning and computational intelligence, early disease detection is critical for assisting practitioners in disease diagnosis and decision-making. Traditional methods, including Support Vector Machine (SVM), Random Forest (RF), and XGBoost, have proven effective for disease predictions but raise significant privacy concerns due to the sensitive nature of the data involved. To mitigate these privacy issues, this research study proposes the creation of a synthetic dataset for training the supervised classification models for Diabetes Mellitus (DM) prediction, ensuring the preservation of the ground truth. The proposed method employs a discriminative-generative distillation approach using private Bayesian networks to protect the data confidentiality. By using the models as intermediaries to extract information from personal data, the proposed technique enables knowledge transfer to a student network through dual channels, preventing data leakage and safeguarding sensitive healthcare information. This approach enhances the security and privacy of medical data while maintaining the accuracy and reliability of predictive models.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/74394acb828892abd03e0b3ae059d662bb6a5b3b",
        "citation_count": 0
    },
    {
        "title": "Analysis and Prediction of Diabetes Disease Using Machine Learning Methods",
        "abstract": "To increase healthcare quality, early illness prediction helps patients prevent potentially life-threatening health issues before it is too late. Artificial intelligence is a rapidly evolving area, and its applications to diabetes, a worldwide epidemic, have the potential to revolutionize the way diabetes is diagnosed and managed. A total of six supervised machine learning algorithms based on patient data were used and compared to predict the diagnosis of diabetes mellitus. For experiments, the Pima Indians Diabetes Database was used, and their missing values were carefully handled by different techniques. For random train-test splits, the Random Forest classification algorithm achieved an accuracy rate of 92 percent. This model outperforms other state-of-the-art approaches due to the application of a combination of techniques for dealing with missing values (the mixture of imputing missing values techniques) that is proposed. With this approach, the models of this manuscript achieved better accuracy than prior work done with the Pima diabetes data.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/74745ae51dc1fe97b7729397e2f87736f09e4841",
        "citation_count": 1
    },
    {
        "title": "Supervised Learning techniques for analysis of neonatal data",
        "abstract": "In the current healthcare setup, the use of Machine Learning has been limited as clinicians diagnose and administer treatment manually. Supervised Learning techniques can help solve many prognostic problems and help clinicians in taking decisions pertaining to healthcare. The paper presents selected machine learning techniques that can be applied for medical data, and in particular some supervised learning techniques with their applications on the analysis of neonatal data. The goal of the paper is to review and discuss the methodology, advantages and disadvantages of supervised learning techniques and the use on neonatal data. In addition, this paper also highlights the model evaluation parameters and also suggests the ways to improve the performance of a model designed for neonatal data analysis.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/747a9cc84ac442b9f69ec712f3d37cfc607a7533",
        "citation_count": 5
    },
    {
        "title": "Role of artificial intelligence in predicting neurological outcomes in postcardiac resuscitation",
        "abstract": "Being an extremely high mortality rate condition, cardiac arrest cases have rightfully been evaluated via various studies and scoring factors for effective resuscitative practices and neurological outcomes postresuscitation. This narrative review aims to explore the role of artificial intelligence (AI) in predicting neurological outcomes postcardiac resuscitation. The methodology involved a detailed review of all relevant recent studies of AI, different machine learning algorithms, prediction tools, and assessing their benefit in predicting neurological outcomes in postcardiac resuscitation cases as compared to more traditional prognostic scoring systems and tools. Previously, outcome determining clinical, blood, and radiological factors were prone to other influencing factors like limited accuracy and time constraints. Studies conducted also emphasized that to predict poor neurological outcomes, a more multimodal approach helped adjust for confounding factors, interpret diverse datasets, and provide a reliable prognosis, which only demonstrates the need for AI to help overcome challenges faced. Advanced machine learning algorithms like artificial neural networks (ANN) using supervised learning by AI have improved the accuracy of prognostic models outperforming conventional models. Several real-world cases of effective AI-powered algorithm models have been cited here. Studies comparing machine learning tools like XGBoost, AI Watson, hyperspectral imaging, ChatGPT-4, and AI-based gradient boosting have noted their beneficial uses. AI could help reduce workload, healthcare costs, and help personalize care, process vast genetic and lifestyle data and help reduce side effects from treatments. Limitations of AI have been covered extensively in this article, including data quality, bias, privacy issues, and transparency. Our objectives should be to use more diverse data sources, use interpretable data output giving process explanation, validation method, and implement policies to safeguard patient data. Despite the limitations, the advancements already made by AI and its potential in predicting neurological outcomes in postcardiac resuscitation cases has been quite promising and boosts a continually improving system, albeit requiring close human supervision with training and improving models, with plans to educate clinicians, the public and sharing collected data.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/74a5718d0ec79224fce3e55ff27dabee5d4cf0a0",
        "citation_count": 0
    },
    {
        "title": "Early Diabetes Prediction using Random Forest",
        "abstract": "Non-communicable diseases such as diabetes and hypertension account for nearly half of all early deaths every year. Diabetes is a disease that necessitates continuous monitoring of blood sugar levels, particularly glucose, in order to effectively mitigate the emerging health complications. Self-management of the disease, particularly maintaining glucose levels in the blood within a specific range, is critical for treatment. This involves actively monitoring blood glucose and insulin levels, as well as managing diet and physical activity. Diabetes advancements and self-administration applications have made it easier for patients to gain access to more relevant information. The ability of Machine Learning (ML) techniques to solve complex tasks in dynamic environments and with dynamic data has contributed to its success in the study of diseases such as diabetes. This research study has attempted to design and develop a personal healthcare system, which can use the data generated from daily activities and other significant parameters to monitor the blood glucose level and provide proper report representation online. The Machine Learning (ML) technique has been used to detect non-communicable diseases at an early stage. The proposed research study has surveyed previous relevant literatures in order to understand the approaches used previously for the detection or presence of disease in the human body. There are various methods to determine blood glucose levels non-invasively, but a universally acceptable method with good accuracy and precision is not yet available. This paper emphasized about using Random Forest, a supervised machine learning algorithm to determine the probability of occurrence of diabetes mellitus to take precautions accordingly.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/74cdb562688d9af580ee285a957175a95d215ce6",
        "citation_count": 2
    },
    {
        "title": "A Supervised Machine Learning Approach with Feature Selection for Sex-Specific Biomarker Prediction",
        "abstract": "Biomarkers play a crucial role in various aspects of healthcare, offering valuable insights into disease diagnosis, prognosis, and treatment selection. Recently, machine learning (ML) techniques have emerged as effective tools for uncovering novel biomarkers and improving predictive modelling capabilities. However, bias within ML algorithms, particularly regarding sex-based disparities, remains a concern. In this study, a supervised ML model was developed in order to predict 9 common biomarkers widely used in clinical settings. These biomarkers included triglycerides, body mass index, waist circumference, systolic blood pressure, blood glucose, uric acid, urinary albumin-to-creatinine ratio, high-density lipoproteins and albuminuria. During the validation test, it was observed that the ML models successfully predicted values within 5 and 10% error of the actual values. Out of the 121 female individuals tested, the following percentages of predicted values fell within this 10% range: 93% for albuminuria, 86% for waist circumference, 76% for BMI, and the lowest being 64% for systolic blood pressure and blood glucose. For the 119 male individuals tested, the percentages were as follows: 92% for albuminuria, 96% for waist circumference, 91% for BMI, 74% for blood glucose, and 68% for systolic blood pressure. Triglycerides, uric acid, urinary albumin-to-creatinine ratio and high-density lipoproteins all predicted lower than 50% for both male and female subgroups. Overall, the male subgroup had higher prediction scores than the female group. Graphical Abstract",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/7528d66deacb796101a4f1c67bd7f0d896a2060f",
        "citation_count": 1
    },
    {
        "title": "PREDICTING THYROID DISEASE USING DATAMINING TECHNIQUE",
        "abstract": "- Data mining has been used intensively and extensively by many organizations. In healthcare, data mining is becoming increasingly popular, if not increasingly essential. Data mining applications can greatly benefit all parties involved in the healthcare industry. For example, data mining can help healthcare insurers detect fraud and abuse, healthcare organizations make customer relationship management decisions, physicians identify effective treatments and best practices, and patients receive better and more affordable healthcare services. The huge amounts of data generated by healthcare transactions are too complex and voluminous to be processed and analyzed by traditional methods. Data mining provides the methodology and technology to transform these mounds of data into useful information for decision making. There are two main methods of Data mining: Clustering and Classification. In many cases the concept of classification is confused by means of clustering, but there is difference between these two methods. According to the perspective of Machine learning clustering method is unsupervised learning and tries to group sets of objects having relationship between them, whereas classification method is supervised and assigning objects to sets of predefined classes. in proposed system are classified and cluster of the thyroid disease in data mining.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/7539d7c16afd787ac1d9fd7031b97bbdefd6cbb1",
        "citation_count": 4
    },
    {
        "title": "DISEASE PREDICTION USING MACHINE LEARNING ALGORITHMS",
        "abstract": "With big data growth in biomedical and healthcare communities, accurate analysis of medical data is devisee for early complaint discovery, patient care, and community services. One similar perpetration of machine literacy algorithms is in the field of healthcare. Medical installations need to be advanced so that better opinions for patient opinion and treatment options can be made. Accurate and on-time analysis of any health-related problem is important for the forestallment and treatment of the illness. The traditional way of opinion may not be sufficient in the case of a serious disease. Still, supervised machine literacy (ML) algorithms have showcased significant eventuality in surpassing standard systems for complaint opinion and abetting medical experts in the early discovery of high-threat conditions. In this literature, the end is to fete trends across colorful types of supervised ML models in complaint discovery through the examination of performance criteria. Developing a medical opinion system grounded on machine literacy (ML) algorithms for vaticination of any complaint can help in a more accurate opinion than the conventional system. We've designed a complaint vaticination system using multiple ML algorithms. The data set used had further than 230 conditions for processing. Grounded on the symptoms, age, and gender of an individual, the opinion system gives the affair as the complaint that the existent might be suffering from. By relating significant patterns and detecting correlations and connections among numerous variables in huge databases, the use of colorful data mining tools and machine literacy approaches has changed healthcare associations. It serves as an important instrument in the medical sector, furnishing and comparing being data for the unborn course of action. This technology combines multiple logical methodologies with ultramodern and complex algorithms, allowing for the disquisition of massive quantities of data. Our opinion model can act as a croaker for the early opinion of a complaint to insure the treatment can take place on time and lives can be saved.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/753c7e718c9cd19059e4cf3e4e8c50f630665dd5",
        "citation_count": 1
    },
    {
        "title": "Supervised Learning Based Medicare Hospital Fraud Detection",
        "abstract": "With the overall increase in the elderly population come additional, necessary medical needs and costs. Medicare is a U.S. healthcare program that provides insurance, primarily to individuals 65 years or older, to offload some of the financial burden associated with medical care. Even so, healthcare costs are high and continue to increase. Fraud is a major contributor to these inflating healthcare expenses. Our paper provides a comprehensive study leveraging machine learning methods to detect fraudulent Medicare providers. We use publicly available Medicare data and provider exclusions for fraud labels to build and assess three different learners. In order to lessen the impact of class imbalance, given so few actual fraud labels, we employ Logistic Regression creating two class distributions. Our results show that the other algorithms have poor performance compared with Logistic Regression. Learners have the best fraud detection performance, particularly for the 80:20 class distributions with average AUC scores, respectively, and low false negative rates. We successfully demonstrate the efficacy of employing machine learning Models to detect Medicare fraud.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/754ee4af9e9fb56c426f5c1309076b8d560db381",
        "citation_count": 0
    },
    {
        "title": "Neural Language Models with Distant Supervision to Identify Major Depressive Disorder from Clinical Notes",
        "abstract": "Major depressive disorder (MDD) is a prevalent psychiatric disorder that is associated with significant healthcare burden worldwide. Phenotyping of MDD can help early diagnosis and consequently may have significant advantages in patient management. In prior research MDD phenotypes have been extracted from structured Electronic Health Records (EHR) or using Electroencephalographic (EEG) data with traditional machine learning models to predict MDD phenotypes. However, MDD phenotypic information is also documented in free-text EHR data, such as clinical notes. While clinical notes may provide more accurate phenotyping information, natural language processing (NLP) algorithms must be developed to abstract such information. Recent advancements in NLP resulted in state-of-the-art neural language models, such as Bidirectional Encoder Representations for Transformers (BERT) model, which is a transformer-based model that can be pre-trained from a corpus of unsupervised text data and then fine-tuned on specific tasks. However, such neural language models have been underutilized in clinical NLP tasks due to the lack of large training datasets. In the literature, researchers have utilized the distant supervision paradigm to train machine learning models on clinical text classification tasks to mitigate the issue of lacking annotated training data. It is still unknown whether the paradigm is effective for neural language models. In this paper, we propose to leverage the neural language models in a distant supervision paradigm to identify MDD phenotypes from clinical notes. The experimental results indicate that our proposed approach is effective in identifying MDD phenotypes and that the Bio- Clinical BERT, a specific BERT model for clinical data, achieved the best performance in comparison with conventional machine learning models.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7594a5e4d0e23f838cedf45353c1e2760c3aafdd",
        "citation_count": 4
    },
    {
        "title": "Supervised Machine Learning Modelling of Demand for Outpatient Health-Care Services in Kenya using Artificial Neural Networks and Regression Decision Trees.",
        "abstract": "Machine learning models are frequently gaining wide applications in different fields with an emphasis on supervised machine learning for data exploration as in healthcare provision. With an increase in demand for outpatient health care services in Kenya, the Government is faced with the problem of forecasting this type of demand. Its in this regard that this research develops a supervised machine learning model for the modeling and prediction of demand for outpatient health-care services in Kenya using artificial neural networks, Linear Regression analysis and Decision trees. The objectives of this research were to analyze, develop and evaluate machine learning models in the modeling of outpatient healthcare data. Model evaluation was via the deviance residuals and mean squared error. Data used in this research was secondary data obtained from the Kenya Household Health Expenditure Utilization Survey, 2017 in which the R statistical software was used to aid the analysis. A total of nine thousand one hundred and fifty-nine outpatients were used in the research and data attributes were age, gender, cost of outpatient health care sought and number of visits made by the outpatients. Experiment results showed that age and gender of an outpatient were significant factors in the estimation and forecasting of demand for outpatient healthcare services for which the neural network architecture was used in the data training. Cost and Visits were used as primary variables in decision tree construction for the classification and regression decision trees respectively.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/75a7025d8f278029be8ecb24a74f563f1c5c1625",
        "citation_count": 1
    },
    {
        "title": "A machine learning-based on-demand sweat glucose reporting platform",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/75c4052f75a547586168dfddbd2cf6934fcf856e",
        "citation_count": 40
    },
    {
        "title": "Towards Graph-Based Semi-Supervised Learning on Audio Embeddings for Label Classification",
        "abstract": "The increasing importance of audio-based healthcare diagnostics, particularly in chronic respiratory problems, has prompted the development of novel approaches for disease classification using the full spectrum analysis of cough sounds. This paper presents an innovative study exploring the potential of employing supervised and semi-supervised learning methodologies for disease categorization based on cough audio samples. Specifically, this study focuses on scenarios characterized by a shortage of annotated data related to chronic diseases. The objectives of our study involved the utilization of standard machine learning algorithms for direct classification based on embeddings, as well as the integration of Graph Neural Networks (GNNs) on the KNN graph. Preliminary results indicate that GNN models consistently outperformed traditional classifiers. For instance, with just 1 % of the data, GAT and GCN achieved AUC PR values of 0.84 and 0.87, respectively, surpassing all traditional methods. The superiority mentioned above was sustained even when the data fraction was augmented to 3% and 5%. The usefulness of graph neural networks (GNNs) was further supported by comprehensive performance measures, wherein the graph convolutional network (GCN) exhibited exceptional preci-sion and PR (precision-recall). In summary, the AudioVecDiagnosis framework presents a promising opportunity for further investigation in audio-based healthcare diagnostics. It provides an optimum approach for situations with a limited availability of labeled data.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/769642256e3a972ec2df621b35c7e4a32c5b1852",
        "citation_count": 0
    },
    {
        "title": "Identification of patient demographic, clinical, and SARS-CoV-2 genomic factors associated with severe COVID-19 using supervised machine learning: a retrospective multicenter study",
        "abstract": null,
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/769f00021eaa043e4f35e36dfaa9a679aa700a48",
        "citation_count": 0
    },
    {
        "title": "Machine Learning Approaches for Early Prostate Cancer Prediction Based on Healthcare Utilization Patterns",
        "abstract": "The goal of this study was to build a machine learning model for early prostate cancer prediction based on healthcare utilization patterns. We examined the frequency and pattern changes of healthcare utilization in 2916 prostate cancer patients 3 years prior to their prostate cancer diagnoses and explored several supervised machine learning techniques to predict possible prostate cancer diagnosis. Analysis of patients' medical activities between 1 year and 2 years prior to their prostate cancer diagnoses using XGBoost model provided the best prediction accuracy with high F1 score (0.9) and AUC score (0.73). These pilot results indicated that application of machine learning to healthcare utilization patterns may result in early identification of prostate cancer diagnosis.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/76aca2c8623daf2cfd3b4e3f2ffc9fec0fe87f2a",
        "citation_count": 1
    },
    {
        "title": "Advancements in Machine Learning Algorithms for Predictive Analytics in Healthcare",
        "abstract": "Recent improvements in machine learning (ML) algorithms have changed predictive analytics in healthcare in a way that has never been seen before. This means that there are now more ways than ever to improve patient results and business efficiency. This summary looks at important changes and what they mean. A lot of healthcare data, like electronic health records (EHRs), medical images, genetics, and personal sensor data, is being used more and more with machine learning methods like guided learning, unsupervised learning, and deep learning. These methods make it possible to use predictive models to diagnose diseases, give patients specific treatment suggestions, and keep track of their care. For sorting things into groups, supervised learning techniques like support vector machines (SVM) and random forests have been used to correctly spot diseases based on complicated data trends. For example, SVMs have been useful for telling the difference between different types of cancer from genetic data, which helps with focused treatments. On the other hand, unsupervised learning algorithms like grouping algorithms help find groups of patients who share similar traits, which makes personalized medicine possible. Deep learning, has been very successful in medical picture analysis, being more accurate than humans at tasks like finding tumors in x-rays and lab slides. Its ability to instantly learn traits from raw data has made diagnosis easier and more accurate. ML algorithms also help healthcare operations run more smoothly by using prediction analytics to help hospitals handle their resources better, make the best use of their staff, predict which patients will need to be admitted, and lower the number of times they have to be readmitted. These predictive models use a variety of data sources to guess how patients will do and how they will use healthcare resources, which helps people make smart decisions and make the best use of their resources.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/76ca70334069a09aedddab9375da6f31bdf89c54",
        "citation_count": 0
    },
    {
        "title": "Interdisciplinary Applications of AI: Dermatology and Psychology",
        "abstract": "Artificial Intelligence (AI) is profoundly transforming interdisciplinary domains like dermatology and psychology, providing revolutionary possibilities in the areas of diagnosis, treatment, and patient care. AI-driven solutions in dermatology are improving diagnostic accuracy by analyzing medical photos to identify skin disorders such as melanoma with a level of precision comparable to that of professional dermatologists. These technologies utilize machine learning algorithms that have been trained on extensive datasets to detect minor patterns and anomalies in skin lesions. This enables the early detection of skin conditions and the creation of personalized treatment strategies. Moreover, artificial intelligence (AI) assists in optimizing the efficiency of workflows, minimizing diagnostic inaccuracies, and enhancing the availability of dermatological treatment, particularly in places with limited access to healthcare services. Within the field of psychology, artificial intelligence (AI) has a significant influence. It is utilized to assess individuals' mental well-being by analyzing their text and speech patterns, employing techniques such as natural language processing and sentiment analysis. Artificial intelligence algorithms have the capability to observe and analyze patient interactions, offering immediate and accurate observations regarding emotional states and possible psychological illnesses. The incorporation of AI enables more precise evaluations and prompt actions, enhancing conventional therapeutic methods. In addition, chatbots and virtual therapists that utilise artificial intelligence provide instant assistance and ongoing supervision, thereby extending the accessibility of mental health care. The integration of AI with dermatology and psychology not only improves diagnostic skills and treatment results but also highlights the significance of interdisciplinary collaboration in advancing healthcare. By using artificial intelligence (AI), these industries can utilize data-driven analysis to provide more accurate, tailored, and easily accessible healthcare, thereby enhancing patient results and quality of life.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/76d5e79f33edcfb75614b27ec43850a90f4bd92e",
        "citation_count": 0
    },
    {
        "title": "Edge-based Human Activity Recognition System for Smart Healthcare",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/76e2c0cde8d4c04975362b5e13315be67bb96ab7",
        "citation_count": 4
    },
    {
        "title": "Central Blood Pressure Estimation From Distal PPG Measurement Using Semiclassical Signal Analysis Features",
        "abstract": "Background and objective: Blood pressure (BP) is one of the crucial indicators that contains valuable medical information about cardiovascular activities. Developing photoplethysmography (PPG)-based cuffless BP estimation algorithms with enough robustness and accuracy is clinically useful in practice, due to its simplicity and noninvasiveness. In this paper, we have developed and tested two frameworks for arterial blood pressure (ABP) estimation at the central arteries using photoplethysmography and electrocardiogram. Methods: Supervised learning, as adapted by most studies regarding this topic, is introduced by comparing three machine learning algorithms. Features are extracted using semi-classical signal analysis (SCSA) tools. To further increase the accuracy of estimation, another BP estimation algorithm is presented. A single feed-forward neural network (FFNN) is utilized for BP regression with PPG features, which are extracted by SCSA and later used by FFNN as the network input. Both BP estimation algorithms perform robustly against MIMIC II database to guarantee statistical reliability. Results: We evaluated the performance against the Advancement of Medical Instrumentation (AAMI) and British Hypertension Society (BHS) standards, and we have compared the standard deviation (STD) of estimation error with current state of the arts. With the AAMI standard, the first method yields comparable performance against existing literature in the estimation of BP values. Regarding the BHS protocol, the second method achieves grade A in the estimation of BP values. Conclusion: We conclude that by using the PPG signal in combination with informative features from the Schr\u00f6dinger\u2019s spectrum, the BP can be non-invasively estimated in a reliable and accurate way. Furthermore, the proposed frameworks could potentially enable applications of cuffless estimation of the BP and development of mobile healthcare device.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/76fb5c86393df00720f54cfd32e9703d50d313bd",
        "citation_count": 36
    },
    {
        "title": "Predicting Heart Disease at Early Stages using Machine Learning: A Survey",
        "abstract": "Predicting and detection of heart disease has always been a critical and challenging task for healthcare practitioners. Hospitals and other clinics are offering expensive therapies and operations to treat heart diseases. So, predicting heart disease at the early stages will be useful to the people around the world so that they will take necessary actions before getting severe. Heart disease is a significant problem in recent times; the main reason for this disease is the intake of alcohol, tobacco, and lack of physical exercise. Over the years, machine learning shows effective results in making decisions and predictions from the broad set of data produced by the health care industry. Some of the supervised machine learning techniques used in this prediction of heart disease are artificial neural network (ANN), decision tree (DT), random forest (RF), support vector machine (SVM), na\u00efve Bayes) (NB) and k-nearest neighbour algorithm. Furthermore, the performances of these algorithms are summarized.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/77ab2dead2357e9ffa97418b36fd663c04a3a2fc",
        "citation_count": 89
    },
    {
        "title": "Importance analysis of psychosociological variables in frailty syndrome in heart failure patients using machine learning approach",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/77c9953b6e6448aed348a7f59244f376adc55956",
        "citation_count": 3
    },
    {
        "title": "Intelligent Learning Analytics in Healthcare Sector Using Machine Learning",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/77cca6d6354947359a10526a603261332083a991",
        "citation_count": 2
    },
    {
        "title": "Developing A Machine Learning Model to Predict Medication Adherence in Chronic Disease Management",
        "abstract": "In the healthcare industry, chronic disease prediction is crucial. It is crucial to diagnose the illness early. Large amounts of data are generated in computer science as a result of significant technological advancements. Many medical databases are created as clinical information networks advance. Data mining, the process of managing vast amounts of diverse data and extracting insights from it, has emerged as a crucial area of study. Early illness detection, patient treatment, and community services from huge data creation in the biomedical and healthcare communities are all benefited by the accurate analysis of medical data. Nowadays, one of the main areas of research is the management and extraction of knowledge from vast amounts of diverse data. Accurate processing of health data helps the biomedical and healthcare communities by improving patient care, early illness detection, and community services. However, analytical precision is reduced if medical data is not sufficiently consistent. For the domains of biomedical pattern recognition and master learning, the perception and diagnosis of chronic disease are guaranteed to be consistent. Additionally, the decision-making approach's goal is pushed. The study of high-dimensional, multi-modal biomedical data can be effectively addressed by machine learning. In computer science, chronic disease prediction is crucial. Early detection and prediction of chronic disease is crucial. The dataset for chronic obstructive pulmonary disease is used for analysis by the suggested model. Using supervised machine learning techniques such as Random Forest, Multiplayer Perceptron, Logistic Regression, Stochastic Gradient Descent, and XG boost, we provide a chronic obstructive pulmonary disease prediction system. Next, we examine classification techniques for predicting chronic diseases using a variety of criteria, such as accuracy, precision, sensitivity, ROC, and AUC.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/78155ee1cecfe9ecd25c13aa565f280c56a0dd51",
        "citation_count": 0
    },
    {
        "title": "68-OR: Artificial Intelligence and Disparities in Pediatric Type 1 Diabetes Care: Predictive Model Performance Varies by Age and Sex",
        "abstract": "Background and Aim: We can use predictive models to intensify care among youth with type 1 diabetes (T1D) who are predicted to experience a rise in hemoglobin A1c (HbA1c), yet little is known about the impact of age and sex on the performance of machine learning-based models. We evaluated the performance of a model to predict 90-day change in HbA1c by sex and age. Method: We applied supervised machine learning (random forest + natural language processing with 305 data features) to electronic health record data from May 2013 to December 2018 for 1725 youth aged 1-20 years with T1D seen at a Midwest US diabetes center with 11 sites. Eligible encounters included those with an HbA1c measurement >70 days (median 106 days; IQR 94,132) after baseline, with resampling of youth who had multiple eligible encounters. We evaluated model performance characteristics (sensitivity, positive predicted values [PPV]) by age and sex to evaluate for disparities in performance. Results: Median youth age was 14.3 years (IQR=10.9, 16.5), with 50.9% female and 17% non-Hispanic, non-white. Sensitivity and PPV of the model for predicting HbA1c rise of \u22650.3% were 12.4% and 47.2%, in the overall cohort, 13.8% and 51.4% in males, and 10.9% and 0.4% (p Conclusions: Predictive models used in clinical practice should be examined for disparities in performance across groups. Our present predictive model exhibits disparities in performance characteristics by sex and age. Whether the model performs differently among groups defined by race, ethnicity, socioeconomic status, and treatment modalities remains to be determined; such disparities have the potential to exacerbate disparities in healthcare delivery. Disclosure D. Ferro: None. D. D. Williams: None. S. R. Patton: None. R. Mcdonough: None. M. A. Clements: Consultant; Self; Eli Lilly and Company, Employee; Self; Glooko, Inc., Research Support; Self; Abbott Diabetes, Dexcom, Inc.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/782d37ad19f666f3c2906b9e7626a7224e528604",
        "citation_count": 0
    },
    {
        "title": "Efficient Discrete Feature Encoding for Variational Quantum Classifier",
        "abstract": "Recent days have witnessed significant interests in applying quantum-enhanced techniques for solving machine learning tasks in, e.g., classification, regression, and recommender systems. Variational methods that use quantum resources of imperfect quantum devices with the help of classical computing techniques are popular for supervised learning. Variational Quantum Classification (VQC) is one of such variational methods with possible quantum advantage in using quantum-enhanced features that are hard to compute by classical methods. Its performance depends on the mapping of classical features into quantum-enhanced feature space. Although there have been many quantum-mapping functions proposed so far, there is little discussion on efficient mapping of discrete features, such as, race, gender, marriage status and others that are often significant for classifying datasets of interest. We first introduce the use of Quantum Random Access Coding (QRAC) to map such discrete features efficiently into limited number of qubits for VQC. We numerically show that QRAC can help speeding up the training of VQC by reducing its parameters via reduction on the number of qubits for the mapping. We confirm the effectiveness of the QRAC in VQC by experimenting on classification of healthcare datasets with both simulators and real quantum devices.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/782eb456d38256380708e524f9f5cf064fbcdc47",
        "citation_count": 44
    },
    {
        "title": "A claims\u2010based, machine\u2010learning algorithm to identify patients with pulmonary arterial hypertension",
        "abstract": "Abstract Many patients with pulmonary arterial hypertension (PAH) experience substantial delays in diagnosis, which is associated with worse outcomes and higher costs. Tools for diagnosing PAH sooner may lead to earlier treatment, which may delay disease progression and adverse outcomes including hospitalization and death. We developed a machine\u2010learning (ML) algorithm to identify patients at risk for PAH earlier in their symptom journey and distinguish them from patients with similar early symptoms not at risk for developing PAH. Our supervised ML model analyzed retrospective, de\u2010identified data from the US\u2010based Optum\u00ae Clinformatics\u00ae Data Mart claims database (January 2015 to December 2019). Propensity score matched PAH and non\u2010PAH (control) cohorts were established based on observed differences. Random forest models were used to classify patients as PAH or non\u2010PAH at diagnosis and at 6 months prediagnosis. The PAH and non\u2010PAH cohorts included 1339 and 4222 patients, respectively. At 6 months prediagnosis, the model performed well in distinguishing PAH and non\u2010PAH patients, with area under the curve of the receiver operating characteristic of 0.84, recall (sensitivity) of 0.73, and precision of 0.50. Key features distinguishing PAH from non\u2010PAH cohorts were a longer time between first symptom and the prediagnosis model date (i.e., 6 months before diagnosis); more diagnostic and prescription claims, circulatory claims, and imaging procedures, leading to higher overall healthcare resource utilization; and more hospitalizations. Our model distinguishes between patients with and without PAH at 6 months before diagnosis and illustrates the feasibility of using routine claims data to identify patients at a population level who might benefit from PAH\u2010specific screening and/or earlier specialist referral.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/786dc9c384b4ec77146d0f53bf3fd353b58575fb",
        "citation_count": 9
    },
    {
        "title": "PREDICTION OF INFORMATIVE REGIONS IN MEDICAL TEXT USING MACHINE LEARNING TECHNIQUES",
        "abstract": "Machine Learning is the science of getting computers to act without being explicitly programmed. Machine learning is gradually making its way into medical domain and has become the most reliable and accurate tool. This paper provides an overview of the development of intelligent data analysis in medical data (Medline) using a machine learning perspective. Medical data contains information about the nature of disease and the effectiveness of treatments. The process of identifying and disseminating the disease and treatment related to a sentence from the Medline abstracts is a difficult task. In this paper we aim at investigating the performance of supervised learning algorithms in order to develop an application that can accurately identify and disseminate the healthcare information that can be utilized by both healthcare providers and patients. This is the first step towards achieving reliable/accurate disease and treatment related information which is useful for better understanding.",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/78ae9e60648dacc9d5d49da6f2296901b9ba2191",
        "citation_count": 0
    },
    {
        "title": "Using machine learning to improve anaphylaxis case identification in medical claims data.",
        "abstract": "Objective\nAnaphylaxis is a severe life-threatening allergic reaction, and its accurate identification in healthcare databases can harness the potential of \"Big Data\" for healthcare or public health purposes.\n\n\nMethods\nThis study used claims data obtained between October 1, 2015 and February 28, 2019 from the CMS database to examine the utility of machine learning in identifying incident anaphylaxis cases. We created a feature selection pipeline to identify critical features between different datasets. Then a variety of unsupervised and supervised methods were used (eg, Sammon mapping and eXtreme Gradient Boosting) to train models on datasets of differing data quality, which reflects the varying availability and potential rarity of ground truth data in medical databases.\n\n\nResults\nResulting machine learning model accuracies ranged between 47.7% and 94.4% when tested on ground truth data. Finally, we found new features to help experts enhance existing case-finding algorithms.\n\n\nDiscussion\nDeveloping precise algorithms to detect medical outcomes in claims can be a laborious and expensive process, particularly for conditions presented and coded diversely. We found it beneficial to filter out highly potent codes used for data curation to identify underlying patterns and features. To improve rule-based algorithms where necessary, researchers could use model explainers to determine noteworthy features, which could then be shared with experts and included in the algorithm.\n\n\nConclusion\nOur work suggests machine learning models can perform at similar levels as a previously published expert case-finding algorithm, while also having the potential to improve performance or streamline algorithm construction processes by identifying new relevant features for algorithm construction.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/78e4bdf0f3346a13f5917ae582286ab62e567b1a",
        "citation_count": 2
    },
    {
        "title": "Balancing efficiency and patient care: Exploring AI's role in the hospital discharge",
        "abstract": "Kovoor et al., in this issue of the journal provide a glimpse of how AI may soon impact the way we do things in medicine. They used several AI algorithms to search for patterns in a large patient dataset enabling prediction of hospital discharge. They propose this may be used in future to assess whether a surgical patient is ready for discharge. It is a timely reminder of how AI has the potential to impact all aspects of our personal and professional lives, including managing surgical patient discharges. Kovoor et al. applied open-source machine learning algorithms on which to train, test, and validate datasets made up of clinical vital signs and laboratory data derived from surgical patients admitted to two large hospitals over a two-year period. They chose \u201cobjective\u201d rather than \u201csubjective\u201d inputs (e.g., clinical note entries written by nurses, doctors, or allied health workers) to test whether AI algorithms could be used as an adjunct to human clinical decision making in surgical patients. The authors showed that the derived AI measures (the \u201cAdelaide Score\u201d) using data collected in the preceding 48 h accurately predicted discharge within 12 and 24 h in >8800 elective and emergency general surgery patients. They acknowledged, and deliberately did not include in the assessment any \u201csocial data\u201d such as family support or conditions at the patient\u2019s normal place of residence. Obviously, these factors are critical in the final decision making to ensure a safe and successful hospital discharge. As hospitals grapple with limited bed capacity, an expedient and well-timed discharge of patients may hold the key to liberating at least some beds. In this context, the study suggests the use of AI algorithms in such a large surgical dataset may be worthwhile. Accordingly, it is important for surgeons to have at least a basic understanding of the assumptions and limitations of the methodologies involved. There are many categories of AI each serving different purposes including narrow AI, general AI, machine learning, deep learning, robotics, computer vision, cognitive computing, and natural language algorithms. Although not obvious, many of these systems are already embedded in our lives and have revolutionized many industries by improving efficiency and driving innovation. The machine learning algorithms used by Kovoor et al. to develop the \u201cAdelaide Score\u201d use a process known as supervised learning to find patterns in datasets to help predict outcomes. They are not natural language algorithms like ChatGPT which was designed to answer questions, provide sentiment analysis, and to generate text resembling human language. Importantly, the quality of the output of supervised learning algorithms is only as useful and reliable as the accuracy and quality of the input data. Although Kovoor et al. used \u201cobjective\u201d data in their study, the documentation of clinical vital signs (BP, pulse, temperature etc.) in most hospitals is still entered manually in the medical record, giving rise to the potential for human error. Also, to undertake the process, the authors first had to automate the transfer of large amounts of clinical and laboratory data from the electronic medical records to create the datasets. Many clinicians who have grappled with this near impossible task in their own hospitals would view this as a major achievement in itself. As part of the study, Kovoor et al. extracted demographic data (age, gender, primary language spoken, specified religion, and postcode details as a surrogate for socio-economic status), as well as data about patient comorbidity as measured by the Charlson Comorbidity Index (CCI). Although this information was used to help characterize the cohort, these data were not used in the final AI algorithms. Interestingly, and given that comorbidity has such an impact on hospital discharge, it seems the CCI could not be documented from the medical records in almost 50% of patients. The authors acknowledge that the \u201cAdelaide Score\u201d needs external validation to test its applicability across different surgical datasets\u2014 and in other surgical specialties and different hospital settings. The inclusion of both elective and emergency surgical patients may have introduced bias in the results given the hospital stays of these groups often differ. Also, the study design did not capture relevant factors in relation to the complexity and variability of individual patient situations, and there was no attempt to assess re-admissions or complications in post-discharge patients relative to the algorithm prediction scores. This may be the best measure of the value of the algorithms and could be incorporated into future studies. Clarity about the data collection processes and the AI algorithms themselves will be critical to avoid ambiguity. Without this, AI algorithms may be perceived as a \u201cblack box\u201d generating outputs that seem detached from the clinical reality. The authors rightly stress that such a tool should only be used as an adjunct to human clinical decision-making. It may improve efficiency and help address variations in discharge practices which exist in many hospitals. It may also open up unforeseen new job opportunities in collaborative healthcare data management and analyses. However, there are potential risks. Would it just add stress for already over-burdened team members who might feel pressured to prioritize discharges based on the algorithm score? Would there be patient or family member involvement in generating the algorithms? Would there be over-reliance on AI which would only serve to exacerbate the perception by some clinicians of a widening disconnect between junior clinical staff and the patient? Would it set up a clash between clinical and hospital administrative staff with competing pressures in the face of bed block? The key to answering these questions will be the continued examination of the technology in an open and transparent way.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/794498d184d761de8d108561f1b993d21c55489a",
        "citation_count": 0
    },
    {
        "title": "Predicting Fear of Breast Cancer Recurrence from Healthcare Reimbursement Data using Deep Learning",
        "abstract": "Breast cancer is the prevalent and leading cause of mortality among women in France, with profound impacts on physical, emotional, and psychological well-being. Despite advances in treatment, the fear of cancer recurrence (FCR) persists among survivors and may lead to increased healthcare utilization and diminished overall well-being. However, accurately predicting FCR probability using traditional statistical models and machine learning (ML) algorithms remains a challenge due to the complex interplay of healthcare data over time. In this study, we propose an approach utilizing neural network-based predictive models and healthcare reimbursement data to predict FCR likelihood in women five years post-diagnosis. Our proposed method integrates temporal information and leverages both labeled and non-labeled medicoadministrative data through Neural Network (NN) architectures and semi-supervised learning techniques, offering a promising avenue for personalized risk assessments and tailored intervention strategies for BC survivors. The ongoing experimental results using ML and NN demonstrate promising outcomes, suggesting that neural network models may have the potential to further improve the prediction performance.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/7a14b143b7b654c649aebe85e0cc02a96223b91e",
        "citation_count": 0
    },
    {
        "title": "Tackling the Challenges of Machine Learning for Mobile Health Systems",
        "abstract": "The prominence of mobile devices and recent breakthroughs in machine learning have enabled an emerging class of new mobile health systems which hold the promise of transforming today's reactive healthcare practice to proactive, individualized care and wellbeing. However, the current mainstream machine learning approaches are largely supervised and must be trained by a large amount of labelled high-quality data. In contrast, due to small form factor and limited sensing capability, today's off-the-shelf mobile devices can only collect noisy and sporadic samples from users. Moreover, personal health data collected by on-device sensors cannot be uploaded or shared with other devices due to privacy concerns. These challenges have significantly hindered the performance and utility of mobile health systems in real-world settings. In this talk, I will first discuss new mobile systems that exploit human physiological models and innovative use of sensing modalities to achieve highly robust sensing performance without requiring extensive training. I will describe RunBuddy - the first smartphone-based system for monitoring continuous running rhythm and improving exercise efficiency. To mitigate significant environmental noise during running, RunBuddy integrates novel ambient sensing algorithms and a physiological model called Locomotor Respiratory Coupling (LRC). Based on this result, we also develop BreathCoach, a smart and unobtrusive system using smartwatch and smartphone-based VR for in-home RSA-BT (Respiratory Sinus Arrhythmia biofeedback-based Breathing Training), which is a common cardiorespiratory intervention to diseases such as asthma and an effective exercise to reduce anxiety. BreathCoach continuously monitors key bio-signals such as breathing pattern and inter-beat interval, and then recommends breathing patterns in the form of an intuitive VR game to provide an immersive training experience. In the second part of this talk, I will discuss a new approach for home activity recognition via federated learning. People spend significant portion of time in home. Characterizing home activities including both individual and family activities is important for studies of health, sociology, and home economics. For instance, risk factors of dementia and childhood obesity are strongly associated with a family's daily activities, and activity logging is proved a very effective approach to improve the self-awareness and motivate people to modify their behaviors toward a healthy lifestyle. Unfortunately, to date, there has been no unobtrusive and convenient methods to log family activities. I will present several new sensing and federated learning algorithms that enable mobile devices to collaboratively improve the accuracy of home activity sensing without sharing any sensor data, preserving user privacy.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/7addb8c9761309484cad9fe0bca70b123676f2d9",
        "citation_count": 3
    },
    {
        "title": "PREDICTIVE ANALYSIS OF HEART DISEASES WITH MACHINE LEARNING APPROACHES",
        "abstract": "Machine Learning (ML) is used in healthcare sectors worldwide. ML methods help in the protection of heart diseases, locomotor disorders in the medical data set. The discovery of such essential data helps researchers gain valuable insight into how to utilize their diagnosis and treatment for a particular patient. Researchers use various Machine Learning methods to examine massive amounts of complex healthcare data, which aids healthcare professionals in predicting diseases. In this research, we are using an online UCI dataset with 303 rows and 76 properties. Approximately 14 of these 76 properties are selected for testing, which is necessary to validate the performances of different methods. The isolation forest approach uses the data set\u2019s most essential qualities and metrics to standardize the information for better precision. This analysis is based on supervised learning methods, i.e., Naive Bayes, SVM, Logistic regression, Decision Tree Classifier, Random Forest, and K- Nearest Neighbor. The experimental results demonstrate the strength of KNN with eight neighbours order to test the effectiveness, sensitivity, precision, and accuracy, F1-score; as compared to other methods, i.e., Naive Bayes, SVM (Linear Kernel), Decision Tree Classifier with 4 or 18 features, and Random Forest classifiers.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/7aff061d6447eefdd89aaf0176f9cd54152d9f38",
        "citation_count": 220
    },
    {
        "title": "Short-term local predictions of COVID-19 in the United Kingdom using dynamic supervised machine learning algorithms",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/7afff222c83102e75373d677d7d7d2e6b2614187",
        "citation_count": 1
    },
    {
        "title": "Machine-learning fusion approach for the prediction of atrial fibrillation onset using photoplethysmographic-based smart device",
        "abstract": "\n \n \n The mobile and wearable technology and artificial technology are rapidly developing for atrial fibrillation (AF) detection. Nonetheless, how these smart technologies combine to improve AF prediction, rather than detection, remains unclear.\n \n \n \n To investigate a machine-learning fusion approach beyond photoplethysmographic (PPG)-based AF detection for predicting AF onset.\n \n \n \n There are 2,120,210 individuals who used PPG-based smart devices (Huawei Technologies Co., Ltd., Shenzhen, China) to monitor their pulse rhythm from pre-mAFA study (Huawei heart study) for AF screening across China between October 26, 2018 and March 26, 2021. Two machine-learning (ML) models, short-term model and long-term mode, have been developed based on PPG continuing monitoring signals to predict AF episode at 4h or 8h before AF onset respectively, with supervised ML (XGBoost and LightGBM) techniques, and further optimized with feature extension and hyperparameter optimization, respectively. The probabilities of AF onset calculated by both short-term and long-term models with timely PPG monitoring signals would be further input into Warning Decision Module, combined with prior predicting risk of AF onset, then the real risk ratio of predicting AF onset in advance would be output by the fusion module (Figure). The predictive ability of ML models, classified by time to last AF onset, has been validated among individuals involving in AF screening from pre-mAFA study between March 19 to March 26, compared to identified AF by PPG monitoring.\n \n \n \n There were 6294 (mean age \u00b1 standard deviation, 51.6\u00b116.0 years old, 5439 male) individuals with identified AF, with total 142,518 identified AF episodes by PPG. The 107,864 identified AF were utilized to validate ML fusion approach for the prediction of AF, given effective PPG monitoring signals before identified AF episodes for ML models. There were 443,630 PPG monitoring signals before identified AF episodes and 563,309 non-AF PPG monitoring signals of ML models.\n The sensitivity of ML fusion approach for the prediction of AF onset was 94.04%, the specificity of 96.35%, and the recall of 94.04%, respectively (Table). When time to last AF onset over 24 hours, the sensitivity of ML fusion approach for AF onset at 8h in advance was 85.73%, specificity of 96.62%, and recall of 85.73%, respectively (Table).\n \n \n \n The ML fusion approach based on PPG-smart devices provided the effective early 'alters' of AF onset in advance in this large cohort, which may help the early 'upstream' management of AF.\n \n \n \n Type of funding sources: Public grant(s) \u2013 National budget only. Main funding source(s): National HealthCare of China (20BJZ26)\n",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7b3ccd51134fcd1e8118d47b3eb63d69edf4f907",
        "citation_count": 1
    },
    {
        "title": "Animal Healthcare and Farm Animal Disease Prediction Using Machine Learning",
        "abstract": "Veterinary care is an extremely important part of animal care. The focus of the Veterinary doctor or practitioner is to supervise the overall health and clinical care of the animals. A veterinary doctor is responsible for observing and promoting the well-being of the animal at all phases of the animal's life span. In the inaccessible remote locations of India, access to Veterinary services is difficult. Farmers or livestock owners have to travel long distances from their villages when they require treatment for their animals. This has adversely affected eutherian mammal farming in rural regions that square measure usually set in remote locations. A website to connect Veterinarians with Livestock owners can turn out to be a valuable solution. Farm Animals represent a valuable quality of nutritional products such as dairy products they also are a great resource of the economy for the owners. The production of dairy and other nutritional products is being challenged due to the toxic use of pests and malady infestation resulting in poor productivity. Death of the animals can also be expected in such cases, massive economic losses to livestock owners and the nation. Such issues must be addressed timely before the situation gets out of hand, this is only possible by making Veterinary services available to every part of the nation, be it via online mode or by providing Veterinary practitioners to rural areas. Livestock production in the farm sector acts as an important source of nutrition to India, it provides economic support to many farmers and contributes to the economy of India.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/7bb0686630504621c301c4bfee5f2ff57abf2ee5",
        "citation_count": 0
    },
    {
        "title": "Pneumonia Detection Using Machine Learning",
        "abstract": "An enormous amount of morbidity and mortality cases are caused by pneumonia, which is still a major global health concern. Pneumonia must be accurately and quickly detected in order to manage patients effectively and achieve better results. Machine learning (ML) algorithms have become effective instruments in recent years for automating the detection and diagnosis of pneumonia from medical imaging data. The goal of this review paper is to give a thorough overview of recent developments in ML-based pneumonia detection. It includes the various ML algorithms used, the training and testing datasets, and the evaluation metrics used to rate the effectiveness of these models. Additionally, this review highlights the difficulties encountered in the field and suggests possible directions for improvement in order to create a more reliable and robust pneumonia detection system. Healthcare professionals place a high value on pneumonia detection, and machine learning (ML)-based automation of There's been a lot of attention paid to this process. The importance of pneumonia detection and the part that ML techniques play in automating this process are highlighted in the introduction to this review paper. In the following section, it examines different machine learning (ML) The various system used for the discernment of pneumonia. Such include supervised understanding algorithms like logistic statistics, vector machine and randomization. forests, and convolutional neural networks. The review also discusses pneumonia detection using unsupervised learning techniques like clustering, dimensionality reduction, and autoencoders. In order to develop them, an assessment of pneumonia detection models is essential. The study has examined several appraisal metrics which are commonly used for that purpose, such as sensitivity, specificity, precision and the operational status of receivers. characteristic (ROC) curve, recall, precision, and F1-score. The selection of suitable metrics, which considers specific requirements for pneumonia detection, is main factor to be taken into consideration. The main obstacles is that there are no annotation data. to creating reliable pneumonia detection models. Accurate ML algorithms must be trained on high-quality labelled datasets. However, since chest X-ray images must be annotated by qualified radiologists, obtaining a sizable annotated dataset for pneumonia is frequently challenging. The creation of efficient ML models for pneumonia detection is hampered by the limited availability of annotated data.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/7bd45af493a8da9ac5eed6f4b88bd718ee25c12c",
        "citation_count": 0
    },
    {
        "title": "Identifying diseases symptoms and general rules using supervised and unsupervised machine learning",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/7c12fad97227cd0fdae8b1ffcd33504c35d325d1",
        "citation_count": 4
    },
    {
        "title": "Self-supervised Transformer for Multivariate Clinical Time-Series with Missing Values",
        "abstract": "Multivariate time-series (MVTS) data are frequently observed in critical care settings and are typically characterized by excessive missingness and irregular time intervals. Existing approaches for learning representations in this domain handle such issues by either aggregation or imputation of values, which in-turn suppresses the \ufb01ne-grained information and adds undesirable noise/overhead into the machine learning model. To tackle this challenge, we propose STraTS ( S elf-supervised Tra nsformer for T ime-S eries) model which bypasses these pitfalls by treating time-series as a set of observation triplets instead of using the traditional dense matrix representation. It employs a novel Continuous Value Embedding (CVE) technique to encode continuous time and variable values without the need for discretization. It is composed of a Transformer component with Multi-head attention layers which enables it to learn contextual triplet embeddings while avoiding problems of recurrence and vanishing gradients that occur in recurrent architectures. Many healthcare datasets also su\ufb00er from the limited availability of labeled data. Our model utilizes self-supervision by leveraging unlabeled data to learn better representations by performing time-series forecasting as a self-supervision task. Experiments on real-world multivariate clinical time-series benchmark datasets show that STraTS shows better prediction performance than state-of-the-art methods for mortality prediction, especially when labeled data is limited. Finally, we also present an interpretable version of STraTS which can identify important measurements in the time-series data.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7c2a345df687cc54044d04a7e214e9d391dbadcb",
        "citation_count": 9
    },
    {
        "title": "Comparing the Performance of Different Supervised Learning Algorithms",
        "abstract": "In recent years, machine learning has grown in popularity, with applications in a wide range of industries. This study discusses the fundamentals of machine learning and its various approaches, such as supervised classifier, unsupervised classifier and reinforcement learning. Moreover, the drawbacks of machine learning, such as the requirement for a lot of labelled data, the possibility of bias in the training process etc. are studied. Finally, some of the field's potential future developments, such as the use of machine learning in areas like healthcare and finance, have been elaborated. Furthermore, two algorithms of machine learning such as Decision Tree and Naive Bayes algorithms are compared. Overall, this work provides a thorough overview of machine learning's current state and potential future impact.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/7c5437a3ad69b05bc621fa7ea85a583e64a7b9ac",
        "citation_count": 0
    },
    {
        "title": "Analysis for Designing a Symptom-Based Health Improvement System Using Machine Learning",
        "abstract": "Healthcare providers are under more and more pressure to save costs and improve patient outcomes. The creation of symptom-based health improvement systems that make use of machine learning algorithms is one such strategy for reaching goals. The proposed methods employ supervised and unsupervised machine learning techniques to discover patterns and associations between symptoms and probable medical diseases. Based on each patient's unique symptom profile, the system seeks to provide them with individualized advice. The system's ability to recognize probable medical problems based on symptom patterns has been tested using a huge dataset of patient records. The technology strives for high accuracy rates in recognizing probable health issues and gives patients personalized advice depending on their symptoms. Furthermore, it helps in reducing healthcare expenses by identifying potential health conditions at earlier stages, which can help prevent unnecessary treatments and hospitalizations, as well as by providing insights into symptom patterns and relationships between symptoms and potential health conditions, which can help healthcare providers make more informed decisions. This research analyzes those proposed solutions in brief and presents us with an insight into the number of works and research done on the topic of symptom-based health improvement systems.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/7c6a77fd68b5012ae5965f8fac5c4a5e34f23920",
        "citation_count": 0
    },
    {
        "title": "Methods for safety signal detection in healthcare databases: a literature review",
        "abstract": "ABSTRACT Introduction: With increasing availability, the use of healthcare databases as complementary data source for drug safety signal detection has been explored to circumvent the limitations inherent in spontaneous reporting. Areas covered: To review the methods proposed for safety signal detection in healthcare databases and their performance. Expert opinion: Fifteen different data mining methods were identified. They are based on disproportionality analysis, traditional pharmacoepidemiological designs (e.g. self-controlled designs), sequence symmetry analysis (SSA), sequential statistical testing, temporal association rules, supervised machine learning (SML), and the tree-based scan statistic. When considering the performance of these methods, the self-controlled designs, the SSA, and the SML seemed the most interesting approaches. In the perspective of routine signal detection from healthcare databases, pragmatic aspects such as the need for stakeholders to understand the method in order to be confident in the results must be considered. From this point of view, the SSA could appear as the most suitable method for signal detection in healthcare databases owing to its simple principle and its ability to provide a risk estimate. However, further developments, such as automated prioritization, are needed to help stakeholders handle the multiplicity of signals.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/7c873a3e3b28652d718237eeda61cb8f2d240fe3",
        "citation_count": 68
    },
    {
        "title": "Welcome to the Industry Track of SIGIR 2012 ! The Industry",
        "abstract": "Watson, named after IBM founder Thomas J. Watson, was built by a team of IBM researchers who set out to accomplish a grand challenge build a computing system that rivals a human's ability to answer questions posed in natural language with speed, accuracy and confidence. The quiz show Jeopardy! provided the ultimate test of this technology because the game's clues involve analyzing subtle meaning, irony, riddles and other complexities of natural language in which humans excel and computers traditionally fail. Watson passed its first test on Jeopardy!, beating the show's two greatest champions in a televised exhibition match, but the real test will be in applying the underlying natural language processing and analytics technology in business and across industries. In this talk I will introduce the Jeopardy! grand challenge, present an overview of Watson and the DeepQA technology upon which Watson is built, and explore future applications of this technology. Bio: Eric Brown is a Research Staff Member and Manager at the IBM T. J. Watson Research Center. Eric earned his B.S. at the University of Vermont and M.S. and Ph.D. at the University of Massachusetts, all in Computer Science. Eric joined IBM in 1995 and has conducted research in information retrieval, document categorization, text analysis, question answering, bio-informatics, and applications of automatic speech recognition. Since 2007 Eric has been a technical lead on the DeepQA project at IBM and the application of automatic, open domain question answering to build the Watson Question Answering system. The goal of Watson is to achieve human-level question answering performance. This goal was realized in February of 2011 when Watson beat Ken Jennings and Brad Rutter in a televised Jeopardy! exhibition match. Eric's role on the project has spanned architecture development, special question processing, and hardware planning, and he is currently focused on applying Watson to clinical decision support in Healthcare. John O\u2018Neil, Attivio Title: Entity Sentiment Extraction Using Text Ranking Abstract: Entity extraction and sentiment extraction are among the most common types Entity extraction and sentiment extraction are among the most common types of information extracted from documents. Both have been studied extensively, with different approaches. However, the problem of directly associating entities and sentiment has received less attention. We assume that entities of interest have already been extracted in the document. Entity extraction is well-understood, and can be done in numerous ways. Also, we assume that appropriate word sentiment weights have been calculated. We use a training set of documents, where each document is associated with a positive or negative sentiment label, and use standard discriminative supervised machine learning to calculate sentiment weights for each word appearing in the corpus. We also use a stopword list and an absolute value weight cutoff to derive a relatively small set of word-sentiment values. Then, we use Text Ranking (Mihalcea 2004), adapting it to use a bipartite graph of entities and sentiment-laden words and phrases, where entities and sentiment words are connected if within a configurable distance. We calculate the dominant eigenvector of the matrix corresponding to the graph; we then extract final sentiment weights to the entities, given all the contexts each entity appears in. Also, we can more accurately determine the sentiment weights of the words in the document given their contexts, as well as discovering the positive or negative sentiment \u201chot spots\u201d in a document. We then explore a number of related issues. First, we explore if (and how much) this improves the accuracy of the sentiment associated with entities in a document, compared to assigning the document's overall sentiment to all the entities in the document. We also explore if (and how much) of an accuracy improvement there is if we track the entity sentiment over time. Then, we explore whether faceting on entity sentiment is improved using this technique in the context of search applications. Finally, we consider performance. Bio: John O\u2018Neil is the Chief Scientist at Attivio. He has written and designed software for search, natural language processing and machine learning for more then a decade. After receiving a Ph.D. in linguistics from Harvard University, he worked for LingoMotors, where he designed their main commercial search product, and at other search and IR companies. He also worked for over five years at Basis Technology, Inc., where he was the designer and lead developer for the Rosette Linguistics Platform, their language processing and entity extraction suite of products. He is the author of more than twenty papers in Computer Science, Linguistics and associated fields, and has given talks at numerous professional and academic conferences. Andrei Broder, Google Title: IR Paradigms in Computational Advertising Abstract: The central problem in the emerging discipline of computational advertising is The central problem in the emerging discipline of computational advertising is to find the \u201cbest match\u201d between a given user in a given context and a suitable advertisement. The context could be a user entering a query in a search engine (\u201csponsored search\u201d), a user reading a web page (\u201ccontent match\u201d and \u201cdisplay ads\u201d), a user streaming a movie, and so on. In some situations, it is desirable to solve the \u201cdual\u201d optimization problem: rather then find the best ad given a user in a context, the goal is to identify the \u201cbest audience\u201d, i.e. the most receptive set of users and/or the most suitable contexts for a given advertising campaign. The information about the user can vary from scarily detailed to practically nil. The number of potential advertisements might be in the billions. Thus, depending on the definition of \u201cbest match\u201d and \u201cbest audience\u201d these problems lead to a variety of massive optimization problems, with complicated constraints, and challenging data representation and access issues. In general, the direct problem is solved in two stages: first a rough filtering is used to determine a relatively small set of ads that should be considered as potential matches, followed by a more sophisticated secondary ranking where economics considerations take center stage. Historically, the filtering has been conceived as a database selection problem, and was done using simple Boolean formulae, for instance, in sponsored search the filter could be \"all ads that provide a specific bid for the present query string or a subset of it\". Similarly for the dual problem (audience definition) for, say, a sports car ad, the filter could be \"all males in California, aged 40 or less\". This \"database approach\" for the direct problem has been recently supplanted by an \"IR approach\" based on a similarity search between a carefully constructed query that captures the advertising opportunity and an annotated document corpus that represents the potential ads. Similarly, in the dual problem, the newer approach is to devise an efficient and effective representation of the users, then form a query that represents a prototypical ideal user, and finally find the users most similar to the prototype. The aim of this talk is to discuss the penetration of the IR paradigms in computational advertising and present some research challenges and opportunities in this area of enormous economic importance. Bio: Andrei Broder has recently joined Google as a Distinguished Scientist. Previously, he was a Fellow and Vice President for Computational Advertising in Yahoo!. Prior to this, he worked at IBM as a Distinguished Engineer and the CTO of the Institute for Search and Text Analysis and at AltaVista as Vice President for Research and Chief Scientist. He was graduated Summa cum Laude from Technion, the Israeli Institute of Technology, and obtained his M.Sc. and Ph.D. in Computer Science at Stanford University. His current research interests are centered on computational advertising, user understanding, context-driven information supply, and randomized algorithms. Broder has authored more than a hundred papers and was awarded thirty-six patents. He is a member of the US National Academy of Engineering, a fellow of ACM and of IEEE, and past chair of the IEEE Technical Committee on Mathematical Foundations of Computing.",
        "year": 2012,
        "url": "https://www.semanticscholar.org/paper/7cc23e2a7b6da933a9e71aa2a652abc187d7940f",
        "citation_count": 0
    },
    {
        "title": "Prediction of Disease Stage by Machine Learning Classification Methods for Covid-19 Patients",
        "abstract": "Supervised machine learning classificitaion algorithms have been widely used in many fields in recent years. Especially, health is one of the most important areas where machine learning studies are carried out successfully. The aim of this study is to develop models that predict the disease stage of people who apply to hospital with the diagnosis of Covid-19.\nInadequacies such as intensive care occupancy, insufficiency of beds, and shortage of respiratory equipment are among these problems, and this has left healthcare workers faced with the overwhelming burden of patients. Therefore, estimating the disease stages of Covid-19 patients at an early stage is of great importance. The data set used in the study includes the clinical and laboratory data of the patients during in their admission to the hospital.It has been tried to develop models that predict disease stage by using Logistic Regression, Random Forest and Support Vector Machine algorithms in the data set. The random forest model with 9 variables was the best performing model.\nWith the models obtained, it will be ensured that the hospital management receives information in order to see the necessary treatment for low-risk or high-risk patients and to avoid medical system inadequacies.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/7cc80452d9523d7d92536a64aa714a7bb0cdccce",
        "citation_count": 0
    },
    {
        "title": "RF POWERED ID SENSOR BASED ACTIVITY RECOGNITION SYSTEM FOR ALERTING",
        "abstract": "Falls have serious consequences and are prevalent in acute hospitals and nursing homes caring for older people Fall lead to many adverse consequences for the patients apart from physical injuries such as anxiety, depression and loss of independence. Technological interventions to reduce the risk of falling aim to monitor automatically monitor bed-exit events and subsequently alert healthcare personnel to provide timely supervisions. In that sense, the present work proposes an innovative IoT-based system for detecting falls of elderly people in indoor environments, which takes advantages of low-power wireless sensor networks and smart devices. For this purpose, we recognize the potential to employ a low resolution acceleration sensing modality in contrast to powering and sensing with a conventional MEMS (Micro Electro Mechanical System) accelerometer. A 3D-axis passive accelerometer with gyroscope embedded into a wearable sensor device is used, which is responsible for collecting data from movements of elderly people in real-time. The accelerometer data from the devices are continuously sent to a multithreaded server which hosts a pretrained machine learning model that analyzes the data to determine whether a fall has occurred or not. Finally this system provides service built on cloud. If a fall is detected, an alert is activated and the system reacts automatically by sending notifications to the groups responsible for the care of the elderly people. Index Terms bed-exit events, 3D-axis accelerometer and gyroscope, IoTbased system, cloud.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/7cd3cab3a1bd506b100cf27e41375dc26130207d",
        "citation_count": 0
    },
    {
        "title": "Supervised Machine Learning Chatbots for Perinatal Mental Healthcare",
        "abstract": "Perinatal mental health (PMH) problems are types of mood disorders which arise during pregnancy and within 24 months after the birth of a child, which affects pregnant women, newborns and family relationships. These problems may occur at any stage of maternal women. PMH is mainly diagnosed through behavioral observation, self-reporting, and behavioral scale testing. Chatbot is an effective technology. Through human-robot interaction, it can monitor the mental health status of perinatal women in real time while collecting user health data. The application of human-robot interaction in mental health services has attracted widespread attention. Compared with traditional methods, robot intervention in mental health care can help reduce the obstacles for subjects to seek help for mental health, and can collect more comprehensive and detailed data of patients, which helps users recognize their own mental health level, and can also help clinicians make diagnoses more accurately and in a timely manner. In this article, the author proposes a chatbot to monitor and assess the mental state of perinatal women. This article uses supervised machine learning to analyze the 31 characteristics of 223 samples, and trains a model to determine the anxiety, depression and hypomania index of perinatal women. Meanwhile, psychological test scales are used to assist in evaluation and make treatment suggestions to help users improve their mental health.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/7cdc651715f395c1732b0effe7b6edb9f81d5be6",
        "citation_count": 25
    },
    {
        "title": "Human Activity Recognition Using Tri-Axial Angular Velocity",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/7ce8af93dacada7cef3bd454c7a10db4039be999",
        "citation_count": 1
    },
    {
        "title": "Real-time multi-class signal quality assessment of photoplethysmography using machine learning technique",
        "abstract": "Photoplethysmography (PPG) signal quality assessment (SQA) ensures improved measurements of various surrogate cardiovascular measurements like heart rate, SpO2, blood pressure, cardiac output and many more and as well reduces false alrams in ambulatory measurements. Although PPG SQA (PSQA) is a well researched area, but multiclass prediction of signal quality and its hardware implementation is limited. In this paper, a new non-segmenting approach for multiclass PSQA is presented with an optimal set of seven time-frequency domain features in conjuction with supervised classifiers to identify clean, partly clean and corrupted PPG data. The present work was carried out in three major stages- signal (dataset) acquisition, feature extraction and 3-class classification using random forest classifier. The technique was evaluated with volunteers\u2019 data, MIMIC-III data from PhysioNet, CSL data, and combined data and achieved an overall average accuracy of 96.8% with good (0.98 or above) sensitivity, specificity, F1 score, precision and recall. On-device implementation of the proposed PSQA was accomplished using 7.2 h of PPG dataset on a quad-core Broadcom BCM 2837 controller with 1.2 GHz, supported by 1 GB RAM-based standalone device, with an accuracy of 97.09%. The latency and the peak memory requirement of the implementation was 0.81 s and 19 kB respectively to process 3 s PPG data. The present technique may be integrated as a part of a remote healthcare system using wearable sensors.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7cf494c0a7e009f31eedc74ac799d7738d5f9721",
        "citation_count": 10
    },
    {
        "title": "Collaborative networks and their breeding environments : IFIP TC5 WG 5.5 Sixth IFIP Working Conference on Virtual Enterprises, 26-28 September, 2005, Valencia, Spain",
        "abstract": "Holistic Approaches to Collaborative Networks.- Ecolead: A Holistic Approach to Creation and Management of Dynamic Virtual Organizations.- Request Based Virtual Organisations (RBVO): An Implementation Scenario.- Multi-Perspective Challenges on Collaborative Networks Business Environments.- Breeding Environments Management.- A Framework for Management of Virtual Organization Breeding Environments.- Co-Desnet: An Approach to Modeling Collaborative Demand and Supply Network.- Coordination of Competencies Development within Networks of SMEs.- Vo Creation - Frameworks.- Towards a Framework for Creation of Dynamic Virtual Organizations.- An Integrative Approach for Vo Planning and Launching.- The Formation of Collaborative Chains for Conceptual Design.- Vo Creation - Partners Selection.- A Systematic Approach for VE Partners Selection Using the SCOR Model and the AHP Method.- The Role of Enterprise Modelling in Virtual Enterprises.- Towards Ontology-Based CNO Matching Applied to Squads.- Vo Creation - Optimization.- A Multi-Criteria Mathematical Programming Model for Agile Virtual Organization Creation.- Hierarchical Multi-Attribute Decision Support Approach to Virtual Organization Creation.- A Multi-Criteria Decision Support System for the Formation of Collaborative Networks of Enterprises.- Trust Management.- Trust Building for Smes Through an E-Engineering Hub.- A Decision Support Approach to Trust Modeling in Networked Organizations.- Toward Web Services Profiles for Trust and Security in Virtual Organisations.- A Secure Model to Establish Trust Relationships in Web Services for Virtual Organizations.- Vo Management.- Characterizing Virtual Organizations and Their Management.- Understanding and Managing Shared Projects in Smes Networks.- A Generic Framework Based on Machine Learning Techniques for Virtual Organization Management.- Vo Coordination.- Human Supervised Virtual Organization Management.- Improving Client Service Reliability in Collaborative Supply Chains: A Mas Scheduler.- Security Controls in Collaborative Business Processes.- Network Benefit Analysis.- An Approach for the Ascertainment of Profit Shares for Network Participants.- Network Analysis of Terrorism Defense Organizations - A Network Approach for Developing Performance Indicators.- Performance Indicators Based on Collaboration Benefits.- Performance Measurement.- A Performance Measurement System for Virtual and Extended Enterprises.- Virtual Scorecard as a Decision-Making Tool in Creating Virtual Organisation.- Towards Performance Measurement in Virtual Organizations.- Performance Management.- Global Performance Management for Small and Medium-Sized Enterprises (GPM-SME).- Combining Strategic, Operational and Financial Performance in the Virtual Organisation.- Perceptions of Value That Sustain Collaborative Networks.- Modeling and Meta-Modeling.- A Meta-Methodology Prototype for Collaborative Networked Organisations.- Methodology for Business Model Definition of Collaborative Networked Organizations.- A Folding Syntax for Semantic Modeling.- Towards a Meta-Model for Collaborative Construction Project Management.- Process Modeling.- Specification Model for the Development and Operation of a Virtual Company in the Aerospace Industry.- Modeling Structured Non-Monolithic Collaboration Processes.- Quantitative Models of Collaborative Networks.- Collaborative Healthcare Process Modelling: A Case Study.- Professional Virtual Communities the Organization and Business.- The Organization and Business Model of a Software Virtual Community in China.- A Conceptual Framework for \"Professional Virtual Communities\".- Mobile and Location-Aware Workplaces and Global Value Networks: A Strategic Roadmap.- Service Oriented Architectures.- Open Multi-Technology Service Oriented Architectur for \"Its\" Business Models: The ITSIBus Etoll Services.- Enhancing Supply Chain Co-Ordination by Means of a Collaborative Platform Based on Service Oriented Architecture.- E-Services Interoperability Analysis and Roadmap Actions.- Interoperability and ICT Infrastructures.- Feature-Based Analysis Framework for Interoperability in Networked Organisations.- E-Business Software Evaluation.- Experiments on Grid Computing for VE-Related Applications.- Technology Infrastructure for Virtual Organisation of Toolmakers.- Legal Issues and Entities.- Legal Security and Credibility in Agent Based Virtual Enterprises.- Legal Risk Analysis with Respect to IPR in a Collaborative Engineering Virtual Organization.- Institutional Services for Dynamic Virtual Organizations.- Learning and Knowledge Creation.- A Different View of Learning and Knowledge Creation in Collaborative Networks.- A New Approach for E-Learning in Collaborative Networks.- A Simulation Game Approach to Support Learning and Collaboration in Virtual Organisations.- Collaborative Networks in Transportation Systems.- A Collaborative Network Case Study: The Extended \"ViaVerde\" Toll Payment System.- Towards a Virtual Enterprise for Passenger Transportation Using Agents.- The Global Automation Platform: An Agent-Based Framework for Virtual Organizations.- Other Case Studies.- Building an Integrated Pan-European News Distribution Network.- Success and Failure Factors of Collaborative Networks of Sme.",
        "year": 2005,
        "url": "https://www.semanticscholar.org/paper/7d071ba58c2848b5fc2acae10bd754da7581848c",
        "citation_count": 28
    },
    {
        "title": "\u00adUse of Artificial Intelligence for Public Health Surveillance: A case study to develop a Machine Learning-algorithm to estimate the incidence of Diabetes Mellitus in France",
        "abstract": "\n Background The use of machine learning techniques is increasing in healthcare which allows to estimate and predict health outcomes from large administrative data sets more efficiently. The main objective of this study was to develop a generic machine learning (ML) algorithm to estimate the incidence of diabetes based on the number of reimbursements over the last 2 years. Methods We selected a training data set from a population-based epidemiological cohort (i.e., CONSTANCES) linked with French National Health Database (i.e., SNDS) to develop a ML-algorithm for estimating the incidence of diabetes. To develop this algorithm, we adopted a supervised ML approach. Following steps were performed: i. selection of final data set, ii. target definition, iii. coding variables for a given window of time, iv. split final data into training and test data sets, v. variables selection, vi. training model, vii. validation of model with test data set and viii. selection of the model. Results The final data set used to develop the algorithm included 44,659 participants from CONSTANCES. Out of 3,468 variables, which were similar in SNDS and CONSTANCES cohort were coded, 23 variables were selected to train different algorithms. The final algorithm to estimate the incidence of diabetes was a Linear Discriminant Analysis model based on number of reimbursements of selected variables related to biological tests, drugs, medical acts and hospitalization without a procedure over the last two years. This algorithm has a sensitivity of 62%, a specificity of 67% and an accuracy of 67% [95% CI: 0.66 \u2013 0.68]. Conclusions Supervised ML is an innovative tool for the development of new methods to exploit large health administrative databases. In context of InfAct project, we have developed and applied the first time a generic ML-algorithm to estimate the incidence of diabetes for public health surveillance. The ML-algorithm we have developed, has a moderate performance. The next step is to apply this algorithm on SNDS to estimate the incidence of type 2 diabetes cases. More research is needed to apply various MLTs to estimate the incidence of various health conditions and to calculate the contribution of various risk factors on developing type 2 diabetes.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7d0de9a55d1e5e6f94d7b06d45c4324eac58c7ae",
        "citation_count": 1
    },
    {
        "title": "Perceptual Algorithms for Social Robots in Early Childhood Education",
        "abstract": "Social robots are becoming a part of everyday life, from household smart companions to education and healthcare assistants, assembly robots in factories and museum guide robots, they adapt different appearances and exhibit a range of capabilities and duties. These robots are benefiting from machine perception systems that automatically recognize people, recognize their facial expressions, and the surrounding environment. In this thesis, we focus on RUBI, a social robot designed to interact with toddlers in classroom and enrich the early childhood education environments. We develop perception algorithms for RUBI to recognize faces while interacting with toddlers in the classroom. We use facial recognition, along with facial expression recognition to analyze the social structure of the classroom and to monitor the emotional development of toddlers in the classroom. In the first two chapters of this thesis, we show that RUBI discovers useful aspects of the social structure of the toddler's group, as well as the children's preferences for different activities and toddler's preferences to play with or to avoid playing with other specific children. These studies illustrate that social robots may become a useful tool in early childhood education to discover socio-emotional patterns over time and to monitor toddlers development. In the next chapters, we focus on active object recognition in RUBI. While interacting with children, RUBI can teach object names to children, to extend their vocabulary and monitor their learning skills. In chapter 3, we introduce GERMS, a dataset designed to accelerate progress on active object recognition in the context of human robot interaction. In chapter 4, a deep neural network is used for joint prediction of the object label and the action. A generative model of object similarities based on the Dirichlet distribution is proposed and embedded in the network for encoding the state of the system. In chapter 5, we propose a method for supervised learning of active object recognition, in which we train a Long Short Term Memory (LSTM) network to predict the best next action on the training set rollouts. We show improved recognition performance by optimizing the observation function and retraining the supervised LSTM network.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/7d5bde049b85175d259959534b21b5487d8d93d5",
        "citation_count": 1
    },
    {
        "title": "Patient Satisfaction and Hospital Quality of Care Evaluation in Malaysia Using SERVQUAL and Facebook",
        "abstract": "Social media sites, dubbed patient online reviews (POR), have been proposed as new methods for assessing patient satisfaction and monitoring quality of care. However, the unstructured nature of POR data derived from social media creates a number of challenges. The objectives of this research were to identify service quality (SERVQUAL) dimensions automatically from hospital Facebook reviews using a machine learning classifier, and to examine their associations with patient dissatisfaction. From January 2017 to December 2019, empirical research was conducted in which POR were gathered from the official Facebook page of Malaysian public hospitals. To find SERVQUAL dimensions in POR, a machine learning topic classification utilising supervised learning was developed, and this study\u2019s objective was established using logistic regression analysis. It was discovered that 73.5% of patients were satisfied with the public hospital service, whereas 26.5% were dissatisfied. SERVQUAL dimensions identified were 13.2% reviews of tangible, 68.9% of reliability, 6.8% of responsiveness, 19.5% of assurance, and 64.3% of empathy. After controlling for hospital variables, all SERVQUAL dimensions except tangible and assurance were shown to be significantly related with patient dissatisfaction (reliability, p < 0.001; responsiveness, p = 0.016; and empathy, p < 0.001). Rural hospitals had a higher probability of patient dissatisfaction (p < 0.001). Therefore, POR, assisted by machine learning technologies, provided a pragmatic and feasible way for capturing patient perceptions of care quality and supplementing conventional patient satisfaction surveys. The findings offer critical information that will assist healthcare authorities in capitalising on POR by monitoring and evaluating the quality of services in real time.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7da6f9ac247f6924c02a52ea37ddf04df1396c0b",
        "citation_count": 27
    },
    {
        "title": "A Linear Primal-Dual Multi-Instance SVM for Big Data Classifications",
        "abstract": "Multi-instance learning (MIL) is an area of machine learning that handles data that is organized into sets of instances known as bags. Traditionally, MIL is used in the supervised-learning setting and is able to classify bags which can contain any number of instances. This property allows MIL to be naturally applied to solve the problems in a wide variety of real-world applications from computer vision to healthcare. However, many traditional MIL algorithms do not scale efficiently to large datasets. In this paper we present a novel Primal-Dual Multi-Instance Support Vector Machine (pdMISVM) derivation and implementation that can operate efficiently on large scale data. Our method relies on an algorithm derived using a multi-block variation of the alternating direction method of multipliers (ADMM). The approach presented in this work is able to scale to large-scale data since it avoids iteratively solving quadratic programming problems which are generally used to optimize MIL algorithms based on SVMs. In addition, we modify our derivation to include an additional optimization designed to avoid solving a least-squares problem during our algorithm; this optimization increases the utility of our approach to handle a large number of features as well as bags. Finally, we apply our approach to synthetic and real-world multi-instance datasets to illustrate the scalability, promising predictive performance, and interpretability of our proposed method. We end our discussion with an extension of our approach to handle non-linear decision boundaries. Code and data for our methods are available online at: https://github.com/minds-mines/pdMISVM.jl.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/7e07c93d2517a6b5861e1a6a99943c425b8f277e",
        "citation_count": 6
    },
    {
        "title": "Kernel Alignment for Quantum Support Vector Machines Using Genetic Algorithms",
        "abstract": "The data encoding circuits used in quantum support vector machine (QSVM) kernels play a crucial role in their classification accuracy. However, manually designing these circuits poses significant challenges in terms of time and performance. To address this, we leverage the GASP (Genetic Algorithm for State Preparation) framework for gate sequence selection in QSVM kernel circuits. We explore supervised and unsupervised kernel loss functions' impact on encoding circuit optimisation and evaluate them on diverse datasets for binary and multiple-class scenarios. Benchmarking against classical and quantum kernels reveals GA-generated circuits matching or surpassing standard techniques. We analyse the relationship between test accuracy and quantum kernel entropy, with results indicating a positive correlation. Our automated framework reduces trial and error, and enables improved QSVM based machine learning performance for finance, healthcare, and materials science applications.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/7e08198d6f6a5c11e26577f32652caa20feb170f",
        "citation_count": 1
    },
    {
        "title": "Classification and Prediction Evaluation of a Fuzzy Rule-Based Model for Diabetes Diagnosis, Level of Care and Pima Indians Diabetes Datasets",
        "abstract": "\u2014 Classification and prediction of diseases is crucial in decision-making for the healthcare sectors, especially diabetes, a chronic disease. The availability and accessibility of diabetes datasets assists medical practitioners in the diagnosis process as well as researchers in various fields and these datasets are valuable sources. However, diabetes datasets are exposed to vagueness and uncertainty issues. This research work improved an interrelated decision-making model for diabetes by proposing a fuzzy rule-based model to handle the vagueness and uncertainty issues. The research methodology starts with pre-processing of the simulated diabetes diagnosis and level of care datasets that were validated by medical experts, as well as the Pima Indians Diabetes Dataset (PIDD). This is followed by the design of the fuzzy model and the construction of the fuzzy rules. Next, the testing of the fuzzy model using six supervised machine learning algorithms namely J48, Logistic, Naive Bayes Updateable, Random Tree, Bayes Net and AdaBoostM1. Lastly, the evaluation of the fuzzy model in terms of the accuracy, precision, recall, F1-Score and confusion matrix. Experimental results show 100% accuracy for the diabetes diagnosis fuzzy model, for all the five machine learning algorithms mentioned except AdaBoostM1 with 79.8165% accuracy. In addition, for the level of care fuzzy model, the highest accuracy produced is 97.1098% for J48 algorithm and the lowest accuracy is 93.1049% for Naive Bayes Updateable and Bayes Net algorithms. Furthermore, for the PIDD fuzzy model, the highest accuracy obtained is 74.8698% for J48 and AdaBoostM1 algorithms and the lowest accuracy is 70.1823% for Random Tree algorithm. Overall, the proposed fuzzy model produced a good accuracy and working as expected associated to the previous interrelated decision-making model.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/7e363315fb63b00d7b40a71a35116980e2e57df8",
        "citation_count": 0
    },
    {
        "title": "A Clustering-Aided Approach for Diagnosis Prediction: A Case Study of Elderly Fall",
        "abstract": "Data-driven diagnosis prediction has been adopted in clinical decision support systems. However, only a few studies have focused on non-supervised clustering approaches to building a high-quality patient data set. This study focused on a clustering-aided approach to diagnosis prediction. We leveraged clustering-aided machine learning models to predict elderly falls. First, we used patients' risk factors to build a feature set. The feature set showed a clustering-aided approach could aggregate patient factors that shared similar clinical and demographic characteristics. Subsequently, a K-means clustering approach significantly improved the data set quality. Overall, our study demonstrated that clustering approaches improve the prediction performance of elderly falls. A clustering-aided approach can be applied to similar clinical healthcare practices to potentially improve elderly care.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/7e4071b59ac4dfe0991dbb4977e0743fc310c31e",
        "citation_count": 1
    },
    {
        "title": "Detecting Ransomware within Real Healthcare Medical Records Adopting Internet of Medical Things using Machine and Deep Learning Techniques",
        "abstract": "The Internet of Medical Things was immensely implemented in healthcare systems during the covid 19 pandemic to enhance the patient's circumstances remotely in critical care units while keeping the medical staff safe from being infected. However, Healthcare systems were severely affected by ransomware attacks that may override data or lock systems from caregivers' access. In this work, after obtaining the required approval, we have got a real medical dataset from actual critical care units. For the sake of research, a portion of data was used, transformed, and manifested using laboratory-made payload ransomware and successfully labeled. The detection mechanism adopted supervised machine learning techniques of K Nearest Neighbor, Support Vector Machine, Decision Trees, Random Forest, and Logistic Regression in contrast with deep learning technique of Artificial Neural Network. The methods of KNN, SVM, and DT successfully detected ransomware's signature with an accuracy of 100%. However, ANN detected the signature with an accuracy of 99.9%. The results of this work were validated using precision, recall, and f1 score metrics \u00a9 2022,International Journal of Advanced Computer Science and Applications.All Rights Reserved",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/7e491bc9e63c0e4a1307da28e4d4ba188373496a",
        "citation_count": 5
    },
    {
        "title": "Recommendation of Drugs and Its Substitute Medicines Also Purchasing Using Cosine Similarity Vector",
        "abstract": "In the current digital era, healthcare is one of the main focuses of the medical sector. A mistake with a patient's medication is one of the most dangerous medical errors that might risk the patient's life. It leads the healthcare sector to assist users in making more suitable and cost- effective health-related decisions. A machine learning-based drug recommendation system that takes into account the patient's reported symptoms or drugs is suggested by this study. The algorithm utilised is cosine similarity vector and data frames of medicine, and the system uses supervised learning techniques such as decision trees and K- nearest neighbours to propose the alternative drug and urges users to buy that specific drug.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/7e7d4a18eaf8335e4858ec48f29d5419ae0c32b0",
        "citation_count": 0
    },
    {
        "title": "PREDICTION AND CLASSIFICATION OF LIVER DISEASE USING MACHINE LEARNING",
        "abstract": ": Due to the quick rise in liver illness caused by excessive alcohol use, contaminated gas inhalation, drug use, tainted food, and pickled food packaging, a doctor can make an automatic forecast with the aid of a medical expert system. Early liver disease prediction is now attainable because to the consistent advancements in machine learning technology, allowing for simple early identification of the fatal condition. This will make healthcare more beneficial, and a medical expert system can be employed in a remote location. The liver is vital to life and promotes the body's ability to rid itself of poisons. Early detection of the condition is therefore crucial for recovery. many machine learning techniques, including supervised, unsupervised, and semi-supervising, bolstering SVM, KNN, K-Mean clustering, neural networks, decision trees, and other learning techniques for diagnosing liver disease provide varying accuracy, precision, and sensitivity. The goal of this paper is to provide an overview and comparative analysis of all machine learning techniques currently being used in the medical field for the diagnosis and prediction of liver disease. The analysis is based on accuracy, sensitivity, precision, and specificity.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/7ef3aaca40bb02dd747fc2543daba9310184968a",
        "citation_count": 0
    },
    {
        "title": "Parkinson\u2019s Disease Diagnosis Using Machine Learning and Voice",
        "abstract": "Biomarkers derived from human voice can offer in-sight into neurological disorders, such as Parkinson\u2019s disease (PD), because of their underlying cognitive and neuromuscular function. PD is a progressive neurodegenerative disorder that affects about one million people in the the United States, with approximately sixty thousand new clinical diagnoses made each year [1]. Historically, PD has been difficult to quantity and doctors have tended to focus on some symptoms while ignoring others, relying primarily on subjective rating scales [2]. Due to the decrease in motor control that is the hallmark of the disease, voice can be used as a means to detect and diagnose PD. With advancements in technology and the prevalence of audio collecting devices in daily lives, reliable models that can translate this audio data into a diagnostic tool for healthcare professionals would potentially provide diagnoses that are cheaper and more accurate. We provide evidence to validate this concept here using a voice dataset collected from people with and without PD. This paper explores the effectiveness of using supervised classification algorithms, such as deep neural networks, to accurately diagnose individuals with the disease. Our peak accuracy of 85% provided by the machine learning models exceed the average clinical diagnosis accuracy of non-experts (73.8%) and average accuracy of movement disorder specialists (79.6% without follow-up, 83.9% after follow-up) with pathological post-mortem examination as ground truth [3].",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/7f27838d8e212932ab9372b0fe605e24113f4d3f",
        "citation_count": 136
    },
    {
        "title": "Relation Extraction of Medical Concepts Using Categorization and Sentiment Analysis",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/800b895525ef1acc68df8b8b3ba96a08beb7a588",
        "citation_count": 0
    },
    {
        "title": "Prediction of Thyroid Disease using Machine Learning Approaches and Featurewiz Selection",
        "abstract": "Thyroid disease is one of the most disturbing hormonal disorders faced by the global population. To help the healthcare industry to diagnose the disorder rapidly and accurately, supervised machine learning algorithms and feature selection were introduced to play an essential role in predicting whether a patient has developed thyroid disease from his/her various characteristics. Therefore, in this work, a new feature selection library was introduced, which was the Featurewiz in the Python library. The goals were to present the performance of the Featurewiz library and to decide on a remarkable model for thyroid disease prediction among several machine learning models, such as Decision Tree, K-Nearest Neighbor, Logistic Regression, Nai\u0308ve Bayes, Support Vector Classifier, and ensembled machine learning algorithms (Random Forest and Extreme Gradient Boost). A data set consisting of records of thyroid patients in Australia was used to develop the machine-learning models. After the data set was cleaned, exploratory data analysis was carried out. The models were then built in two ways: without feature selection and with feature selection. The feature selection process was conducted by using a new Python library called Featurewiz. The performances of the models from the two operations were evaluated using three performance metrics, including accuracy, F1-score, and AUC (Area Under Curve) value from ROC (Receiver Operating Characteristics Curve). From the two operations, the results are similar in the way that tree-based models, especially those formed by the ensemble method, outperform the statistical models. Initially, in the process without feature selection, the champion model is XGBoost with 99.23% accuracy, while Random Forest ranks second with 98.79% accuracy. However, after the feature selection, the result reveals that the champion model is Random Forest. This model achieves an improvement of 0.66% in accuracy (99.45%), making it the best model from both operations. The model also scores 0.99 and 0.97 in F1-score and AUC values, respectively. The valuable insights gained from this study can serve as a comprehensive framework for machine learning applications in predicting thyroid illness. Additionally, the study highlights the advantageous utilization of the Python feature selection library, Featurewiz. With the combination of Featurewiz and machine learning applications, medical authorities can save time and reduce the risk of misdiagnosis when identifying patients with thyroid disease.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/801b47eb686fefb7d9f2555e668cc44e0ea21ebe",
        "citation_count": 6
    },
    {
        "title": "Applying Self-Supervised Representation Learning for Emotion Recognition Using Physiological Signals",
        "abstract": "The use of machine learning (ML) techniques in affective computing applications focuses on improving the user experience in emotion recognition. The collection of input data (e.g., physiological signals), together with expert annotations are part of the established standard supervised learning methodology used to train human emotion recognition models. However, these models generally require large amounts of labeled data, which is expensive and impractical in the healthcare context, in which data annotation requires even more expert knowledge. To address this problem, this paper explores the use of the self-supervised learning (SSL) paradigm in the development of emotion recognition methods. This approach makes it possible to learn representations directly from unlabeled signals and subsequently use them to classify affective states. This paper presents the key concepts of emotions and how SSL methods can be applied to recognize affective states. We experimentally analyze and compare self-supervised and fully supervised training of a convolutional neural network designed to recognize emotions. The experimental results using three emotion datasets demonstrate that self-supervised representations can learn widely useful features that improve data efficiency, are widely transferable, are competitive when compared to their fully supervised counterparts, and do not require the data to be labeled for learning.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/80e36d026efee72631efb834cfbbc4e136e56391",
        "citation_count": 17
    },
    {
        "title": "A Machine-Learning Approach For Predicting Antibiotic Resistance in Pseudomonas aeruginosa",
        "abstract": "Background: Pseudomonas aeruginosa is an important nosocomial pathogen associated with intrinsic and acquired resistance mechanisms to major classes of antibiotics. To better understand clinical risk factors for drug-resistant P. aeruginosa infection, decision-tree models for the prediction of fluoroquinolone and carbapenem-resistant P. aeruginosa were constructed and compared to multivariable logistic regression models using performance characteristics. Methods: In total, 5,636 patients admitted to 4 hospitals within a New York City healthcare system from 2010 to 2016 with blood, respiratory, wound, or urine cultures growing PA were included in the analysis. Presence or absence of drug-resistance was defined using the first culture of any source positive for P. aeruginosa during each hospitalization. To train and validate the prediction models, cases were randomly split (60 of 40) into training and validation datasets. Clinical decision-tree models for both fluoroquinolone and carbapenem resistance were built from the training dataset using 21 clinical variables of interest, and multivariable logistic regression models were built using the 16 clinical variables associated with resistance in bivariate analyses. Decision-tree models were optimized using K-fold cross validation, and performance characteristics between the 4 models were compared. Results: From 2010 through 2016, prevalence of fluoroquinolone and carbapenem resistance was 32% and 18%, respectively. For fluoroquinolone resistance, the logistic regression algorithm attained a positive predictive value (PPV) of 0.57 and a negative predictive value (NPV) of 0.73 (sensitivity, 0.27; specificity, 0.90) and the decision-tree algorithm attained a PPV of 0.65 and an NPV of 0.72 (sensitivity 0.21, specificity 0.95). For carbapenem resistance, the logistic regression algorithm attained a PPV of 0.53 and a NPV of 0.85 (sensitivity 0.20, specificity 0.96) and the decision-tree algorithm attained a PPV of 0.59 and an NPV of 0.84 (sensitivity 0.22, specificity 0.96). The decision-tree partitioning algorithm identified prior fluoroquinolone resistance, SNF stay, sex, and length-of-stay as variables of greatest importance for fluoroquinolone resistance compared to prior carbapenem resistance, age, and length-of-stay for carbapenem resistance. The highest-performing decision tree for fluoroquinolone resistance is illustrated in Fig. 1. Conclusions: Supervised machine-learning techniques may facilitate prediction of P. aeruginosa resistance and risk factors driving resistance patterns in hospitalized patients. Such techniques may be applied to readily available clinical information from hospital electronic health records to aid with clinical decision making. Funding: None Disclosures: None",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/81898a7d7efe7a1fab3dca54ca2e290db560aa4e",
        "citation_count": 0
    },
    {
        "title": "Using multi-anchors to identify patients suffering from multimorbidities",
        "abstract": "Chronic diseases, and in particular the co- occurrence of more than one chronic disease in an patient, which is known as multimorbidity, represent an increasing problem in modern society. For the individual patients the consequences are potentially serious, especially if not diagnosed and/or treated. In order to allow for an efficient allocation of health resources, and slow down the progression of these diseases, methods for predicting the health status of chronic patients have been developed. In this work, we propose a data-driven approach to identify the health status of chronically ill patients using data extracted from their electronic health records. For this purpose we take advantage of recent advances in machine learning for healthcare and use anchor learning that exploits vast amounts of unlabeled data. Moreover, in order to identify patients suffering from multimorbidities, we adapt the anchor method to a multi-anchor learning framework. The experiments show that using multi- anchor learning one can accurately identify patients who suffer from one or more chronic conditions. In fact, the performance is almost comparable to a completely supervised baseline.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/81a2811d58a875e4c6197b6681b048c6926d47b2",
        "citation_count": 0
    },
    {
        "title": "Early Prediction Model for Anemia in Infants Using Clinical Data from Per\u00fa Applying Supervised Machine Learning Algorithms",
        "abstract": "Anemia is a disease that is always present from early stages; children are the most prone to contracting it from birth if it's not diagnosed, which can lead to more severe illnesses. Therefore, a predictive model is proposed for the detection of anemia in infants using their clinical data. The Cross Industry Standard Process for Data Mining (CRISP-DM) methodology is employed, along with Analysis Services for the Extract, Transform, Load (ETL) process and four Machine Learning (ML) algorithms: Logistic Regression (LR), Decision Tree (DT), Support Vector Machine (SVM), and Random Forest (RF). All four phases of CRISP-DM were utilized: Business Understanding, Data Understanding, Data Preparation, Modeling, and Evaluation. The dataset used consists of 400,000 records related to the medical history of children from a healthcare institution in Peru, from which 27 variables were selected. The results showed that the DT algorithm performed better, achieving an AUC-ROC Curve greater than 93%, and the \u201cScikit Learn\u201d library for ML in Python facilitated obtaining the results.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/81d129951300e57db550cc887011516e16c09b83",
        "citation_count": 0
    },
    {
        "title": "Information Fusion for Seveirty Detection using Machine Learning in Data Mining Healthcare",
        "abstract": "Improved patient care and less mental strain on healthcare providers are two benefits of using algorithms for machine learning to healthcare data. These algorithms may be used to spot irregularities in vital signs, which might speed up medical assistance or provide light on a disease's progression. While there is a wealth of literature comparing the unsupervised and supervised performances of anomaly detection algorithms on popular public datasets, this same level of conceptual comparison is lacking when it comes to physiological data. Knowing one's heart rate may provide valuable insight on one's health and level of physical activity, making it an underutilised data source. Specifically, we used and compared five machine learning methods, two of which were unsupervised and the other three supervised, to identify outliers in heart rate data. The algorithms were tested using physiological data from human subjects' hearts. Results demonstrated that both outlier factor and regression trees algorithms were effective in detecting heart rate anomalies, with both models successfully generalising from their simulation heart rate data training to real-world heart rate data. In addition, the findings lend credence to the idea that, in the absence of real labelled data, simulated data can be used to configure methodologies to a certain degree of performance, indicating that this kind of training could be particularly useful in the initial rollout of a system with no preexisting data.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/81dc18a21384a1d597686b6fdb9e0c06db673d36",
        "citation_count": 0
    },
    {
        "title": "Characterizing the Differences in Descriptions of Violence on Reddit During the COVID-19 Pandemic",
        "abstract": "Concerns have been raised over the experiences of violence such as domestic violence (DV) and intimate partner violence (IPV) during the COVID-19 pandemic. Social media such as Reddit represent an alternative outlet for reporting experiences of violence where healthcare access has been limited. This study analyzed seven violence-related subreddits to investigate the trends of different violence patterns from January 2018 to February 2022 to enhance the health-service providers\u2019 existing service or provide some new perspective for existing violence research. Specifically, we collected violence-related texts from Reddit using keyword searching and identified six major types with supervised machine learning classifiers: DV, IPV, physical violence, sexual violence, emotional violence, and nonspecific violence or others. The increase rate (IR) of each violence type was calculated and temporally compared in five phases of the pandemic. The phases include one pre-pandemic phase (Phase 0, the date before February 26, 2020) and four pandemic phases (Phases 1\u20134) with separation dates of June 17, 2020, September 7, 2020, and June 4, 2021. We found that the number of IPV-related posts increased most in the earliest phase; however, that for COVID-citing IPV was highest in the mid-pandemic phase. IRs for DV, IPV, and emotional violence also showed increases across all pandemic phases, with IRs of 26.9%, 58.8%, and 28.8%, respectively, from the pre-pandemic to the first pandemic phase. In the other three pandemic phases, all the IRs for these three types of violence were positive, though lower than the IRs in the first pandemic phase. The findings highlight the importance of identifying and providing help to those who suffer from such violent experiences and support the role of social media site monitoring as a means of informative surveillance for help-providing authorities and violence research groups.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/81f194e776baea8b5491d9c0b95d508ca6df10f7",
        "citation_count": 1
    },
    {
        "title": "A Multi-Activity Fusion Approach for Gender Recognition based on Human Activity",
        "abstract": "Due to its advantages in numerous industries, including healthcare, sports, rehabilitation, and wearable electronics, gender recognition has garnered a lot of attention in the last ten years. The gender recognition method described in this study uses a wearable sensor device with inertial measurement units to record a variety of activities. The system consists of five sensors that are mounted to the upper and lower bodies while performing seven standing, walking, and climbing exercises that are meant to replicate daily activity. To create a model for gender recognition, we carried out an extensive study based on supervised machine learning. This study identifies a collection of sensor locations and behaviours to better precisely classify gender. Gender classification based on single activity was performed using Random Forest Classifier (RFC) and Support Vector Machines (SVM). Maximum accuracy of 92.06% was gained using Random Forest Classifier for the sensor located at the ankle when walking. Multi-activity based gender classification outperformed former by achieving an accuracy of 94.13% using RFC. This was for the activity combination of Romberg test eyes open, Single leg stance eyes open and Staircase up and down.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8289530d18c8640c6f270394ff4b04ed063f3345",
        "citation_count": 2
    },
    {
        "title": "Computer Vision for Gait Assessment in Cerebral Palsy: Metric Learning and Confidence Estimation",
        "abstract": "Assessing the motor impairments of individuals with neurological disorders holds significant importance in clinical practice. Currently, these clinical assessments are time-intensive and depend on qualitative scales administered by trained healthcare professionals at the clinic. These evaluations provide only coarse snapshots of a person\u2019s abilities, failing to track quantitatively the detail and minutiae of recovery over time. To overcome these limitations, we introduce a novel machine learning approach that can be administered anywhere including home. It leverages a spatial-temporal graph convolutional network (STGCN) to extract motion characteristics from pose data obtained from monocular video captured by portable devices like smartphones and tablets. We propose an end-to-end model, achieving an accuracy rate of approximately <inline-formula> <tex-math notation=\"LaTeX\">${76}.{6}\\%$ </tex-math></inline-formula> in assessing children with Cerebral Palsy (CP) using the Gross Motor Function Classification System (GMFCS). This represents a <inline-formula> <tex-math notation=\"LaTeX\">${5}\\%$ </tex-math></inline-formula> improvement in accuracy compared to the current state-of-the-art techniques and demonstrates strong agreement with professional assessments, as indicated by the weighted Cohen\u2019s Kappa (<inline-formula> <tex-math notation=\"LaTeX\">$\\kappa _{\\textit {lw}} = {0}.{733}$ </tex-math></inline-formula>). In addition, we introduce the use of metric learning through triplet loss and self-supervised training to better handle situations with a limited number of training samples and enable confidence estimation. Setting a confidence threshold at <inline-formula> <tex-math notation=\"LaTeX\">${0}.{95}$ </tex-math></inline-formula>, we attain an impressive estimation accuracy of <inline-formula> <tex-math notation=\"LaTeX\">${88}\\%$ </tex-math></inline-formula>. Notably, our method can be efficiently implemented on a wide range of mobile devices, providing real-time or near real-time results.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/82acae8c23afb2a5c2542baf3f976b5747ac3762",
        "citation_count": 0
    },
    {
        "title": "A Machine Learning-based Approach to Diabetes Prediction",
        "abstract": "ML-Diabetes is a machine learning-based predictive model for the early detection of diabetes. Diabetes is a chronic metabolic disorder that affects millions of people worldwide. Early detection of diabetes can help prevent its complications and improve patient outcomes. ML-Diabetes is designed to use demographic and clinical data to predict the likelihood of a patient developing diabetes. The model uses a combination of supervised and unsupervised machine learning techniques to analyse and classify data.\nML-Diabetes uses a dataset containing demographic and clinical information of patients, including age, sex, BMI, blood pressure, and glucose levels. The dataset is preprocessed and cleaned to remove missing values and outliers. The processed data is then split into training and testing sets, and the model is trained on the training set.\nThe model uses a combination of supervised and unsupervised machine learning techniques, including logistic regression, decision trees, and k-means clustering, to predict the likelihood of a patient developing diabetes. The model is evaluated on the testing set using various performance metrics, including accuracy, precision, recall, and F1-score.\nThe results show that ML-Diabetes is a reliable and accurate predictive model for the early detection of diabetes. The model achieves an accuracy of 85%, precision of 90%, recall of 80%, and F1-score of 85%. The model can be used by healthcare professionals to screen patients for diabetes and provide early interventions to prevent complications.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/82cb55389625a0f1bfa82fc99db5af65f9d23383",
        "citation_count": 0
    },
    {
        "title": "An adaptive user interface based on spatiotemporal structure learning",
        "abstract": "We developed a user interface prototype for the Android smartphone, which recommends a number of applications to best match the user's context. To consider the user's context of use, we utilized 5 prototypical variables; time, location, weather, emotion, and activities. The developed system derives the best three recommended applications based on the results of supervised machine learning from such data sets. To consider the history of past context information, in addition to the current one, we developed a novel and effective probabilistic learning and inference algorithm named \"Spatiotemporal Structure Learning.\" By extending Nai\u0308ve Bayesian Classifier, the spatiotemporal structure learning can create a probability model which represents relationship between time-series contextual variables. We implemented a prototype system which shows the current context and the inferred recommendation of applications. For the prototype system, we developed an Android widget application for the user interface and a Java-based server application which learns structure from training data and provides inference results in real time. To gather training data and evaluate the proposed system, we conducted a pilot study which showed 69 percent accuracy in predicting the user's application usage. The prototype demonstrated the feasibility of an adaptive user interface applied to a state of the art smartphone. We also believe that the suggested spatiotemporal structure learning can be applied to number of application areas including healthcare or energy problems.",
        "year": 2011,
        "url": "https://www.semanticscholar.org/paper/82de3377a7816aa5d9dfff7baf1c82b3a99271b1",
        "citation_count": 4
    },
    {
        "title": "Improving Heart Disease Prediction of Classifiers with Data Transformation using PCA and Relief Feature Selection",
        "abstract": "Cardiovascular disorders (CVD) are the key cause of mortality worldwide. One in three male premature deaths and one in five female premature deaths are thought to be attributable to Cardiovascular disorders. Early prediction of CVDs may help to attenuate the disease, potentially lowering death rates. The existence of cardiac disease can be predicted using machine learning approaches; however, the effectiveness of the classifiers may be enhanced by applying PCA, relief feature selection, and data transformation techniques. The objective of employing data transformation, PCA, and relief feature selection approaches is to enhance classifier performance and increase the interpretability and ability of classifiers to predict heart disease. Heart disease anticipating is a challenging problem in the field of healthcare. This uses popular supervised machine learning (ML) algorithms including k-NN, LR, DT, RF, SVM, and ANN to help healthcare practitioners and specialists easily identify the prevalence of heart-related illnesses in patients. In these trials, data transformation is achieved using PCA, normalized features, and relief techniques, and RF surpasses all other classifiers with a prediction accuracy of 90%, followed by ANN and DT with AUCs of 87% and 86%, respectively. SVM and Naive Bayes classifiers were shown to be lesser effective at predicting heart disease.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8350295744940b968eec4c9b80dbc641d0010dd4",
        "citation_count": 1
    },
    {
        "title": "Analysis of Significant Factors for Dengue Infection Prognosis Using the Random Forest Classifier",
        "abstract": "Random forests have emerged as a versatile and highly accurate classification and regression methodology, requiring little tuning and providing interpretable outputs. Here, we briefly explore the possibility of applying this ensemble supervised machine learning technique to predict the vulnerability for complex disease - Dengue which is often baffled with chikungunya viral fever. This study presents a new-fangled approach to determine the significant prognosis factors in dengue patients. Random forests is used to visualize and determine the significant factors that can differentiate between the dengue patients and the healthy subjects and for constructing a dengue disease survivability prediction model during the boosting process to improve accuracy and stability and to reduce over fitting problems. The presented methodology may be incorporated in a variety of applications such as risk management, tailored health communication and decision support systems in healthcare",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/83b195384d52a5a469eb0d0d232cec7160eaaf60",
        "citation_count": 19
    },
    {
        "title": "Managing sensor data streams in a smart home application",
        "abstract": "A challenge in developing an ambient activity recognition system for use in elder care is finding a balance between the sophistication of the system and a cost structure that fits within the budgets of public and private sector healthcare organisations. Much activity recognition research in the context of elder care is based on dense networks of sensors and advanced methods, such as supervised machine learning algorithms. This paper presents the data processing aspects of an activity recognition system based on a simpler, knowledge-based unsupervised approach, designed for a sparse network of sensors. By structuring sensor data management as a streaming system, we provide a simple programming model for the application logic, which facilitates building a fault-tolerant system with the potential for distributed data management within the sensor network. The system, evaluated by a public sector healthcare organisation, constitutes an example of a system that is useful and has a sustainable cost structure.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/83bde75b5f8444aa0656be6fcc784a4aaf341348",
        "citation_count": 4
    },
    {
        "title": "Enhancing Healthcare Claims and Membership Data Quality: SPSS Modeler Predictive Analysis",
        "abstract": "Purpose: This paper explores the use of SPSS Modeler predictive analysis to enhance healthcare claims and membership data quality. The analysis uses advanced analytical techniques and algorithms to identify discrepancies and improve data accuracy, improving decision-making and operational efficiencies within healthcare organizations. The paper also provides insights to optimize data integrity, streamline claims processing, and ultimately improve patient care outcomes by ensuring that accurate and reliable data can sustain all healthcare operations. \nMethodology: This paper explores the use of advanced data mining and predictive analytics techniques to improve the identification of claims and membership data quality. The study aims to leverage supervised learning methods, including Neural Networks and the Auto Data Prep Modeling Option, and unsupervised learning methods, utilizing cutting-edge machine learning algorithms to train models capable of detecting and addressing data quality issues. \nFindings: Data Quality of an application affects various factors of an organization including operations, decision making and Planning. It therefore becomes very important to make sure that the data being stored and used is of high quality. Data must be regularly monitored and cleaned to support more informed and effective healthcare decision-making. As per a research study published by MIT Sloan, poor data quality has made companies lose around 15% to 25% of their revenues [1]. Another study found that data scientist spends around 80% of their time cleaning and correcting data leaving them with only 20%of time to perform the actual analysis [2]. \nUnique Contributions to Theory, Practice, and Policy: By incorporating advanced\u00a0predictive analytics\u00a0techniques like supervised and unsupervised learning models within\u00a0SPSS Modeler, the study enhances the ability to proactively address data quality issues, streamline operations, and ensure regulatory compliance.\u00a0It can also help healthcare organizations by offering. Innovative perspectives on how data mining and predictive analysis can help reshare healthcare data governance, policy development and industry-wide standards for data quality.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/83d67c14d708ed72fe400743d35a1ea024443d9d",
        "citation_count": 0
    },
    {
        "title": "Identification model for hearing loss symtoms using machine learning techniques",
        "abstract": "There is potential knowledge inherent in vast amounts of untapped and possibly valuable \ndata generated by healthcare providers. Clinicians rely in their knowledge and experience \nand the basic diagnostic procedure to determine the likely symptom of a disease. \nSometimes, many stages of diagnosis and longer procedures can leads to longer \nconsultation hours and can consequently results to longer waiting time for other patients \nthat need to be attended to. This can results to stress and anxiety on the part of those \npatients. This research presents an efficient way to facilitate the hearing loss symptoms \ndiagnosis process by designing a symptoms identification model that efficiently identify \nhearing loss symptoms based on air and bone conduction pure-tone audiometry data. The \nmodel is implemented using both unsupervised and supervised machine learning \ntechniques in the form of Frequent Pattern Growth (FP-Growth) algorithm as feature \ntransformation method and multivariate Bernoulli naive Bayes classification model as the \nclassifier. In order to find, the correlation that exist between the hearing thresholds and \nsymptoms of hearing loss, FP-Growth and association rule algorithms were first used to \nexperiment with a small sample and large sample datasets. The result of these two \nexperiments showed the existence of this relationship and the performance of the hybrid of \nthe FP-Growth and naive Bayes algorithms in identifying hearing loss symptoms was \nfound to be efficient with very minimum error rate.",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/83f773ca1e0bb3876d600884a921ea6e97d725bf",
        "citation_count": 0
    },
    {
        "title": "Foundations of Big Data, Machine Learning, and Artificial Intelligence and Explainable Artificial Intelligence",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/842338416528807fa4ba26ec0f3eabb07c802e10",
        "citation_count": 2
    },
    {
        "title": "Review Paper on a Healthcare Prognosis Using Machine Learning",
        "abstract": "Abstract: Diseases tracing plays important role in daily life. Every one cares about their own health. According to some social study, lot of people spends their time on online searching of health related issues. By browsing they get lot of information about the medical concepts and health related issues. Normally, people use Google to search their queries and that search engine respond them with the answer but that answer is in scattered format. User does not gets the exact answer for their queries. From previous work there has been vital work on the information needs of health seekers in terms of questions and then select those that ask for possible disease of their manifested symptoms for further analytic. To resolve such issues an extensive experiment on a real-world dataset labelled by online doctor\u2019s show the significant performance. In this paper, we discussed the techniques for further restructuring of the question and answer has been done in order to get the exact answer of query. A tag mining framework for health seekers will be proposed; aim to identify discriminant features for each specific disease. In this paper we are going to use one of the most famous algorithm of machine learning that is decision tree. It is a type of supervised learning algorithm that is mostly used for classification problems. Surprisingly, it works for both categorical and continuous dependent variables. In this algorithm, we split the population into two or more homogeneous sets. This is done based on most significant attributes/ independent variables to make as distinct groups as possible. Keywords: SVM (Support Vector Machine), sparse deep learning, Classifiers, Querying, Signature mining",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/842a659fdb816bf20988252fa882f0cdff690148",
        "citation_count": 0
    },
    {
        "title": "Predicting Successful Weaning from Mechanical Ventilation by Reduction in Positive End-expiratory Pressure Level Using Machine Learning",
        "abstract": "Weaning patients from mechanical ventilation (MV) is a critical and resource intensive process in the Intensive Care Unit (ICU) that impacts patient outcomes and healthcare expenses. Weaning methods vary widely among providers. Prolonged MV is associated with adverse events and higher healthcare expenses. Predicting weaning readiness is a non-trivial process in which the positive end-expiratory pressure (PEEP), a crucial component of MV, has potential to be indicative but has not yet been used as the target. We aimed to predict successful weaning from mechanical ventilation by targeting changes in the PEEP-level using a supervised machine learning model. This retrospective study included 12,153 mechanically ventilated patients from Medical Information Mart for Intensive Care (MIMIC-IV) and eICU collaborative research database (eICU-CRD). Two machine learning models (Extreme Gradient Boosting and Logistic Regression) were developed using a continuous PEEP reduction as target. The data is splitted into 80% as training set and 20% as test set. The model\u2019s predictive performance was reported using 95% confidence interval (CI), based on evaluation metrics such as area under the receiver operating characteristic (AUROC), area under the precision-recall curve (AUPRC), F1-Score, Recall, positive predictive value (PPV), and negative predictive value (NPV). The model\u2019s descriptive performance was reported as the variable ranking using SHAP (SHapley Additive exPlanations) algorithm. The best model achieved an AUROC of 0.84 (95% CI 0.83\u20130.85) and an AUPRC of 0.69 (95% CI 0.67\u20130.70) in predicting successful weaning based on the PEEP reduction. The model demonstrated a Recall of 0.85 (95% CI 0.84\u20130.86), F1-score of 0.86 (95% CI 0.85\u20130.87), PPV of 0.87 (95% CI 0.86\u20130.88), and NPV of 0.64 (95% CI 0.63\u20130.66). Most of the variables that SHAP algorithm ranked to be important correspond with clinical intuition, such as duration of MV, oxygen saturation (SaO2), PEEP, and Glasgow Coma Score (GCS) components. This study demonstrates the potential application of machine learning in predicting successful weaning from MV based on continuous PEEP reduction. The model\u2019s high PPV and moderate NPV suggest that it could be a useful tool to assist clinicians in making decisions regarding ventilator management.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/846abbae097545db708048ac07f4c37f0883ed09",
        "citation_count": 0
    },
    {
        "title": "Detecting the Human Activities of Aging People using Restricted Boltzmann Machines with Deep Learning Technique in IoT",
        "abstract": "Approximately 962,000,000 persons worldwide are 60 or older. Despite the widespread adoption of techniques for human activity detection, there has been a dearth of study into the specific challenge of identifying the tasks performed by the elderly. Given the proliferation of wearable and mobile devices, the Internet of Healthcare Things is assuming a larger role in Human Activity Recognition (HAR). This article focuses on assisting the elderly by tracking their movements in both indoor and outdoor settings. The dataset includes human actions like sitting, walking, ascending and descending stairs, standing, and lying down. Here, how deep learning might improve HAR in Internet of Home Things settings has been examined. For better HAR results, a semi-supervised deep learning framework has been developed that makes effective use of the imperfectly labelled sensor data in order to fine-tune the classifier learning model. An intelligent auto-labelling system is built on top of Deep Q-Network to enhance learning performance in Internet of Things (IoT) environment and address the issue of insufficient labelled samples. Finally, real-world data is used in trial and evaluation to prove the method\u2019s utility and efficacy.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/847361dcaa6661425350d8983b5f75e69efea353",
        "citation_count": 2
    },
    {
        "title": "A Hybrid Feature Modeling Approach for Content-Based Medical Image Retrieval",
        "abstract": "With the proliferation of various imaging based diagnostic procedures in the healthcare field, patient-specific scan images constitute huge volumes of data that needs to be well-organized and managed for supporting clinical decision support applications. One such crucial application with a significant impact on point-of-care treatment quality is a Content Based Medical Image Retrieval (CBMIR) system that can assist doctors in disease diagnosis based on similar image retrieval. Medical images are multi-dimensional and often contain manifold information, due to which efficient techniques for optimal feature extraction from large-scale image collections are the need of the day. In this paper, an efficient CBMIR model is proposed that is built on multi-level feature sets extracted from medical images. Four different feature extraction techniques are used to optimally represent images in a multi-dimensional feature space, for facilitating classification using supervised machine learning algorithms and top-k similar image retrieval. Experimental validation of proposed model on the standard ImageCLEF 2009 dataset containing 12,560 X-ray images across 116 classes showed promising results in terms of classification accuracy of 85.91%.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/8477e318de1aebc3c3b74f303d9e89109ad930a6",
        "citation_count": 9
    },
    {
        "title": "Interactive online learning for clinical entity recognition",
        "abstract": "Named entity recognition and entity linking are core natural language processing components that are predominantly solved by supervised machine learning approaches. Such supervised machine learning approaches require manual annotation of training data that can be expensive to compile. The applicability of supervised, machine learning-based entity recognition and linking components in real-world applications can be hindered by the limited availability of training data. In this paper, we propose a novel approach that uses ontologies as a basis for entity recognition and linking, and captures context of neighboring tokens of the entities of interest with vectors based on syntactic and semantic features. Our approach takes user feedback so that the vector-based model can be continuously updated in an online setting. Here we demonstrate our approach in a healthcare context, using it to recognize body part and imaging modality entities within clinical documents, and map these entities to the right concepts in the RadLex and NCIT medical ontologies. Our current evaluation shows promising results on a small set of clinical documents with a precision and recall of 0.841 and 0.966. The evaluation also demonstrates that our approach is capable of continuous performance improvement with increasing size of examples. We believe that our human-in-the-loop, online learning approach to entity recognition and linking shows promise that it is suitable for real-world applications.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/84924b88e4c903f7cc110fdf71e028173994060c",
        "citation_count": 1
    },
    {
        "title": "Enhanced Diabetic Retinopathy Diagnosis: A Comparative Analysis of models with an Ensemble classifier and Deep Q Learning",
        "abstract": "- A novel method that combines the strengths of different classifiers such as Naive Bayes, Multi-Layer Perceptron (MLP), and Support Vector Machine (SVM) is introduced in this paper. This method tackles the urgent need for cutting-edge diagnostic methods in the field of ophthalmology, mainly for the identification of diabetic retinopathy (DR). The approach is ensemble-based. Classical methods in retinal analysis of images often fail as they are static and are unable to adjust to the unique details that each distinct image presents. This constraint results in less accurate and precise diagnostic results, highlighting the urgent need for more adaptable and dynamic methods. The suggested model differs significantly from previous methods. Through the use of an ensemble approach, it capitalizes on the distinct advantages of each classifier: the MLP process's sophisticated feature extraction skill, Naive Bayes' probabilistic analysis, and SVM's non-linear pattern recognition capacity. By combining these techniques, the inherent drawbacks of utilizing a single strategy are addressed, guaranteeing a more thorough examination of retinal samples and images. The core of this idea is the system using Deep Q Learning (DQL) for adaptive classifier selection. Using learned Q Values for various contexts, this reinforcement learning technique selects the best classifier adaptively for each unique retinal image, hence optimizing the ensemble. \nThis approach not only advances diagnosis accuracy and precision but also guarantees ongoing learning and adaptation to keep up with changing data patterns and advances in imaging technology. Extensive experiments on the IDRiD & EyePACS Dataset show the effectiveness of this model with a 5.5% increase in overall accuracy with other performance metrics, the results show a significant improvement over the current method. They represent a significant advancement in the timely and accurate identification of diabetic retinopathy, which will ultimately benefit patients and lessen the strain on healthcare systems. \nThus, this work represents a major step forward in patient care as well as a technological advance, opening the door to more efficient supervision and treatment of retinal illnesses.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/84e85d153ab89e0fe9e53afdd37b178e9446392c",
        "citation_count": 0
    },
    {
        "title": "Methods and computational techniques for predicting adherence to treatment: a scoping review",
        "abstract": "Background: Treatment non-adherence of patients stands as a major barrier to effectively manage chronic conditions. Treatment adherence can be described as the extent to which a patient's behavior of taking medications follows the agreed recommendations from the healthcare provider. However, non-adherent behavior is estimated to affect up to 50% of patients with chronic conditions, leading to poorer health outcomes among patients, higher rates of hospitalization, and increased mortality. In fact, 200.000 premature deaths each year in the European Union are related to non-adherence. A promising approach to understand adherence behavior of patients represent artificial intelligence and computational techniques. These techniques can be especially useful in analyzing large amounts of heterogeneous patient data, identifying both inter and intra-relationships between factors and patterns associated with non-adherence. Objective: This study offers a provision of a structured overview of the computational methods and techniques used to build predictive models of treatment adherence of patients. Methodology: A scoping review was conducted, and the following databases were searched to identify relevant publications: PubMed, IEEE and Web of Science. The screening of publications consisted of two steps. First, the hits obtained from the search were independently screened and selected using an open-source machine learning (ML)-aided pipeline applying active learning: ASReview, Active learning for Systematic Reviews. Publications selected for further review were those highly prioritized by ASReview. Results: 45 papers were selected into the second round of screening were reviewers performed the full-text screening. The final review included 29 papers.T he findings suggest supervised learning (regression and classification) to be the most used analytical approach. Over 54% of adherence topics being related to chronic metabolic conditions such as diabetes, hypertension, and hyperlipidemia. Most assessed predictors were both treatment and socio-demographic and economic-related factors followed by condition-related factors. The selection of a particular computational technique was based on the research question, the type of data available and the desired outcome. A limitation of the reviewed studies is the lack of accountancy for interrelationships between different determinants of adherence behavior. Adherence behavior is a complex phenomenon that is influenced by multiple factors, and these factors likely interact with one another in complex ways. Conclusion: The creation of systems to accurately predict treatment adherence can pave the way for improved therapeutic outcomes, reduced healthcare costs and enabling personalized treatment plans. This paper can support understanding the efforts made in the field of modelling adherence-related factors. In particular, the results provide a structured overview of the computational methods and techniques used to build predictive models of treatment adherence of patients to guide future advancements in healthcare.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/853f934766b0312868531e22d6c6e1c2b8835a42",
        "citation_count": 0
    },
    {
        "title": "Prediction of delayed breastfeeding initiation among mothers having children less than 2\u2009months of age in East Africa: application of machine learning algorithms",
        "abstract": "Background Delayed breastfeeding initiation is a significant public health concern, and reducing the proportion of delayed breastfeeding initiation in East Africa is a key strategy for lowering the Child Mortality rate. However, there is limited evidence on this public health issue assessed using advanced models. Therefore, this study aimed to assess prediction of delayed initiation of breastfeeding initiation and associated factors among women with less than 2\u2009months of a child in East Africa using the machine learning approach. Methods A community-based, cross-sectional study was conducted using the most recent Demographic and Health Survey (DHS) dataset covering the years 2011 to 2021. Using statistical software (Python version 3.11), nine supervised machine learning algorithms were applied to a weighted sample of 31,640 women and assessed using performance measures. To pinpoint significant factors and predict delayed breastfeeding initiation in East Africa, this study also employed the most widely used outlines of Yufeng Guo\u2019s steps of supervised machine learning. Results The pooled prevalence of delayed breastfeeding initiation in East Africa was 31.33% with 95% CI (24.16\u201338.49). Delayed breastfeeding initiation was highest in Comoros and low in Burundi. Among the nine machine learning algorithms, the random forest model was fitted for this study. The association rule mining result revealed that home delivery, delivered by cesarean section, poor wealth status, poor access to media outlets, women aged between 35 and 49 years, and women who had distance problems accessing health facilities were associated with delayed breastfeeding initiation in East Africa. Conclusion The prevalence of delayed breastfeeding initiation was high. The findings highlight the multifaceted nature of breastfeeding practices and the need to consider socioeconomic, healthcare, and demographic variables when addressing breastfeeding initiation timelines in the region. Policymakers and stakeholders pay attention to the significant factors and we recommend targeted interventions to improve healthcare accessibility, enhance media outreach, and support women of lower socioeconomic status. These measures can encourage timely breastfeeding initiation and address the identified factors contributing to delays across the region.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/85593509919b78e4405a7108c44b37325e61f8f6",
        "citation_count": 1
    },
    {
        "title": "High-fidelity birth simulators in American culture: an ecofeminist analysis.",
        "abstract": "Mother was once a standard term for the womb, and rising of the mother, fits of the mother, and even simply mother were hysterical fits brought on by disturbance of the womb - \"Hypochondria,\" The Aferriam-WebsterNew Book of Word Histories. Introduction Today, a new teaching tool, the high-fidelity birth simulator, is increasingly being promoted and implemented to educate aspiring medical professionals in the United States about childbirth. The machines are anatomically correct mannequins with the capacity to simulate some aspects of labor. The mannequin mother can be programmed to vomit as well as verbalize pain and anxiety. Equipped with a motor in its stomach, the machine is able to \"birth\" an accompanying mannequin child and placenta. Medical scholars Roaxane Gardner and Daniel B. Raemer tout the use of high-fidelity birth simulators as teaching tools for \"identifying clinical error, reducing clinical risk, and improving clinical outcomes\" (110). Proponents claim that birth simulators improve students' confidence, \"time-management, leadership and critical thinking\" (Leigh and Hurst 2). Gardner and Raemer go so far as to proclaim, \"The days of relying on the apprenticeship style of learning in obstetrics and gynecology have passed\" (Gardner and Raemer 119). What appears to be significantly lacking from the growing body of literature endorsing such teaching tools are the potential drawbacks of their use, including, for instance, their capacity to perpetuate the presentation of birth as pathological and birthing women as passive patients. While even some midwifery schools, at times, utilize such technology, they are always secondary to live models, role playing and first-hand experience (Phillips).1 Moreover, students are introduced to not only abnormal births but normal, mother-led births, too. Indeed, with some important representational adjustments, birth simulators might be acceptable as a means of teaching students basic anatomy and emergency birth scenarios. However, birth simulators are purposed to do much more than this. As Nelson explains, \"They're teaching [medical professionals] how to manage a woman when she is in labor, how to manage a baby when they're in birth, which means taking absolute control. [They're] not leading by following what's actually happening, but they're learning to literally manage the whole thing.\" In her seminal 2010 article on birth simulation, \"Obstetrical Nursing Experience Simulation, Filling the Gap,\" Deborah A. Raines makes the case for use of high-fidelity birth simulators to educate nurses on grounds that they provide important learning opportunities unavailable in the clinical setting. She writes, \"A student or a new labor and delivery nurse could potentially complete an entire clinical rotation or orientation period and not experience some of the common or high-acuity events that a nurse needs to come into contact with to be prepared to provide safe and effective care\" (112). Raines goes on to explain that \"Highfidelity\" birth simulators allow students \"to apply knowledge and skills used to assess and intervene in patient care situations\" (114). Absent from such analysis is any concern that medical professionals, nurses and obstetricians, alike, are likely to complete their medical training without having witnessed a normal birth, a birth that did not require medical intervention. One can certainly appreciate the desire to teach healthcare workers to practice medical techniques without threatening the safety of the \"patient\" (Raines 114). However, viewed through the lenses of ecofeminism and traditional midwifery, the ways that such birth simulators are being implemented tends to perpetuate a dualistic conceptualization of women and birth, in which birthing women and the natural world are backgrounded and dominated, while medical professionals are pushed to the foreground as birthing agents. Arguably, mannequin birth simulators epitomize and, thus, recapitulate the medical conceptualization of birth as a project that relies upon the supervision, technological control, and skill of the medical authorities rather than mothers and natural processes. \u2026",
        "year": 2012,
        "url": "https://www.semanticscholar.org/paper/85642f5c93fa29e339bf27223f1f2c67147e29cf",
        "citation_count": 4
    },
    {
        "title": "Abstract 39: Development of a Hypoglycemia Prediction Model for Veterans With Diabetes Using Supervised Machine Learning Applied to Electronic Health Record Data",
        "abstract": "Accurate assessment of hypoglycemia risk is critical for treatment selection in individuals with diabetes and cardiovascular disease (CVD) - patients for whom hypoglycemia is particularly harmful. We developed and validated a hypoglycemia prediction model in diabetes patients with and without CVD using data routinely available in electronic health records (EHR) and compared performance to a published prediction model. We studied 128,893 US Veterans with diabetes and angiographic assessment of CVD from 2005 to 2018. We used a random 2/3 of the sample for model development and the remaining 1/3 for validation. The primary outcome was severe hypoglycemia based on a previously validated algorithm that uses diagnosis codes and glucose measurements. We evaluated 33 potential predictors, including demographics, diabetes-related variables, comorbidities, and CVD risk factors. We sequentially used two machine learning algorithms for model development. First, we used multivariable adaptive regression splines, which can accommodate interactions and non-linearities for continuous variables, to select predictors. Second, we used adaptive elastic net, which can accommodate time-to-event outcomes, to fit a model with the selected variables. We tested model discrimination using the area under the ROC curve (AUC) and calibration by plotting predicted versus observed event rates in the independent validation cohort. The best-fitting prediction model included 18 predictors; a history of hypoglycemia was the strongest predictor (Table). In external validation, AUC was 0.729 for 2-year events, and the slope of the calibration curve was 1.05, exceeding performance of the published model in this patient population for both discrimination and calibration (Table).\n \n Conclusions:\n Applying supervised machine learning to EHR data may provide an efficient approach to tailoring prediction of preventable clinical outcomes, e.g., hypoglycemia, for high risk patients receiving care in an integrated healthcare system.\n \n \n \n",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/856daff6720bb38ce915466dd8f7ccfe2747f3e6",
        "citation_count": 1
    },
    {
        "title": "Predicting Coronary Heart Disease Using a Suite of Machine Learning Models",
        "abstract": "Coronary Heart Disease affects millions of people worldwide and is a well-studied area of healthcare. There are many viable and accurate methods for the diagnosis and prediction of heart disease, but they have limiting points such as invasiveness, late detection, or cost. Supervised learning via machine learning algorithms presents a low-cost (computationally speaking), non-invasive solution that can be a precursor for early diagnosis. In this study, we applied several well-known methods and benchmarked their performance against each other. It was found that Random Forest with oversampling of the predictor variable produced the highest accuracy of 84%.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/85888ca4ca666fa778c5959c0000d8c17f16b906",
        "citation_count": 1
    },
    {
        "title": "An Adaptive Approach for Fake News Detection in Social Media: Single vs Cross Domain",
        "abstract": "The extensive use of online information platforms over traditional news media has amplified the dissemination of fake news. Supervised machine learning based techniques are being extensively used in the detection of fake news in Social Media. However, the performance of such models degrades in the case of cross-domain data scenarios. In this study, we empirically show that the performance of a model depends on the domain-specific and agnostic case. To conduct this study, we extracted the tweets based on the Afghanistan crisis and developed a dataset which we call \u2019FakeBan\u2019. The country has witnessed the sudden spread of misinformation where several actors are misusing it as ammunition, leading to far-flung troubling implications. We chose to study the most recent Afghanistan and experimented with three completely different domains widely involved in fake news: national crisis, healthcare, and politics. Several advanced datasets are already available in the domain of healthcare and politics. However, it takes a long time to build a labeled dataset based on a recent national crisis. We propose an adaptive fake news detection technique capable of selecting the model based on the domain (single or cross) and thus address the challenging issues arising from the voluminous and highly varied information available on social media. The results of our study affirm that in the case of domain-specific data, machine learning classifiers have performed well using a set of selected features out of twenty-one extracted features. In contrast, deep learning models, particularly the BERT model, have outperformed traditional machine learning classifiers in domain agnostic cases.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/85f4aa1bc7577cab4f96eb250e24ae3384987116",
        "citation_count": 1
    },
    {
        "title": "Machine Learning Algorithms for Disease Prediction Using IoT Environment",
        "abstract": "In the most advanced healthcare application environment, the use of IoT technologies brings convenience to medical professionals and patients, since they have applied to health areas. In IoT, Body sensor network (BSN) technology plays a vital role in the healthcare system where lightweight wireless and low-powered sensor nodes used for monitoring the patients. In this paper, we propose a healthcare system using IoT and BSN technology. This system includes various sensors like pulse rate sensor, temperature sensor, and blood pressure sensor. These sensors sense the parameters and send the data to the controller. According to the conditions, the buzzer will on as temperature exceeds the given range. It carries the sensed data to the LCD to display on it. At the same time, data send to doctors using the internet, so that they can give quick and proper solution in real-time. Many patients suffer because of not getting the timely and appropriate solution and help for their problem. Proposed system hence offers the real-time solution and help in case of emergency. This system is convenient; therefore, a person can carry it with them. Thus continuous health checking is possible. The system also predicts the disease for a particular patient base on current reading using various supervised learning algorithms",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/865e111b7c99909e5551165641d7d19dfaa129d6",
        "citation_count": 22
    },
    {
        "title": "DETERMINATION OF HEALTH CARE DISEASE USING DATA MINING TECHNIQUES",
        "abstract": "Data mining is the best technique for the enormous amounts of data processed and analyzed. Several data mining methodologies are existed and useful to transform these amount of data into useful information for making certain decision. Different classification data mining techniques produce different results for the same data set. Thus, finding the optimal algorithm for the given data set is a challenging task. The paper focuses on healthcare area where the aim is to analyzed diabetes patients via different supervised machine learning methods. The paper also shows an effective technique for detection of the diabetes disease where the outcome can be useful in selecting most suitable classifier for the given dataset. To determine the effectiveness of various classification algorithms like Linear Regression, Multilayer Perception, Gaussian Process, Simple Linear Regression, SMOreg, authors run some well-known classification algorithms against some standard datasets. Effectiveness of various algorithms is measured on various parameters like average accuracy, time taken to build classification model, mean absolute error, etc. Based on the comparative study of the experiment results, authors suggest the optimal algorithm.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/8689e94a553f5d8dfa51d4dee01846e9275ed7f8",
        "citation_count": 0
    },
    {
        "title": "Leveraging metabolic modeling to identify functional metabolic alterations associated with COVID-19 disease severity",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/86a78c4f5c02ee1dd69999a744c680595322a221",
        "citation_count": 9
    },
    {
        "title": "A supervised machine learning approach to predicting subjective cognitive decline (SCD) among diverse Hispanics/Latinos: The SOL\u2010INCA Study",
        "abstract": "Abstract Background Increasingly, research evidence is identifying subjective cognitive decline (SCD) as a precursor for cognitive impairment and dementia. Identifying predictors of SCD is essential for understanding its utility as a preclinical indicator for impairment and especially pertinent for Hispanics/Latinos who have limited access to healthcare resources and clinical diagnostics and are disproportionally affected by Alzheimer\u2019s disease and related dementias. We extend work on predictors of Mild Cognitive Impairment (MCI) in diverse Hispanics/Latinos in the US by modeling multidomain predictors of SCD. Method We use data (n = 4347, average baseline age = 56.4\u2010years) from the Hispanic Community Health Study/ Study of Latinos (HCHS/SOL; 2008\u20102011; Visit 1), a multisite prospective cohort study of diverse Hispanics/Latinos, and its ancillary study, the SOL\u2010Investigation of Neurocognitive Aging (SOL\u2010INCA; average 7\u2010years after Visit 1). Our outcome is a composite SCD measured at SOL\u2010INCA by averaging the component items of the Everyday Cognition (ECog\u201012) scale and is modeled using 37 cross\u2010domain Visit 1 indicators, previously linked to MCI, reflecting (1) sociodemographic characteristics, (2) childhood factors, (3) acculturation factors, (4) biological and (5) behavioral markers, and (6) mental and (7) functional health factors. We use supervised machine learning (ML: Random Forest = RF; regression = ML\u2010Reg) and standard statistical techniques (regression = Reg) for identifying leading predictors of SCD. In secondary analysis, we assess enhancement in predictive performance by accounting for Visit 1 global cognitive (GC) function. Result Our best performing (i.e., R\u2010squared) ML model (ML\u2010Reg) explained only 17% of the variance in SCD. Leading identified predictors of SCD included physical health scores, airflow obstruction, anxiety, mental health scores, Hispanic/Latino heritage, education, depression, income, and language and social acculturation. GC was predictive of SCD and explained an additional 5% of the variance. Conclusion Our findings indicate that multidomain factors contribute to SCD prediction, but the explained variance was relatively low. Biological markers, previously linked to MCI in our cohort, played a less significant role. Notably, the fit of the ML models for SCD was low relative to MCI specific models in the same population. Follow\u2010up work investigates how incorporating contemporaneous measures of the factors (vs. baseline alone) may improve the predictive capacity of the ML models.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/86b962f2badddcf1264b5cf986098a77fd75cdf7",
        "citation_count": 0
    },
    {
        "title": "Secure and Reliable ML-based Disease Detection for a Medical Wireless Body Sensor Networks",
        "abstract": "The recent development of the Internet of Things (IoT) has enabled a significant technology that aids quick healthcare solutions through the use of smart wearables sensors. Indeed, undesirable events and network threats can appear in any physiological recording in Wireless Body Sensor Networks (WBSN), leading to a misdiagnosis. These events and threats are recognizable by experienced medical staff, thereby it is necessary to identify them before making any diagnosis. In this paper, a secure and energy efficient approach is proposed. For disease detection, our research provide insight into several physiological signals, including the ElectroCardioGram (ECG), ElectroMyoGram (EMG), and Blood Pressure (BP), where the security is achieved by the application of the Advanced Encryption Symmetric (AES) and the Secure Hash Algorithm (SHA). Similarly, to obtain a reasonable range of reliability, a classification procedure based on supervised Machine Learning (ML) techniques is used. The simulation results proved the accuracy and sensitivity of the system by 97% and 92%, respectively by enhancing a high level of security. Moreover, a suitable prototype is developed for medical staff to ensure the applicability of our proposal.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/86ef1508fdc2309e8eb0ba461fec049955d5280a",
        "citation_count": 4
    },
    {
        "title": "Securing Electronic Health Records from Insider Threats in Smart City Healthcare Cloud Using Machine Learning Approach",
        "abstract": "In recent years, healthcare in smart cities is considered as significant to create a more resilient and well-informed healthcare ecosystem. The integration of cloud computing in healthcare industry has facilitated the storage and sharing of electronic health records (EHRs), enabling seamless access to medical information. However, this transition to cloud-based systems has introduced new security challenges, particularly the risk of insider threats. Insiders with authorized access to cloud-based EHR systems, such as healthcare professionals and cloud service providers, may exploit vulnerabilities or misuse sensitive patient data, leading to privacy breaches and unauthorized disclosure. This research work presents an innovative approach to securing EHRs from insider threats in the cloud using Gaussian Mixture Model and Classification algorithms. These techniques analyze user behaviour patterns and detect anomalous activities that may indicate insider threats. Here UK hospital electronic patient health record data set is used to conduct the experiments. The proposed approach comprises two key stages. In the initial stage, the unsupervised Gaussian Mixture Model is utilized to find the abnormal patterns in the dataset and label each record in the dataset as normal or anomaly. The second stage involves different supervised classification algorithms namely SVM, KNN, DT, NB and RF are used to classify the new instance. The results demonstrate that the Random Forest (RF) achieves high accuracy in detecting insider threats with an accuracy of 99.97%. The findings of this research contribute to the field of healthcare data security by offering an intelligent and proactive solution for mitigating insider threats to cloud-based EHRs in Smart city environments.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/874627e145bf8a173191c79c0870d2e717486a25",
        "citation_count": 0
    },
    {
        "title": "Developing and Evaluating a Machine Learning Based Diagnosis System for Diabetes Mellitus using Interpretable Techniques",
        "abstract": "Diabetes is a major global health issue that affects multiple bodily components and contributes to millions of deaths each year. Traditional approaches to diabetes diagnosis and treatment are often limited by their lack of accuracy, transparency, and efficiency. This study aims to develop and evaluate a novel machine learning-based diagnosis system for diabetes mellitus using interpretable supervised and neural network techniques. The study used a dataset of 9 features listed in 2000 patient information from The Frankfurt Hospital, Germany, and trained and tested several ML algorithms including logistic regression, gradient boosting, naive Bayes classifier, random forest classifier, and artificial neural network (ANN). The performance of each algorithm was evaluated using precision, recall, and F1-score, and the findings indicate that the ANN model performs best with a larger number of features, achieving 100% accuracy. Interpretable techniques were used to facilitate understanding of the ML model decision-making process. The suggested system offers several implications and potential impacts on healthcare practice, including improved diagnosis accuracy, automation of diabetes testing and referral algorithms, and reduced time, work, and labor in medical services. These findings highlight the potential of machine learning to address the limitations of traditional diabetes diagnosis and treatment, and contribute to better patient outcomes.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/877a1d2c155284bb2de665a4f059486188535303",
        "citation_count": 0
    },
    {
        "title": "Automated disease diagnosis and precaution recommender system using supervised machine learning",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/87833f9c08ac1f2af907ed4de0ca55a6b5e5129c",
        "citation_count": 17
    },
    {
        "title": "An expert clinical decision support system to predict disease using classification techniques",
        "abstract": "Currently in the healthcare industry different data mining methods are used to mine the interesting pattern of diseases using the statistical medical data with the help of different machine learning techniques. The conventional disease diagnosis system uses the perception and experience of doctor without using the complex clinical data. The proposed system assists doctor to predict disease correctly and the prediction makes patients and medical insurance providers benefited. This research focuses on to diagnosis diabetes disease as it is a great threat to human life worldwide. The system uses the Decision Tree and K-Nearest Neighbor (KNN) Algorithms as supervised classification model. Finally, the proposed system calculates and compares the accuracy of C4.5 and KNN and the experimental result demonstrates that the C4.5 provides better accuracy for diagnosis diabetes. For the clinical database, the Pima Indians Dataset is used in this research.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/87e1ff88fbcb02dfea73b858ea5f6bbd55d6dc4e",
        "citation_count": 89
    },
    {
        "title": "Artificial Intelligence Technologies in Cardiology",
        "abstract": "As the world produces exabytes of data, there is a growing need to find new methods that are more suitable for dealing with complex datasets. Artificial intelligence (AI) has significant potential to impact the healthcare industry, which is already on the road to change with the digital transformation of vast quantities of information. The implementation of AI has already achieved success in the domains of molecular chemistry and drug discoveries. The reduction in costs and in the time needed for experiments to predict the pharmacological activities of new molecules is a milestone in science. These successful applications of AI algorithms provide hope for a revolution in healthcare systems. A significant part of artificial intelligence is machine learning (ML), of which there are three main types\u2014supervised learning, unsupervised learning, and reinforcement learning. In this review, the full scope of the AI workflow is presented, with explanations of the most-often-used ML algorithms and descriptions of performance metrics for both regression and classification. A brief introduction to explainable artificial intelligence (XAI) is provided, with examples of technologies that have developed for XAI. We review important AI implementations in cardiology for supervised, unsupervised, and reinforcement learning and natural language processing, emphasizing the used algorithm. Finally, we discuss the need to establish legal, ethical, and methodical requirements for the deployment of AI models in medicine.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/87e925481abbb3781f6bfbb70d5c33453ca2ecb1",
        "citation_count": 24
    },
    {
        "title": "We must oppose lethal autonomous weapons systems.",
        "abstract": "As advancements in machine learning and artificial intelligence (AI) continue at an ever-increasing rate, there are growing concerns over the potential development of lethal autonomous weapons systems (LAWS), commonly known as \u2018killer robots\u2019.1 Such systems are defined as any weapon capable of targeting and initiating the use of potentially lethal force without direct human supervision and direct human involvement in lethal decision making.2 Several countries, including the UK, are developing these weapons for military use, setting the stage for an imminent arms race. The emergence of these technologies would represent the complete automation of lethal harm, which AI experts fear would mark a third revolution in warfare, following gunpowder and nuclear weapons.3 LAWS would radically violate the ethical principles and moral code that are integral to our profession, necessitating urgent and collective action from the entire healthcare community.\n\nThe prospect of a world with LAWS generates ethical, legal, and diplomatic apprehensions. These technologies would bring dire humanitarian consequences and geopolitical destabilisation. They would make possible the \u2026",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/87eedf9b4b6c6130b9356f0d195df0ca88dce373",
        "citation_count": 2
    },
    {
        "title": "A clinical decision support system for heart disease prediction with ensemble two-fold classification framework",
        "abstract": "Cardiovascular disease (CVD) is a severe public health concern globally. Early and accurate CVD diagnosis is a difficult task but a necessary endeavour required to prevent further damage and protect patients\u2019 lives. Machine Learning (ML)-based Clinical Decision Support Systems (CDSS) have the potential to assist healthcare providers in making accurate CVD diagnoses and treatments. Clinical data usually contains missing values (MVs); hence, the incorporated imputation techniques for ML have become a critical consideration when working with real-world medical datasets. Furthermore, removing instances with MVs will lead to essential data loss and produce incorrect results. To overcome these issues, this paper proposes an efficient and reliable CDSS with Ensemble Two-Fold Classification (ETC) framework for classifying heart diseases. The effectiveness of the proposed ETC framework using different supervised ML algorithms is evaluated with four distinct imputation methods for handling MVs over the standard benchmark dataset, viz., the University of California, Irwin (UCI). Experimental results show that our proposed ETC framework with the k-Nearest Neighbors(k-NN) imputation method achieves better classification accuracy of 0.9999 and a lesser error rate of 0.0989 compared to other imputation methods and classifiers with similar execution times.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/87faea98e7a65c332c16b4c5bfe6551f87232fd7",
        "citation_count": 0
    },
    {
        "title": "Cardiovascular Disease Prediction Using Machine Learning",
        "abstract": "Heart disease-related deaths have become a big issue in today's world, with one person dying from the disease every minute. It considers both male and female groups, and the ratio varies by location. It is also used for the 25-69 age group. This isn't to say that people of all ages will be affected by heart disease. This condition could start in the early stages of life, and predicting the source and sickness is currently a huge challenge. Heart disease is one of the world's most fatal problems, one that cannot be seen with the naked eye and manifests itself as soon as it reaches its limits. As a result, precise diagnosis at the right moment is necessary. Every day, the health-care business generates massive amounts of patient and illness-related data. Researchers and practitioners, on the other hand, do not make appropriate use of this data. Despite its lack of knowledge, the healthcare business now has a wealth of data. In data mining and machine learning, there are a variety of approaches and tools for extracting usable information from databases and using that information to make more accurate diagnoses and decisions. So, in order to detect such disorders in time for adequate treatment, a reliable, precise, and feasible approach is required. In the realm of medicine, machine learning algorithms and approaches have been used to process enormous data sets. Researchers employ a variety of data mining and machine learning approaches to analyse large data sets and aid in the accurate prediction of cardiac illnesses. This research compares and contrasts the Nave Bayes, Help Vector Machine, Random Forest, and supervised learning models to find the most successful algorithm. When compared to other algorithms, Random Forest has95.08 per cent more precision.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/881e8574a6c1e5daa9f362d67d1003b4df407901",
        "citation_count": 0
    },
    {
        "title": "Evaluating multiple models using labeled and unlabeled data",
        "abstract": "It remains difficult to evaluate machine learning classifiers in the absence of a large, labeled dataset. While labeled data can be prohibitively expensive or impossible to obtain, unlabeled data is plentiful. Here, we introduce Semi-Supervised Model Evaluation (SSME), a method that uses both labeled and unlabeled data to evaluate machine learning classifiers. SSME is the first evaluation method to take advantage of the fact that: (i) there are frequently multiple classifiers for the same task, (ii) continuous classifier scores are often available for all classes, and (iii) unlabeled data is often far more plentiful than labeled data. The key idea is to use a semi-supervised mixture model to estimate the joint distribution of ground truth labels and classifier predictions. We can then use this model to estimate any metric that is a function of classifier scores and ground truth labels (e.g., accuracy or expected calibration error). We present experiments in four domains where obtaining large labeled datasets is often impractical: (1) healthcare, (2) content moderation, (3) molecular property prediction, and (4) image annotation. Our results demonstrate that SSME estimates performance more accurately than do competing methods, reducing error by 5.1x relative to using labeled data alone and 2.4x relative to the next best competing method. SSME also improves accuracy when evaluating performance across subsets of the test distribution (e.g., specific demographic subgroups) and when evaluating the performance of language models.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/883cd91d70a1391f78b35421290173ade21e90db",
        "citation_count": 0
    },
    {
        "title": "Prediction of Pregnancy-Induced Hypertension Levels Using Machine Learning Algorithms",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/8887d8e7dfb9e413973497f47ecdccb6b39c119f",
        "citation_count": 2
    },
    {
        "title": "Prediction Models for Diabetes Mellitus Incidence",
        "abstract": ": Diabetes mellitus is an incurable disease with global prevalence and exponentially increasing incidence. It is one of the greatest health hazards of the twenty-first century which poses a great economic threat on many nations. The premise behind effective disease management in healthcare system is to ensure coordinated intervention targeted towards reducing the incidence of such disease. This paper presents an approach to reducing the incidence of diabetes by predicting the risk of diabetes in patients. Diabetes mellitus risk prediction model was developed using supervised machine learning algorithms of Na\u00efve Bayes, Support Vector Machine and J48 Decision Tree. The decision tree was able to give a prediction accuracy of 95.09% using rules of prediction that give acceptable results, that is, the model was approximately 95% accurate. The easy-to-understand rules of prediction got from J48 decision tree make it excellent in developing predictive models.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/889aa3ff6380932e9df26fd69d944252ab0f39be",
        "citation_count": 1
    },
    {
        "title": "Introduction of Reinforcement Learning and Its Application Across Different Domain",
        "abstract": "In the modern era of rapid development in Deep Neural Networks, Reinforcement Learning (RL) has evolved into a pivotal and transformative technology. RL, a learning process where these machine agent interacts with several unknown environment through trial and error. The agent, responsive to the learning machine, go through these interaction, and start receiving feedback in the form of positive rewards or negative rewards like penalties from the environment, and constantly refines its behavior. This research paper offers an in-depth introduction to the foundational concepts of RL, focusing on Markov Decision Processes and various RL algorithms.\nMachine Learning (ML) is a subset of Artificial Intelligence, which deals with \u2018\u2018the question of how to develop software agents (Machine) that improve automatically with experience\u2019\u2019. The basic three categories of Machine Learning are.\n\nSupervised Learning\nUnsupervised Learning\nReinforcement Learning\n\nRL method is that in any situation the agent has to choose between using its acquired knowledge of the environment i.e. using an action already tried or performed previously or exploring actions never tried before in that situation.\nIn this review paper, we will discuss the most used learning algorithms in games robotics and healthcare, autonomous control as well as communication and networking, natural language processing.[1]",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/890d4178302b1d54c1c2ceb6748758a0279b5d5a",
        "citation_count": 0
    },
    {
        "title": "Evaluation of Sentiment using Deep Learning and Machine Learning using Word Integration Techniques",
        "abstract": "Sentiment analysis involves deciphering contextual sentiments from textual data, which may originate from various sources such as social media posts, comments, reviews, blogs, tweets, and news articles. This process begins with text preprocessing techniques like stop word removal, lemmatization, and stemming, preparing the text for further analysis. Subsequently, the preprocessed text undergoes transformation into vectors via word embedding techniques, facilitating the application of machine learning and neural network methodologies. Among these, Word2vec and Skip-gram have emerged as effective supervised learning techniques, while GLoVe stands out in the unsupervised learning domain. Additionally, Recurrent Neural Networks (RNNs) and Convolution Neural Networks (CNNs) represent the deep learning approaches for analyzing textual data. This paper delves into how these machine learning and deep learning algorithms, applied within word embedding frameworks, can be instrumental in extracting features. These features can then be classified into positive, negative, or neutral sentiments, offering insights into the moral and ethical perspectives of individuals across various sectors, including business, politics, e-commerce, healthcare, and film reviews. Our findings indicate that deep learning methods surpass traditional machine learning in accuracy and effectiveness in predicting sentiments.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/89cea3412083d1feffe6ebba9da370d184771142",
        "citation_count": 0
    },
    {
        "title": "Semi-Supervised Learning for Sparsely-Labeled Sequential Data: Application to Healthcare Video Processing",
        "abstract": "Labeled data is a critical resource for training and evaluating machine learning models. However, many real-life datasets are only partially labeled. We propose a semi-supervised machine learning training strategy to improve event detection performance on sequential data, such as video recordings, when only sparse labels are available, such as event start times without their corresponding end times. Our method uses noisy guesses of the events\u2019 end times to train event detection models. Depending on how conservative these guesses are, mislabeled samples may be introduced into the training set. We further propose a mathematical model for explaining and estimating the evolution of the classification performance for increasingly noisier end time estimates. We show that neural networks can improve their detection performance by leveraging more training data with less conservative approximations despite the higher proportion of incorrect labels. We adapt sequential versions of CIFAR-10 and MNIST, and use the Berkeley MHAD and HMBD51 video datasets to empirically evaluate our method, and find that our risk-tolerant strategy outperforms conservative estimates by 3.5 points of mean average precision for CIFAR, 30 points for MNIST, 3 points for MHAD, and 14 points for HMBD51. Then, we leverage the proposed training strategy to tackle a real-life application: processing continuous video recordings of epilepsy patients, and show that our method outperforms baseline labeling methods by 17 points of average precision, and reaches a classification performance similar to that of fully supervised models. We share part of the code for this article at the following repository: fpgdubost/CIFAR-10-Sparsely-Labeled-Sequential-Data.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/89e4a9acf7b748a5cb950921a880ec3141ab9be5",
        "citation_count": 0
    },
    {
        "title": "Detecting Visually Observable Disease Symptoms from Faces",
        "abstract": null,
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/8a336e9a4c42384d4c505c53fb8628a040f2468e",
        "citation_count": 26
    },
    {
        "title": "Predicting Adverse Interactions: A Comprehensive Review of AI-Driven Drug-Drug Interaction Models for Enhanced Patient Safety",
        "abstract": "The complexity of the additive medications in today's clinical practice demands sincere methods in determining the probable drug-drug interactions (DDIs) to ensure the safety of the patients. This research proposal focuses on an assessment of the use of AI models in forecasting DDIs to reduce the impact of adverse effects on patients' results. By using supervised machine learning (ML) techniques, we process large pharmacological datasets to find patterns that are associated with DDIs. The study uses the deep learning method, NLP property, and reinforcement learning processes to analyze complex dependency patterns in drug characteristics and interaction possibilities. Outcome analysis has shown that the AI models have better sensitivity and specificity scores, which confirms the models' superiority over the traditional rule-based systems in predicting DDIs. In addition, with the help of AI algorithms applied to EHR, it is possible to make predictions and obtain the alerts integrated into EHR helping healthcare professionals to make decisions. Therefore, this paper discusses how by developing a firmer groundwork for AI in pharmacovigilance, it is possible to improve patient safety and minimize the number of severe adverse consequences elicited by DDIs in a cost-effective manner. Future work will be mainly on fine-tuning the model for improving the accuracy of the models and further collection of data set to include all possible drug interactions. This is true due to the discovery of the capabilities of AI as shown in the respective fields of medicine with more secure and distinct medical informatics on the horizon.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8a425ba0e9fae9b004f3a1eb0c67ee3d780556f2",
        "citation_count": 0
    },
    {
        "title": "Identifying Risks in Cardiovascular Disease using Supervised Machine Learning Algorithms",
        "abstract": "Detecting and predicting any disease is very important in these modern days, why because everyone is busy with their day to day life and no one is caring about their health and no one is following proper food diet and this recklessness leads to several diseases. Among all the diseases heart disease is a very severe disease. And one of the major reasons for heart disease is taking tobacco, drinking alcohol, and inactive in doing exercise, etc. The WHO (world health organization) records, it says that 31 million people lost their lives because of CVD (cardiovascular disease). So, there is a necessity for the prediction of heart disease before it attacks the person. There is a vast amount of data coming from healthcare industries and hospitals but humans like doctors or medical experts are not able to analyze that data so here comes machine learning to analyze that vast amount of data and gives better results. Form the past several year's researchers have found that machine learning works pretty well in analyzing the data so we came up with few machine learning algorithms like artificial neural networks(ANN), Random forest(RF), logistic regression, K-nearest neighbors(KNN), Naive Bayes(NB), Support vector machine(SVM), Decision tree(DT), etc. to predict the heart disease. And in this paper, we got results of various machine learning algorithms and we did the comparison among them.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/8a58bd4b35e672bca56356dc9d84ddd4fe5be60e",
        "citation_count": 5
    },
    {
        "title": "M-Health Android Application Using Firebase, Google APIs and Supervised Machine Learning",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/8a5d8f880428593483ba0b46eedb13bbdf7535e4",
        "citation_count": 2
    },
    {
        "title": "Fast homomorphic SVM inference on encrypted data",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/8acded290268973ce7260e7f1fa053788b84bf0e",
        "citation_count": 6
    },
    {
        "title": "Unstructured Data Abstraction utilizing Selective Prediction-Oriented Neural Networks in Healthcare Settings",
        "abstract": "This project focuses on revolutionizing the extraction of valuable insights from unstructured clinical data in healthcare. Many existing machine learning and deep learning models are supervised and thus require labeled data for training. Annotating unstructured clinical data can be challenging because of the task\u2019s cognitive complexity and the variability in the data quality. We aim to leverage a multi-layer perceptron (MLP) to parse through unstructured clinical narratives and output the statement of diagnosis, used by past work such as Conneau et al. (2020). Such tasks include natural language processing techniques such as text classification, information extraction, and selective prediction. This project to contribute to this immense potential for improving medical decision-making and patient care.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/8b00ecaeaf34702ebc3621ecab30b660bf90cd16",
        "citation_count": 0
    },
    {
        "title": "An application of a supervised machine learning model for predicting life expectancy",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8b3eafb284734478783f2a3df330a8395d63b84d",
        "citation_count": 5
    },
    {
        "title": "Analytical review on human activity recognition in video",
        "abstract": "The main motive of this review paper is to recognise the human activities in video using different posses and various types of activities done by human in video. To achieve this activity recognition author's used a different technique such as object segmentation, feature extraction and representation, Hidden markov model, bag of word approach. And some basic concepts of machine learning and algorithms such as supervised learning, clustering, Linear Discriminant analysis, Finite state automata, K-Nearest Neighbour have been used. The domain area for this analysis is surveillances, entertainment and healthcare environment. And the authors have collected the data for their analysis from various sources such as Youtube, movies, real human activities videos are collected from Railway stations, banks, hospitals, circus area specially which are under the camera notification.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/8b5474aedb0e9f7d4ab59edc7c48464adc8dbe68",
        "citation_count": 6
    },
    {
        "title": "Prediction of Lung Cancer Survival using Machine Learning Algorithms",
        "abstract": ": Recently, machine learning (ML), a subfield of artificial intelligence (AI), thrives in the healthcare system. It is widely accepted by healthcare practitioners that ML can revolutionize the decision-making procedure on diagnosis and prognosis of disease. ML reveals its importance by detecting key features from complex datasets based on routine clinical and laboratory evaluations. Through this process, predictive accuracy is computed, and reliable results are provided with the estimations of generalization errors. Significantly, such technical advantages of ML become further significant in cancer research. A more accurate prediction can provide curative treatments and prevent death by managing clinical procedures. In this study, we demonstrate the methods to predict the survival rate of advanced lung cancer patients by utilizing supervised machine learning methods. We identified the key features strongly associated with cancer survival from a publicly accessible dataset from the North Central Cancer Treatment Group (NCCTG). We hope this study follows up on the potential of ML technical applications used to prevent lung cancer death.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8c853da5e1647d88ef1a4d4d389791cc941d4ec1",
        "citation_count": 0
    },
    {
        "title": "Large language models in physical therapy: time to adapt and adept",
        "abstract": "Healthcare is experiencing a transformative phase, with artificial intelligence (AI) and machine learning (ML). Physical therapists (PTs) stand on the brink of a paradigm shift in education, practice, and research. Rather than visualizing AI as a threat, it presents an opportunity to revolutionize. This paper examines how large language models (LLMs), such as ChatGPT and BioMedLM, driven by deep ML can offer human-like performance but face challenges in accuracy due to vast data in PT and rehabilitation practice. PTs can benefit by developing and training an LLM specifically for streamlining administrative tasks, connecting globally, and customizing treatments using LLMs. However, human touch and creativity remain invaluable. This paper urges PTs to engage in learning and shaping AI models by highlighting the need for ethical use and human supervision to address potential biases. Embracing AI as a contributor, and not just a user, is crucial by integrating AI, fostering collaboration for a future in which AI enriches the PT field provided data accuracy, and the challenges associated with feeding the AI model are sensitively addressed.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8cb396d4db03070c2942a6e6f31d3c82579cb27f",
        "citation_count": 1
    },
    {
        "title": "Active Learning for LSTM-autoencoder-based Anomaly Detection in Electrocardiogram Readings",
        "abstract": "Recently, the amount of generated time series data has been increasing rapidly in many areas such as healthcare, security, meteorology and others. However, it is very rare that those time series are annotated. For this reason, unsupervised machine learning techniques such as anomaly detection are often used with such data. There exist many unsupervised algorithms for anomaly detection ranging from simple statistical techniques such as moving average or ARIMA till complex deep learning algorithms such as LSTM-autoencoder. For a nice overview of the recent algorithms we refer to read [2,1]. Difficulties with the unsupervised approach are: defining an anomaly score to correctly represent how anomalous is the time series, and setting a threshold for that score to distinguish between normal and anomaly data. Supervised anomaly detection, on the other hand, needs an expensive involvement of a human expert. An additional problem with supervised anomaly detection is usually the occurrence of very low ratio of anomalies, yielding highly imbalanced data. In this extended abstract, we propose an active learning extension for an anomaly detector based on a LSTM-autoencoder. It performs active learning using various classification algorithms and addresses data imbalance with oversampling and under-sampling techniques. We are currently testing it on the ECG5000 dataset from the UCR time series classification archive [3].",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/8cdbb2773a6380f313559df8b0e5d6919b4efa6f",
        "citation_count": 2
    },
    {
        "title": "Bridging Data Gaps: Predicting Sub-national Maternal Mortality Rates in Kenya Using Machine Learning Models",
        "abstract": "Introduction Maternal mortality remains a critical global health issue, with ongoing efforts to reduce its incidence as part of international health priorities. Kenya, a sub-Saharan country that has a disproportionate number of maternal mortality is likely to miss this target unless evidence-based interventions are deployed. The paucity of reliable maternal health data calls for the development of alternative predictive models to complement the impaired civil registration system and the aperiodic national surveys. Methods We utilized DHS surveys from several Sub-Saharan African countries to estimate parameters for predicting Kenya\u2019s maternal mortality rate (MMR) in the absence of recent Kenya Demographic and Health Survey (KDHS) data. We developed a multiple linear regression model using supervised machine learning using the R-programming suite. Our model leverages machine learning techniques to analyze regional trends and predict sub-national MMR variations. We then applied the model to predict MMR for Kenyan counties using the data for the KDHS 2022 survey. Results Using Pearson\u2019s correlation, we observed a significant positive correlation between MMR and total fertility (r = 0.32, p = 0.025) and a significant negative correlation between MMR and maternal age at first birth (r = -0.40, p = 0.005). Additionally, a significant correlation was observed with the cumulative percentage of mothers attending post-natal clinics, the prevalence of thinness (r = 0.77, p < 0.001), HIV infection in women (r = 0.20, p = 0.164), and physical violence during pregnancy. The model estimate of national MMR in 2022 was 367 deaths per 100,000 live births, ranging from 49 deaths per 100,000 live births in Kisii County to 1794 deaths per 100,000 live births in Turkana County. Conclusion Although MMR in Kenya displayed a general downward trend, our model\u2019s estimates for DHS 2022 indicate an increase compared to the 2019 National Census and Housing Survey estimate of 355 deaths per 100,000 live births. This rise may be attributed to COVID-19-related maternal deaths during the same period. The integration of predictive models to inform interventions and resource allocation could play a crucial role in enhancing maternal healthcare outcomes in Kenya.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8d3c22a23f0289819a3cfaed37155239dbfbcb9c",
        "citation_count": 1
    },
    {
        "title": "Enhanced ResNet-18: A Novel Approach for Automated Classification and Early Detection of Eye Diseases",
        "abstract": "Eye disease classification is a topic of much concern among states worldwide. The object is to apply advanced algorithms developed on the basis of research to a variety of previous models and thus make them more flexible in an attempt to accurately diagnose all sorts of eye diseases using photographs as evidence. This paper adopted the methods of machine learning and computer vision to classify images for four types of eye disorders: cataract, diabetic retinopathy, glaucoma, and normal conditions. In this study, we retrained ResNet-18 with a learning rate of 5x10^-5 within the ResNet-18 block and 8x10^-4 for additional dense layers. The performance of our model was excellent, with an overall accuracy of 0.86. Especially notable was that the model had high precision, recall, and F1-score for diabetic retinopathy cataract. But for other glaucoma groups, it scored markedly lower on these metrics. These results clearly suggest the potential of the model for early discovery, diagnosis, supervision, and treatment plans for eye diseases and will thus be of immense benefit to human society in general as well as individual medical treatments. This will contribute to society by contributing positively to the general level of medical care. Doctors and nurses everywhere are using these results as a general reference manual, aiming for high-quality outcomes at a reasonable cost throughout the healthcare industry.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8d3fce1b3921004664fe941e88bd11dc28d8d5e9",
        "citation_count": 0
    },
    {
        "title": "Liver Disease Prediction Using Machine Learning",
        "abstract": "Due to the rapid rise in liver illness caused by excessive alcohol use, drug use, tainted food, and pickled food packaging, a doctor can make an automatic forecast with the aid of a medical expert system. Early liver disease prediction is now attainable because to the consistent advancements in machine learning technology, allowing for simple early identification of the fatal condition. This will make healthcare more beneficial, and a medical expert system can be employed in a remote location. The liver is vital to life and promotes the body's ability to rid itself of poisons. Early detection of the condition is therefore crucial for recovery. many machine learning techniques, including supervised, unsupervised, and supervised, Reinforcement SVM, KNN, K- Mean clustering, neural networks, decision trees, and other learning techniques for diagnosing liver disease and providing varying accuracy, precision, and sensitivity.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8d76b9e94ef0d4c48e5ec2e3a3bd779d3b624580",
        "citation_count": 1
    },
    {
        "title": "Stack Ensemble Oriented Parkinson Disease Prediction Using Machine Learning Approaches Utilizing GridSearchCV-Based Hyper Parameter Tuning.",
        "abstract": "Since the coronavirus came into existence and brought the entire world to a standstill, there have been drastic changes in people's lives that continue to affect them even as the pandemic recedes. The isolation reduced physical activity and hindered access to non-COVID related healthcare during lockdown and the ensuing months brought increased attention to mental health and the neurological disorders that might have been exacerbated. One nervous system disorder that affects the elderly and needs better awareness is Parkinson's disease. We have machine learning and a growing number of deep learning models to predict, and detect its onset; their scope is not completely exhaustive and can still be optimized. In this research, the authors highlight techniques that have been implemented in recent years for prediction of the disease. Models based on the less redundantly used classifiers-naive Bayes, logistic regression, linear-support vector machine, kernelizing support vector machine, and multilayer perceptron-are initially implemented and compared. Based on limitations of the results, an ensemble stack model of hyper-tuned versions using GridSearchCV out of the top performing supervised classifiers along-with extreme gradient boosting classifier is implemented to further improve overall results. In addition, a convolutional neural network-based model is also implemented, and the results are analyzed using two epoch values to compare the performance of deep learning models. The benchmark datasets-UCI Parkinson's data and the spiral and wave datasets-have been used for machine and deep learning respectively. Performance metrics like accuracy, precision, recall, support, and F1 score are utilized, and confusion matrices and graphs are plotted for visualization. 94.87% accuracy was achieved using the stacking approach.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/8d91c781e9d60a6efe66862afec772846e33253b",
        "citation_count": 2
    },
    {
        "title": "Healthcare Provider Summary Data for Fraud Classification",
        "abstract": "Fraud, waste, and abuse are spreading throughout the healthcare industry and costing patients and taxpayers billions of dollars. Fortunately, electronic medical records and publicly available data sources like the Centers for Medicare & Medicaid Services (CMS) have enabled data mining and machine learning techniques that can help automate the detection of healthcare fraud. In this study, we explore the application of healthcare provider summary data for the purpose of fraud detection. We leverage the latest CMS Part B Summary by Provider big data sets to curate two new labeled data sets for supervised learning. The two new data sets are compared to a popular baseline data set from related works using six runs of cross validation with two popular ensemble learners, multiple complementary performance metrics, and statistical tests. Classification results show that the proposed provider summary features are good indicators of healthcare fraud. A two-way analysis of variance test and 95% confidence intervals show that the new features yield significantly better performance on the fraud detection task when used to enrich existing data sets. Finally, feature contributions are measured with Shapley values to illustrate the top 20 features that contribute to fraud estimation.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/8db227ec371adc62dd267a0ca8d415e31d6feb0b",
        "citation_count": 1
    },
    {
        "title": "Behavioural Risk Factor Surveillance of Diabetes Using Supervised Learning",
        "abstract": "The CDC conducts the Behavioral Risk Factor Surveillance System (BRFSS) annually, a health-related telephone survey, gathering responses from more than 400,000 Americans since 1984. It focuses on health-related risk behaviors, chronic conditions, and the use of preventive services. In study, we utilized a CSV dataset from Kaggle for the year 2015, containing 253,680 survey responses to the BRFSS2015. The dataset comprises 21 feature variables derived from questions posed to participants or calculated from their responses. The target variable, Diabetes binary, categorizes individuals as having either no diabetes (0) or prediabetes/diabetes (1). The dataset is imbalanced, reflecting real-world distributions of health conditions. We utilized a range of machine learning algorithms, including decision trees, logistic regression, gradient boosting machine, random forest, k-nearest neighbors, support vector machines, XGBoost, Naive Bayes, feed-forward neural networks, and Ada Boost, to predict diabetes status based on the provided features. Evaluation metrics like accuracy, F1-score, and confusion matrices were employed to assess model performance across different algorithms. Through this analysis, our goal is to offer insights into the effectiveness of different machine learning techniques in predicting diabetes and highlight the significance of feature selection and model evaluation in healthcare applications.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8db71e549686463e654b2f0c2e32f3cdff560204",
        "citation_count": 0
    },
    {
        "title": "Privacy Protection of Healthcare Data over Social Networks Using Machine Learning Algorithms",
        "abstract": "With the rapid development of mobile medical care, medical institutions also have the hidden danger of privacy leakage while sharing personal medical data. Based on the k-anonymity and l-diversity supervised models, it is proposed to use the classified personalized entropy l-diversity privacy protection model to protect user privacy in a fine-grained manner. By distinguishing solid and weak sensitive attribute values, the constraints on sensitive attributes are improved, and the sensitive information is reduced for the leakage probability of vital information to achieve the safety of medical data sharing. This research offers a customized information entropy l-diversity model and performs experiments to tackle the issues that the information entropy l-diversity model does not discriminate between strong and weak sensitive features. Data analysis and experimental results show that this method can minimize execution time while improving data accuracy and service quality, which is more effective than existing solutions. The limits of solid and weak on sensitive qualities are enhanced, sensitive data are reduced, and the chance of crucial data leakage is lowered, all of which contribute to the security of healthcare data exchange. This research offers a customized information entropy l-diversity model and performs experiments to tackle the issues that the information entropy l-diversity model does not discriminate between strong and weak sensitive features. The scope of this research is that this paper enhances data accuracy while minimizing the algorithm's execution time.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/8dce7978ad10e7587283900a8ba29e426a2bbdc0",
        "citation_count": 18
    },
    {
        "title": "Application of Machine Learning Algorithm: Forecasting Heart disease",
        "abstract": "The healthcare industry produces a huge amount of complex data about patient records. This data can be processed and mined to uncover hidden patterns, which will provide professionals in the healthcare field with additional information and help them in making better informed decisions. Using data in such a way is known as data mining. One such area in the healthcare industry where data mining can be used is early prediction of heart diseases so that patients can get the appropriate treatment. This paper compares the efficiencies of the following supervised machine learning models: Logistic Regression, Na\u00efve Bayes, Support Vector Machine, K-Nearest Neighbors, Decision Tree, Neural Networks, Random Forest. It was found that the Neural Networks algorithm provides the highest accuracy of 81.32%.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8dd9cd694242d0eec3d032a276befd2463ced9a5",
        "citation_count": 1
    },
    {
        "title": "Positive feedback loops lead to concept drift in machine learning systems",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8e96f9710158ec123f8d007ba80116f483258a4f",
        "citation_count": 2
    },
    {
        "title": "CLOUD BASED PATIENT PRIORITIZATION AS A SERVICE IN THE PUBLIC HEALTH SECTOR OF THE DEVELOPING WORLD",
        "abstract": "Cyber-healthcare has recently emerged as a new field of medicine that builds on the advances made in sensor/actuator and RFID technologies. It is aimed at expanding Cybermedicine beyond the sole consultation of virtual patients by Cyber doctors through the Internet. It provides new opportunities for enhancing health care in the developing world through low acquisition costs and flexible deployment, while improving accuracy by replacing manual operations by fully digitized processes. This paper proposes and evaluates the performance of a Cyber-healthcare system which is aimed at providing patient prioritization over the cloud as a public health service for the rural and urban communities of the developing world. We propose a deployment model for the proposed Cyber-healthcare system, and describe a patient prioritization process as part of its situation recognition component. The results obtained from a real experimental implementation reveal the field readiness of the off-the-shelf bio-sensor technology used by the system and the relative communication capabilities provided by the IEEE802.11 and IEEE802.15.4 protocols when deployed on the indoor and outdoor links of the implemented system. The relative efficiency of using supervised machine learning compared to unsupervised machine learning when performing patient prioritization, is also revealed through two popular algorithms: support vector machine and K-means clustering algorithms.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/8ec28ff5494eb98eda8f307312d59043fc9150b2",
        "citation_count": 0
    },
    {
        "title": "Tutorial IV computational intelligence for data analytics",
        "abstract": "Humankind has been collecting data since the recording started, but in the last decade with the considerable advances in computing and storage technologies, advancements of cloud computing, development of ubiquitous connectivity and the internet of things, there has been explosion in the size and variety of collected data. Nevertheless, one can be data-rich and knowledge-poor, and this is where the data analytics and the development and application of machine learning models become necessity for gaining insight of complex processes to prove scientific theories and discoveries, support decision making and enhance strategic planning in different areas of the economy, finance, industry, healthcare, etc. Recently, there is an influx of polymorphic, unstructured and multimodal data - social media, images, audio, video, etc., which is complicating further the data processing and knowledge extraction process. But even the traditional structured datasets present problems that need to be addressed and overcome in the early stages of data pre-processing, feature extraction and feature selection. This is because they usually contain variety of data formats, e.g., categorical, continuous, ordinal, and frequently missing data (usually result of sensors faults, human errors, collection, transportation, or storage problems). The most popular approaches in dealing with missing data generally fall in three groups: Deletion methods; Single imputation methods; and Model-based methods. In this tutorial I will talk about the third group methods, which are considered to be the most popular, 'modem' model-based approaches. Particularly, Multiple imputation (MI) method will be introduced and discussed in addition to the K-Nearest Neighbour Imputation (KNN-I) and Bagged Tree Imputation (BTI). Subsequently, MI, KNN-I and BTl will be applied in a case study for pre-processing a real world radar signal large dataset (more than 30 000 samples). The dataset comprises intercepted and collected pulse train characteristics, which typically include signal frequencies, type of modulation, scan period, pulse repetition intervals, etc., and usually consist of mixture of continuous, discrete and categorical data, and also frequently include missing values. Missing values are imminent part of real world datasets and radar datasets make no exception of that. Then will briefly talk about supervised and unsupervised learning and the use of three supervised approaches: Neural Networks (NN); Random Forests (RF); and Support Vector Machines (SVM) for solving radar signal classification and source identification problem. Results from applying the NN, RF and SVM (using R and Matlab) on complete data subset (without missing data) and the full dataset with substituted (up to 60%) missing data with MI, KNN-I and BTl will be critically analysed and discussed. Finally, I'll talk about the opportunities and challenges in applying computational intelligence and machine learning techniques to Big Data and the available software for Big Data.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/8edb474ac92db95c4d825ac2578e3ae8692a5330",
        "citation_count": 0
    },
    {
        "title": "Data Science Application for Creation of Maternal Morbidity and Mortality Predictive Software",
        "abstract": "In Mexico, the estimated Maternal Mortality Ratio is 34.6 deaths per 100,000 estimated births. Consequently, healthcare facilities and services have given precedence to prenatal care, childbirth services, and postpartum care. In Mexico, the Ministry of Health maintains an open database concerning maternal deaths, encompassing 58 variables. Among these variables is the CIE (International Statistical Classification of Diseases and Related Health Problems), which covers a total of 248 diseases linked to maternal deaths. Currently, there is no software that classifies women undergoing pregnancy check-ups (according to their socio-clinical risk of mortality), using variables selected with data science. This project is rooted in the methodology advanced by International Business Machines (IBM) for the implementation of data science. The software's utilized model was constructed through the Na\u00efve Bayes supervised learning algorithm, yielding an accuracy of 0.7236. The overall precision stood at 0.75, with an overall recall of 0.74, and an overall F1-score of 0.71. For the eclampsia during labor class, precision reached 0.71, recall was 0.94, and the F1- score attained 0.81. As for secondary or late postpartum hemorrhage, precision scored 0.81, recall measured 0.43, and the F1-score was 0.56.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/8edea1aa2b5ef270417386ad32268c316affd6e6",
        "citation_count": 1
    },
    {
        "title": "Comprehensive Analysis of Multiple Diseases using Machine Learning",
        "abstract": "In the contemporary landscape of the healthcare industry, the pervasive integration of computer-based technology has resulted in the prolific accumulation of electronic health data. However, this abundance of information poses a significant challenge for medical professionals, impeding their ability to accurately analyze symptoms and promptly detect diseases. Addressing this issue, supervised Machine Learning (ML) algorithms have emerged as a promising solution, showcasing superior performance compared to traditional diagnostic methods. This literature review aims to discern patterns in disease diagnosis across various supervised ML models, with a specific focus on predicting fungal infections, diabetes, jaundice, malaria, and heart diseases. The model faces challenges in managing complex disease data, addressing class imbalances, and optimizing feature selection. Disease datasets present complexities in symptom-disease relationships, while imbalances in disease occurrences impact model accuracy. Among the myriad of algorithms explored, particular attention is directed towards the efficacy of Random Forest and Decision Trees. The proposed model aims to develop robust techniques for handling complex disease data, addressing class imbalances, and optimizing feature selection. These objectives target the improvement of disease prediction models, enhancing their accuracy and reliability for practical applications. Through an in-depth analysis of performance indicators, this study intends to contribute valuable insights into enhancing the diagnostic capabilities of healthcare professionals, facilitating early identification of high-risk conditions, and ultimately improving patient outcomes.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8ee86c46dae055894628e8621e7c17fb18969180",
        "citation_count": 0
    },
    {
        "title": "Machine learning-driven automatic storage space recommendation for object-based cloud storage system",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/8f01af6fa437cd96a005a3001ccbd798ab1993a8",
        "citation_count": 2
    },
    {
        "title": "Weakly Supervised Learning for Categorization of Medical Inquiries for Customer Service Effectiveness",
        "abstract": "With the growing unstructured data in healthcare and pharmaceutical, there has been a drastic adoption of natural language processing for generating actionable insights from text data sources. One of the key areas of our exploration is the Medical Information function within our organization. We receive a significant amount of medical information inquires in the form of unstructured text. An enterprise-level solution must deal with medical information interactions via multiple communication channels which are always nuanced with a variety of keywords and emotions that are unique to the pharmaceutical industry. There is a strong need for an effective solution to leverage the contextual knowledge of the medical information business along with digital tenants of natural language processing (NLP) and machine learning to build an automated and scalable process that generates real-time insights on conversation categories. The traditional supervised learning methods rely on a huge set of manually labeled training data and this dataset is difficult to attain due to high labeling costs. Thus, the solution is incomplete without its ability to self-learn and improve. This necessitates techniques to automatically build relevant training data using a weakly supervised approach from textual inquiries across consumers, healthcare professionals, sales, and service providers. The solution has two fundamental layers of NLP and machine learning. The first layer leverages heuristics and knowledgebase to identify the potential categories and build an annotated training data. The second layer, based on machine learning and deep learning, utilizes the training data generated using the heuristic approach for identifying categories and sub-categories associated with verbatim. Here, we present a novel approach harnessing the power of weakly supervised learning combined with multi-class classification for improved categorization of medical information inquiries.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/8f2ae46a9fb742c092b246bf8c9c1de1fccdd4b0",
        "citation_count": 5
    },
    {
        "title": "Human Activity Recognition Using Machine Learning",
        "abstract": "Nowadays, humans can recognize their daily activities by using smartphone activity recognition. Numerous studies have been conducted to identify activities, but for some reason, the classifiers\u2019 performance is poor due to various issues with the data or the classifiers themselves. This study provides a way to obtain the most effective classifiers. A comparative study was conducted to evaluate the performance of supervised and ensemble learning classifiers. In this study, a system that is based on the best-performing classifier is also introduced. Two publicly accessible datasets of recognized human activities from the UCI repository are used to assess the approach. The first is Human Activities based recognition and Postural Transitions, and the second is UCI-Human Activity Recognition. For this research study, the many different activities have been chosen like walking, standing, sitting, lying down, and upstairs. These input signals represent a challenging 3-dimensional raw data format. The Principal Elements In order to extract the most significant data features for the classification of human activities, the analysis (PCA) technique is used to reduce the dimensionalities of the data features. HAR involves the automatic identification and classification of human activities based on information which are collected from sensors, cameras, and wearable devices. It has become increasingly essential in healthcare for monitoring and early detection, in fitness and sports for performance tracking, and in security for suspicious behaviour identification.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8f3eda84298ac9fa8dc2104664a6b9903567e867",
        "citation_count": 0
    },
    {
        "title": "Detecting and Predicting Diabetes Using Supervised Learning: An Approach towards Better Healthcare for Women",
        "abstract": "This paper aims at Detecting Diabetes with PIMA Indian Diabetes Data-set. PIMA India is concerned with women\u2019s health. The risk of developing diabetes in Women is quite high due to various factors. Hence, the idea is to Detect and Predict this Disorder with the help of Machine Learning techniques-Support Vector Machine and Decision Trees respectively. The advantage of using these techniques is that it helps in automation of process and makes tasks like Classification, Clustering simpler. The Paper begins with the introduction and emphasize on the worst effect of the Diabetes by explaining various disorders associated with it brief Literature Survey is done to study the work done in it.Then,Section 3 describes the Proposed Approach with Pseudo Code in R Framework. The Framework is used here is R Studio for better analysis and Visualizations. Finally, Results are discussed with Conclusion and Future Scope.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/8f6606cf5c34cd2f5aeee4e639e0d8923ce6d559",
        "citation_count": 26
    },
    {
        "title": "Strategies for Reliable Stress Recognition: A Machine Learning Approach Using Heart Rate Variability Features",
        "abstract": "Stress recognition, particularly using machine learning (ML) with physiological data such as heart rate variability (HRV), holds promise for mental health interventions. However, limited datasets in affective computing and healthcare research can lead to inaccurate conclusions regarding the ML model performance. This study employed supervised learning algorithms to classify stress and relaxation states using HRV measures. To account for limitations associated with small datasets, robust strategies were implemented based on methodological recommendations for ML with a limited dataset, including data segmentation, feature selection, and model evaluation. Our findings highlight that the random forest model achieved the best performance in distinguishing stress from non-stress states. Notably, it showed higher performance in identifying stress from relaxation (F1-score: 86.3%) compared to neutral states (F1-score: 65.8%). Additionally, the model demonstrated generalizability when tested on independent secondary datasets, showcasing its ability to distinguish between stress and relaxation states. While our performance metrics might be lower than some previous studies, this likely reflects our focus on robust methodologies to enhance the generalizability and interpretability of ML models, which are crucial for real-world applications with limited datasets.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/8ffdb0dbb0aef7f8276a4ecda7be01e8cc070ed7",
        "citation_count": 5
    },
    {
        "title": "A Standardised Approach for Preparing Imaging Data for Machine Learning Tasks in Radiology",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/904d4d6128443dbf92257cdc814e0ee76c1039c1",
        "citation_count": 36
    },
    {
        "title": "Machine learning-based colorectal cancer prediction using global dietary data",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/907f149e2349e18496db218bc286a44f153dccef",
        "citation_count": 14
    },
    {
        "title": "265-OR: Identifying Adults at Risk of Unintentional Severe Hypoglycemia in Hospital Using Artificial Intelligence (RUSHH-AI)",
        "abstract": "Background: Machine learning carries great promise to improve healthcare delivery. Clinical outcomes that are routinely and objectively measured, and have serious consequences that can be prevented, are ideal targets for prediction and intervention. Hypoglycemia, defined as a blood glucose less than 3.9 mmol/L (70 mg/dL), meets these criteria. The purpose of this study was to predict hypoglycemia using artificial intelligence models in patients hospitalized to general internal medicine (GIM) and cardiovascular surgery (CV) at a tertiary-care teaching hospital in Toronto, Ontario. Methods: Models were built using routinely-collected clinical data from the hospital\u2019s electronic health record. Models were trained using data from Jan 2013-Apr 2017, tested using data from Apr 2017-Mar 2018, and validated using held-out test data from Apr 2018-Mar 2019. Three models were generated using supervised machine learning: LASSO regression, gradient boosted trees, and a recurrent neural network. Each model included baseline patient data and time-varying data. Natural language processing was used to incorporate text data from physician and nursing notes. Results: We included 8492 GIM admissions and 8044 CV admissions. The average age of patients was 68 years, 35% were women, the baseline creatinine was 90 \u03bcmol/L (1.0mg/dL) and the baseline A1C was 7%. Hypoglycemia occurred in 15% of GIM admissions and 13% of CV admissions. The area under the curve for the model in the held-out validation set was approximately 0.80 on the GIM ward and 0.82 on the CV ward. When the threshold for hypoglycemia was lowered to 2.9 mmol/L (52 mg/dL), similar results were observed. Among the patients at the highest decile of risk, the positive predictive value was approximately 50% and the sensitivity was 99%. Conclusion: Using natural language processing and machine learning we were able to accurately identify patients at high risk of hypoglycemia in hospital. Disclosure M. Fralick: None. D. Dai: None. C. Pou-Prom: None. A.A. Verma: None. M. Mamdani: None.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/90c1b49251b3ac26db280e0323805666daa2e041",
        "citation_count": 0
    },
    {
        "title": "A Supervised Machine Learning Approach using Different Feature Selection Techniques on Voice Datasets for Prediction of Parkinson\u2019s Disease",
        "abstract": "Among the neurological diseases, parkinson\u2019s disease is the second most common disease, which affect the old age people over the age of 65 year. It is also mentioned that the number of people affected with Parkinson\u2019s disease will increase at a higher rate until 2050, and it will be a rising concern to many developed countries because the cost due to the healthcare service of these disease is really high. Parkinson\u2019s disease (PD) belongs to the group of neurological disorder, which directly affect the brain cells and the effect is shown in terms of movement, voice and other cognitive disabilities. Past few years researchers are working for detection and monitoring of the Parkinson\u2019s disease by using the speech analysis as well as the gait analysis data. Machine learning and artificial intelligence techniques are gaining popularity because these techniques are able to automate the pattern recognition process with high accuracy.However so far, no body has compared the performance metrics using different feature sets by applying nonlinear and linear classification approaches based on the voice data. So, in this paper we have proposed a new approach by comparing the performance metrics with different feature sets such as genetic algorithm-based feature sets as well as Principal Component Analysis based feature reduction technique for selecting the feature sets. We have used different classification approaches to compare the performance metrics. We have found an accuracy of 97.57% using SVM with RBF by using genetic algorithm-based feature sets. This analysis will help the clinicians to differentiate the PD group from healthy group based on the voice data.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/90c479f028a58af04f6ba080a1e6e0b953558a00",
        "citation_count": 39
    },
    {
        "title": "BIOS-01. MACHINE LEARNING-BASED PREDICTION OF INPATIENT CARE COSTS FOR PATIENTS WITH BRAIN METASTASES: A REAL-WORLD ANALYSIS",
        "abstract": "\n \n \n Brain metastases (BMs) are increasingly a cause of significant cancer-related morbidity, mortality, and economic burden. While BM-related healthcare costs have been previously described, predictive analytics based on contemporary cohorts, particularly for inpatient care, remain unavailable. This study sought to evaluate inpatient care costs (IPCC) and associated reimbursements for patients with BMs and perform predictive modeling through supervised machine learning (sML) using a contemporary, commercial US claims database.\n \n \n \n This retrospective study, reported following STROBE and TRIPOD+AI reporting guidelines, included adult patients (aged 18-65 years) in the United States (US) with BMs included in the MarketScan Commercial Claims and Encounters Database who received inpatient care during January 2016 to December 2021. Eligible patients were identified using ICD-10 codes. IPCC measures were adjusted using the Medical Care component of the 2023 Consumer Price Index. The primary study outcome was total IPCC, represented by adjusted gross total payments. After log-transformation performed due to data skew, sML was carried out using Random Forest algorithm with 1000 iterations with a 70:30 training-test data split, followed by residual analysis and evaluation of predictive performance using root-mean-squared error (RMSE), out-of-bag error (OOBE), and calibration curve. Multivariable linear regression was carried out for sensitivity analyses.\n \n \n \n A total of 25117 unique inpatient admissions across 13477 BM patients were included, with median (IQR) age of 57 years (51-61). Gross median (IQR) CPI-medical-care-adjusted values per admission were: total payments $28,119.51 (16847.45-55111.67); hospital payments $24,678.74 (14601.66-47864.84); and payments to principal physician $884.80 (441.07-2434.15), being 3.6% (IQR 1.9-6.8) of total payment. Median inpatient length of stay was 4 days (IQR 2-8). ML model had an OOBE of 0.61 and, using test data, RMSE of 0.85, indicating robust performance. No major deviations were found on residual analysis.\n \n \n \n Contemporary IPCCs for BM patients in US are substantial but driven minimally by payments to principal physician. sML may be utilized to successfully predict IPCC for BM patients.\n",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/9127616d707416a8c808a80709c58352e788e6ce",
        "citation_count": 0
    },
    {
        "title": "Breast Cancer Detection: Unleashing The Power Of Artificial Intelligence",
        "abstract": ": With the use of artificial intelligence (AI) tools, notably machine learning algorithms, breast cancer diagnosis has advanced significantly. This study examines many approaches used in the diagnosis of breast cancer, with a particular emphasis on the use of convolutional neural networks (CNNs) for the analysis of mammography pictures. To create strong artificial intelligence (AI) models that can recognize minute anomalies suggestive of breast cancer, a series of steps including data collecting, pre-processing, training, validation, and testing are required. Early diagnosis, increased accuracy, increased speed and efficiency, tailored medication, support for radiologists, resource optimization, ongoing learning, and easier access to healthcare are among the goals of using AI in breast cancer detection. Healthcare professionals may enhance patient outcomes by using AI-powered technologies to speed the interpretation process, customize treatment regimens, and allocate resources optimally. Because of its ease of use and adaptability, the K-Nearest neighbours (KNN) algorithm stands out among the many machine learning algorithms investigated as being very promising for breast cancer prediction. Analyses comparing several algorithms, such as Random Forest, SVM, Decision Tree, and KNN, demonstrate how effective KNN is in detecting breast cancer. This study emphasizes how crucial it is to concentrate on creating AI models that can identify breast cancer in its early stages in order to facilitate prompt intervention and enhance patient outcomes. Prospective research avenues might encompass training models on extensive datasets containing annotated early-stage mammograms and investigating novel approaches such as transfer learning or weakly supervised learning to augment detection efficiency and accuracy even more.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/918dd6f24be4d95e5cdf08839d0e154a2fb4db4a",
        "citation_count": 0
    },
    {
        "title": "Algorithmic Approaches, Practical Implementations and Future Research Directions in Machine Learning",
        "abstract": "Machine learning has become a disruptive force that is advancing technology and changing industries. With an emphasis on algorithmic techniques, real-world applications, and important future research avenues, this study examines the rapidly changing field of machine learning. It explores the fundamentals of supervised, unsupervised, and semi-supervised learning algorithms and highlights how they are used in a variety of fields, including autonomous systems, healthcare, and finance. The report highlights the potential of several important future research directions, such as explainable AI, robust and privacy-preserving learning, quantum machine learning, and multimodal AI, to overcome present constraints and open up hitherto unheard-of possibilities. These multidisciplinary research avenues emphasize the value of interdisciplinary cooperation in addressing difficult problems and guaranteeing the creation of morally sound and significant AI systems. In order to help academics and practitioners who want to progress the subject, this review attempts to give a thorough grasp of the present situation and potential future direction of machine learning.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/918f3392f2a42078155f7730bb91e456788cff64",
        "citation_count": 0
    },
    {
        "title": "Heart Disease Prediction using Supervised Machine Learning Algorithms",
        "abstract": "Generally, the most complicated task in the healthcare field is the diagnosis of the disease itself. The diagnosis phase in disease detection is usually the most time-consuming task and is prone to most of the errors. Such complications can be effectively handled if the disease detection process is well automated by incorporating effective machine learning algorithms trained with some benchmark datasets. It should also be noted that huge amounts of data that are acquired from Heart Specialization Hospitals are being wasted every year. In this paper, various classification algorithms have been used to train the machine to diagnose heart disease. By a comparative study of various learning models, we have identified the appropriate learning model for the heart disease dataset. Initially, the work will begin with an overview of various machine learning algorithms followed by the algorithmic comparison.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/91a636443e63ea411480c5a55f88678f912fb5ae",
        "citation_count": 14
    },
    {
        "title": "Role of AI in Cardiovascular Health Care; a Brief Overview",
        "abstract": "Introduction: In the field of cardiovascular health, machine learning and artificial intelligence (AI) have become effective tools with potential applications ranging from disease detection and diagnosis to individualized treatment planning and decision making. The purpose of this study is to identify and analyze the role of AI in cardiovascular health care. Method: The methodology of this review paper involved an extensive literature review of the existing research on the topic of AI in cardiovascular health care. Result: Medical imaging is very important in the diagnosis and treatment of many diseases, but the interpretation of medical images is often time-consuming and subjective. Artificial intelligence (AI) algorithms, such as supervised and unsupervised learning, have been developed to assist in the analysis and interpretation of data from medical imaging. Convolutional neural networks (CNNs) and support vector machines (SVM) are the two most frequently used AI algorithms in medical image analysis. Conclusion: Artificial intelligence (AI) and machine learning in cardiovascular healthcare have great potential to improve patient outcomes and lower costs. However, there are still some hurdles that need to be overcome such as integration with clinical workflows, model validation and generalization, and privacy and security issues related to patient data. To overcome this, collaboration between doctors, researchers and industrial partners is needed. This technology has a bright and promising future with continuous investment in research and development.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/91b19f7515d18d2f4484728bac6f8d41df1ebb71",
        "citation_count": 5
    },
    {
        "title": "Advancing Healthcare AI Education Through Cloud Computing: Benchmarking AWS vs. GCP",
        "abstract": "This research-to-practice full paper represents our work to comprehensively analyze cloud computing benchmarking with integrated AI-driven healthcare projects. As time progresses, the need to migrate a variety of system applications to the cloud has grown significantly. Yet, choosing a particular cloud service provider can be troublesome and proposes several challenges, whether computational or financial, depending on the domain of the application. Thus, the reliance on cloud platform benchmarking has become an essential skill engineers must develop in order to make informed and efficient decisions. Healthcare applications, in particular, constitute an excellent from-ground- to-cloud example that we needed to analyze and study, especially from the perspective of Artificial Intelligence (AI) applications. At the moment, there is high demand for AI applications in the domain of healthcare seeking higher performance while lowering the costs of the services. Nonetheless, the healthcare domain is considered a tough field to experience and experiment to new graduates and proposes challenges to successfully cloudify the designated system applications. Therefore, we developed an effectual pedagogical approach capable of addressing those stacked challenges and preparing a new generation of competent engineers. Our work is designed to implement multiple stages sequentially and individually. The first stage commences by introducing students to various concepts as a foundation for their core work, covering Machine Learning (ML) basics, healthcare domain knowledge basics, finding a solution via ground and cloud computation, and benchmarking. Students then attempted to address a chosen healthcare problem using AI techniques. Finally, they solve the proposed healthcare challenge and successfully benchmark the cloud platforms of both Google Cloud Platform (GCP) and Amazon Web Services (AWS). Students, as instructed, relied on concepts of metrics, measurements, criteria, and their disparities to accurately assess each cloud. This paper efficiently documents and analyzes the results of each proposed stage based on the represented students' deliverables and the supervisors' feedback to reflect the effectiveness of the suggested teaching approach.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/91cc0089676d2ae2100f6a5cb0f8914fffd6a1cd",
        "citation_count": 0
    },
    {
        "title": "A Wearable System to Objectify Assessment of Motor Tasks for Supporting Parkinson\u2019s Disease Diagnosis",
        "abstract": "Objective assessment of the motor evaluation test for Parkinson\u2019s disease (PD) diagnosis is an open issue both for clinical and technical experts since it could improve current clinical practice with benefits both for patients and healthcare systems. In this work, a wearable system composed of four inertial devices (two SensHand and two SensFoot), and related processing algorithms for extracting parameters from limbs motion was tested on 40 healthy subjects and 40 PD patients. Seventy-eight and 96 kinematic parameters were measured from lower and upper limbs, respectively. Statistical and correlation analysis allowed to define four datasets that were used to train and test five supervised learning classifiers. Excellent discrimination between the two groups was obtained with all the classifiers (average accuracy ranging from 0.936 to 0.960) and all the datasets (average accuracy ranging from 0.953 to 0.966), over three conditions that included parameters derived from lower, upper or all limbs. The best performances (accuracy = 1.00) were obtained when classifying all the limbs with linear support vector machine (SVM) or gaussian SVM. Even if further studies should be done, the current results are strongly promising to improve this system as a support tool for clinicians in objectifying PD diagnosis and monitoring.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/92265002916f99d385804744d196384bbbaabc8d",
        "citation_count": 34
    },
    {
        "title": "On-Ground Distributed COVID-19 Variant Intelligent Data Analytics for a Regional Territory",
        "abstract": "The onset of the COVID-19 pandemic and the subsequent transmission among communities has made the entire human population extremely vulnerable. Due to the virus\u2019s contagiousness, the most powerful economies in the world are struggling with the inadequacies of resources. As the number of cases continues to rise and the healthcare industry is overwhelmed with the increasing needs of the infected population, there is a requirement to estimate the potential future number of cases using prediction methods. This paper leverages data-driven estimation methods such as linear regression (LR), random forest (RF), and XGBoost (extreme gradient boosting) algorithm. All three algorithms are trained using the COVID-19 data of Pakistan from 24 February to 31 December 2020, wherein the daily resolution is integrated. Essentially, this paper postulates that, with the help of values of new positive cases, medical swabs, daily death, and daily new positive cases, it is possible to predict the progression of the COVID-19 pandemic and demonstrate future trends. Linear regression tends to oversimplify concepts in supervised learning and neglect practical challenges present in the real world, often cited as its primary disadvantage. In this paper, we use an enhanced random forest algorithm. It is a supervised learning algorithm that is used for classification. This algorithm works well for an extensive range of data items, and also it is very flexible and possesses very high accuracy. For higher accuracy, we have also implemented the XGBoost algorithm on the dataset. XGBoost is a newly introduced machine learning algorithm; this algorithm provides high accuracy of prediction models, and it is observed that it performs well in short-term prediction. This paper discusses various factors such as total COVID-19 cases, new cases per day, total COVID-19 related deaths, new deaths due to the COVID-19, the total number of recoveries, number of daily recoveries, and swabs through the proposed technique. This paper presents an innovative approach that assists health officials in Pakistan with their decision-making processes.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/92ad4bd2edd300c176bb3bfa8cd19271656dd342",
        "citation_count": 3
    },
    {
        "title": "Hybridizing Artificial Neural Networks Through Feature Selection Based Supervised Weight Initialization and Traditional Machine Learning Algorithms for Improved Colon Cancer Prediction",
        "abstract": "Computer-aided decision support systems (DSSs) are becoming popular in a variety of professions. Notably, medical DSSs assist healthcare professionals (decision makers) choose the optimal course of action (decisions) while treating patients. Such systems help decision-makers in situations when there is uncertainty in manual decisions due to lack of information or expertise. Choosing a suitable learning algorithm in a DSS is essential and affects its performance. Among machine learning (ML) algorithms, artificial neural networks (ANNs) are considered the most suitable framework for many classification tasks. In healthcare, an ML-based prediction system/DSS employs data (genetic profile or clinical characteristics) and learning algorithms to forecast target values, which may give promising results. However, improving prediction accuracy is a crucial step in making informed decisions. One can apply various preprocessing methods (cross validation, feature selection, bagging, boosting, etc.) to achieve this. For complex classification tasks like cancer, decision-makers can utilize the hybridization of classifiers to increase prediction accuracy. The presented study investigates the possibilities of improvements in the design of hybridized systems for DSSs to assist healthcare professionals in robust decision-making before, during, and after cancer diagnosis. Since the network weights and the activation functions are the two crucial elements in the learning process of an ANN, this study is organized to investigates the improvement in the hybrid system by selecting suitable features from gene expression microarray data and using these features to compute the more realistic initial weights instead of using random guesses as initial weights for ANN. The use of the proposed framework gives promising results (upto 6.67% gain in accuracy when compared to previous study (Table-5) while 10.43% increase in accuracy when compared to conventional ML classifiers (Table-4).",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/92b270931bdff180641f099bcf68c0689bbe4855",
        "citation_count": 1
    },
    {
        "title": "Embedded System for Efficient Brain Stroke Prediction using CSML on PYNQ-Z2",
        "abstract": "This paper proposes an embedded system for efficient, real-time brain stroke prediction. While many machine learning techniques achieve high accuracy, their implementation on embedded platforms remains challenging. The solution utilizes a Correlated Supervised Machine Learning (CSML) method implemented on PYNQ-Z2 board, optimized through the PYNQ framework. Various classifiers are evaluated, with performance measured by F1 Score, Accuracy, Precision, Recall, and AUC-ROC. Additionally, power consumption and resource utilization are analyzed, demonstrating the system\u2019s suitability for real-time healthcare applications with low computational overhead.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/92e49e9c4cb7cdf502441cd547841f278d7edfac",
        "citation_count": 0
    },
    {
        "title": "Weakly-supervised learning for automatic facial behaviour analysis",
        "abstract": "In this Thesis we focus on Automatic Facial Behavior Analysis, which attempts to develop autonomous systems able to recognize and understand human facial expressions. Given the amount of information expressed by facial gestures, this type of systems has potential applications in multiple domains such as Human Computer Interaction, Marketing or Healthcare. For this reason, the topic has attracted a lot of attention in Computer Vision and Machine Learning communities during the past two decades. Despite the advances in the field, most of facial expression analysis problems can be considered far from being solved. \nIn this context, this dissertation is motivated by the observation that the vast majority of methods in the literature has followed the Supervised Learning paradigm, where models are trained by using data explicitly labelled according to the target problem. However, this approach presents some limitations given the difficult annotation process typically involved in facial expression analysis tasks. In order to address this challenge, we propose to pose Automatic Facial Behavior Analysis from a weakly-supervised perspective. Different from the fully-supervised strategy, weakly-supervised models are trained by using labels which are easy to collect but only provide partial information about the task that aims to be solved (i.e, weak-labels). Following this idea, we present different weakly-supervised methods to address standard problems in the field such as Action Unit Recognition, Expression Intensity Estimation or Affect Analysis. Our results obtained by evaluating the proposed approaches on these tasks, demonstrate that weakly-supervised learning may provide a potential solution to alleviate the need of annotated data in Automatic Facial Behavior Analysis. Moreover we also show how these approaches are able to facilitate the labelling process of databases designed for this purpose.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/932dc2e553dedba79183d39dbae5b4704f47df68",
        "citation_count": 0
    },
    {
        "title": "Teleconsultations between Patients and Healthcare Professionals in Primary Care in Catalonia: The Evaluation of Text Classification Algorithms Using Supervised Machine Learning",
        "abstract": "Background: The primary care service in Catalonia has operated an asynchronous teleconsulting service between GPs and patients since 2015 (eConsulta), which has generated some 500,000 messages. New developments in big data analysis tools, particularly those involving natural language, can be used to accurately and systematically evaluate the impact of the service. Objective: The study was intended to assess the predictive potential of eConsulta messages through different combinations of vector representation of text and machine learning algorithms and to evaluate their performance. Methodology: Twenty machine learning algorithms (based on five types of algorithms and four text representation techniques) were trained using a sample of 3559 messages (169,102 words) corresponding to 2268 teleconsultations (1.57 messages per teleconsultation) in order to predict the three variables of interest (avoiding the need for a face-to-face visit, increased demand and type of use of the teleconsultation). The performance of the various combinations was measured in terms of precision, sensitivity, F-value and the ROC curve. Results: The best-trained algorithms are generally effective, proving themselves to be more robust when approximating the two binary variables \u201cavoiding the need of a face-to-face visit\u201d and \u201cincreased demand\u201d (precision = 0.98 and 0.97, respectively) rather than the variable \u201ctype of query\u201d (precision = 0.48). Conclusion: To the best of our knowledge, this study is the first to investigate a machine learning strategy for text classification using primary care teleconsultation datasets. The study illustrates the possible capacities of text analysis using artificial intelligence. The development of a robust text classification tool could be feasible by validating it with more data, making it potentially more useful for decision support for health professionals.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/93ab88ab369cd86fc601cf50d8fb79e383e7eaa4",
        "citation_count": 22
    },
    {
        "title": "Smart healthcare: developing a pattern to predict the stress and anxiety among university students using machine learning technology",
        "abstract": "Background: Anxiety among students has become a fairly major problem. In the current era, Machine Learning (ML) can be used as a quick technology to predict students' anxiety with the high-level accuracy.\u00a0\n Objectives: This research aims to predict university students' anxiety by using supervised learning algorithms with providing pertinent feedback.\u00a0\n Methods: A total of 231 students from the University of Belgrade filled out the standard questionnaire called the State-Trait Anxiety Inventory (STAI). In addition, deeper information related to students\u2019 anxiety like physical activity, Grade Point Average (GPA), and smoking cigarettes were collected. The Linear Regression algorithm was chosen to examine STAI using Python. \u00a0\n Results: Linear regression as an appropriate algorithm was exploited for this purpose. The accuracy metric obtained by using the Mean Absolute Error (MAE), was 7.86 for state anxiety and 5.68 for trait anxiety. In addition, the Mean Squared Error (MSE) has also been calculated with state anxiety at 7.80, and trait anxiety at 9.66. Moreover, to find the factor with the highest impact after training, a regression analysis method (LASSO) was used. K-Nearest Neighbour (KNN) algorithm also checked the accuracy of training by overfitting and underfitting.\u00a0\n Conclusion: The purpose of this study was the analysis of anxiety factors with the highest impact as well as the analysis of the STAI by linear regression to improve a smart healthcare model by discovering an acceptable output with the highest accuracy. \u00a0",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/944f58e0ee5765d2a4742ff6702da52f2510ea11",
        "citation_count": 0
    },
    {
        "title": "Using clinical text to refine unspecific condition codes in Dutch general practitioner EHR data",
        "abstract": "Objective: Observational studies using electronic health record (EHR) databases often face challenges due to unspecific clinical codes that can obscure detailed medical information, hindering precise data analysis. In this study, we aimed to assess the feasibility of refining these unspecific condition codes into more specific codes in a Dutch general practitioner (GP) EHR database by leveraging the available clinical free text. Methods: We utilized three approaches for text classification-search queries, semi-supervised learning, and supervised learning-to improve the specificity of ten unspecific International Classification of Primary Care (ICPC-1) codes. Two text representations and three machine learning algorithms were evaluated for the (semi-)supervised models. Additionally, we measured the improvement achieved by the refinement process on all code occurrences in the database. Results: The classification models performed well for most codes. In general, no single classification approach consistently outperformed the others. However, there were variations in the relative performance of the classification approaches within each code and in the use of different text representations and machine learning algorithms. Class imbalance and limited training data affected the performance of the (semi-)supervised models, yet the simple search queries remained particularly effective. Ultimately, the developed models improved the specificity of over half of all the unspecific code occurrences in the database. Conclusions: Our findings show the feasibility of using information from clinical text to improve the specificity of unspecific condition codes in observational healthcare databases, even with a limited range of machine-learning techniques and modest annotated training sets. Future work could investigate transfer learning, integration of structured data, alternative semi-supervised methods, and validation of models across healthcare settings. The improved level of detail enriches the interpretation of medical information and can benefit observational research and patient care.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/947fcafd1f527bb3ea6ddce5782ac1037b570543",
        "citation_count": 0
    },
    {
        "title": "A Proposed Serious Game Architecture to Self-Management HealthCare for Older Adults",
        "abstract": "As people age, older adults' health begins to slow down. Moreover, the elderly population number will grow in upcoming years, according to statistics. This fact can lead to clinics and the hospitals becoming overloaded, and the demand for supervision becomes a challenge for the healthcare area. Because the majority of health issues are in the kinesiology domain, using new technologies like Kinect Sensor, this paper proposes a home system that implies the serious games for older adults, machine learning models for exercises recognition and remote activity supervision. The aim is to minimize the physical effort by offering a believable and motivating virtual world where the patient simulates kinesiology exercises, responds to quizzes and sends feedback. In the same time, the system recovers the exercise data and interprets it in order to model personalized care solutions, to create user profiles, to calibrate the difficulty level of the game using a language of powerful questions, to analyze the exercises progress and the performance feedback, to detect symptoms or falls and to learn the users' behavior. The approach described in this paper is based on analyses of the existing similar systems and on the statistics regarding the acceptability of the lifestyle in self-management physical level for elders.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/9496dd0e9933d2e539519cdfedc52fca3d201add",
        "citation_count": 10
    },
    {
        "title": "Supervised models for detecting GPS attacks and faults in UAVs: a comparative analysis",
        "abstract": "There is a growing demand for unmanned aerial vehicles (UAVs) in the industry as they are being widely used in various areas such as healthcare, security, military missions, agriculture, etc. However, the increase in the production and use of UAVs requires the improvement of solid decision-making principles, safety, security, and relevant technologies. In this regard, the present study investigated the performance of different machine learning models in detecting faults and attacks in UAV systems. To achieve this, we systematically compared eight supervised models applied to the early detection of attacks and faults in the physical components of UAVs. To reach this purpose, the relative performances of each model are evaluated in two controlled testing scenarios.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/94ab842f9aa4ee3c31571e045f541271dcb4b241",
        "citation_count": 0
    },
    {
        "title": "Predicted Multi-Chronic Disease by Supervised Machine Learning Algorithms: Performance and Evaluation",
        "abstract": "Current environmental conditions and human lifestyles have resulted in the emergence of numerous diseases. The medical field generates an enormous amount of new data each year for remote monitoring of patients. Due to increased data growth in the medical and healthcare industries, accurate medical data analysis has been advantageous to early patient care. However, physicians often face challenges in accurately diagnosing diseases in patients far from hospitals. Therefore, utilizing remote patient systems (telemedicine systems) due to the complexities associated with their chronic conditions. On the other hand, predicting illness is also a challenging task. Thus, data extracted from heterogeneous, fast-flowing, and reliable sources is crucial for decision-making and disease prediction. This research paper aims to utilize supervised Machine Learning (ML) techniques to predict chronic diseases such as heart and hypertension based on the patient\u2019s features or symptoms by analyzing patient data collected by sensors and sources enabled by the Internet of Medical Things (IoMT). Supervised ML technology in Hadoop and Spark environments is employed to guarantee that this classification accurately identifies individuals with chronic illnesses. The methods are evaluated using 55,680 patient records to discover the proper match between the data set and the final disease-predicted result. The results demonstrate that the proposed procedure employing the Decision Tree (DT) algorithm is 94% accurate, and DT outperforms the other four ML algorithms. This includes the Support Vector Machine (SVM), a Naive Bayes (NB) model, Random Forest (RF), and Logistic Regression (LR) in terms of both performance and accuracy metrics (precision, recall, and F-score).",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/94dbcfde7757f4349519dcc794d953ae30286c32",
        "citation_count": 0
    },
    {
        "title": "Emerging Value-Based Radiology in the Era of Artificial Intelligence",
        "abstract": "Radiology has a long history of adopting state-of-the-art digital technology to provide better diagnostic services and facilitate advances in image-based therapeutics throughout the healthcare system. The radiology community has been developing diagnostic artificial intelligence (AI) tools over the past 20 years, long before AI became fashionable in the public press. Currently, there are approximately four hundred Food and Drug Administration approved imaging AI products. However, the clinical adoption of these products in radiology has been relatively dismal, indicating that the current technology-push model needs to evolve into the demand-pull model. We will review the current state of AI use in radiology from the perspective of clinical adoption and explore the ways in which AI products will become an ensemble of critically important tools to help radiology transition from volume-based service to value-based healthcare. This transition will create new demands for AI technologies. We contrast the current \u201ctechnology-push\u201d model with a \u201cdemand-pull\u201d model that will aligns technology with user priorities. We summarize the lessons learned from AI experience over the past twenty years, mainly working with computer-aided detection for breast cancers and lung cancers. The radiology community calls for AI tools that can do more than detection with increasing attention toward higher workflow efficiency and higher productivity of radiologists. Major radiological societies of North America and Europe promulgated the emerging concept of value-based radiology service, an integral part of overall value-based healthcare. The transition to value-based radiology will happen and that higher value will come from the effective use of AI throughout the radiology workflow. The value-based radiology will need to work with a full range of machine learning tools, including supervised, unsupervised, and reinforcement learning, as well as natural language processing and large language models (e.g., chatbots). The engineering community is rapidly developing many concepts and sophisticated software tools for data orchestration, AI orchestration, and automation orchestration. Current radiology operation has been supported by PACS, a monolithic IT infrastructure of past generations. This system will need to migrate to an intelligence management system to support the new workflow needed for high value radiology.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/950596c5b616ef6e79b6b341b67b5582de91c330",
        "citation_count": 3
    },
    {
        "title": "Meta-Exploration of Machine Learning in Smart Cities",
        "abstract": "Machine Learning (ML) significantly drives the advancement of smart cities. This survey, using databases like IEEE Explorer, Web of Sciences, and Google Scholar, thoroughly investigated 22 papers published between 2021 and 2023. The focus was on identifying the prevalent ML models in smart cities and the specific sub-areas capturing the most attention. The study says that out of 22 research papers, about 63% used supervised learning techniques for smart city applications. The most common models were Naive Bayes and Support Vector Machines, especially in the areas of transportation, energy, environment, and healthcare. The industry has significance, due to its potential for conversion, especially with the urbanization of rural areas. This highlights the necessity for extensive future advancements. The results of this survey about the significance of machine learning in smart cities give us a path that will demand ongoing innovation to ensure the sustainable growth of both urban and rural areas going forward. Using machine learning, we can not only enhance the productivity of the city system but also increase the efficiency in diverse aspects of urban life.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/95425c111c8188fa1573b8e75af275d8b71f1398",
        "citation_count": 0
    },
    {
        "title": "Synthesizing Effective Diagnostic Models from Small Samples using Structural Machine Learning: a Case Study in Automating COVID-19 Diagnosis",
        "abstract": "The global COVID-19 pandemic has demonstrated the urgent need for diagnostic tools that can be both readily applied and dynamically calibrated by non-specialists, in terms of a sensitivity/specificity tradeoff that complies with relevant healthcare policies and procedures. This article describes the design and deployment of a novel machine learning algorithm, Structural Machine Learning (SML), that combines memetic grammar-guided program synthesis with self-supervised learning in order to learn effectively from small data sets while remaining relatively resistant to overfitting. SML is used to construct a signal processing pipeline for audio time-series, which then serves as the diagnostic mechanism for a wide-spectrum, infrasound-to-ultrasound e-stethoscope. In blind trials supervised by a third party, SML is shown to be superior to Deep Learning approaches in terms of the area under the ROC curve, while allowing for transparent interpretation of the decision-making process.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/95a06f8810d911b2b87a9e8335cb094f85afac20",
        "citation_count": 0
    },
    {
        "title": "Machine learning based prediction tool of hospitalization cost",
        "abstract": "The increase in the cost of healthcare is a worldwide challenge. It has thus become essential to understand the nature and the weight of the factors that influence it and to foresee its future changes in order to ensure good governance, improve hospital management of material and financial resources and therefore be ready to face emergency situations such as the ongoing global pandemic. Using Python programming language, different supervised machine learning algorithms, were tested on a dataset extracted from digital medical records of hospitalized patients in the infectious diseases department at Sfax university hospital (Tunisia). Different models for predicting the hospitalization cost of a patient upon admission were created and evaluated after having processed and analyzed the collected data. This dataset initially comprised 542 observations and 136 variables including 36 quantitative ones and 100 dummy variables. Two variable selection methods were applied and subgroups of independent variables with different semantic meanings were also used. Despite few shortcomings such as missing data, the most precise of the different tested prediction models was that of 15th degree multiple linear regression. Regressors were the season of the period of hospitalization, suspected diagnosis and patient characteristics such as gender. When applied in reality, this tool would make it possible to predict the hospitalization cost and therefore forecast precise budgets. However, technical improvements remain to be made in order to optimize the quality of this tool and other algorithms could be tested to further broaden this study. The generalization of the implementation and use of well-developed digital medical records would allow the production of more complete databases from which better prediction models could be generated.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/96085f3c6afd94edd06e0214eec465a67427d6b4",
        "citation_count": 0
    },
    {
        "title": "PhD Thesis Title: Vector Extrapolation and Guided Filtering Methods for Improving Photoacoustic and Microscopic Images",
        "abstract": "Photoacoustic imaging is a non-invasive imaging methodology which combines the benefits of optical contrast and ultrasonic resolution. It is applied widely for monitoring tissue health conditions in the fields of cardiology, ophthalmology, oncology, dermatology, and neurosciences. The photoacoustic tomographic image reconstruction problem is typically ill-posed and requires model-based iterative algorithms. The microscopic image analysis of pathological slides is considered as a gold standard for medical diagnosis. To acquire good quality images, one needs to deploy high-cost microscopes, which leads to increase in the cost and hence becomes prohibitive to have utility in low-resource settings. The low-cost microscopic image has low quality due to its inability to acquire focused stacks. The thesis deploys methods based on vector extrapolation and guided filtering to improve photoacoustic and histopathology (microscopic) images. The limited data photoacoustic tomographic image reconstruction problem is known to be illposed and hence the iterative reconstruction methods were proven to be effective in terms of providing good quality initial pressure distribution. Often, these iterative methods require a large number of iterations to converge to a solution, in turn making the image reconstruction procedure computationally inefficient. Two variants of vector polynomial extrapolation techniques were proposed to accelerate two standard iterative photoacoustic image reconstruction algorithms, including regularized steepest descent and total variation regularization methods. It was shown using numerical and experimental phantom cases that the extrapolation methods, proposed in this thesis, can provide significant acceleration (as high as 4.7 times) along with added advantage of improving reconstructed image quality. Several algorithms exist to solve the photoacoustic image reconstruction problem depending on the expected reconstructed image features. These reconstruction algorithms promote typically one feature, such as being smooth or sharp, in the output image. Combining these features using a guided filtering approach was proposed, which requires an input and a guiding image. This approach acts as a postprocessing step to improve the commonly used Tikhonov or total variational regularization method. The result obtained from linear back projection was used as a guiding image to improve these results. Using both numerical and experimental cases, it was shown that the proposed guided filtering approach was able to improve (as high as 11.23 dB) the signal-to-noise ratio of the reconstructed images with added advantage while being computationally efficient. This approach was compared with state-of-the-art basis pursuit deconvolution as well as standard denoising methods and outperformed them. Microscopic analysis of pathological slide smears is the gold standard for medical diagnosis, therefore the research community is making efforts towards low-cost image acquisition and automated computational analysis equipment that is especially suitable for developing countries. However, the requirement of the images being very well in focus may not be met with these equipment and thus image enhancement methods that can compensate for this shortcoming gain critical importance. A guided filtering (GF) based approach was proposed for enhancement of outof-focus microscopic images of human blood smear slides containing healthy and malaria infected Red Blood Cells (h-RBCs and i-RBCs) and PAP smears. Comparisons have also been made with a histogram-equalization method for image enhancement (CLAHE), RIQMC-based optimal histogram matching (ROHIM), modified L0 based method and the proposed guided filtering method has been shown to outperform these methods. The guided filtering enhanced images lead to better segmentation accuracy and visual quality compared to the native ones. Both these traits are necessary to perform automated diagnosis via image processing and machine learning and hence the method proposed in this thesis work can play an important role towards the goal of universal healthcare. This thesis work aims at improving the photoacoustic tomography images as well as histopathological microscopic images, where quality of images is an important factor to provide correct diagnosis. The thesis work proposed fast and improved post-processing methods for photoacoustic and microscopic images, especially in cases these images tend to be noisy. The central theme of this thesis work was to improve the quality of photoacoustic/microscopic images obtained in limited/low-quality data scenarios. In microscopy, the low-cost apparatus used for obtaining the microscopic images are often corrupted with noise and provide very limited diagnostic accuracy, especially with automated algorithms. Various methods were proposed and systematically evaluated for performing post-processing of the data obtained using these limited data and low-quality data scenarios for photoacoustic and microscopic images. References to author publications that relate specifically to the dissertation: 1. Navchetan Awasthi, K. Ram Prabhakar, Sandeep Kumar Kalva, Manojit Pramanik, R. Venkatesh Babu, and Phaneendra K. Yalavarthy, \"PA-Fuse: A Deep Supervised Approach for Fusion of Photoacoustic Images with Distinct Reconstruction Characteristics,\" Biomedical Optics Express 10(5), 2227-2243 (2019). [doi: 10.1364/BOE.10.002227] 2. Navchetan Awasthi, Sandeep K. Kalva, Manojit Pramanik, and Phaneendra K. Yalavarthy, \u201cImage Guided Filtering for Improving Photoacoustic Tomographic Image Reconstruction,\u201d Journal of Biomedical Optics 23(9), 091413 (2018). [doi: 10.1117/1.JBO.23.9.091413] 3. Navchetan Awasthi, Sandeep K. Kalva, Manojit Pramanik, and Phaneendra K. Yalavarthy, \u201cVector Extrapolation Methods for Accelerating Iterative Reconstruction Methods in LimitedData Photoacoustic Tomography,\u201d Journal of Biomedical Optics 23(7), 071204 (2018).[doi: 10.1117/1.JBO.23.7.071204] 4. Navchetan Awasthi, Prateek Katare, Sai Siva Gorthi, and Phaneendra K. Yalavarthy, \u201cGuided filter based image enhancement for focal error compensation in low cost automated histopathology microscopic system,\u201d Journal of Biophotonics (2020). [doi: 10.1002/jbio.202000123].",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/961cd39ccd64c0dabad1f4f2a1907f73f5fedb7c",
        "citation_count": 0
    },
    {
        "title": "Advancing Cardiac Care: Machine Learning-Based Prediction of Heart Disease Risk Factors (CORONARY DISEASE)",
        "abstract": "Because technology has changed how people live, the healthcare industry has to adapt as well in order to proactively diagnose a range of disorders. Heart disease is the leading cause of death in India and a major cause of morbidity. This study explores the use of machine learning approaches to precisely estimate the risk of heart disease, utilizing these techniques' efficacy in prediction and decision-making inside the large-scale healthcare data. This research attempts to enable early identification of probable heart abnormalities using supervised machine learning techniques like Decision Tree (DT), Random Forest (RF), Support Vector Machine (SVM), Na\u00efve Bayes (NB), and k-nearest neighbor algorithm. The incorporation of this technology has potential in expediting the prompt identification of heart-related issues, hence prolonging the lives of individuals. Over time, machine learning has demonstrated its effectiveness in handling large-scale healthcare datasets. This study investigates how these methods could revolutionize healthcare, particularly in terms of early detection and treatment of heart disease risks before they reach dangerous levels.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/96297ec567d75da6037f804d116627e9dcdef8ab",
        "citation_count": 0
    },
    {
        "title": "A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centers",
        "abstract": "Patient length of stay (LoS) is a critical metric for evaluating the efficacy of hospital management. The primary objectives encompass to improve efficiency and reduce costs while enhancing patient outcomes and hospital capacity within the patient journey. By seamlessly merging data-driven techniques with simulation methodologies, the study proposes an all-encompassing framework for the optimization of patient flow. Using a comprehensive dataset of 2.3 million de-identified patient records, we analyzed demographics, diagnoses, treatments, services, costs, and charges with machine learning models (Decision Tree, Logistic Regression, Random Forest, Adaboost, LightGBM) and Python tools (Spark, AWS clusters, dimensionality reduction). Our model predicts patient length of stay (LoS) upon admission using supervised learning algorithms. This hybrid approach enables the identification of key factors influencing LoS, offering a robust framework for hospitals to streamline patient flow and resource utilization. The research focuses on patient flow corroborates the efficacy of the approach, illustrating decreased patient length of stay within a real healthcare environment. The findings underscore the potential of hybrid data-driven models in transforming hospital management practices. This innovative methodology provides generally flexible decision-making, training, and patient flow enhancement; such a system could have huge implications for healthcare administration and overall satisfaction with healthcare",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/962b5a30cd5182814329519eca6d51efc4440858",
        "citation_count": 0
    },
    {
        "title": "Using machine learning to predict disease outbreaks and enhance public health surveillance",
        "abstract": "Disease outbreaks pose significant challenges to public health systems, often requiring rapid response strategies to mitigate widespread health and economic impacts. Traditional methods of outbreak prediction and surveillance, while effective, often lack the capacity to process and analyse the vast quantities of heterogeneous data generated in modern healthcare ecosystems. Machine learning (ML) offers transformative potential in this domain, leveraging its ability to process large datasets, identify complex patterns, and provide real-time insights. By integrating diverse data sources such as electronic health records (EHRs), social media feeds, climate data, and genomic sequences, ML algorithms can predict disease outbreaks with unprecedented accuracy. Supervised learning models, for instance, have been successfully applied to forecast influenza trends, while unsupervised clustering techniques have been employed to detect anomalies indicative of emerging infectious diseases. Moreover, ML facilitates advanced public health surveillance by automating data processing pipelines, enhancing real-time monitoring capabilities, and enabling resource optimization for outbreak responses. Despite these advances, the adoption of ML in public health surveillance is not without challenges. Issues related to data privacy, ethical considerations, algorithm interpretability, and integration with existing public health infrastructures remain significant hurdles. Addressing these challenges requires a multidisciplinary approach, incorporating robust data governance frameworks, improved algorithm transparency, and collaborations between technology developers and public health stakeholders. This paper highlights the critical role of ML in transforming public health surveillance, focusing on its application in disease outbreak prediction. It underscores the importance of continued innovation, regulatory support, and ethical considerations in advancing ML-driven solutions for global health security.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/96385980e95621272d83ac2303d1d073daaf17ff",
        "citation_count": 0
    },
    {
        "title": "Fraud Detection in Healthcare Insurance Claims Using Machine Learning",
        "abstract": "Healthcare fraud is intentionally submitting false claims or producing misinterpretation of facts to obtain entitlement payments. Thus, it wastes healthcare financial resources and increases healthcare costs. Subsequently, fraud poses a substantial financial challenge. Therefore, supervised machine and deep learning analytics such as random forest, logistic regression, and artificial neural networks are successfully used to detect healthcare insurance fraud. This study aims to develop a health model that automatically detects fraud from health insurance claims in Saudi Arabia. The model indicates the greatest contributing factor to fraud with optimal accuracy. The labeled imbalanced dataset used three supervised deep and machine learning methods. The dataset was obtained from three healthcare providers in Saudi Arabia. The applied models were random forest, logistic regression, and artificial neural networks. The SMOT technique was used to balance the dataset. Boruta object feature selection was applied to exclude insignificant features. Validation metrics were accuracy, precision, recall, specificity, F1 score, and area under the curve (AUC). Random forest classifiers indicated policy type, education, and age as the most significant features with an accuracy of 98.21%, 98.08% precision, 100% recall, an F1 score of 99.03%, specificity of 80%, and an AUC of 90.00%. Logistic regression resulted in an accuracy of 80.36%, 97.62% precision, 80.39% recall, an F1 score of 88.17%, specificity of 80%, and an AUC of 80.20%. ANN revealed an accuracy of 94.64%, 98.00% precision, 96.08% recall, an F1 score of 97.03%, a specificity of 80%, and an AUC of 88.04%. This predictive analytics study applied three successful models, each of which yielded acceptable accuracy and validation metrics; however, further research on a larger dataset is advised.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/964e7a27f17e0caac452baf1847e5291d2327fd9",
        "citation_count": 21
    },
    {
        "title": "Cancer diagnosis and prognosis using multi-Omics data: A data science and machine learning approach",
        "abstract": "Cancer remains one of the leading causes of morbidity and mortality worldwide, demanding innovative approaches for early diagnosis and accurate prognosis. Recent advances in multi-omics technologies, which integrate genomics, transcriptomics, proteomics, metabolomics, and epigenomics, provide comprehensive insights into the complex biological mechanisms underlying cancer. By capturing molecular signatures at multiple levels, multi-omics data offers unparalleled potential for identifying cancer biomarkers, stratifying patients, and predicting therapeutic responses. However, the volume, complexity, and heterogeneity of multi-omics data present significant analytical challenges, necessitating robust data science and machine learning techniques. Machine learning algorithms, including supervised, unsupervised, and deep learning approaches, are increasingly being utilized to unravel the patterns embedded in multi-omics datasets. These methods enable feature selection, dimensionality reduction, and the integration of multi-modal data, facilitating the identification of precise biomarkers and the development of predictive models for cancer progression. Furthermore, advanced frameworks such as explainable AI (XAI) provide interpretability to these models, ensuring their clinical applicability and enhancing trust among healthcare professionals. This review highlights recent breakthroughs in cancer diagnosis and prognosis using multi-omics data, emphasizing the synergy between data science and machine learning in transforming oncology research. It also explores the challenges in data integration, algorithmic bias, and model validation, proposing solutions to enhance predictive accuracy and generalizability. By bridging molecular biology and computational sciences, this interdisciplinary approach has the potential to revolutionize precision oncology, paving the way for personalized treatment strategies and improved patient outcomes.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/96a0d708fc5ddc3e023c5b94be5f3a06243aeb93",
        "citation_count": 0
    },
    {
        "title": "Near-Infrared Spectroscopy with Supervised Machine Learning as a Screening Tool for Neutropenia",
        "abstract": "The use of non-invasive tools in conjunction with artificial intelligence (AI) to detect diseases has the potential to revolutionize healthcare. Near-infrared spectroscopy (NIR) is a technology that can be used to analyze biological samples in a non-invasive manner. This study evaluated the use of NIR spectroscopy in the fingertip to detect neutropenia in solid-tumor oncologic patients. A total of 75 patients were enrolled in the study. Fingertip NIR spectra and complete blood counts were collected from each patient. The NIR spectra were pre-processed using Savitzky\u2013Golay smoothing and outlier detection. The pre-processed data were split into training/validation and test sets using the Kennard\u2013Stone method. A toolbox of supervised machine learning classification algorithms was applied to the training/validation set using a stratified 5-fold cross-validation regimen. The algorithms included linear discriminant analysis (LDA), logistic regression (LR), random forest (RF), multilayer perceptron (MLP), and support vector machines (SVMs). The SVM model performed best in the validation step, with 85% sensitivity, 89% negative predictive value (NPV), and 64% accuracy. The SVM model showed 67% sensitivity, 82% NPV, and 57% accuracy on the test set. These results suggest that NIR spectroscopy in the fingertip, combined with machine learning methods, can be used to detect neutropenia in solid-tumor oncology patients in a non-invasive and timely manner. This approach could help reduce exposure to invasive tests and prevent neutropenic patients from inadvertently undergoing chemotherapy.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/9717c18b36c727bcd006f966c29de18c1d4466c5",
        "citation_count": 2
    },
    {
        "title": "DUNE: Decoding Unified Naive Bayes Explainability through Gaussian methods for a Heart Disease Diagnostic",
        "abstract": "Heart disease is still a prominent cause of illness and fatal death worldwide. In this work, we examine whether the existence of heart disease can be predicted using the Gaussian Naive Bayes (GNB) algorithm from a tabular dataset that includes several clinical, lifestyle, and demographic factors. We did a substantial amount of feature engineering on the dataset to manage missing values and standardize features before training the GNB classifier to diagnose heart illness. We evaluate the supervised model using widely-used metrics including accuracy, precision, recall, and F1-score to show thst it distinguishes between people with and without heart disease. Using two state-of-the-art Explainable AI (XAI) techniques, SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Modelagnostic Explanations), we shed light on the underlying mechanisms of the predictions made by the GNB model. The authors offer significant new insights into the prognostic potential of the GNB algorithm for heart disease. Our findings demonstrate the value of the dependability and transparency of machine learning models for significant healthcare applications",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/971bd5ee1c8f0c4a1681c47a3fc662f67d19ebb6",
        "citation_count": 0
    },
    {
        "title": "Machine learning in healthcare invoicing systems: Using text mining and supervised learning to verify classifications of unstructured medical texts",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/9773148e3381e74267459e680df0c64a0b066d13",
        "citation_count": 0
    },
    {
        "title": "Sequential Stochastic Optimization in Separable Learning Environments",
        "abstract": "We consider a class of sequential decision-making problems under uncertainty that can encompass various types of supervised learning concepts. These problems have a completely observed state process and a partially observed modulation process, where the state process is affected by the modulation process only through an observation process, the observation process only observes the modulation process, and the modulation process is exogenous to control. We model this broad class of problems as a partially observed Markov decision process (POMDP). The belief function for the modulation process is control invariant, thus separating the estimation of the modulation process from the control of the state process. We call this specially structured POMDP the separable POMDP, or SEP-POMDP, and show it (i) can serve as a model for a broad class of application areas, e.g., inventory control, finance, healthcare systems, (ii) inherits value function and optimal policy structure from a set of completely observed MDPs, (iii) can serve as a bridge between classical models of sequential decision making under uncertainty having fully specified model artifacts and such models that are not fully specified and require the use of predictive methods from statistics and machine learning, and (iv) allows for specialized approximate solution procedures.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/984837229cfe2c43a2066d06d2866561810eb0f2",
        "citation_count": 0
    },
    {
        "title": "Study of machine learning algorithms for special disease prediction using principal of component analysis",
        "abstract": "The worldwide study on causes of death due to heart disease/syndrome has been observed that it is the major cause of death. If recent trends are allowed to continue, 23.6 million people will die from heart disease in coming 2030. The healthcare industry collects large amounts of heart disease data which unfortunately are not \u201cmined\u201d to discover hidden information for effective decision making. In this paper, study of PCA has been done which finds the minimum number of attributes required to enhance the precision of various supervised machine learning algorithms. The purpose of this research is to study supervised machine learning algorithms to predict heart disease. Data mining has number of important techniques like categorization, preprocessing. Diabetic is a life threatening disease which prevent in several urbanized as well as emergent countries like India. The data categorization is diabetic patients datasets which is developed by collecting data from hospital repository consists of 1865 instances with dissimilar attributes. The examples in the dataset are two categories of blood tests, urine tests. In this research paper we discuss a variety of algorithm approaches of data mining that have been utilized for diabetic disease prediction. Data mining is a well known practice used by health organizations for classification of diseases such as diabetes and cancer in bioinformatics research.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/99123df7c70ef16ae0bb7498b5d28ab69571c838",
        "citation_count": 106
    },
    {
        "title": "Artificial Intelligence in Clinical Chemistry: Dawn of a New Era?",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/99338926f208a65cdf0e7f2384c781e19b93c688",
        "citation_count": 2
    },
    {
        "title": "Sentiment Analysis of Twitter Data: A Review",
        "abstract": "For a business organization, Sentiment Analysis is a great way to understand the needs of the customers, find out whether they are happy with the product or not and which areas need an improvement. It is also used in various other fields like Healthcare to check how public feels about a specific drug and Politics to predict which party is going to win the election. In light of the current surge in interest in sentiment analysis among researchers for a range of applications, a framework for carrying out a highly accurate sentiment analysis is required. A lot of research has been done for sentiment analysis of tweets from Twitter since it helps in understanding public's view of the particular product, situation or any other topic. There are various models proposed by the researchers with which we can perform sentiment analysis but there are still many challenges that still need to be addressed as well. The presence of emoticons, spam, sarcasm and other forms of content in large number of social media posts makes the feature extraction challenging. Among the Machine Learning Algorithms, the supervised classifiers outperformed the unsupervised approaches in terms of scalability and efficiency. In this review paper, we will discuss the various ways we can perform sentiment analysis and we will also discuss the various applications and challenges of sentiment analysis as well.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/9957233fdec5b615ad7bbafc59ef0f1509a01db4",
        "citation_count": 4
    },
    {
        "title": "Comparative Study of Supervised Machine Learning Algorithms for Healthcare Dataset Using Orange",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/996abea102c25df397c4d9bac111d55a4dca87ba",
        "citation_count": 1
    },
    {
        "title": "Prognosticating Liver Debility Using Classification Approaches of Machine Learning",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/99cc561cb2404e762a17c816ff3cb3da44555adb",
        "citation_count": 0
    },
    {
        "title": "Prediction of Health Care Employee Turnover using Gradient Boosting Algorithm",
        "abstract": "Employee turnover is a measurement of how many employees are leaving a company and how many employees are retaining. Retaining the Employee is going to be biggest challenge for any of the organization in the world. Small to l arge organizations are hugely affected by such a big employee turnover problem. The healthcare industries are hugely affected by employee turnover problem. When employee leave the organization, the organization must have to replace such a employee with the employee having same skills, experience, behavior etc. This employee turnover prediction model uses the machine learning gradient boosting algorithms namely XGBoost, CatBoost, and LightGBM algorithms. Each models are trained, tested and validated and checked the performance metrices based on Pearson\u2019s correlation coefficients. Employee turnover prediction model helps to the supervisor to have a frequent, timely and relevant interactions or actions with the employee group based on prediction. Based on the prediction the supervisor may take actions on the employee before termination.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/99e6699956bec8fd8e2e31508347dede8abf5761",
        "citation_count": 0
    },
    {
        "title": "A Data Enhancement Approach to Improve Machine Learning Performance for Predicting Health Status Using Remote Healthcare Data",
        "abstract": "Machine Learning (ML) is becoming tremendously important to improve the performance of remote healthcare systems. Portable health clinic (PHC), a remote healthcare system contains a triage function that classifies the patients in two major groups - (a)healthy and (b)unhealthy. Unhealthy patients require regular health checkups. This paper aims to predict the status of the registered patients to decide the follow-up date and frequency. Health management cost can be reduced by decreasing the number of follow-up frequency. We carried out an experiment on 271 corporate members and monitored their health status in every three months and collected four phases of data. The data records contain clinical data, socio-demographical data, dietary behavior data. However, most of the machine learning algorithms can not directly work with categorical data. Several encoding techniques are available which can also enhance the prediction performance. In this paper, We applied three encoding techniques and proposed a new encoding approach to handle categorical variables. The result shows that Random Forest Classifier performs the best with 95.33% accuracy. A comparison chart displaying the performance of eight different supervised learning algorithms in terms of three existing encoding mechanisms is reported.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/99fa076e59d238041107ebb44f75c8c45f18c449",
        "citation_count": 4
    },
    {
        "title": "Novel Supervised Learning Scheme for Optimizing the Classification Performance of Breast Cancer MRI",
        "abstract": "Usage of machine learning has been always proven potential in identifying the best solution from the set of complex variables with the highly inter-twined relationship of problems. Similarly, supervised learning approach is one essential operation under machine learning that has always contributed in the area of healthcare and diagnostics. However, there are still some problems associated with the detection and classification of complex disease condition that is yet to be solved. The proposed system introduces a novel supervised learning approach along with a novel feature extraction scheme which is more progressive and less iterative. The proposed system considers a case study to perform classification of breast cancer using Magnetic Resonance Imaging (MRI) where it is subjected to normalization first followed by a novel segmentation process that compliments the classification operation too. The study outcome shows that the proposed system offers better classification performance in contrast to existing supervised approaches.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/9a2eb83f28d8bb170eac681d2ecb08e8ddffedd4",
        "citation_count": 1
    },
    {
        "title": "Diagnosis of Various Thyroid Ailments using Data Mining Classification Techniques",
        "abstract": "Classification is one of the most considerable supervised learning data mining technique used to classify predefined data sets the classification is mainly used in healthcare sectors for making decisions, diagnosis system and giving better treatment to the patients. In this work, the data set used is taken from one of recognized lab of Kashmir. The entire research work is to be carried out with ANACONDA3-5.2.0 an open source platform under Windows 10 environment. An experimental study is to be carried out using classification techniques such as k nearest neighbors, Support vector machine, Decision tree and Na\u00efve bayes. The Decision Tree obtained highest accuracy of 98.89% over other classification techniques.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/9a5b94512e0809e1b9b3429ed6e76dc29ecc1223",
        "citation_count": 6
    },
    {
        "title": "Disease outbreaks: tuning predictive machine learning",
        "abstract": "Climate change is expected to exacerbate diarrhoea outbreaks in developing nations, a leading cause of morbidity and mortality in such regions [3]. The development of predictive models with the ability to capture complex relationships between climate factors and diarrhoea may be effective for diarrhoea outbreak control. Various supervised Machine Learning (ML) algorithms and Deep Learning (DL) methods have been used in developing predictive models for various diseases [7]. Despite their advances in a range of healthcare applications, overall method task performance still largely depends on available training data and parameter settings which is a significant challenge for most predictive machine learning methods [9]. This study investigates the impact of Relevance Estimation and Value Calibration (REVAC) [4], an evolutionary parameter optimization method applied to predictive task performance of various ML and DL methods applied to ranges of real-world and synthetic data-sets (diarrhoea and climate based) for daily diarrhoea outbreak prediction in a regional case-study (South African provinces). Preliminary results indicate that REVAC is better suited for the DL models regardless of the data-set used for making predictions.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/9a5ec03f3e246c1239f026aecb287d891b85ce06",
        "citation_count": 0
    },
    {
        "title": "Technology Management for Accelerated Recovery during COVID-19",
        "abstract": "Objective- The research looks forward to extracting strategies for accelerated recovery during the ongoing Covid-19 pandemic.\nDesign - Research design considers quantitative methodology and evaluates significant factors from 170 countries to deploy supervised and unsupervised Machine Learning techniques to generate non-trivial predictions.\nFindings - Findings presented by the research reflect on data-driven observation applicable at the macro level and provide healthcare-oriented insights for governing authorities.\nPolicy Implications - Research provides interpretability of Machine Learning models regarding several aspects of the pandemic that can be leveraged for optimizing treatment protocols.\nOriginality - Research makes use of curated near-time data to identify significant correlations keeping emerging economies at the center stage. Considering the current state of clinical trial research reflects on parallel non-clinical strategies to co-exist with the Coronavirus.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/9a806c2ce1737b906ee78f3b66f1f2f0bdbcecfb",
        "citation_count": 2
    },
    {
        "title": "Investigating Beta-Variational Convolutional Autoencoders for the Unsupervised Classification of Chest Pneumonia",
        "abstract": "The world\u2019s population is increasing and so is the challenge on existing healthcare infrastructure to cope with the growing demand in medical diagnosis and evaluation. Although human experts are primarily tasked with the diagnosis of different medical conditions, artificial intelligence (AI)-assisted diagnoses have become considerably useful in recent times. One of the critical lung infections, which requires early diagnosis and subsequent treatment to reduce the mortality rate, is pneumonia. There are different methods for obtaining a pneumonia diagnosis; however, the adoption of chest X-rays is popular since it is non-invasive. The AI systems for a pneumonia diagnosis using chest X-rays are often built on supervised machine-learning (ML) models, which require labeled datasets for development. However, collecting labeled datasets is sometimes infeasible due to constraints such as human resources, cost, and time. As such, the problem that we address in this paper is the unsupervised classification of pneumonia using unsupervised ML models including the beta-variational convolutional autoencoder (\u03b2-VCAE) and other variants, such as convolutional autoencoders (CAE), denoising convolutional autoencoders (DCAE), and sparse convolutional autoencoders (SCAE). Namely, the pneumonia classification problem is cast into an anomaly detection to develop the aforementioned ML models. The experimental results show that pneumonia can be diagnosed with high recall, precision, f1-score, and f2-score using the proposed unsupervised models. In addition, we observe that the proposed models are competitive with the state-of-the-art models, which are trained on a labeled dataset.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/9acdd6c0cfff5d556c9aeb2787efe7466830be4d",
        "citation_count": 3
    },
    {
        "title": "Detection of Cardiovascular Disease of Patients at an Early Stage Using Machine Learning Algorithms",
        "abstract": "Among the significant causes of death worldwide, cardiovascular diseases (CVD) account for 80 percent of deaths in low- and middle-income countries such as Bangladesh, according to the World Health Organization (WHO). In Bangladesh, the prevalence of HIV/AIDS and the mortality linked with it have climbed considerably over the past few decades. The rising incidence of cardiovascular disease in Bangladesh needs a complete understanding of the epidemiology of CVD risk among the population. Clinical data analysis is a significant concern for someone dealing with cardiovascular illness. When it comes to generating decisions and making predictions from the vast volumes of data generated by the healthcare industry, machine learning (ML) is to be extremely useful. It is proposed in this research to apply a supervised machine learning algorithm to detect cardiovascular disease (CVD) in individuals early on, allowing them to become concerned about their medical status and avert significant illnesses. When it comes to detecting the disease, four different machine learning methods have been used. The dataset of patients was used, and various machine learning methods, including K-nearest neighbors, Random Forest, Decision trees, and XGBoost, were used to make predictions. As a consequence of the tests, the XGBoost method is superior to the other three tactics (73.72 percent). Moreover, for the modified dataset where smoking, alcohol intake, and physical activity are positive, the percentage is 81.14% to show the effect of smoking and alcohol consumption in a physically active person in terms of cardiovascular disease. Furthermore, these strategies have been evaluated regarding their ability to detect early-stage CVD inpatients. This paper examined the Kaggle dataset to observe the trait and suitability to implement the system for primary data collected from Bangladeshi patients.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/9ad5074fdbdd0fc319f33827db121482b1907121",
        "citation_count": 3
    },
    {
        "title": "Machine Learning in Computer Vision: A Review",
        "abstract": "INTRODUCTION: Due to the advancement in the field of Artificial Intelligence (AI), the ability to tackle entire problems of machine intelligence. Nowadays, Machine learning (ML) is becoming a hot topic due to the direct training of machines with less interaction with a human. The scenario of manual feeding of the machine is changed in the modern era, it will learn automatically. Supervised and unsupervised ML techniques are used as a distinct purpose like feature extraction, pattern recognition, object detection, and classification. OBJECTIVES: In Computer Vision (CV), ML performs a significant role to extract crucial information from images. CV successfully contributes to multiple domains, surveillance system, optical character recognition, robotics, suspect detection, and many more. The direction of CV research is going toward healthcare realm, medical imaging (MI) is the emerging technology, play a vital role to enhance image quality and recognized critical features of binary medical image, covert original image into grayscale and set the threshold values for segmentation. CONTRIBUTION: This paper will address the importance of machine learning, state-of-the-art, and how ML is utilized in computer vision and image processing. This survey will provide details about the type of tools and applications, datasets, and techniques. Limitations of previous work and challenges of future work also discussed. Further, we identify and discuss a set of open issues yet to be addressed, for efficiently applying of ML in Computer vision and image process. METHODS, RESULTS, AND CONCLUSION: In this review paper, we have discussed the techniques and various types of supervised and unsupervised algorithms of ML, general overview of image processing and the results based on the impact; neural network enabled models, limitations, tools and application of CV, moreover, highlight the critical open research areas of ML in CV.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/9ae30ac3609a90b487df3beec10eeface021c7c5",
        "citation_count": 90
    },
    {
        "title": "Multitask learning and benchmarking with clinical time series data",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/9ae9d2b060e50094be7e473e449f192403019225",
        "citation_count": 819
    },
    {
        "title": "Comparison of Supervised Machine Learning and Probabilistic Approaches for Record Linkage",
        "abstract": "Introduction. Specialization of healthcare delivery and increased mobility of patient populations has led to the fragmentation of patient data across healthcare facilities and information systems 1 . Aggregation of fragmented patient data enables better patient care by preventing lengthened hospital stays, poor patient outcomes, and costly testing 2 . Due to legal restrictions on use of a uniform patient identifier, patient data is integrated using record linkage methods which utilize patient demographic information such as name, date of birth, address, and identifiers such as social security number. Probabilistic methods that leverage a wide range of patient demographic records for linkage are widely used for record linkage 3, 4 . However, probabilistic methods rely on human experts for many aspects of decision making, including selection of blocking schemes and evaluation of various matching thresholds for linkage. In contrast, supervised machine learning (ML) has been utilized to address various healthcare challenges with great success 5 . ML approaches are well suited for this challenge given their ability to learn complex rules using combinations of features. There have been successful attempts within other domains using ML for record linkage 6 . We hypothesize that supervised ML classifiers can efficiently identify duplicate patient record pairs with equal or greater accuracy than standard probabilistic linkage methods. Methods. We leveraged two manually curated gold standard datasets representing two use cases; (a) deduplicating a public health registration file, which identifies multiple instances of the same individual within a single patient registry (MCHD), and (b) linking death records to clinical data, which identifies instances of the same patient across different systems (SSDMF). The MCHD dataset consisted of 33,005 patient record pairs with 5.9% true duplicate pairs, while the SSDMF dataset consisted of 20,000 record pairs with 84.3% true matching pairs 7 . Each dataset consisted of a series of demographic features for each patient (Appendix A). We standardized",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/9b206e6d8c2389dccc73fe7215ec08275c8da1e2",
        "citation_count": 1
    },
    {
        "title": "A Euclidean Group Assessment on Semi-Supervised Clustering for Healthcare Clinical Implications Based on Real-Life Data",
        "abstract": "The grouping of clusters is an important task to perform for the initial stage of clinical implication and diagnosis of a disease. The researchers performed evaluation work on instance distributions and cluster groups for epidemic classification, based on manual data extracted from various repositories, in order to evaluate Euclidean points. This study was carried out on Weka (3.9.2) using 281 real-life health records of diabetes mellitus patients including males and females of ages>20 and <87, who were simultaneously suffering from other chronic disease symptoms, in Nigeria from 2017 to 2018. Updated plugins of K-mean and self-organizing map(SOM) machine learning algorithms were used to cluster the data class of mellitus type for initial clinical implications. The results of the K-mean assessment were built in 0.21 seconds with nine iterations for \u201ctype\u201d and eight for \u201cclass\u201d attributes. Out of 281 instances, 87 (30.97%) were classified as negative and 194 (69.03%) as positive in the testing on the Euclidean space plot. By assessment for Euclidean points, SOM discovered the search space in a more effective way, but K-mean positioning potencies are impulsive in convergence. This study is important for epidemiological disease diagnosis in countries with a high epidemic risk and low socioeconomic status.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/9b25acf2655cb65d32d5ea2d2d0e61fbaad5aa58",
        "citation_count": 14
    },
    {
        "title": "Cloud Computing Based Systems for Healthcare",
        "abstract": "The emergence of cloud computing leads to new developments for diverse application domains. This is particularly true for healthcare with its tremendous importance in today's society, thus making it worth to investigate the relevant perspectives and insights. In this special issue, readers will find the foundations together with cutting-edge developments in the state-of-the-art of cloud computing based systems for healthcare. \n \nCloud computing is getting increasing attention and represents nowadays one of the most important research topics in computing science and information systems. Cloud computing refers to both the applications delivered as services over the Internet and the hardware and software systems within the data centers which provide those services. Cloud is now seen as a valid strategy and specific applications based on these technologies have become widespread. \n \nHealthcare, as with any other service operation, has been impacted by the cloud computing phenomenon with the literature reporting both benefits and challenges of cloud computing in the area. However, the evolving nature of science and technology creates new scenarios that must be studied using interdisciplinary and holistic means. \n \nThe aim of this special issue was to collect innovative and high-quality research contributions regarding the advances in the healthcare domain that are enabled by the use of cloud computing architectures and techniques. The focus is intended to be integral for cloud computing in healthcare, but emphasizing not only the IT side of the phenomenon but also the managerial and the health practitioner side. \n \nEditors received a considerable amount of submissions that were peer-reviewed by top experts in the field. Based on the reviews and our reading of the papers, editors selected seven high-quality ones to be published. Contributions of these papers are summarized as follows. \n \nTwo contributions deal with scenarios where cloud computing can serve as an enabler for improved decision making and contribute to systemic improvements in healthcare domain. In \u201cUsalpharma: a cloud-based architecture to support Quality Assurance training processes in health area using Virtual Worlds\u201d by F. J. Garcia-Penalvo et al., the authors discuss ways cloud-based architectures can extend and enhance the functionality of training environments based on Virtual Worlds with focus on training processes in Quality Assurance for pharmaceutical laboratories. In \u201cCloud based meta-learning system for predictive modeling of biomedical data\u201d by M. Vukicevic et al., the authors propose a cloud-based system that integrates a meta-learning framework for ranking and selection of the best predictive algorithms for data at hand and open-source big data technologies for analysis of biomedical data. \n \nTwo contributions focus on the topics of risk and security as management issues in cloud computing based systems for healthcare. In \u201cProposal for a security management in cloud computing for health care\u201d K. by Haufe et al., the authors propose a framework that aims to cover the most important security processes related to cloud computing in the healthcare sector. The approach considers both the standards of the ISO 27000 family, as well as specific aspects of healthcare organizations using cloud computing. In \u201cRisks and crises for healthcare providers: the impact of cloud computing\u201d by R. Glasberg et al., the multidisciplinary team of authors analyze risks and crises for healthcare providers and discuss the impact of cloud computing in such scenarios. \n \nThree contributions deal with specific healthcare-related use cases of cloud computing in diverse application scenarios. In \u201cSAMuS: service-oriented architecture for multisensor surveillance in smart homes,\u201d S. Van Hoecke et al. present the design of a service-oriented architecture (SOA) for multisensor surveillance in smart homes. The solution is evaluated by building a smart Kinect sensor that is able to dynamically switch between IR and RGB and improves person detection by incorporating feedback from pressure sensors within the SOA. In \u201cA cloud-based X73 ubiquitous mobile healthcare system: design and implementation\u201d by Z. Ji et al., a ubiquitous mobile healthcare uHealth system is presented. It is based on the ISO/IEEE11073 personal health data (PHD) standards (X73) and cloud computing techniques. In \u201cAn expert fitness diagnosis system based on elastic cloud computing,\u201d K. C. Tseng et al. describe an expert diagnosis system based on cloud computing that is able to classify a user's fitness level based on supervised machine learning techniques. This system uses parameters such as user's physiological data, age, gender, and body mass index (BMI) and utilizes an elastic algorithm based on Poisson distribution to allocate computation resources dynamically. \n \nThe special issue editors would like to take this opportunity to thank the authors for their papers and the reviewers for their valuable comments and suggestions. Special thanks also to the editorial team for its help and also for providing us an opportunity to edit this special issue.",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/9b716916628ab9003f87bf5841350a847ff09c38",
        "citation_count": 34
    },
    {
        "title": "Dynamic Record Linking Using Multi-Agent Machine Learning: An Architecture for Noisy and Variable Datasets",
        "abstract": "The aim of this article is to present a dynamic record linkage solution using high level machine learning to solve the problems associated with noisy, inconsistent and dynamic data sets. Classic deterministic and probabilistic models fail to work in such environments because they are static and based on assumptions. Incorporating supervised learning algorithm, active learning, and ensemble techniques such as random forests and boosting allows the proposed structure to change in response to different data types and thus become more accurate and scaleable. Some of its highlights are feature selection to ensure match accuracy, clustering to support noisy inputs, and active learning to minimize reliance on large labeled datasets. Simulations with real data, such as government or healthcare data, show that compared with the traditional approach, linkage is significantly more accurate and efficient. The flexible model led to 15% higher F1-scores on noisy datasets and was scalable across large data sets. This work demonstrates how adaptive machine learning can revolutionize the modern record linkage tasks and provides a powerful and effective solution to ever-changing data conditions.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/9c1888e67605592da3e24e2e4cdcaa730bbe40ce",
        "citation_count": 0
    },
    {
        "title": "Data-Centric AI for Healthcare Fraud Detection",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/9c840db2efeb8f335a1bf3c581056fb2d555efe4",
        "citation_count": 28
    },
    {
        "title": "Unsupervised anomaly detection in time series data using deep learning",
        "abstract": "Detecting anomalies in time series data is an important task in areas such as energy, healthcare and security. The progress made in anomaly detection has been mostly based on approaches using supervised machine learning algorithms that require big labelled datasets to be trained. However, in the context of applications, collecting and annotating such large-scale datasets is difficult, time-consuming or even too expensive, while it requires domain knowledge from experts in the field. Therefore, anomaly detection has been such a great challenge for researchers and practitioners. This Thesis proposes a generic, unsupervised and scalable framework for anomaly detection in time series data. The proposed approach is based on a variational autoencoder, a deep generative model that combines variational inference with deep learning. Moreover, the architecture integrates recurrent neural networks to capture the sequential nature of time series data and its temporal dependencies. Furthermore, an attention mechanism is introduced to improve the performance of the encoding-decoding process. The results on solar energy generation and electrocardiogram time series data show the ability of the proposed model to detect anomalous patterns in time series from different fields of application, while providing structured and expressive data representations.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/9ce67f4d6e86785628553debf0c63824630a97ce",
        "citation_count": 5
    },
    {
        "title": "Mammogram Classification and Abnormality Detection from Nonlocal Labels using Deep Multiple Instance Neural Network",
        "abstract": "Mammography is the common modality used for screening and early detection of breast cancer. The emergence of machine learning, particularly deep learning methods, aims to assist radiologists to reach higher sensitivity and speci\ufb01city. Yet, typical supervised machine learning methods demand the radiological images to have \ufb01ndings annotated within the image. This is a tedious task, which is often out of reach due to the high cost and unavailability of expert radiologists. We describe a computer-aided detection and diagnosis system for weakly supervised learning, where the mammogram (MG) images are tagged only on a global level, without local annotations. Our work addresses the problem of MG classi\ufb01cation and detection of abnormal \ufb01ndings through a novel deep learning framework built on the multiple instance learning (MIL) paradigm. Our proposed method processes the MG image utilizing the full resolution, with a deep MIL convolutional neural network. This approach allows us to classify the whole MG according to a severity score and localize the source of abnormality in full resolution, while trained on a weakly labeled data set. The key hallmark of our approach is automatic discovery of the discriminating patches in the mammograms using MIL. We validate the proposed method on two mammogram data sets, a large multi-center MG cohort and the publicly available INbreast, in two different scenarios. We present promising results in classi\ufb01cation and detection, comparable to a recent supervised method that was trained on fully annotated data set. As the volume and complexity of data in healthcare continues to increase, such an approach may have a profound impact on patient care in many applications.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/9d4241e46a6136b87d723bdba502340c025474c6",
        "citation_count": 26
    },
    {
        "title": "An Experimental Study on Applying Supervised Machine Learning Techniques for Identification and Detection of Cardiac Attacks",
        "abstract": "Predicting cardiac disease is one of the most challenging undertakings in the medical industry. At this time, heart disease is responsible for about one death per minute. Using data science to process massive volumes of information is critical in the healthcare industry. Automating the forecasting procedure is necessary to reduce risks connected by it and warn the patient well in advance because predicting heart conditions can be a difficult undertaking. The healthcare sector employs millions of people worldwide and creates a considerable amount of data. The multidimensional medical datasets are being broken down by machine learning-based algorithms, which are revealing new information. In this study, a cardiovascular dataset is successfully categorized to produce illness predictions utilizing a number of cutting-edge supervised machine learning techniques. The findings showed that the Decision Tree classification model outperformed Naive Bayes and Logistic Regression in predicting cardiovascular disease. The Decision Tree was used to obtain accuracy of 74%. This technique may help doctors identify cardiac problems early and start treatment on schedule.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/9d9558973138782142469bed4a3ced9dbd31be08",
        "citation_count": 4
    },
    {
        "title": "The effects of training on employee performance in the public healthcare facilities in Kenya : a case of Mbagathi District Hospital",
        "abstract": "Training is a planned process to modify attitudes, knowledge or skill behavior through learning experience to achieve effective performance in an activity or range of activities, as defined in the glossary of training terms (Dessler, 2001). The emphasis is on planned process and effective performance. Training also refers to the methods used to guide new or present employees on the skills they need to perform their job. It might thus mean showing a mechanic how to operate his new machine, a new salesman how to sell his firm's products, or a new supervisor how to interview and appraise employees (Dessler, 2001. Training and development therefore entails a deliberately planned process that is carried in a systematic fashion and aimed at bringing about effective performance. The performance of any organization is dependent on the quality of its workforce. The general view is that training and development leads to improved employees performance and that organizations should therefore invest in training and development. The study seeks to examine whether training is an essential tool in enhancing employee productivity in the public health sector in Kenya. This was made possible by studying the Mbagathi District Hospital in a bid to examine the various variables relating to performance, success and survival the organization. The study also tried to assess the various aspects of performance like increased productivity, increased efficiency, improved quality levels, improved morale, working together with regard to specific training and development methods adopted by the health sector in Kenya. The scope of the study was liniited to the Mbagathi District Hospital. The target population was the 402 employees of the Mbagathi District Hospital. In this target population a sample of 160 employees was drawn by stratified random sampling technique. Data was collected using structured questionnaires and analyzed using descriptive statistics such as percentages, frequencies and measures of central tendencies through the SPSS computer package.",
        "year": 2011,
        "url": "https://www.semanticscholar.org/paper/9d9afe75c61121aeb2dc7a95fd532ba4f32bdd9f",
        "citation_count": 1
    },
    {
        "title": "Ensemble of Autoencoders for Anomaly Detection in Biomedical Data: A Narrative Review",
        "abstract": "In the context of biomedical data, an anomaly could refer to a rare or new type of disease, an aberration from normal behavior, or an unexpected observation requiring immediate attention. The detection of anomalies in biomedical data has a direct impact on the health and safety of individuals. However, anomalous events are rare, diverse, and infrequent. Often, the collection of anomalous data may involve significant loss of human life and healthcare costs. Therefore, traditional supervised machine and deep learning algorithms may not be directly applicable to such problems. Biomedical data are often collected in the form of images, electronic health records, and time series. Typically, an autoencoder (AE) or its corresponding variant is trained on normal data, and an anomaly is identified as a significant deviation from these data based on reconstruction error or other metrics. An Ensemble of AEs (EoAEs) can serve as a robust approach for anomaly detection in biomedical data by combining diverse and accurate views of normal data. An EoAE can provide superior detection to a single encoder; however, its performance can depend on various factors, including the diversity of the created data, the accuracy of the individual AEs, and the combination of their outcomes. Herein, we perform a comprehensive narrative literature review on the use of EoAEs when using different types of biomedical data. Such an ensemble provides a promising approach for anomaly detection in biomedical data, offering the potential for performance improvement by leveraging the strengths of diverse AEs. However, several challenges remain, such as the need for data specification and determination of the optimal number of AEs in the ensemble. By addressing these challenges, researchers can enhance the effectiveness of EoAEs for anomaly detection in various types of biomedical data. Furthermore, through this review, we highlight the significance of evaluating and comparing the performance of an EoAE with that of single AEs by establishing agreed-upon evaluation metrics and investigating normalization techniques for anomaly scores. We conclude the review by presenting challenges and open questions in the field with for future research.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/9dd196b941f340a4396c08fc6660dba5d50f928f",
        "citation_count": 12
    },
    {
        "title": "A Review on Artificial Intelligence in Pharmaceutical Science",
        "abstract": "Abstract: In recent years, the use of artificial intelligence (AI) in health care has risen steadily, including a wide range of applications in the field of pharmacology. AI is now used throughout the entire continuum of pharmacology research and clinical practice and from early drug discovery to real-world data mining. The types of AI models used range from unsupervised clustering of drugs or patients aimed at identifying potential drug compounds or suitable patient populations, to supervised machine learning approaches to improve therapeutic drug monitoring. Additionally, natural language processing is increasingly used to mine electronic health records to obtain real-world data. In this mini-review, we discuss the basics of AI followed by an outline of its application in pharmacology research and clinical practice. Artificial intelligence is the upcoming technology in advance health care system. Current digitalization of medicine and availability of electronic health records (EHRs) has inspired clinical researchers and healthcare personnel to acquire artificial intelligence (AI) methodologies for big data analytics and for very large scale medical databases. The major advantage of AI is that it reduces the time that is needed for drug development and, in turn, it reduces the costs that are associated with drug development, enhances the returns on investment and may even cause a decrease in cost for the end user. A large number of researches are being carried out to improve the current available AI technology to make the pharmacy profession more efficient. The present article briefly describes the importance of AI in the process of drug development and then looks at the various AI tools that are available at the disposal of a modern-day pharmacist to aid in a more efficient functioning.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/9de90bb1df107ad9ab7015c4d03a7d6eda64c310",
        "citation_count": 0
    },
    {
        "title": "Statistical similarity matching and filtering for clinical image retrieval by machine learning approach",
        "abstract": "Clinical image retrieval plays a pivotal role in modern healthcare for diagnostics and research, but prior research has grappled with the challenge of achieving high accuracy due to limited filtering techniques. The proposed method includes statistical distance measurements for similarity comparison and a machine learning technique for image filtering. Throughout this framework, the search area for similarity matching is reduced by first filtering away irrelevant images using the probabilistic outcomes of the Support Vector Machine (SVM) classification as class predictions of search and database images. Resizing is done as part of the preprocessing. Then, using Principal Component Analysis (PCA), the preprocessed data\u2019s textural features, visual characteristics, and low-level features are extracted. The study also suggested an adaptive similarity matching method centered on a linear integration of feature-level similarities on the individual-level level. The precision and ranking order details of the most appropriate images retrieved and predicted by SVMs are considered when calculating the feature weights. The system continually alters weights for every distinctive search to generate beneficial outcomes. The supervised and unsupervised learning strategies are studied to link low-level global image features in the generated PCA-based Eigen Space using their high-level semantic and visual classifications to reduce the semantic gap and enhance retrieval effectiveness. The ground-truth database used in experiments has 1594 unique medical images with 3 different databases. Our method significantly improves the precision and recall rates in image retrieval tasks by combining sophisticated feature extraction, data-driven algorithms, and deep learning models. Research obtained an impressive accuracy of 0.99, demonstrating the effectiveness of our approach. This novel methodology addresses the limitations of prior research and provides a robust and reliable solution for clinicians and researchers in the medical field seeking to access and analyze relevant clinical images.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/9e063a48fb1900d1cd6a6cda3cadc892717ade4c",
        "citation_count": 1
    },
    {
        "title": "Study design: Development of an advanced machine learning algorithm for the early diagnosis of Gaucher disease using real-world data",
        "abstract": "Background: Gaucher disease (GD) is a rare, autosomal recessive condition, characterized by deficiency of the lysosomal enzyme \u03b2-glucocerebrosidase. The main disease features are anemia, thrombocytopenia, hepato-splenomegaly and bone infarction, osteonecrosis, and pathological fractures. However, diagnosis of GD can be challenging, especially for non-specialists, owing to wide variability in age at presentation, non-specific features, severity and type of clinical manifestations, and lack of awareness of the early signs and symptoms of the disease. Delayed and misdiagnosis of GD may lead to irreversible bone disease, severe growth retardation, and high risk of bleeding; in rare cases, misdiagnosis may be life-threatening. Developing a system for early and accurate diagnosis of GD is thus an essential unmet need. The development of an algorithm for early diagnosis of patients with rare diseases such as GD may help reduce delays in diagnosis and enable prompt, appropriate initiation of therapy, earlier decision-making, prevent potentially irreversible morbidities and unnecessary tests (some invasive), reduce anxiety, and facilitate genetic counseling. This study aims to develop a predictive model for the accurate diagnosis of GD using machine learning based on real-world clinical data.\n Methods: This study will be comprised of three parts. Part 1, a retrospective observational database analysis, will use data from the electronic patient database of the Maccabi Healthcare Service (MHS), the second largest Health Maintenance Organization in Israel. The MHS includes 2.2 million health records from 25% of the Israeli population. Clinical records have been fully computerized for >20 years and are fully integrated with automated central laboratory, digitized imaging and pharmacy purchase data. Patients with confirmed GD who have been enrolled in the MHS health plan for \u22651 year will be eligible for inclusion, with approximately 250 patients with GD expected to be enrolled. Using MHS data from patients with GD, the Gaucher Earlier Diagnosis Consensus (GED-C) scoring system, developed by a consensus panel using Delphi methodology on the signs and co-variables that may be important for the diagnosis of GD, will be evaluated and compared with alternative scores developed directly from clinical data based on supervised machine learning.\n In Part 2, a clinical study, the best performing modeled scores from Part 1 will be applied to the MHS database to identify individuals who may have undiagnosed GD ('GD suspects'). Samples for diagnostic testing (using a specific and sensitive biomarker (glucosylsphingosine, lyso-Gb1) followed by beta-glucocerebrosidase (GBA) genotyping for positive samples) will be collected from MHS biobank (for individuals who have consented). Individuals not participating in the biobank will be asked to provide a sample. This part of the study will evaluate the predictive value of the modeled scores, and assess the sensitivity and specificity of the model for the diagnosis of new patients with GD.\n In Part 3, analysis of data from newly diagnosed patients identified in Part 2 will be used to develop machine learning models for the diagnosis of GD (Figure 1). Signs and co-variables included in the GED-C score will be used, eliminating features that are non-informative. Features will be quantitative where possible, and interaction terms will be added for age of onset and trend for key features. A number of methods will be developed, with the best performing, based on its precision at a given sensitivity level, being selected as the final model. External validation of the best identified model is planned, to ensure unbiased estimate of the model's accuracy.\n Discussion: The main goal of the study is to develop an algorithm to help detect patients with GD, independent of physicians' ability to recognize signs and symptoms, using the application of machine learning to data from a large health database. The study is expected to result in a practical tool that will alert physicians to the possibility of GD. The resulting model will also improve our understanding of GD based on the relative importance of features for GD prediction. Such tools will have a positive impact on patient care and quality of life and on healthcare costs and may lead to a change in approach for diagnosing rare diseases.\n \n \n \n Revel-Vilk: Takeda: Honoraria; sanofi-Genzyme: Honoraria; Pfizer: Honoraria. Chodick:Novartis Pharma AG: Other: Institutional grant. Gadir:Takeda: Current Employment.\n",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/9e6696d2af68cfe763323b6106621cd43a737b59",
        "citation_count": 3
    },
    {
        "title": "Optimizing the Performance of Plastic Injection Molding Using Weighted Additive Model in Goal Programming",
        "abstract": "This paper describes a methodology and lessons learned from collecting datasets in Ambient Intelligence Environments. The authors present considerations on how to setup an experiment and discuss decisions taken at different planning steps, ranging from the selection of human activities over sensor choices to issues of the recording software. The experiment design and execution is illustrated through a dataset involving 150 recording sessions with 28 sensors worn on the subject body and embedded into tools and the environment. The paper also describes a number of unforeseen problems that affected the experiment and useful considerations that help other researchers recording their own ambient intelligence datasets. DOI: 10.4018/jaci.2010040103 International Journal of Ambient Computing and Intelligence, 2(2), 42-56, April-June 2010 43 Copyright \u00a9 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. This work focuses on the recognition of human activities, which allows for activity-based computing (Davies et al., 2008), and is seen here as a sense and classify problem. Common approaches can be divided into those relying on video tracking systems (Mitra et al., 2007) and others relying on multimodal sensor networks that include body-worn sensors, smart sensors and sensors embedded in furniture (Ward et al., 2006; Jeong et al., 2008; Amft, 2007). In this paper, we focus on the second group. In such settings, data is collected from a large number of sensors and is fused using machine learning algorithms to recognize people activity. Typical algorithms include decision tree classifiers, Bayesian networks, linear discriminant classifiers, neural networks, Hidden Markov Models, voting techniques and many others (Duda et al., 2000). These algorithms belong to the class of supervised classifiers which learn by example. In a training phase, they require a large set of sample instances of all classes. From these instances, they optimize their model parameters to reflect the classes. The recognition performance can then be tested using a validation set, a second set of class instances, which have not been seen used in training. Complex classification algorithms or complicated signal patterns often require large datasets for reliable training and testing. Establishing large datasets from AmI environments is costly and time-consuming, but crucial for the research community (Ponce et al., 2006). Besides deploying and maintaining sensors, data needs to be collected over weeks, months, or even years. All data needs to be annotated by humans, such that activities of interest are marked in the sensor streams. Aware of these limits, many researchers share the datasets they have obtained from their instrumented environments (Intille, 2009; BoxLab, 2009). The objective is to accelerate the creation of novel applications in the fields of human-computer interaction, healthcare and ubiquitous computing. But what are the specific problems encountered when collecting datasets? What should researchers be aware of when they plan experiments? We present the methodology and we have learned from recording various complex datasets of everyday activities. For every step we present, we describe how we have solved it during a joint project of the University of Bologna and ETH Z\u00fcrich. The experiment consists of 28 sensors implementing 5 sensing modalities and recording 64 atomic activities within 8 scenarios of everyday life. The dataset is freely available for research purposes1. The article is organized as follows; the next section presents an overview of freely available datasets. We then describe our methodology and the individual steps we have followed to produce our dataset. The article concludes with a number of lessons learned.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/9ec3cfb6f1c41b0f52654af6357fcfb6147d0d8c",
        "citation_count": 10
    },
    {
        "title": "Contemporary Human Activity Recognition Based Predictions by Sensors Using Random Forest Classifier",
        "abstract": "The task of recognizing human activities directs extensive divergence of various functions and applications. Despite analysing the intricate activity it endures demanding requirements in contemporary field of research. A subject performs a definite task at a particular time by determining\n the activity by using sensor data. In this research task we appraise a unique way by using data with supervised learning techniques by placing sensors on the human body by contingent upon classification process at different stages. The State-of-art machine learning approach random forests\n are widely discussed in terms of covering practical and theoretical aspects of body sensing. The eventual target is the superior rate of accurate predictions effecting Human Activity Recognition further effective for behavioural monitoring, medical and healthcare sectors. Classification processes\n are deployed for pairs of activities that are distracted often and this work attempts to analyse the essential sensors for the improved prediction. The results shows the best accuracy scores and the remaining of our findings we expose the outline, exhibiting the degree of distraction between\n features of ranking and human activities which renders back to sensor ranking.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/9f16587edcbaf7a1d1dc54cdf58c2fdaa1015c2d",
        "citation_count": 1
    },
    {
        "title": "EPIC: Enhancing Privacy through Iterative Collaboration",
        "abstract": "Advancements in genomics technology lead to a rising volume of viral (e.g., SARS-CoV-2) sequence data, resulting in increased usage of machine learning (ML) in bioinformatics. Traditional ML techniques require centralized data collection and processing, posing challenges in realistic healthcare scenarios. Additionally, privacy, ownership, and stringent regulation issues exist when pooling medical data into centralized storage to train a powerful deep learning (DL) model. The Federated learning (FL) approach overcomes such issues by setting up a central aggregator server and a shared global model. It also facilitates data privacy by extracting knowledge while keeping the actual data private. This work proposes a cutting-edge Privacy enhancement through Iterative Collaboration (EPIC) architecture. The network is divided and distributed between local and centralized servers. We demonstrate the EPIC approach to resolve a supervised classification problem to estimate SARS-CoV-2 genomic sequence data lineage without explicitly transferring raw sequence data. We aim to create a universal decentralized optimization framework that allows various data holders to work together and converge to a single predictive model. The findings demonstrate that privacy-preserving strategies can be successfully used with aggregation approaches without materially altering the degree of learning convergence. Finally, we highlight a few potential issues and prospects for study in FL-based approaches to healthcare applications.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/9f1683fff6d51832af050fc68ab551f76d9ea091",
        "citation_count": 0
    },
    {
        "title": "Application of AI and ML in the Field of DevSecOps",
        "abstract": "Security is a paramount concern in DevOps. The adoption of Infrastructure as Code (IaC) has increased the potential impact of even minor flaws, particularly in critical domains like healthcare and maritime applications. Existing solutions typically focus on either Static Application Security Testing (SAST) or run-time behavior analysis. This paper introduces the IaC Scan Runner, an open-source tool developed in Python for inspecting various IaC languages during application design, and LOMOS, a run-time anomaly detection tool. Both tools work together to enhance the security of DevOps processes. In today\u2019s rapidly evolving technological landscape, the vulnerability of infrastructure and applications is growing due to a combination of factors. Attackers are becoming more sophisticated, leveraging improved intelligence to exploit weaknesses. At the same time, there is a lack of technical capability in many organizations to effectively secure their systems. This paper explores a dual approach to cybersecurity: static security monitoring through rule matching and the application of self-supervised machine learning. By combining these approaches, organizations can better defend against cyber threats. One area of focus is supply chain resilience and smart logistics, where the integration of these methods is particularly critical. This approach emphasizes a self-learning and self-healing approach, allowing systems to adapt and respond to new threats autonomously. Integrating Artificial Intelligence (AI) and Machine Learning (ML) into DevSecOps practices is essential for improving security, efficiency, and innovation in software development and deployment. This paper delves into strategies and best practices for leveraging AI/ML within the DevSecOps framework. It discusses automated threat detection, predictive analytics for vulnerability management, and intelligent automation for continuous integration and deployment. However, this integration also presents challenges, such as data privacy, algorithm transparency, and ethical implications. The paper addresses these challenges and showcases how organizations can use AI/ML to optimize their DevSecOps pipelines, mitigate security risks, and foster continuous improvement. The adoption of Infrastructure as Code (IaC) has increased the potential impact of even minor flaws, especially in critical domains like healthcare and maritime applications. Existing solutions typically focus on either Static Application Security Testing (SAST) or run-time behavior analysis.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/9f36864910abfe897284abeca971479a703135ae",
        "citation_count": 2
    },
    {
        "title": "A Review of Deep Learning Algorithms and Their Applications in Healthcare",
        "abstract": "Deep learning uses artificial neural networks to recognize patterns and learn from them to make decisions. Deep learning is a type of machine learning that uses artificial neural networks to mimic the human brain. It uses machine learning methods such as supervised, semi-supervised, or unsupervised learning strategies to learn automatically in deep architectures and has gained much popularity due to its superior ability to learn from huge amounts of data. It was found that deep learning approaches can be used for big data analysis successfully. Applications include virtual assistants such as Alexa and Siri, facial recognition, personalization, natural language processing, autonomous cars, automatic handwriting generation, news aggregation, the colorization of black and white images, the addition of sound to silent films, pixel restoration, and deep dreaming. As a review, this paper aims to categorically cover several widely used deep learning algorithms along with their architectures and their practical applications: backpropagation, autoencoders, variational autoencoders, restricted Boltzmann machines, deep belief networks, convolutional neural networks, recurrent neural networks, generative adversarial networks, capsnets, transformer, embeddings from language models, bidirectional encoder representations from transformers, and attention in natural language processing. In addition, challenges of deep learning are also presented in this paper, such as AutoML-Zero, neural architecture search, evolutionary deep learning, and others. The pros and cons of these algorithms and their applications in healthcare are explored, alongside the future direction of this domain. This paper presents a review and a checkpoint to systemize the popular algorithms and to encourage further innovation regarding their applications. For new researchers in the field of deep learning, this review can help them to obtain many details about the advantages, disadvantages, applications, and working mechanisms of a number of deep learning algorithms. In addition, we introduce detailed information on how to apply several deep learning algorithms in healthcare, such as in relation to the COVID-19 pandemic. By presenting many challenges of deep learning in one section, we hope to increase awareness of these challenges, and how they can be dealt with. This could also motivate researchers to find solutions for these challenges.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/9f40b09d8752c687b0589a79892e4a6f17d97ee6",
        "citation_count": 53
    },
    {
        "title": "Childhood Asthma Disease Prediction Using Classification Algorithms of Supervised Machine Learning",
        "abstract": "Asthma is a very dangerous lung disease in which our airways are swollen and become narrow and blocked. Air does not flow through narrow airways properly. It is an ongoing disease and does not go away, regular treatment is needed lifelong. According to the survey report, 25 million people in the United States are living with this disease and out of that 5 million are children who are asthma patients. Asthma is a life-threatening disease if don\u2019t get treatment timely, can lose your life. Early prediction of this disease among children not only provides a recovery solution for the disease but also helps to increase their lifetime. The proposed designed Intelligent system provides useful resources to the healthcare system to make accurate decisions for preventing asthma in childhood. The research paper aims to design an intelligent artificial-based machine learning classification model to predict asthma disease among children aged less than 10 years. Research also included a comparative analysis of different classification methods of machine learning like Linear regression, KNN Model, Decision Trees, Random Forests and Support Vector machines. It also helps to select the best model by analyzing the performances of these algorithms based on efficiency and accuracy. The outcomes of the research paper to study asthma prediction using different classification models and help doctors and patients to take the right decision timely.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/9f566a418ec3f6fe9caa02a3bbdfcc57d1d66453",
        "citation_count": 2
    },
    {
        "title": "CRITICAL DECISION SUPPORT SYSTEM AT HEALTHCARE USING MACHINE LEARNING",
        "abstract": ": Intensive Care Unit should be the most monitored and supervised area in a health-care sector. But, the unfortunate point is ICU is being monitored but not supervised always as patient-nurse ratio is not appropriate. Due to the lack of nurse\u2019s availability, insufficient number of beds in ICU, this problem happened. For most people, the ICU is a black box. According to the Society of Critical Care Medicine (SCCM), the five primary ICU admission diagnoses for adults are respiratory insufficiency/failure with ventilator support, acute myocardial infarction, intracranial hemorrhage or cerebral infarction, percutaneous cardiovascular procedures, and septicemia or severe sepsis without mechanical ventilation. Sometimes, it is very difficult to decide whether a patient needs to be transferred from a general ward to the ICU or not or even some medical persons may not decide whether the patient admitted into ICU needs to be transferred into the ICU or not. Misdiagnosis in the intensive care unit (ICU) is 50% more common than other areas. Not taking the right decision at the proper time may cause the patient\u2019s death. So, this is a very vital time to take action for making the right decision at the right time. In our paper, we have proposed a classification model by combining two most popular machine learning(ML) classification models i.e. logistic regression and Support vector machine(SVM). We have combined these two models by employing a most popular ensemble learning technique called Voting classifier. Our experiment proves that employing the ensemble technique of the Voting classifier outperforms all individual classification models. We have also shown a comparative study of logistic regression, SVM, Decision tree, Na\u00efve-Bayes and their ensemble combinations. We have performed a performance test with the parameters of accuracy, sensitivity and specificity with our proposed model by using real-world dataset(from Kaggle). Feature selection also performed carefully to increase the performance and interpretability of our model and we achieved 99.65% of accuracy with our proposed model",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/9f56f021742ef8953e2db33d55902744d8cc9736",
        "citation_count": 0
    },
    {
        "title": "Image Document Classification Prediction based on SVM and gradient-boosting Algorithms",
        "abstract": "Image document classification is crucial in various domains, including healthcare, finance, and security. Automatically categorizing images into predefined classes can significantly improve data management and decision-making processes. For this research, we investigate the effectiveness of two machine learning algorithms, Support Vector Machines (SVM) and Gradient Boosting, for image document classification. First, we preprocess the image data by extracting relevant features, such as Image Embedding, to create a feature vector for each image. These features are essential for representing the content of the images accurately. Next, we apply SVM, a robust supervised learning algorithm, to train a classification model. SVM aims to Determine the optimal hyperplane for effectively distinguishing the images into different classes while maximizing the margin. Furthermore, we explore the Gradient Boosting algorithm, an ensemble learning method combining multiple weak learners to create a robust classifier. We experimented with different classification results with ten classes. We employ Multiple measures, including accuracy, precision, recall, F1-score, and ROC-AUC, are used to assess the performance of the SVM and Gradient Boosting models. The higher result of 0.964 for SVM compared with Adaboost is achieved. 0.853.\u00a0",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/9fa05602f05b2eb543c19df5505af2b6b3a89035",
        "citation_count": 4
    },
    {
        "title": "Federated Semi-Supervised Learning for Medical Image Segmentation via Pseudo-Label Denoising",
        "abstract": "Distributed big data and digital healthcare technologies have great potential to promote medical services, but challenges arise when it comes to learning predictive model from diverse and complex e-health datasets. Federated Learning (FL), as a collaborative machine learning technique, aims to address the challenges by learning a joint predictive model across multi-site clients, especially for distributed medical institutions or hospitals. However, most existing FL methods assume that clients possess fully labeled data for training, which is often not the case in e-health datasets due to high labeling costs or expertise requirement. Therefore, this work proposes a novel and feasible approach to learn a Federated Semi-Supervised Learning (FSSL) model from distributed medical image domains, where a federated pseudo-labeling strategy for unlabeled clients is developed based on the embedded knowledge learned from labeled clients. This greatly mitigates the annotation deficiency at unlabeled clients and leads to a cost-effective and efficient medical image analysis tool. We demonstrated the effectiveness of our method by achieving significant improvements compared to the state-of-the-art in both fundus image and prostate MRI segmentation tasks, resulting in the highest Dice scores of 89.23% and 91.95% respectively even with only a few labeled clients participating in model training. This reveals the superiority of our method for practical deployment, ultimately facilitating the wider use of FL in healthcare and leading to better patient outcomes.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a0267655c2384f7684f024422d37b17d472bc8db",
        "citation_count": 21
    },
    {
        "title": "Enhancing Automated and Early Detection of Alzheimer's Disease Using Out-Of-Distribution Detection",
        "abstract": "More than 10.7% of people aged 65 and older are affected by Alzheimer's disease. Early diagnosis and treatment are crucial as most Alzheimer's patients are unaware of having it until the effects become detrimental. AI has been known to use magnetic resonance imaging (MRI) to diagnose Alzheimer's. However, models which produce low rates of false diagnoses are critical to prevent unnecessary treatments. Thus, we trained supervised Random Forest models with segmented brain volumes and Convolutional Neural Network (CNN) outputs to classify different Alzheimer's stages. We then applied out-of-distribution (OOD) detection to the CNN model, enabling it to report OOD if misclassification is likely, thereby reducing false diagnoses. With an accuracy of 98% for detection and 95% for classification, our model based on CNN results outperformed our segmented volume model, which had detection and classification accuracies of 93% and 87%, respectively. Applying OOD detection to the CNN model enabled it to flag brain tumor images as OOD with 96% accuracy and minimal overall accuracy reduction. By using OOD detection to enhance the reliability of MRI classification using CNNs, we lowered the rate of false positives and eliminated a significant disadvantage of using Machine Learning models for healthcare tasks. Source code available upon request.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a0438efeca33a80f552bd9f745223f4b215e77bf",
        "citation_count": 4
    },
    {
        "title": "Cerebrovascular Accident Prognosis using Supervised Machine Learning Algorithms",
        "abstract": "Cerebral vascular problems, such as stroke, have become a major concern in healthcare due to their impact on neurological health. Early detection of these illnesses can considerably enhance patient outcomes and lead proper treatment choices. Recently, supervised machine learning algorithms have emerged as potential techniques for anticipating cerebrovascular diseases utilizing numerous clinical indicators. This study compares the predictive performance of three supervised learning algorithms, Random Forest, Decision Tree, and XGBoost, in the context of cerebrovascular disease prediction. The dataset utilized for training and evaluation comprises a variety of clinical parameters such as age, blood pressure, cholesterol levels, smoking status, and medical history. Random Forest has the highest prediction accuracy of the three algorithms, at 99.93% for cerebrovascular diseases. This result demonstrates how effective and reliable Random Forest\u2019s pattern detection algorithms are in this dataset. With a near accuracy of 97.94%, XGBoost exhibits a good capacity for prediction. Decision Tree nevertheless obtains an excellent accuracy of 97.53% despite somewhat inferior performance compared to XGBoost, making it a competitive choice for the prediction of cerebrovascular disease. These results outperform the most recent state-of-the-art results and show a considerable increase in accuracy when compared to existing methods. The study emphasizes how well supervised learning systems, in particular Random Forest, capture the complex relationships between clinical parameters for accurate predictions of cerebrovascular diseases. The outstanding accuracy of these models highlights their potential for accurate cerebrovascular prediction in clinical practice.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a0633b27d44951629bb75472c5880a770e56ddec",
        "citation_count": 2
    },
    {
        "title": "Investigating the Potential of Self-Supervised Learning in Adversarial Machine Learning",
        "abstract": "Machine learning has enabled innovative usage in numerous fields. These systems are vulnerable to hostile assaults. Small intentional alterations to misclassify data constitute a maj or security risk. We examine three solutions: \u201cSelf-Supervised Adversarial Defence\u201d, \u201cAdversarial Mixup\u201d and \u201cSecure and Self-Supervised Learning.\u201d These strategies safeguard and protect machine learning models from other computers. We start our study with the theory underlying these approaches and how they are employed in machine learning. A detailed experimental evaluation utilizing a real-world dataset with difficult adversarial situations is shown. These approaches are tested using accuracy, precision, memory, F1 score, and ROC AUC. Results are certain. All indicators suggest that new methods outperform old ones. \u201cSelf-Supervised Adversarial defence\u201d is the most exact and precise, but \u201cAdversarial Mixup\u201d and \u201cSecure and Self-Supervised Learning\u201d are also useful, especially for memory. The ROC AUC values also demonstrate that the recommended approaches can distinguish positive and negative classes, which is crucial in binary classification problems. Finally, our work indicates that these strategies can make machine learning models safer and more resilient in harmful conditions. This study reveals how adversarial perturbations and self-supervised learning might solve the crucial challenge of adversarial assaults. These strategies can make machine learning systems safer, which might impact hacking, healthcare, and self-driving systems.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a078583973f1cecb94ad40f2e43481abf0a6da3c",
        "citation_count": 0
    },
    {
        "title": "PatchLoc: Embedded Patch Localization Pretext Task for Tumor Segmentation in Medical Images",
        "abstract": "Supervised deep learning methods have produced state-of-the-art results with large labeled datasets. However, accessing large labeled datasets is difficult in medical image analysis because of a shortage of medical experts, expensive annotations, and privacy constraints in the healthcare domain. Self-supervised learning is a branch of machine learning that exploits unlabeled data to encourage network weights toward a valid latent representation of the data during a so-called pretext task. The features learned by the model while solving pretext tasks are transferred to a downstream task where limited annotations are available. In this work, we propose PatchLoc, a novel pretext task whose objective is to find the location of a given patch from an image as a source of supervision. We validated the effectiveness of PatchLoc on a downstream segmentation task using three different medical datasets. PatchLoc yields substantial improvements compared to U-Net trained from scratch and other pretext task-based approaches in a low data regime.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a102da207ce4db156103494f56e1b709d36521b9",
        "citation_count": 1
    },
    {
        "title": "The Role of AI in Revolutionizing Healthcare Practices: Conceptual Approach",
        "abstract": "Artificial intelligence is transforming and enhancing modern healthcare by enabling technologies that predict, understand, learn, and act. Whether used to uncover new genetic code linkages or manage surgery-assisting robots, AI combines the terms \"artificial\" and \"intelligence.\" Intelligence encompasses reasoning, generating novel ideas, understanding information, and acquiring knowledge. In contrast, \"artificial\" refers to something not genuine or naturally occurring. In healthcare, traditional machine learning, a form of AI, is commonly used for precision medicine. This approach aims to determine the most effective treatment procedures for a patient based on their specific qualities and therapy context. Supervised learning, a prerequisite for most machine learning and precision medicine applications, requires a training dataset with a known outcome variable, such as disease onset. This paper explores key applications of AI in healthcare and the ethical principles guiding its application.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/a1554129702fff470e0c0f09d7c8b672c24c2d63",
        "citation_count": 0
    },
    {
        "title": "Federated Learning Approach to Protect Healthcare Data over Big Data Scenario",
        "abstract": "The benefits and drawbacks of various technologies, as well as the scope of their application, are thoroughly discussed. The use of anonymity technology and differential privacy in data collection can aid in the prevention of attacks based on background knowledge gleaned from data integration and fusion. The majority of medical big data are stored on a cloud computing platform during the storage stage. To ensure the confidentiality and integrity of the information stored, encryption and auditing procedures are frequently used. Access control mechanisms are mostly used during the data sharing stage to regulate the objects that have access to the data. The privacy protection of medical and health big data is carried out under the supervision of machine learning during the data analysis stage. Finally, acceptable ideas are put forward from the management level as a result of the general privacy protection concerns that exist throughout the life cycle of medical big data throughout the industry.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/a172591d42f536ecdeaae05ffd5c2f128970da5c",
        "citation_count": 45
    },
    {
        "title": "Contrastive Self-Supervised Learning for Tabular Data",
        "abstract": "Much of the worlds data is stored in databases or spreadsheets and consists of columns of features which comprise of continuous, categorical or binary variables. A range of challenging and important machine learning tasks rely on data of this format such as applications in healthcare, business analytics and recommendation systems. However, large amounts of labelled data for a specific task can often be either expensive or impossible to obtain. Self-supervised learning is a technique in machine learning in which representations are learned from large amounts of unlabelled data and then used to assist other models trained on tasks for which there is only a small amount of labelled data. Recent research has shown that this approach can improve performance on tabular data when labelled data is scarce, and therefore finding better self-supervised learning methods for tabular data is an important area of research. Contrastive learning is a framework for learning representations that has recently received a great deal of attention, particularly in computer vision, because of it\u2019s state-of-the-art performance in self-supervised learning. However, whilst it has been applied successfully to image data, the vast majority of current contrastive learning methods require the use of bespoke augmentations that are only applicable to images. Tabular data is a domain where data augmentations are not as widely used because there do not exist strong inductive biases about the latent information in the inputs for all datasets that would be equivalent to, for example, translation invariance for images. There has therefore been almost no research into contrastive learning for tabular data, in spite of the fact that contrastive learning does not demand the use of augmentations, and could potentially be used to achieve equivalent improvements in performance for tabular data if adapted correctly. In this thesis, we explore the use of contrastive learning for tabular data and develop a novel approach called Masked Contrastive Learning (MCL) that does not require domainspecific augmentations and we show that it can be used to achieve state-of-the-art results for self-supervised learning on tabular data. We also extend our approach using a novel masking scheme we develop which allows the mask generator to learn to retain the structural informa-",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a186f1a16c7e570da1bce32cfd87892a3fbce5c6",
        "citation_count": 0
    },
    {
        "title": "Auto-categorization of medical concepts and contexts",
        "abstract": "In healthcare, information extraction is important in order to identify conceptual knowledge as a category of medical concepts from a large number of unstructured and semi-structured corpora. Category describes how medical concepts are fundamentally separated from each other to represent their conceptual knowledge in the corpus. In this paper, we focus on identifying the category of medical concepts and contexts which describe the subjective and the conceptual information of the medical corpus. To recognize the medical concept and assign their category, we employ our previously developed WordNet of Medical Event (WME 2.0) domain-specific lexicon. The lexicon provides medical concepts and their affinity, gravity, polarity scores, similar sentiment words, and sentiment features, help to develop the category assignment system. The identified categories for the concepts are diseases, drugs, symptoms, human_anatomy, and miscellaneous medical terms (MMT), which all refer the broadest fundamental classes of medical concepts. Therefore, the assigned categories of medical concepts used to build the category assignment system for the medical context. The proposed system allows extracting eleven types of pairbased categories as disease-symptom, disease-drug, and disease-MMT of contexts. To validate the categorization system for medical concepts and contexts, we have employed widely used supervised machine learning classifiers namely Na\u00efve Bayes and Logistic Regression in the presence of WME 2.0 lexicon. The two classifiers provide F-scores of 0.81 and 0.86 for the concepts and contexts categorization systems, respectively.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/a1c8734b52a5fa369aabd1aa43a67ab666a83f72",
        "citation_count": 7
    },
    {
        "title": "Applied machine learning for the risk-stratification and clinical decision support of hospitalised patients with dengue in Vietnam",
        "abstract": "Background Identifying patients at risk of dengue shock syndrome (DSS) is vital for effective healthcare delivery. This can be challenging in endemic settings because of high caseloads and limited resources. Machine learning models trained using clinical data could support decision-making in this context. Methods We developed supervised machine learning prediction models using pooled data from adult and paediatric patients hospitalised with dengue. Individuals from 5 prospective clinical studies in Ho Chi Minh City, Vietnam conducted between 12th April 2001 and 30th January 2018 were included. The outcome was onset of dengue shock syndrome during hospitalisation. Data underwent random stratified splitting at 80:20 ratio with the former used only for model development. Ten-fold cross-validation was used for hyperparameter optimisation and confidence intervals derived from percentile bootstrapping. Optimised models were evaluated against the hold-out set. Findings The final dataset included 4,131 patients (477 adults and 3,654 children). DSS was experienced by 222 (5.4%) of individuals. Predictors were age, sex, weight, day of illness at hospitalisation, indices of haematocrit and platelets over first 48 hours of admission and before the onset of DSS. An artificial neural network model (ANN) model had best performance with an area under receiver operator curve (AUROC) of 0.83 (95% confidence interval [CI], 0.76\u20130.85) in predicting DSS. When evaluated against the independent hold-out set this calibrated model exhibited an AUROC of 0.82, specificity of 0.84, sensitivity of 0.66, positive predictive value of 0.18 and negative predictive value of 0.98. Interpretation The study demonstrates additional insights can be obtained from basic healthcare data, when applied through a machine learning framework. The high negative predictive value could support interventions such as early discharge or ambulatory patient management in this population. Work is underway to incorporate these findings into an electronic clinical decision support system to guide individual patient management.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/a210ef4752806aedcc6e57c16b898bacc78f4a57",
        "citation_count": 11
    },
    {
        "title": "Understanding the Role of Machine Learning in Early Prediction of Diabetes Onset",
        "abstract": "Diabetes is a chronic metabolic disorder that affects millions of people worldwide and poses significant health challenges. Early prediction of diabetes onset plays a crucial role in improving patient outcomes and reducing the burden on healthcare systems. Machine learning, a subfield of artificial intelligence, has emerged as a powerful tool in healthcare, offering potential solutions for early detection and intervention. This paper provides an overview of the role of machine learning in predicting the onset of diabetes. It explores the types of diabetes, risk factors, and the importance of early detection. The paper delves into the principles of machine learning and its applications in healthcare. It highlights the advantages of using machine learning techniques for early prediction and emphasizes the need for accurate and reliable prediction models. The process of developing machine learning models for diabetes prediction, including data collection and preprocessing, feature selection, and supervised learning algorithms, is discussed in detail. Various data sources for training machine learning models are explored, including electronic health records, medical imaging, wearable devices, and genetic data. The challenges and limitations associated with implementing machine learning in healthcare, such as data privacy, interpretability, and ethical considerations, are also addressed. Furthermore, the paper discusses the future implications and potential impact of early prediction of diabetes onset on healthcare outcomes. It emphasizes the integration of machine learning into clinical practice and the importance of collaborations between healthcare professionals and data scientists.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/a24721c584b9ad46dea20d24e64023cb3b4a228a",
        "citation_count": 1
    },
    {
        "title": "Machine Learning Approach to Blood Stasis Pattern Identification Based on Self-reported Symptoms",
        "abstract": "Objectives : This study is aimed at developing and discussing the prediction model of blood stasis pattern of traditional Korean medicine(TKM) using machine learning algorithms: multiple logistic regression and decision tree model. Methods : First, we reviewed the blood stasis(BS) questionnaires of Korean, Chinese, and Japanese version to make a integrated BS questionnaire of patient-reported outcomes. Through a human subject research, patients-reported BS symptoms data were acquired. Next, experts decisions of 5 Korean medicine doctor were also acquired, and supervised learning models were developed using multiple logistic regression and decision tree. Results : Integrated BS questionnaire with 24 items was developed. Multiple logistic regression models with accuracy of 0.92(male) and 0.95(female) validated by 10-folds cross-validation were constructed. By decision tree modeling methods, male model with 8 decision node and female model with 6 decision node were made. In the both models, symptoms of \u2018recent physical trauma\u2019, \u2018chest pain\u2019, \u2018numbness\u2019, and \u2018menstrual disorder(female only)\u2019 were considered as important factors. Conclusions : Because machine learning, especially supervised learning, can reveal and suggest important or essential factors among the very various symptoms making up a pattern identification, it can be a very useful tool in researching diagnostics of TKM. With a proper patient-reported outcomes or well-structured database, it can also be applied to a pre-screening solutions of healthcare system in Mibyoung stage.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/a25b73368a0af34ce7e4ffbf54ad6a15ec370134",
        "citation_count": 1
    },
    {
        "title": "An Evaluation of Machine Learning Classifiers for Prediction of Alzheimer's Disease, Mild Cognitive Impairment and Normal Cognition",
        "abstract": "Dementia has a negative impact on global healthcare that has become a serious concern worldwide. The most common cause, Alzheimer's disease, underlies the majority of dementia. The identification and accurate prediction of Alzheimer's disease in its initial stage is most critical, of which has several important practical applications. However, a reliable diagnosis remains a challenging task and requires a combination of methods based on important clinical information. Developing computer-aided diagnosis systems to support early Alzheimer's disease detection is essential for effective treatment planning. In this study, a nationwide cohort dataset, the Korean Brain Aging Study for the Early diagnosis and prediction of Alzheimer's disease is classified by using eight state-of-the-art supervised machine learning algorithms namely Support Vector Machine, Naive Bayes, XGBoost, Decision Tree, Logistic Regression, Random Forest, Bagging and AdaBoost. The best performing model appeared to be the XGBoost classifier yielding an accuracy of 82.09%. Thus, the present research shows that the application of the machine learning model to the KBASE dataset will offer an efficient clinical classification of cognitively normal control individuals, mild cognitive impairment and Alzheimer's disease patients and provides a framework for clinical decision systems.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a2b95e7c62d6c6ac5bdf1602a59691097a84acc9",
        "citation_count": 3
    },
    {
        "title": "A Preliminary Investigation into Use of Admission-Recorded Photoplethysmograms for Predicting Hospital Mortality in Children with Confirmed or Suspected Infection in Resource-Poor Settings",
        "abstract": "Although there have been notable advances in child survival, the rate of infection-related hospital fatalities remains high among pediatric patients in resource-limited settings. Hence, the critical need for enhancing child survival demands immediate attention. Present risk prediction tools for in-hospital complications have been developed through statistical modelling methods and exhibit specific constraints. This study sought to create and compare an array of machine learning-based models using admission-recorded information to predict all-cause in-patient death in two cohorts of children in Uganda: those under 6 months and those aged between 6 and 60 months. 190 (7.0%) out of 2,698 children under six months and 164 (4.3%) out of 3,835 children over six months of age died following admission. For each cohort, five supervised machine learning algorithms were trained and internally validated on 67% and 33% of the data, respectively. The models incorporated demographics, clinical variables, and photoplethysmography-extracted features as inputs. The balanced random forest classifier demonstrated superior performance on the test set in both cohorts. In the first cohort, the model achieved a sensitivity of 0.95, specificity of 0.71, positive predictive value (PPV) of 0.15, and negative predictive value (NPV) of 0.99. Comparing this to the model that exclusively utilized demographic and clinical parameters, an increase of 14.5% was observed in sensitivity, while specificity and PPV experienced reductions of 4% and 11.8%, respectively. NPV, however, remained unchanged. In the second cohort, the model's sensitivity was 0.75, with a specificity of 0.73, a PPV of 0.08, and an NPV of 0.99. Upon training the model with only demographic and clinical variables in this cohort, the corresponding metrics were 0.67, 0.76, 0.09, and 0.98, respectively. By integrating photoplethysmography data with machine learning algorithms, it may be possible to develop predictive models that can identify high-risk patients who are more likely to experience adverse outcomes like in-hospital death. Such models could empower healthcare providers in ill-equipped settings to allocate limited resources effectively and deliver targeted interventions to those most in need.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a2d713ae4eed51dcc64124ca3755d6d09cdcc0c7",
        "citation_count": 0
    },
    {
        "title": "Machine Learning in Wireless Sensor Networks for Smart Cities: A Survey",
        "abstract": "Artificial intelligence (AI) and machine learning (ML) techniques have huge potential to efficiently manage the automated operation of the internet of things (IoT) nodes deployed in smart cities. In smart cities, the major IoT applications are smart traffic monitoring, smart waste management, smart buildings and patient healthcare monitoring. The small size IoT nodes based on low power Bluetooth (IEEE 802.15.1) standard and wireless sensor networks (WSN) (IEEE 802.15.4) standard are generally used for transmission of data to a remote location using gateways. The WSN based IoT (WSN-IoT) design problems include network coverage and connectivity issues, energy consumption, bandwidth requirement, network lifetime maximization, communication protocols and state of the art infrastructure. In this paper, the authors propose machine learning methods as an optimization tool for regular WSN-IoT nodes deployed in smart city applications. As per the author\u2019s knowledge, this is the first in-depth literature survey of all ML techniques in the field of low power consumption WSN-IoT for smart cities. The results of this unique survey article show that the supervised learning algorithms have been most widely used (61%) as compared to reinforcement learning (27%) and unsupervised learning (12%) for smart city applications.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a2da9060ac67c4942b19e3c0bcef9fe2b74059e0",
        "citation_count": 128
    },
    {
        "title": "A Survey on machine learning techniques for the diagnosis of liver disease",
        "abstract": "Suffering from liver disease has been rapidly increasing due to excessive drink of alcohol, inhale polluted gas, drugs, contamination food and packing food pickle, so the medical expert system will help a doctor to automatic prediction. With the repeated development in machine learning technology, early prediction of liver disease is possible so that people can easily diagnosis the deadly disease in the early stage. This will give more useful in the Healthcare department and also a medical expert system can be used in a remote area. The liver plays a very important role in life which supports the removal of toxins from the body. So early prediction is very important to diagnosis the disease and recovers. Different types of machine learning, Supervised, Unsupervised and Semi-Supervised, Reinforcement Learning for diagnosis of liver disease such as SVM, KNN, K-Mean clustering, neural network, Decision tree etc and give difference accuracy, precision, sensitivity. The motive of this paper is to give a survey and comparative analysis of the entire machine learning techniques for diagnosis and prediction of liver disease in the medical area, which has already been used for the prediction of liver disease by various authors and the analysis are based on Accuracy, Sensitivity, Precision, and Specificity.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/a391f8b377a294c6e344ac6d437bff98f080ac2f",
        "citation_count": 29
    },
    {
        "title": "Exploring Gender Differences in Motor Imagery EEG for Brain-Computer Interface Applications*",
        "abstract": "Brain-computer interface (BCI) technology demonstrated immense potential across diverse fields. However, current research on electroencephalogram (EEG) commonly assumed single model can be universally applied across all gender identities. While a few studies have identified gender differences through supervised classification of resting-state EEG, the majority have largely overlooked the potential impact of gender-specific differences in BCI applications. This study explored the gender-specific differences in motor imagery (MI) within BCIs and the feasibility of gender recognition in unsupervised settings. We utilized public datasets of male and female EEG signals, applied widely used machine learning algorithms for task and gender identification. The results showed that the average MI classification accuracy for female was 0.57% higher than male, despite the dataset containing more male subjects. In addition, gender recognition accuracy from EEG MI data exceeded 97%. These findings have highlighted the importance of considering gender-specific differences in BCI research and application. The results of this study could inform the development of more personalized effective BCIs in healthcare and other fields, ultimately leading to improved outcomes and experiences for users of all genders.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a3ef4af763b9d54bacc563ca6c39716febb30ee6",
        "citation_count": 0
    },
    {
        "title": "The use of Machine Learning in Predicting Disease Progression",
        "abstract": "Machine learning (ML) has emerged as a powerful tool in the healthcare sector, especially in predicting disease progression. This paper examines the application of various ML algorithms, including supervised, unsupervised, and reinforcement learning, in predicting disease trajectories, particularly in complex and chronic diseases like Alzheimer\u2019s, multiple sclerosis, cardiovascular disease, and diabetes. By leveraging clinical data, genetic information, and patient history, ML models like random forests and neural networks can accurately predict the time to disease progression. This has profound implications for early diagnosis, personalized treatment, and patient management. However, the integration of these models into clinical practice faces challenges related to data quality, interpretability, and deployment in real-world settings. Despite these limitations, the case studies reviewed demonstrate the transformative potential of machine learning in enhancing decision-making processes in healthcare. Keywords: Machine learning, Disease progression prediction, Healthcare, Supervised learning, Chronic diseases.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a44067cf86113bfd9d7207243574415bdc163b01",
        "citation_count": 0
    },
    {
        "title": "Utilizing Machine Learning to Predict Antimicrobial Resistance in Bacteria",
        "abstract": "Antibiotic resistance has increased significantly in recent years. On the other hand, machine learning (ML) algorithms are increasingly used in medical research and healthcare and are gradually improving clinical performance. \nUsing ML to fight antimicrobial resistance (AMR) is one of the most critical areas of interest among the various applications of these new methods. The rise of antibiotic resistance and managing multidrug-resistant infections that are difficult to treat are important challenges. \nBoth supervised and unsupervised machine learning tools have been successfully used to predict early antibiotic resistance and thus support clinicians in selecting the appropriate treatment. Machine learning and artificial intelligence (AI) in predicting antimicrobial resistance are among today's sciences. Therefore, an antimicrobial stewardship program (ASP) should be implemented to optimize antibiotic prescribing and limit AMR.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/a46226c59dfa66ff9fa27c0c2782e680a2bc3676",
        "citation_count": 0
    },
    {
        "title": "Fairness Artificial Intelligence in Clinical Decision Support: Mitigating Effect of Health Disparity",
        "abstract": "The United States, as well as the global community, experiences health disparities among socially disadvantaged populations. These disparities often manifest in the data utilized for AI model training. Without appropriate de-biasing strategies, models trained to optimize predictive performance may inadvertently capture and perpetuate these inherent biases. The utilization of biased models in clinical decision-making can inflict harm upon patients from disadvantaged groups and exacerbate disparities when these decisions are documented and employed to train subsequent AI models. Unlike conventional correlation-based methods, we aim to mitigate the negative impacts of health disparity by answering a causal inference question for fairness: would the clinical decision support system make a different decision if the patient had a different sensitive attribute (e.g., race)? Recognizing the high computational complexity of developing causal models, we propose a flexible and efficient causal-model-free algorithm, CFReg, which provides causal fairness for supervised machine learning models. In addition, CFReg also develops a novel evaluation metric to quantify fairness within clinical settings. We first validate CFReg using a healthcare dataset of 48,784 patients focused on care management, then generalize to another four benchmark datasets with racial and ethnic disparity, including law school admission, adult income, criminal recidivism, and violent crime prediction. Experimental results demonstrate that CFReg outperforms baseline approaches in both fairness and accuracy, achieving a good trade-off between model fairness and supervised classification performance.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/a46929699fe4dfcefa187e563107e5f624417429",
        "citation_count": 0
    },
    {
        "title": "Supervised Learning by Evolutionary Computation Tuning: An Application to Blockchain-Based Pharmaceutical Supply Chain Cost Model",
        "abstract": "A pharmaceutical supply chain (PSC) is a system of processes, operations, and organisations for drug delivery. This paper provides a new PSC mathematical cost model, which includes Blockchain technology (BT), that can improve the safety, performance, and transparency of medical information sharing in a healthcare system. We aim to estimate the costs of the BT-based PSC model, select algorithms with minimum prediction errors, and determine the cost components of the model. After the data generation, we applied four Supervised Learning algorithms (k-nearest neighbour, decision tree, support vector machine, and naive Bayes) combined with two Evolutionary Computation algorithms (ant colony optimization and the firefly algorithm). We also used the Feature Weighting approach to assign appropriate weights to all cost model components, revealing their importance. Four performance metrics were used to evaluate the cost model, and the total ranking score (TRS) was used to determine the most reliable predictive algorithms. Our findings show that the ACO-NB and FA-NB algorithms perform better than the other six algorithms in estimating the costs of the model with lower errors, whereas ACO-DT and FA-DT show the worst performance. The findings also indicate that the shortage cost, holding cost, and expired medication cost more strongly influence the cost model than other cost components.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a4a51a55522dcb5dba69ec2d29921ada24913fb5",
        "citation_count": 4
    },
    {
        "title": "Automatic emotion recognition in healthcare data using supervised machine learning",
        "abstract": "Human feelings are fundamental to perceive the conduct and state of mind of an individual. A healthy emotional state is one significant highlight to improve personal satisfaction. On the other hand, bad emotional health can prompt social or psychological well-being issues. Recognizing or detecting feelings in online health care data gives important and helpful information regarding the emotional state of patients. To recognize or detection of patient\u2019s emotion against a specific disease using text from online sources is a challenging task. In this paper, we propose a method for the automatic detection of patient\u2019s emotions in healthcare data using supervised machine learning approaches. For this purpose, we created a new dataset named EmoHD, comprising of 4,202 text samples against eight disease classes and six emotion classes, gathered from different online resources. We used six different supervised machine learning models based on different feature engineering techniques. We also performed a detailed comparison of the chosen six machine learning algorithms using different feature vectors on our dataset. We achieved the highest 87% accuracy using MultiLayer Perceptron as compared to other state of the art models. Moreover, we use the emotional guidance scale to show that there is a link between negative emotion and psychological health issues. Our proposed work will be helpful to automatically detect a patient\u2019s emotion during disease and to avoid extreme acts like suicide, mental disorders, or psychological health issues. The implementation details are made publicly available at the given link: https://bit.ly/2NQeGET.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a4a767818512e9601a666f19c04c4ac197366f1d",
        "citation_count": 16
    },
    {
        "title": "Person-independent discomfort detection system for infants",
        "abstract": "Automatic discomfort detection for infants is important in healthcare, since infants have no ability to express their discomfort. We propose a video analysis system, based on supervised learning and classifying previously unseen infants from the testing set in a fully automated way. The \ufb01rst stage of our system consists of fame-based face detection, and then \ufb01t a face shape to the detected face area by using a Constrained Local Model (CLM). In the second stage, we analyze expression features by using Elongated Local Binary Patterns (ELBP), and classify expression features with an Support Vector Machine (SVM) for discomfort detection. The key contribution of our system is that the face model is infant-independent by employing a Constrained Local Model without prior knowledge about previously unseen infants. The system detects discomfort with an accuracy of 84 . 3%, a sensitivity of 82 . 4%, and speci\ufb01city of 84 . 9% on the testing set containing videos of 11 infants. In addition, in order to increase the robustness of the system to head rotation, we introduce a face recovery method based on the symmetry of the face. With this step, the previous performance parameters increase by 3 . 1 \u2212 3 . 8% tested with videos of 2 infants containing 2 , 010 frames.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/a4b00e028da366a8c10a7e9d228818f2607b3989",
        "citation_count": 0
    },
    {
        "title": "Explainable cohort discoveries driven by exploratory data mining and efficient risk pattern detection",
        "abstract": "[EMBARGOED UNTIL 6/1/2023] Finding small homogeneous subgroup cohorts in a large heterogeneous population is a critical process for hypothesis development within a broad range of applications, such as fraud detection, ad targeting, and geospatial traffic intervention. Most recently, cohort discovery has begun to play an important role in medical research as it has contributed to the targeting of high-need patients from smaller homogeneous subgroups for precision heath with better outcomes. Specifically, there has been a rising demand to identify the cohorts and the corresponding risk factors in precision medicine and preventive healthcare to better understand the etiology of diseases in order to tailor treatments for targeting patients. There is a clear need to discover the novel cohorts and the risk factors in the abovementioned application areas. Unfortunately, concurrent computational approaches are still lacking robust answers to the question: \"which subgroups are likely to be novel and may benefit from interventions that are likely to be effective for the selected population?\" Additionally, the majority of prevention research has focused on single or simple factor identification. Only a few studies have considered complex risk factors, and they are still at a preliminary stage. The development of machine learning and data mining algorithms sheds light on many areas. However, most high-performing approaches do not provide the interpretability for eXplainable artificial intelligence (XAI). These black box approaches often provide a predictive analytic capability to determine which class samples belong to. This supervised classification task requires pre-set labels in the data instead of exploring the sub-clusters. There is a need to develop innovative, data-driven, explainable cohort discovery approaches. To bridge the knowledge gap, we developed a novel subgroup discovery method which employs a deep exploratory mining process to slice and dice thousands of potential subpopulations and prioritize potential cohorts based on their explainable contrast patterns. Computational experiments were conducted on both synthesized data and a clinical autism dataset to assess performance quantitatively for coverage of pre-defined cohorts and qualitatively for novel knowledge discovery, respectively. Furthermore, scaling analysis was conducted using a distributed computing environment to suggest computational resource needs when there is an increase in subpopulation number. To address the limitation of current risk factors identification approaches, we further created a novel dynamic tree structure, Risk Hierarchical Pattern Tree (RHPTree), and a top-down search method, RHPSearch, which are both capable of efficiently analyzing a large volume of data. We also introduced two specialized search methods, the extended target search (RHPSearch-TS) and the parallel search approach (RHPSearch-SD), to further speed up the retrieval of certain items of interest. Experiments on both benchmark datasets and real-world data demonstrate that our method is not only faster but also more effective in identifying comprehensive long risk patterns than existing works. To further address real-world applications of computational work in biomedicine, we developed a multi-layer, unbiased cohort discovery architecture to provide the broad biomedical research community with a computational tool that offers capabilities beyond what traditional unsupervised cohort discovery methods, such as latent class analysis, can achieve. Experiments were conducted on both synthetic datasets and a clinical type 1 diabetes (T1D) dataset to assess the efficiency and discovery capability of the method. The high coverage, fast speed, and novel findings on the datasets demonstrate that our method is robust and feasible for cohort discovery research. The computational contributions in this dissertation work lay a foundation for eXplainable and actionable artificial intelligence (X2AI) with multiple successful applications in cancer drug repositioning, type 1 diabetes studies, environmental impacts on liver cancer, and the impact of the COVID-19 pandemic.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/a4d4b070a522e2f04567bdb7c4ff6b410596e2de",
        "citation_count": 0
    },
    {
        "title": "PREDICTING MORTALITY RATE IN ICU USING MACHINE LEARNING: A STUDY",
        "abstract": "Mortality rate is the measure of number of death in a limited population or by a particular cause within a certain time period. In healthcare system Intensive Care unit (ICU) plays an important role for critical condition patients. Mortality prediction of critical condition ICU patients who needs special care is a major problem of concern. The focus of this work is to predict ICU patient\u2019s mortality by the use of health record from ICU. Nowadays, machine learning plays an important role to resolve many health related issues which includes handling of patient\u2019s health related data and records, development of new medical procedures and the treatment of disease like cancer, heart disease, stroke, diabetes and arthritis etc. Various machine learning models are used to analyze health records to come up with solutions for different health related issues. In this work, four popular supervised machine learning algorithms, Decision Tree(DT), Random Forest (RF), K-Nearest Neighbors (KNN) and Logistic Regression(LR) has been used to predict patients mortality in ICU. In this work, In Hospital Mortality Prediction dataset which is part of MIMIC-III database has been used. The dataset is available to download and free to use from Kaggle. In our work of mortality prediction, a maximum accuracy of 0.87 has been achieved.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a51f0607a46c8cfa02fdcc915a35ff2c7402a787",
        "citation_count": 0
    },
    {
        "title": "Detection of Diabetic Foot Ulcers Using SVM Based Classification",
        "abstract": ": Diabetic foot ulcers represent a significant health issue, for both patients\u2019 quality of life and healthcare system costs. Currently, wound care is mainly based on visual assessment of wound size, which suffers from lack of accuracy and consistency. Hence, a more quantitative and computer-based method is needed. Supervised machine learning based object recognition is an attractive option, using training sample images with boundaries labeled by experienced clinicians. We use forty sample images collected from the UMASS Wound Clinic by tracking 8 subjects over 6 months with a smartphone camera. To maintain a consistent imaging environment and facilitate the capture process for patients with limited mobility, an image capture box was designed with two right angled front surface mirrors and LED lighting. We developed a novel foot ulcer recognition system using these sample images as our test data. Instead of operating at the pixel level, we use super-pixels, resulting from the quick shift algorithm, as the basic processing units. Then a support vector machine (SVM) based classifier is trained on the Bag-of-Words histogram representation of local Scale-Invariant Feature Transform (SIFT) features found in each super-pixel. As this classifier is very specific and the resulting histogram is very sparse, we merge the histograms from super-pixels in a size-specified neighborhood into one instance. Finally, to recover more precise boundaries of the foot ulcers, we apply conditional random field techniques to introduce new constraints that allow us to reduce misclassifications that occur",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/a568679c914cc07304ed3b4da883e290a0131af4",
        "citation_count": 1
    },
    {
        "title": "DATA MINING CLASSIFIERS IN THE PREDICTION OF HEART DISEASE",
        "abstract": ": The Healthcare industry is generally information rich but unluckily not all the data are mined which is required for discover hidden patterns & effective decision making. Data mining techniques are used to notice knowledge in database and for medical research, mainly in Heart disease prediction. Cardiovascular disease connecting high death rates Angiography is, more frequently than not, regarded as the best system for the examination of coronary artery disease; on the other hand, it was connected with significant side effects and high costs. Much investigation has, consequently, be conveyed using data mining and machine learning to attempt alternative modalities cardiovascular disease includes coronary heart disease (CHD), cerebrovascular disease (stroke) , Hypertensive heart disease, congenital heart disease peripheral artey disease , rheumatic heart disease, inflammatory heart disease . The main cause of cardiovascular disease is tobacco use, physical inactivity, an unhealthy diet and harmful use of alcohol. Complex data mining benefits from the past experience and algorithm defined with existing software and packages , with certain tools gaining a greater affinity or reputation with different techniques .In this project, the various supervised machine learning classifiers like K-Nearest neighbor and support vector machine is used to identify the heart disease.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/a5888a93f014b037424f55bc8114bb379ba70e75",
        "citation_count": 0
    },
    {
        "title": "A comparative study on various Machine Learning Techniques for Human Activity Recognition and Fall Detection",
        "abstract": "Falling is one of the most serious drawbacks prevailing among the elderly people as well as physically challenged people. It has impressed the researchers in the field of behavioural analysis for healthcare applications. The recent technologies like IoT, sensors placements, wearable devices and so on were contributed to improve the performance of the fall detection systems. To bridge the gap in the mobile technologies, this paper is an extensive survey of fall detection using machine learning algorithms. Initially, we present the scope of the vision based algorithms in brief. The recent techniques are surveyed from the aspects of performance achieved and the limitation. Finally, a comparative study is done to find the issues pertaining in this field. The issues like feature selection, theories of collected data, scope of sensors, privacy and supervised and unsupervised machine learning have to be addressed with the scope of the mobile technologies. Though the researchers have achieved steady progress, this research area still confronts the real-time issues.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/a58dde4330c02c58d76ea60c3167fdfeba03b314",
        "citation_count": 2
    },
    {
        "title": "Fast Model Adaptation for Automated Section Classification in Electronic Medical Records",
        "abstract": "Medical information extraction is the automatic extraction of structured information from electronic medical records, where such information can be used for improving healthcare processes and medical decision making. In this paper, we study one important medical information extraction task called section classification. The objective of section classification is to automatically identify sections in a medical document and classify them into one of the pre-defined section types. Training section classification models typically requires large amounts of human labeled training data to achieve high accuracy. Annotating institution-specific data, however, can be both expensive and time-consuming; which poses a big hurdle for adapting a section classification model to new medical institutions. In this paper, we apply two advanced machine learning techniques, active learning and distant supervision, to reduce annotation cost and achieve fast model adaptation for automated section classification in electronic medical records. Our experiment results show that active learning reduces the annotation cost and time by more than 50%, and distant supervision can achieve good model accuracy using weakly labeled training data only.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/a5b3de9acc9e966914368fbacd1b163c5cac5163",
        "citation_count": 9
    },
    {
        "title": "Hybrid model of unsupervised and supervised learning for multiclass sentiment analysis based on users\u2019 reviews on healthcare web forums",
        "abstract": "Twitter has become a popular platform for sharing health information, including diabetes-related content. Recent research studies have shown that Twitter data can be used for various purposes such as monitoring illnesses, promoting health, analyzing sentiment, and potentially aiding in medical directing. However, detecting fitness-related tweets in the vast amount of data on Twitter can be difficult. This pilot study, therefore, aimed to classify patient text about drugs and disease-associated tweets into meaningful health-related segments. The unlabeled dataset is divided into several groups using an unsupervised learning technique called K-Means Clustering, using this first label the text and followed by a combination of neural networks and machine learning classifiers, they classified 32046 diabetes-related tweets and 161290 drug text lines into five groups. Approximately 66.38% of drug line text was classified as health-related, with 55.14% \u201ctreatment and medication\u201d, 7.10% \u201cprevention\u201d and 4.14% \u201csymptoms and causes\u201d. Over 33% were categorized as \u201cOther and News\u201d. If we talk about the tweets as a dataset then the tweet was classified as health-related, with 44.30% \u201ctreatment and medication\u201d, 7% \u201cprevention\u201d and 5.3% \u201csymptoms and causes\u201d. Over 56.10% were categorized as \u201cOther and News. After this multiclass classification, we applied three machine learning and two deep learning models to find accuracy, precision, recall, and F1 scores. Drug review was used as a dataset then SVM and LR models provided an accuracy of 98% and when tweets were used as a dataset then LR models provided an accuracy of 97%. This research shows the importance of social media data in the decision-making system in the healthcare domain.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a5c242e75756a661a429166caa69f95f9399f853",
        "citation_count": 2
    },
    {
        "title": "Nonclinical Features in Predictive Modeling of Cardiovascular Diseases: A Machine Learning Approach",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a62dc44e57e243f34b4bcad58c873d1862cbbe66",
        "citation_count": 21
    },
    {
        "title": "Personalized Machine Learning using Passive Sensing and Ecological Momentary Assessments for Meth Users in Hawaii: A Research Protocol",
        "abstract": "Background: Artificial intelligence (AI)-powered digital therapies which detect meth cravings delivered on consumer devices have the potential to reduce these disparities by providing remote and accessible care solutions to Native Hawaiians, Filipinos, and Pacific Islanders (NHFPI) communities with limited care solutions. However, NHFPI are fully understudied with respect to digital therapeutics and AI health sensing despite using technology at the same rates as other races. Objective: We seek to fulfill two research aims: (1) Understand the feasibility of continuous remote digital monitoring and ecological momentary assessments (EMAs) in NHFPI in Hawaii by curating a novel dataset of longitudinal FitBit biosignals with corresponding craving and substance use labels. (2) Develop personalized AI models which predict meth craving events in real time using wearable sensor data. Methods: We will develop personalized AI/ML (artificial intelligence/machine learning) models for meth use and craving prediction in 40 NHFPI individuals by curating a novel dataset of real-time FitBit biosensor readings and corresponding participant annotations (i.e., raw self-reported substance use data) of their meth use and cravings. In the process of collecting this dataset, we will glean insights about cultural and other human factors which can challenge the proper acquisition of precise annotations. With the resulting dataset, we will employ self-supervised learning (SSL) AI approaches, which are a new family of ML methods that allow a neural network to be trained without labels by being optimized to make predictions about the data itself. The inputs to the proposed AI models are FitBit biosensor readings and the outputs are predictions of meth use or craving. This paradigm is gaining increased attention in AI for healthcare. Conclusions: We expect to develop models which significantly outperform traditional supervised methods by fine-tuning to an individual subject's data. Such methods will enable AI solutions which work with the limited data available from NHFPI populations and which are inherently unbiased due to their personalized nature. Such models can support future AI-powered digital therapeutics for substance abuse.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a6336b93e738e7aa277dc5f1313f6ed40730a732",
        "citation_count": 1
    },
    {
        "title": "S2VQ-VAE: Semi-Supervised Vector Quantised-Variational AutoEncoder for Automatic Evaluation of Trail Making Test",
        "abstract": "Background: Computer-aided detection of cognitive impairment garnered increasing attention, offering older adults in the community access to more objective, ecologically valid, and convenient cognitive assessments using multimodal sensing technology on digital devices. Methodology: In this study, we aimed to develop an automated method for screening cognitive impairment, building on paper- and electronic TMTs. We proposed a novel deep representation learning approach named Semi-Supervised Vector Quantised-Variational AutoEncoder (S2VQ-VAE). Within S2VQ-VAE, we incorporated intra- and inter-class correlation losses to disentangle class-related factors. These factors were then combined with various real-time obtainable features (including demographic, time-related, pressure-related, and jerk-related features) to create a robust feature engineering block. Finally, we identified the light gradient boosting machine as the optimal classifier. The experiments were conducted on a dataset collected from older adults in the community. Results: The experimental results showed that the proposed multi-type feature fusion method outperformed the conventional method used in paper-based TMTs and the existing VAE-based feature extraction in terms of screening performance. Conclusions: In conclusion, the proposed deep representation learning method significantly enhances the cognitive diagnosis capabilities of behavior-based TMTs and streamlines large-scale community-based cognitive impairment screening while reducing the workload of professional healthcare staff.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a6500cb09a52c43dac8affb2031b34458b686745",
        "citation_count": 1
    },
    {
        "title": "COVID 19 \u2013 Monitoring with IoT Devices",
        "abstract": "In the battle against the COVID-19 pandemic, the integration of Internet of Things (IoT) technologies has played a pivotal role in reshaping public health and healthcare delivery. Interconnected devices have demonstrated their capacity to collect, transmit, and analyze data, significantly impacting various aspects of pandemic management.\n\nCOVID-19 Monitoring with IoT Devices is a comprehensive guide to measuring the impact of COVID-19 infection and monitoring outbreak metrics. Beginning with an introduction to SARS-CoV-2 and its symptoms, the book presents chapters on machine learning (supervised and unsupervised algorithms) and techniques to predict COVID-19 outcomes. The book concludes with the role of IoT technology in detecting COVID-19 infections within a community, showcasing different computing models applicable to specific use-cases.\n\nKey Features:\n\n Explores the pivotal role of IoT technology in the fight against the COVID-19 pandemic.\n Covers a data-driven approach to COVID-19 monitoring by explaining methods for data collection, prediction, and analysis.\n Includes specific recommendations for machine learning algorithms designed for COVID-19 monitoring.\n Easy-to-read structured chapters suitable for novices in computer science and biomedical engineering.\n\nCOVID-19 Monitoring with IoT Devices provides a valuable resource for understanding the role of IoT technology in managing and mitigating the impact of COVID-19, and developing adequate infection control policies. It also showcases the potential of IoT for future research and applications in the healthcare sector. This book is intended for a diverse readership, including academicians, industry professionals, researchers, and healthcare practitioners.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a685576b5323ccdde4ce5c8593f9720a92a2a6a5",
        "citation_count": 0
    },
    {
        "title": "Intrusion Detection in Smart Cities Using Machine Learning",
        "abstract": "Frothy Disturbance Intrusion Detection Systems (FIDSs) hold significant importance in safeguarding against security breaches in the ever-expanding, where the integration of the internet spans diverse domains such as smart homes, healthcare, smart grids, manufacturing, supply chains, and environmental monitoring. Conventional intrusion detection techniques, although useful in traditional settings, need to be modified and improved to address the particular difficulties, such as devices with limited resources, memory that is restricted, batteries that have limited capacity, and certain protocol stacks. In this paper, we propose a lightweight attack detection approach that detects and prevents attackers from trying to introduce unnecessary data into the network by using a supervised machine learning-based FIDS. Our simulation findings show that the suggested FIDS-based classifier performs satisfactorily in terms of classification accuracy and detection time when enhanced with a combination of two or three complex features.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a72b5b430a43ff8d6d8227b785eb58c665d040fe",
        "citation_count": 0
    },
    {
        "title": "Identifying Risk Factors for Acute Asthma Attacks: Application of Machine Learning in a Country-Wide Mobile Health Study (Preprint)",
        "abstract": "\n BACKGROUND\n Asthma is a variable long-term condition that affects 339 million people worldwide who are at risk of acute deteriorations or attacks. Because triggers, patterns, and risk of attacks vary from person to person, asthma can be difficult to study in small cohorts, but recent mobile-based studies like the Asthma Mobile Health Study (AMHS) provide an important opportunity to collect data from large populations. The AMHS is a publicly available dataset collected using a smartphone app from 10,010 asthma patients across the United States.\n \n \n OBJECTIVE\n Using data-driven methods, we aimed to identify different clusters of asthma patients based on patterns of clinical deterioration that may lead to loss of productivity, and determine key factors associated with each patient cluster.\n \n \n METHODS\n Based on existing asthma knowledge, 27 variables about the patient\u2019s history, demographics, behaviour, and self-reported symptoms were extracted to generate 63 features. Of the 63 features, 10 were markers of attacks that were used to cluster patients with the k-means algorithm. We subsequently used a supervised learning approach, least absolute shrinkage and selection operator (LASSO), to rank the remaining 53 features and identify key risk factors associated with each patient cluster. The models were validated with 10-fold cross-validation.\n \n \n RESULTS\n Using data from 827 participants of AMHS with sufficient data, k-means clustering formed four patient clusters based on unscheduled healthcare usage and missed work. The most important factors contributing to the clustering were nocturnal symptoms, activity limitation, and sex. Being female, and having asthma that affects sleep and activity levels, were the key risk factors associated with having an asthma attack that necessitates the need for unscheduled medical care and time off work. Our internal validation resulted in an area under the curve (AUC) of up to 0.80.\n \n \n CONCLUSIONS\n The data-driven approach found risk factors associated with increased levels of asthma attacks that reflected those recognised in clinical practice. Future research about asthma risk factors should include these measures and also consider including work and school absence as markers of asthma attacks.\n",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a73776bd9fd93c8599c3f9abf3235b62e6225e43",
        "citation_count": 0
    },
    {
        "title": "Wireless Channel Modelling for Identifying Six Types of Respiratory Patterns With SDR Sensing and Deep Multilayer Perceptron",
        "abstract": "Contactless or non-invasive technology has a significant impact on healthcare applications such as the prediction of COVID-19 symptoms. Non-invasive methods are essential especially during the COVID-19 pandemic as they minimise the burden on healthcare personnel. One notable symptom of COVID-19 infection is a rapid respiratory rate, which requires constant real-time monitoring of respiratory patterns. In this paper, Software Defined Radio (SDR) based Radio-Frequency sensing technique and supervised machine learning algorithm is employed to provide a platform for detecting and monitoring various respiratory: eupnea, biot, bradypnea, sighing, tachypnea, and kussmaul. The variations in Channel State Information produced by human respiratory were utilised to identify distinct respiratory patterns using fine-grained Orthogonal Frequency-Division Multiplexing signals. The proposed platform based on the SDR and the Deep Multilayer Perceptron classifier exhibits the ability to effectively detect and classify the afore-mentioned distinct respiratory with an accuracy of up to 99%. Moreover, the effectiveness of the proposed scheme in terms of diagnosis accuracy, precision, recall, F1-score, and confusion matrix is demonstrated by comparison with a state-of-the-art machine learning classifier: Random Forest.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a747a7a654663472fe254b87337aa7bdce879677",
        "citation_count": 26
    },
    {
        "title": "Cancer Death Cases Forecasting using Supervised Machine Learning",
        "abstract": "In India, like in the rest of the world, cancer is a major killer. This research objective is to predict cancer mortality in India, using supervised machine learning methods. Cancer mortality rates in India between 1990 and 2017 are provided by age group, gender, and region using data from the Global Burden of Disease Study. We employ three distinct supervised learning algorithms\u2014linear regression, decision tree regression, and random forest regression\u2014after performing data preprocessing, which includes missing value imputation and feature engineering. Using a variety of criteria, we analyze the effectiveness of these models and conclude that the random forest regression model is superior to the other two. The scope of research is provide a long-term prediction of cancer mortality in India using the best model so it will help health department to work on it. Our research has implications for policymakers and healthcare providers in India, where it may inform efforts to reduce cancer rates and improve cancer care.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a74cc74b09ce507b190133d0f790a0ed93babf48",
        "citation_count": 0
    },
    {
        "title": "Optimizing Machine Learning Algorithms for Heart Disease Prediction in Healthcare: A Comparative Study",
        "abstract": "The healthcare business faces significant challenges in successfully maintaining and evaluating large amounts of patient data. Data analytics has emerged as a viable tool for issue resolution and decision-making as a result of technological advancements in healthcare. This automated procedure improves the resilience of healthcare systems by collecting and analyzing data to provide more effective and cost-effective treatments. One critical use of technology, primarily machine learning, involves the identification and diagnosis of diseases, notably heart disease, which contributes significantly to global mortality. This research study analyzes how machine learning methods (NB, RF, SVM, and LR) can predict the existence of heart disease. Given that nearly 90% of cardiac diseases are avoidable, using machine learning for prediction is critical. This research study assesses the performance of different algorithms using performance metrics such as accuracy, precision, area under the curve (AUC), and F1-Score. The experimental results reveal Random Forest (RF) as the most reliable predictor of heart disease with an accuracy of 83.52% compared to other supervised machine learning algorithms. The Random Forest classifier achieves F1-Score, AUC, and accuracy values of 84.21 %, 88.24%, and 88.89%, respectively. This study highlights the potential of ML, notably the Random Forest algorithm, in improving the predictive capacity of healthcare systems for more effective heart disease prevention and treatment.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a78bd92b9dd778125bee59d6eed23137b235b73f",
        "citation_count": 0
    },
    {
        "title": "Performance Evaluation of Supervised Machine Learning Classifiers for Predicting Healthcare Operational Decisions",
        "abstract": ". This paper describes a healthcare operational decision making system based on machine learning classifiers to predict the decisions in comparison to the actual decisions made by the doctor during the healthcare operations. Most of the supervised machine learning classification and optimization techniques is utilized in this type of decision making system. This system can help the doctor make the best decisions. We testify this system on caesarian section which is the most commonly performed obstetric operation in the world to help saves mother and baby. This system helps us to predict when we should use surgery. This study explains utilization of machine learning algorithms in determination of medical operation methods. The results show that k nearest neighbors and Random Forest for this case study generates accuracy of 95.00 % respectively.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/a83005b47006420e5b4ba9830d26f1b4d3cc28de",
        "citation_count": 30
    },
    {
        "title": "A Scoping Review of Supervised Machine Learning Techniques in Predicting the Prevalence of Type 2 Diabetes Mellitus",
        "abstract": "It is crucial for medical practice to navigate from solely dependent on conventional data-analytical approaches for disease screening, diagnostics, and treatment plans to decisions that are configured rapidly through big data analytics from artificial intelligence algorithms. The fog- and edge-computing architectures built within the huge healthcare database systems would allow the applications of machine learning (ML) algorithms for disease predictions and forecasting capacities. This scoping review appraised the use of multiple ML methods for type 2 diabetes mellitus (T2DM) prediction. Search engines used were IEEE Xplore, JSTOR, PubMed, Sage, Scopus, Wiley, and WOS. Inclusion criteria included articles published within the past six years, open access and studies that focused on T2DM only. Out of 41 studies included, the most used ML method was Random Forest (n=33) and the most occurred best ML model (n=13). Customised Ensemble ML method adapted to the dataset was found to show the highest accuracy. However, there were insufficient study areas and samples in Southeast Asia countries, as there were differences in demographics and culture that affect the T2DM risk factors where computational resource and systems development were limited. We conclude ML methods can predict T2DM, from the system\u2019s perspective its intra-operability is viable for use in healthcare systems.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/a88930e331eb9370ea5255e41d6f31cd89f29182",
        "citation_count": 0
    },
    {
        "title": "Neural Network-Based Intelligent System for Glucose Spike Prediction and Type 2 Diabetes Mellitus Risk Assessment",
        "abstract": "Machine learning algorithms have revolutionized the management of clinical data to prevent Type 2 Diabetes Mellitus (T2DM). This paper performs an exploratory study of the relationship between several risk factors, including visceral fat percentage (VF), sedentary lifestyle (SL), sleep hours, adherence to the diet, genetic predisposition (GP), sex, body mass index (BMI), fasting plasma glucose levels (FPG), waist circumference (WC), low dietary fiber intake (LDFI), high carbohydrate intake (HCI), and sleep hygiene, with the development of T2DM. For it, a chi-square statistical tool was used to discern the significance of these features concerning T2DM incidence; among these, VF, SL, sleep hours, and adherence to the diet demonstrated the highest significance. To predict the development of T2DM, a neural network (NN) classifier is proposed, which achieved remarkable accuracy (100%) during the training phase. A Levenberg-Marquardt supervised learning algorithm was employed to minimize the total error. Furthermore, Long-Short Term Memory (LSTM) is leveraged to forecast glucose spike generation, enabling a comprehensive estimation over a seven-day period. The accuracy of the prediction was validated through the Root Mean Square Error (RMSE), which resulted in a value of 0.5803. Clinical Relevance\u2014This exploratory study emphasizes the importance of risk factors and preventive medicine in the context of T2DM. By shifting focus towards prevention, clinicians can transform patient care and promote better health outcomes. Leveraging the combined power of risk factor analysis and machine learning techniques empowers clinicians to effectively guide individuals at risk of developing T2DM. This approach facilitates informed lifestyle choices, potentially leading to a significant reduction in the overall disease burden. This research holds significant promise for improving population health and transforming healthcare practices towards a preventive model",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a8b5c3b848bcce8046ab5346a5a1257e840a871a",
        "citation_count": 0
    },
    {
        "title": "Breast Cancer-Risk Factors and Prediction Using Machine-Learning Algorithms and Data Source: A Review of Literature",
        "abstract": "Breast cancer (BC) is a major health concern worldwide. It is a complex and multifactorial disease, and identifying its risk factors is crucial for early detection and effective treatment. This review article provides an overview of the literature on breast cancer risk factors, data sources, and machine learning algorithms for prediction. The paper discusses the various risk factors associated with breast cancer, including age, family history, lifestyle choices, and environmental factors. Additionally, the article explores the different data sources used in breast cancer research, including clinical data, genomic data, and lifestyle data. The paper then reviews the different machine-learning algorithms used for breast cancer prediction, including supervised and unsupervised learning. The performance of ML algorithms in predicting BC risk using different data sources was assessed. This review provides valuable insights into the current state of research on BC risk factors and prediction using ML algorithms and data sources, and the findings will be useful for healthcare professionals and researchers working in the field of BC.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/a8b669335a4fdd88bc93839879b61c17427fd8d3",
        "citation_count": 3
    },
    {
        "title": "Data Analytics in Mental Healthcare",
        "abstract": "Worldwide, about 700 million people are estimated to suffer from mental illnesses. In recent years, due to the extensive growth rate in mental disorders, it is essential to better understand the inadequate outcomes from mental health problems. Mental health research is challenging given the perceived limitations of ethical principles such as the protection of autonomy, consent, threat, and damage. In this survey, we aimed to investigate studies where big data approaches were used in mental illness and treatment. Firstly, different types of mental illness, for instance, bipolar disorder, depression, and personality disorders, are discussed. The effects of mental health on user\u2019s behavior such as suicide and drug addiction are highlighted. A description of the methodologies and tools is presented to predict the mental condition of the patient under the supervision of artificial intelligence and machine learning.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/a8f5668aeb9b0ca9777015e0243d03e1946e44f3",
        "citation_count": 12
    },
    {
        "title": "Supervised machine learning techniques and genetic optimization for occupational diseases risk prediction",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/a9616e932a6301e642095b83734d55ca51c12c38",
        "citation_count": 34
    },
    {
        "title": "A supervised clustering MCMC methodology for large categorical feature spaces",
        "abstract": "There is a well-established tradition within the statistics literature that explores different techniques for reducing the dimensionality of large feature spaces. The problem is central to machine learning and it has been largely explored under the unsupervised learning paradigm. We introduce a supervised clustering methodology that capitalizes on a Metropolis Hastings algorithm to optimize the partition structure of a large categorical feature space tailored towards minimizing the test error of a learning algorithm. This is a general methodology that can be applied to any supervised learning problem with a large categorical feature space. We show the benefits of the algorithm by applying this methodology to the problem of risk adjustment in competitive health insurance markets. We use a large claims data set that records ICD-10 codes, a large categorical feature space. We aim at improving risk adjustment by clustering diagnostic codes into risk groups suitable for health expenditure prediction. We test the performance of our methodology against common alternatives using panel data from a representative sample of twenty three million citizens in Colombian Healthcare System. Our results outperform common alternatives and suggest that it has potential to improve risk adjustment.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/a9c0289afda90642d26fba577c6faec6c367071b",
        "citation_count": 2
    },
    {
        "title": "Healthcare and anomaly detection: using machine learning to predict anomalies in heart rate data",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/a9d7f354025defe054fff116b769cc1360bb1a90",
        "citation_count": 56
    },
    {
        "title": "Deep Learning Technique to Predict Heart Disease using IoT Based ECG Data",
        "abstract": "Scientific Knowledge and Electronic devices are growing day by day. In this aspect, many expert systems are involved in the healthcare industry using machine learning algorithms. Deep neural networks beat the machine learning techniques and often take raw data i.e., unrefined data to calculate the target output. Deep learning or feature learning is used to focus on features which is very important and gives a complete understanding of the model generated. Existing methodology used data mining technique like rule based classification algorithm and machine learning algorithm like hybrid logistic regression algorithm to preprocess data and extract meaningful insights of data. This is, however a supervised data. The proposed work is based on unsupervised data that is there is no labelled data and deep neural techniques is deployed to get the target output. Machine learning algorithms are compared with proposed deep learning techniques using TensorFlow and Keras in the aspect of accuracy. Deep learning methodology outfits the existing rule based classification and hybrid logistic regression algorithm in terms of accuracy. The designed methodology is tested on the public MIT-BIH arrhythmia database, classifying four kinds of abnormal beats. The proposed approach based on deep learning technique offered a better performance, improving the results when compared to machine learning approaches of the state-of-the-art",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/a9e4060f149a9ec68e86d1354d9df87ebe2c9e50",
        "citation_count": 0
    },
    {
        "title": "Management Information Systems: The Human Factor.",
        "abstract": "MIS 6009 Information Systems Internship (0 semester credit hours) Student gains experience and improves skills through appropriate developmental work assignments in a real business environment. Student must identify and submit specific business learning objectives at the beginning of the semester. The student must demonstrate exposure to the managerial perspective via involvement or observation. At semester end, student prepares an oral or poster presentation, or a written paper reflecting on the work experience. Student performance is evaluated by the work supervisor. Pass/Fail only. Prerequisites: (MAS 6102 or MBA major) and department consent required. (0-0) S MIS 6204 Information Technology for Management (2 semester credit hours) Necessary background to understand the role of information technology and Management Information Systems in today's business environment. Topics include: strategic role of information, organization of information, information decision making requirements, telecommunications and networking, managing information resources, cloud computing distributed processing, and current information systems/technology issues. (2-0) S MIS 6302 (ACCT 6349) Managing Digital Strategy (3 semester credit hours) This course explores the strategic management issues associated with the transformation of all businesses into digital businesses. It focuses on developing an understanding of how to develop a business models to implement strategies that are based on digital systems across different industries. This includes understanding how to develop business plans, how to align the business architecture with the digital systems architecture, and appropriately managing the digital systems to maximize business value. The course will deal with assessing and developing business strategies by harnessing contemporary phenomena in the digital world, such as the Internet of Things, Mobility strategies, and include applications of emerging techniques based on machine learning, artificial intelligence and semantic analysis to craft appropriate business strategies for firms. Credit cannot be received for both ACCT 6349 and MIS 6302. (3-0) Y MIS 6305 (HMGT 6334) Healthcare Analytics (3 semester credit hours) The healthcare industry is yet to find ways to make best use of existing data to improve care, reduce costs, and provide more accessible care. This course introduces the use of business intelligence and decision sciences in healthcare industry. Students will develop a conceptual understanding of data mining techniques and decision analysis and hands-on experience with several analytics software which may include coding in R, Rattle, and WEKA (as needed and depending on availability). Prerequisite: OPRE 6301 or SYSM 6303. (3-0) Y MIS 6308 (ACCT 6340) System Analysis and Project Management (3 semester credit hours) Provides the student with an in-depth knowledge of object oriented systems analysis and design procedures. Software project management techniques will be introduced. At the end of the course, the student will be able to analyze business solutions and design computer based information systems using object-oriented methodologies. Prerequisite or Corequisite: MIS 632 0 or MIS 6326. (3-0) R MIS 6309 (ACCT 6309) Business Data Warehousing (3 semester credit hours) This course provides the student with in depth knowledge of data warehousing principles, data warehouse techniques, and business intelligence systems. The course introduces the topics of data warehouse design, Extract-Transform-Load (ETL), data cubes, and data marts. Students will create business intelligence using data warehouses with several OLAP and analytical tools. SAP, Business Objects, Cognos, or other data warehousing tools will be used to illustrate data warehousing concepts. (3-0) Y",
        "year": 1978,
        "url": "https://www.semanticscholar.org/paper/a9ed14d81f3dc132ae339c54a20ddff6224a3fe5",
        "citation_count": 4
    },
    {
        "title": "Predicting Objective Performance Using Perceived Cognitive Workload Data in Healthcare Professionals: A Machine Learning Study",
        "abstract": "Cognitive Workload (CWL) is a fundamental concept in predicting healthcare professionals' (HCPs) objective performance. The study aims to compare the accuracy of the classical model (utilizes all six dimensions of the National Aeronautics and Space Administration Task Load Index (NASA-TLX)) and novel models (utilize four or five dimensions of NASA-TLX) in predicting HCPs' objective performance. We use a dataset from our previous human factors research studies and apply a broad selection of supervised machine learning classification techniques to develop data-driven computational models and predict objective performance. The study findings confirm that classical models are better predictors of objective performance than novel models. This has practical implications for research in health informatics, human factors and ergonomics, and human-computer interaction in healthcare. Findings, although promising, cannot be generalized as they are based on a small dataset. Future studies may investigate additional subjective and physiological measures of CWL to predict HCPs' objective performance.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/aa2528b93c879f4276568f1b5a0c21693e44474b",
        "citation_count": 1
    },
    {
        "title": "A Robust Framework for Accelerated Outcome-driven Risk Factor Identification from EHR",
        "abstract": "Electronic Health Records (EHR) containing longitudinal information about millions of patient lives are increasingly being utilized by organizations across the healthcare spectrum. Studies on EHR data have enabled real world applications like understanding of disease progression, outcomes analysis, and comparative effectiveness research. However, often every study is independently commissioned, data is gathered by surveys or specifically purchased per study by a long and often painful process. This is followed by an arduous repetitive cycle of analysis, model building, and generation of insights. This process can take anywhere between 1 - 3 years. In this paper, we present a robust end-to-end machine learning based SaaS system to perform analysis on a very large EHR dataset. The framework consists of a proprietary EHR datamart spanning ~55 million patient lives in USA and over ~20 billion data points. To the best of our knowledge, this framework is the largest in the industry to analyze medical records at this scale, with such efficacy and ease. We developed an end-to-end ML framework with carefully chosen components to support EHR analysis at scale and suitable for further downstream clinical analysis. Specifically, it consists of a ridge regularized Survival Support Vector Machine (SSVM) with a clinical kernel, coupled with Chi-square distance-based feature selection, to uncover relevant risk factors by exploiting the weak correlations in EHR. Our results on multiple real use cases indicate that the framework identifies relevant factors effectively without expert supervision. The framework is stable, generalizable over outcomes, and also found to contribute to better out-of-bound prediction over known expert features. Importantly, the ML methodologies used are interpretable which is critical for acceptance of our system in the targeted user base. With the system being operational, all of these studies were completed within a time frame of 3-4 weeks compared to the industry standard 12-36 months. As such our system can accelerate analysis and discovery, result in better ROI due to reduced investments as well as quicker turn around of studies.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/aa2dcaaa936bd85147466e74a69cd8339eb6f070",
        "citation_count": 9
    },
    {
        "title": "Detecting inappropriate access to electronic health records using collaborative filtering",
        "abstract": null,
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/aa30ff16d6de96e8825511ad7c66a13aa1bd5c3c",
        "citation_count": 0
    },
    {
        "title": "Anti-Spoofing in Medical Employee's Email using Machine Learning Uclassify Algorithm",
        "abstract": "\u2014Since the advent of COVID-19, healthcare and IT cybersecurity have been an issue. Digital services and foreign labor have increased cyberattacks. July 2021 saw 260,642 phishing emails. 94% of 12 countries\u2019 employees experienced epidemic cyberattacks. Phishing attacks steal sensitive data from spam emails or legitimate websites for profit. Phishing spam uses URL, domain, page, and content variables. Simple machine-learning methods stop phishing emails. This study discusses phishing emails and patient data and healthcare employee accounts cybersecurity. This paper covers COVID-19 email and phishing detection. This article examines the message's URL, subject, email, and links. Uclassify classifies content, spam, and languages and automates emails. Semi-supervised machine learning dominates healthcare. The Uclassify algorithm used multinomial Naive Bayesian classifiers. Document class is [0\u20131]. This article compared Multinomial Naive Bayesian in two experiments with other algorithms. Experiment 1 achieved an MNB accuracy of 96% based on a database from Kaggle Phishing. Experiment 2 showed that the Multinomial Naive Bayesian system accurately predicted URL and hyperlink targets based on PhishTank data. 96.67% of respondents correctly identified URLs, and 91.6% did so for hyperlinks. These two experiments focused on Tokenization, Lemmatization, and Feature Extraction (FE) and contained an internal feature set (IFS) and an external feature set (EFS). MNB is more exact than earlier methods since it uses decimal digits and word frequency. MNB only takes binary inputs. MNB can detect phishing and spoofing.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/aa7434ede8e8281fdebf0586e6f6d94f0fcdc85c",
        "citation_count": 2
    },
    {
        "title": "A Research on Machine Learning Methods in a Healthcare Management Music System for Recommendations",
        "abstract": "Abstract: One of the best treatments for illnesses is music, which accelerates healing for patients. Music stimulates the patient's emotional thinking, helping them to overcome their illness and become psychologically well. This study examines the many kinds of machine learning techniques and how they are used to music recommendations for healthcare management. Both supervised and unsupervised machine learning approaches, as well as their subcategories, are covered. According to study, music therapy enhances people's quality of life while gradually lessening the negative impacts of illness on the body. A strong recommendation system combined with music therapy is a powerful tool for treating people's emotional and psychological problems.One crucial metric used to assess the efficacy of music recommendation algorithms is classification accuracy. In this survey, music recommendations for patient care management are made using machine learning algorithms.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/aa7aed98b50f9030e291b89fde32fcdda2cfa781",
        "citation_count": 0
    },
    {
        "title": "Synthesizing lesions using contextual GANs improves breast cancer classification on mammograms",
        "abstract": "Data scarcity and class imbalance are two fundamental challenges in many machine learning applications to healthcare. Breast cancer classification in mammography exemplifies these challenges, with a malignancy rate of around 0.5% in a screening population, which is compounded by the relatively small size of lesions (~1% of the image) in malignant cases. Simultaneously, the prevalence of screening mammography creates a potential abundance of non-cancer exams to use for training. Altogether, these characteristics lead to overfitting on cancer cases, while under-utilizing non-cancer data. Here, we present a novel generative adversarial network (GAN) model for data augmentation that can realistically synthesize and remove lesions on mammograms. With self-attention and semi-supervised learning components, the U-net-based architecture can generate high resolution (256x256px) outputs, as necessary for mammography. When augmenting the original training set with the GAN-generated samples, we find a significant improvement in malignancy classification performance on a test set of real mammogram patches. Overall, the empirical results of our algorithm and the relevance to other medical imaging paradigms point to potentially fruitful further applications.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/aa9e2e7619a51fd8e6b15f08ca0884ac768224f6",
        "citation_count": 16
    },
    {
        "title": "Asymptotically Optimal Regret for Black-Box Predict-then-Optimize",
        "abstract": "We consider the predict-then-optimize paradigm for decision-making in which a practitioner (1) trains a supervised learning model on historical data of decisions, contexts, and rewards, and then (2) uses the resulting model to make future binary decisions for new contexts by finding the decision that maximizes the model's predicted reward. This approach is common in industry. Past analysis assumes that rewards are observed for all actions for all historical contexts, which is possible only in problems with special structure. Motivated by problems from ads targeting and recommender systems, we study new black-box predict-then-optimize problems that lack this special structure and where we only observe the reward from the action taken. We present a novel loss function, which we call Empirical Soft Regret (ESR), designed to significantly improve reward when used in training compared to classical accuracy-based metrics like mean-squared error. This loss function targets the regret achieved when taking a suboptimal decision; because the regret is generally not differentiable, we propose a differentiable\"soft\"regret term that allows the use of neural networks and other flexible machine learning models dependent on gradient-based training. In the particular case of paired data, we show theoretically that optimizing our loss function yields asymptotically optimal regret within the class of supervised learning models. We also show our approach significantly outperforms state-of-the-art algorithms on real-world decision-making problems in news recommendation and personalized healthcare compared to benchmark methods from contextual bandits and conditional average treatment effect estimation.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/aaa02a6a241fab5ed851ca9a79fef81f03969b6f",
        "citation_count": 0
    },
    {
        "title": "SVM-based Decision Tree for medical knowledge representation",
        "abstract": "Machine learning has become one of blooming research topics in recent years. Many applications can be found from integrating various techniques such as Chi-squared Automatic Interaction Detection (CHAID), Decision Tree, k-Nearest Neighbors (KNN), Recursive Partitioning and Regression Trees, and Support Vector Machines (SVM), to the obtrusive platforms that include the domains of healthcare, economics and agriculture. Researchers on healthcare domains have built effective systems to help clinicians alleviate diagnosis efforts. However, some models lacked flexibility to interpret the knowledge as if clinician's indulgement. To overcome such problems, SVM, one of the supervised learning algorithms with kernel radial basis function (RBF) as a nonlinear classification model, was exploited to classify and extract knowledge from medical data. The idea behind the proposed system was to classify the given data step by step by SVM. Incorrectly classified patterns will be fed to the succeeding stage to find a better split point in SVM. Split point was used to calculate information gain that can identify principal features from candidate attributes. Finally, knowledge-based decision trees were constructed from the ordered information gain to classify the unknown medical patterns. Experimental results from three different datasets verified that the proposed system was effective and feasible for the classification of medical databases.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/aaddc6d554c89933017ce0dc73bd927ef62d6231",
        "citation_count": 9
    },
    {
        "title": "Enhanced Diagnosis of Voice Disorders: Integrating Machine Learning and Web Technologies",
        "abstract": "Voice disorders, ranging from diplophonia to spasmodic dysphonia, present significant challenges in diagnosis and treatment. Traditional methods often rely on subjective assessments by healthcare professionals, leading to variability in diagnoses and delays in treatment. In this paper, we propose a novel approach for automated voice disorder detection using machine learning techniques, specifically employing a Decision Tree Classifier (DTC) algorithm. Our system utilizes Python for backend processing, incorporating the Flask framework for web application development, and HTML/CSS for frontend presentation. Through a series of experiments and evaluations, we demonstrate the efficacy of our approach in accurately identifying various voice disorders, thereby potentially revolutionizing the diagnostic process and facilitating timely interventions. The proposed system offers several advantages over conventional diagnostic methods. By leveraging machine learning algorithms, it provides objective and consistent assessments of voice disorders, reducing reliance on subjective judgments. Moreover, the integration of web technologies enables convenient access to the system, allowing users to undergo assessments remotely without the need for specialized equipment or expert supervision. This accessibility is particularly beneficial for individuals in remote or underserved areas, enhancing the reach and impact of voice disorder diagnostics. Furthermore, the system's modular design facilitates scalability and extensibility, allowing for the integration of additional features and improvements over time. Future enhancements may include the incorporation of advanced machine learning models, such as deep learning algorithms, for further refinement of diagnostic accuracy. Additionally, the development of a user-friendly interface and the incorporation of interactive elements could enhance user engagement and satisfaction. Overall, our proposed system represents a promising step towards more efficient and accessible voice disorder detection, with the potential to significantly improve patient outcomes and quality of care.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/ab3206a4b83ef86d1b438381000a85d2c5a9bf51",
        "citation_count": 0
    },
    {
        "title": "Is AI really improving the quality of digital diagnosis",
        "abstract": "The research paper shows how AI's application improves the correctness of diagnosis and increases the rate of accomplishing multiple tasks, including when it comes across some hurdles, such as AI-based digital diagnosis algorithms. In the past, AI was used exclusively to process data, work as an analyzing tool for medical images in health information systems, and assist in decision-making. Still, the process often involves deep machine learning. This is an independent work based on the outcome of other research, which indicates that AI increases bias and needs interaction with people.AI has certain privileges over traditional methods, time and again, relating to swift analysis and comprehensive data assimilation. The patient feedback tells us that despite the preference for AI-generated diagnostic hints, people still want a human professional's supervision or confirmation concerning the results achieved in this sphere, which indicates the directions for the further enhancement of AI utilization in healthcare. These comments emphasize the need to continue improving research and development to address concerns regarding data quality, algorithms' explanations, and ethical problems.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/ab6297ae4cbb0858554a3dda84692828e01e2c12",
        "citation_count": 0
    },
    {
        "title": "A machine learning model based on CHAT-23 for early screening of autism in Chinese children",
        "abstract": "Introduction Autism spectrum disorder (ASD) is a neurodevelopmental condition that significantly impacts the mental, emotional, and social development of children. Early screening for ASD typically involves the use of a series of questionnaires. With answers to these questionnaires, healthcare professionals can identify whether a child is at risk for developing ASD and refer them for further evaluation and diagnosis. CHAT-23 is an effective and widely used screening test in China for the early screening of ASD, which contains 23 different kinds of questions. Methods We have collected clinical data from Wuxi, China. All the questions of CHAT-23 are regarded as different kinds of features for building machine learning models. We introduce machine learning methods into ASD screening, using the Max-Relevance and Min-Redundancy (mRMR) feature selection method to analyze the most important questions among all 23 from the collected CHAT-23 questionnaires. Seven mainstream supervised machine learning models were built and experiments were conducted. Results Among the seven supervised machine learning models evaluated, the best-performing model achieved a sensitivity of 0.909 and a specificity of 0.922 when the number of features was reduced to 9. This demonstrates the model's ability to accurately identify children for ASD with high precision, even with a more concise set of features. Discussion Our study focuses on the health of Chinese children, introducing machine learning methods to provide more accurate and effective early screening tests for autism. This approach not only enhances the early detection of ASD but also helps in refining the CHAT-23 questionnaire by identifying the most relevant questions for the diagnosis process.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/ac241d962beb3d50d18081c3cdb1c08c84059c72",
        "citation_count": 1
    },
    {
        "title": "A Comprehensive Review on Machine Learning in Healthcare Industry: Classification, Restrictions, Opportunities and Challenges",
        "abstract": "Recently, various sophisticated methods, including machine learning and artificial intelligence, have been employed to examine health-related data. Medical professionals are acquiring enhanced diagnostic and treatment abilities by utilizing machine learning applications in the healthcare domain. Medical data have been used by many researchers to detect diseases and identify patterns. In the current literature, there are very few studies that address machine learning algorithms to improve healthcare data accuracy and efficiency. We examined the effectiveness of machine learning algorithms in improving time series healthcare metrics for heart rate data transmission (accuracy and efficiency). In this paper, we reviewed several machine learning algorithms in healthcare applications. After a comprehensive overview and investigation of supervised and unsupervised machine learning algorithms, we also demonstrated time series tasks based on past values (along with reviewing their feasibility for both small and large datasets).",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/ac2cffc4b9f96bae24809d738777ae897094ae33",
        "citation_count": 116
    },
    {
        "title": "Machine learning approaches and web-based system to the application of disease modifying therapy for sickle cell",
        "abstract": "Sickle cell disease (SCD) is a common serious genetic disease, which has a severe impact due to red blood cell (RBCs) abnormality. According to the World Health Organisation, 7 million newborn babies each year suffer either from the congenital anomaly or from an inherited disease, primarily from thalassemia and sickle cell disease. In the case of SCD, recent research has shown the beneficial effects of a drug called hydroxyurea/hydroxycarbamide in modifying the disease phenotype. The clinical management of this disease-modifying therapy is difficult and time consuming for clinical staff. This includes finding an optimal classifier that can help to solve the issues with missing values, multi-class datasets, and features selection. For the classification and discriminant analysis of SCD datasets, 7 classifiers based on machine learning models are selected representing linear and non-linear methods. After running these classifiers with a single model, the results revealed that a single classifier has provided us with effective outcomes in terms of the classification performance evaluation metric. In order to produce such an optimal outcome, this research proposed and designed combined classifiers (ensemble classifiers) among the neural network\u2019s models, the random forest classifier, and the K-nearest neighbour classifier. In this aspect, combining the levenberg-marquardt algorithm, the voted perceptron classifier, the radial basis neural classifier, and random forest classifier obtain the highest rate of performance and accuracy. This ensemble classifier receives better results during the training set and testing set process. Recent technology advances based on smart devices have improved the medical facilities and become increasingly popular in association with real-time health monitoring and remote/personal health-care. The web-based system developed under the supervision of the haematology specialist at the Alder Hey Children\u2019s Hospital in order to produce such an effective and useful system for both patients and clinicians. To sum up, the simulation experiment concludes that using machine learning and the web-based system platforms represents an alternative procedure that could assist healthcare professionals, particularly for the specialist nurse and junior doctor to improve the quality of care with sickle cell disorder.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/ac60b6ba050569079a36b899467ec331a2dcd441",
        "citation_count": 2
    },
    {
        "title": "A Supervised Model for Predicting the Risk of Mortality and Hospital Readmissions for Newly Admitted Patients",
        "abstract": null,
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/ac6a328729692ab9199079b25737998caab62556",
        "citation_count": 7
    },
    {
        "title": "Kinematic and Kinetic Gait Features Associated With Mild Cognitive Impairment in Parkinson\u2019s Disease",
        "abstract": "Mild cognitive impairment (MCI) and gait deficits are commonly associated with Parkinson\u2019s disease (PD). Early detection of MCI associated with Parkinson\u2019s disease (PD-MCI) and its biomarkers is critical to managing disability in PD patients, reducing caregiver burden and healthcare costs. Gait is considered a surrogate marker for cognitive decline in PD. However, gait kinematic and kinetic features in PD-MCI patients remain unknown. This study was designed to explore the difference in gait kinematics and kinetics during single-task and dual-task walking between PD patients with and without MCI. Kinematic and kinetic data of 90 PD patients were collected using 3D motion capture system. Differences in gait kinematic and kinetic gait features between groups were identified by using: first, univariate statistical analysis and then a supervised machine learning analysis. The findings of this study showed that the presence of MCI in PD patients is coupled with kinematic and kinetic deviations of gait cycle which may eventually identify two different phenotypes of the disease. Indeed, as shown by the demographical and clinical comparison between the two groups, PD-MCI patients were older and more impaired. Moreover, PD-MCI kinematic results showed that cognitive dysfunction coexists with more severe axial symptoms and an increase postural flexion. A lack of physiological distal-to-proximal shift in joint kinetics was evidenced in the PD phenotype associated with cognitive impairments.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/ac7da878f95ce58bb862bced90d1f64415f0be49",
        "citation_count": 3
    },
    {
        "title": "Ensemble of Multiple Classification Algorithms to Predict Stroke Dataset",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/ac839b192f0f1e4fd8091b1ff9d5d88d9d3338ac",
        "citation_count": 4
    },
    {
        "title": "Integrating Statistical Methods and Machine Learning Techniques to Analyze and Classify COVID-19 Symptom Severity",
        "abstract": "Background/Objectives: The COVID-19 pandemic, caused by Severe Acute Respiratory Syndrome Coronavirus 2 (SARS-CoV-2), led to significant global health challenges, including the urgent need for accurate symptom severity prediction aimed at optimizing treatment. While machine learning (ML) and deep learning (DL) models have shown promise in predicting COVID-19 severity using imaging and clinical data, there is limited research utilizing comprehensive tabular symptom datasets. This study aims to address this gap by leveraging a detailed symptom dataset to develop robust models for categorizing COVID-19 symptom severity, thereby enhancing clinical decision making. Methods: A unique tabular dataset was created using questionnaire responses from 5654 individuals, including demographic information, comorbidities, travel history, and medical data. Both unsupervised and supervised ML techniques were employed, including k-means clustering to categorize symptom severity into mild, moderate, and severe clusters. In addition, classification models, namely, Support Vector Machine (SVM), Adaptive Boosting (AdaBoost), eXtreme Gradient Boosting (XGBoost), random forest, and a deep neural network (DNN) were used to predict symptom severity levels. Feature importance was analyzed using the random forest model for its robustness with high-dimensional data and ability to capture complex non-linear relationships, and statistical significance was evaluated through ANOVA and Chi-square tests. Results: Our study showed that fatigue, joint pain, and headache were the most important features in predicting severity. SVM, AdaBoost, and random forest achieved an accuracy of 94%, while XGBoost achieved an accuracy of 96%. DNN showed robust performance in handling complex patterns with 98% accuracy. In terms of precision and recall metrics, both the XGBoost and DNN models demonstrated robust performance, particularly for the moderate class. XGBoost recorded 98% precision and 97% recall, while DNN achieved 99% precision and recall. The clustering approach improved classification accuracy by reducing noise and dimensionality. Statistical tests confirmed the significance of additional features like Body Mass Index (BMI), age, and dominant variant type. Conclusions: Integrating symptom data with advanced ML models offers a promising approach for accurate COVID-19 severity classification. This method provides a reliable tool for healthcare professionals to optimize patient care and resource management, particularly in managing COVID-19 and potential future pandemics. Future work should focus on incorporating imaging and clinical data to further enhance model accuracy and clinical applicability.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/ad48ecbe879ab76c1fcce37649bfff88e2db364a",
        "citation_count": 0
    },
    {
        "title": "A Review of Generative Adversarial-Based Networks of Machine Learning/Artificial Intelligence in Healthcare",
        "abstract": "Machine learning has been proven to be a game-changing technology in every domain since the late 20th century. There have been many advancements in healthcare not only for the diagnosis of disease but advanced in the prognosis of the diseases. Artificial intelligence/machine learning (AI/ML) has progressed a lot in the medical domain in just a couple of decades and played a very important role in exploring human data to understand human body behavior better than ever before, for predicting and classifying all kinds of medical images or videos. A recent and best-used application is detecting COVID-19 by just checking the chest x-ray in a very accurate manner that can be used without human presence and stop the spread of the virus resulting in fewer doctors getting affected. It is known as generative adversarial networks. Some of the types of GANs used for differentiate domains without human supervision and many such mutations of GANs are useful in the health sector. This is simply a quick review of various technologies that will become more in-depth as time goes on.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/ad56901e8584b64431a4ec6c187aa8a6e7edcb45",
        "citation_count": 2
    },
    {
        "title": "Classifying Leukemia and Gout Patients with Neural Networks",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/ad7672ecf5efb7fa4c908dd80c95e86b5028cced",
        "citation_count": 1
    },
    {
        "title": "Predicting CRISPR-Cas activity and exploring its relationship with antimicrobial resistance in Klebsiella pneumoniae",
        "abstract": "s: Oral Presentation Predicting CRISPR-Cas activity and exploring its relationship with antimicrobial resistance in Klebsiella pneumoniae. Roni Froumine The University of Melbourne Klebsiella pneumoniae (Kp) is a major cause of bacterial healthcare-associated infections worldwide. The Kp population comprises hundreds of lineages (clones), a subset of which are particularly concerning because they have accumulated high frequency and diversity of antimicrobial resistance (AMR) genes through horizontal gene transfer (HGT) and cause infections that are extremely difficult to treat. CRISPR-Cas are adaptive immune systems present in ~33% of Kp. They can block HGT and limit acquisition of AMR genes. Therefore, we hypothesise that Kp clones enriched for AMR are less likely to possess an active CRISPR. While several tools exist for identifying the presence of CRISPR-Cas among genome assemblies, none distinguish active and degraded systems. Here we describe a novel approach to predict CRISPR activity. Cas proteins detect and degrade incoming DNA, and insert copies of short recognition motifs, \u2018spacers\u2019, into the CRISPR array in the host chromosome. Spacer sequences are preferentially incorporated at the array\u2019s leader end thus their ordering provides important temporal information. We exploit this by comparing CRISPR array spacers among Kp in the same clone. Their spacer sequences are extracted, aligned and mapped to the clone\u2019s phylogenetic tree. Ancestral state reconstruction is used to quantify activity based on the predicted amount and location of spacer acquisition or loss in the CRISPR arrays. We use this approach to identify putatively active CRISPR-Cas in 31 Kp clones and test for association with the presence of AMR genes. Our findings have the potential to inform novel control strategies and CRISPR-based therapeutics for Kp infections. Preventing Pangenome Pitfalls with Panaro. Gerry Tonkin-Hill Wellcome Sanger Institute, UK Improvements in genome sequencing have led to larger population samples, but counterintuitively this has led to an increase in the number of gene annotation errors. The automated annotation of draft genomes remains difficult and resulting errors tend to propagate across databases. This has profound consequences for defining the pangenome (the set of all genes found in a species), as most algorithms for clustering genes do not account for such errors. This can lead to an artificial inflation in estimates of pangenome size and can complicate downstream analyses. We have developed Panroo, a pangenome graph based clustering tool that is able to correct for many of the sources of error introduced during annotation by fragmented assemblies, contamination, diverse gene families and mis-assemblies. We verified our approach through extensive simulation of de novo assemblies using the infinitely many genes model and by analysing a diverse set of large bacterial genome datasets. Using a highly clonal dataset containing 1,419 Pseudomonas aeruginosa genomes from a single patient we demonstrate that failing to account for annotation errors leads to a 40% increase in the pangenome size estimated with Roary, a popular pangenome method. Accounting for such errors with Panaroo reduces this error rate to 1.8%. The improved accuracy of Panaroo enabled us to quantify gene gain and loss rates across 13,454 isolates from the major global clades of Streptococcus pneumoniae. Furthermore, our underlying graph based representation allowed for an association study between genes, structural rearrangements and antibiotic resistance in S. pneumoniae. Comparative genomic analysis of Bifidobacterium species isolated from Egyptian fruit bat Rousettus egyptiacus. Maria Satti National Institute of Genetics, Japan Bifidobacterium is an important probiotic genus. The species in the genus were previously isolated from various hosts like cow, rabbit, pig, non-human primates, and human being; our group has recently isolated two novel Bifidobacterium species from Egyptian fruit bat. The host diet contributes to the development of intestinal microbial communities, and the bat dietary habits should affect the development of important probiotic bacterial species like bifidobacteria. The aim of this study was to investigate the genetic biodiversity of bifidobacteria from bat compared to bifidobacterial species from human and nonhuman primates by decoding genome sequences. The description of the genomic features in different niches is fundamental in clarifying repertoire of genes that have caused their evolutionary differentiation. Such genomic analyses support the hypothesis that bat strains have been subjected to genetic adaptations to their host environment such as a peculiar diet heavily based on sugars. The comparative analysis of bifidobacterial species revealed that bifidobacteria in bat possess the higher genomic similarity with non-human primates than human or other mammals. Bat strains report the presence of unique GHs i.e. GH 59 and GH 88 classes. Plant-dietary metabolising GHs such as GH 28, GH 53, GH 78, GH 105, GH 115 and GH 146 were found to be specific for bat and non-human primate species. The comparative analysis in this study has revealed the important features of bifidobacteria in bat such as their contribution in metabolizing the host dietary carbohydrates. Bat and non-human primate specific GHs corresponding to the metabolism of their dietary carbohydrates suggest the dietary association between these groups. CiteFuse: a comprehensive toolkit for the analysis of CITE-seq data. Jieun Hani Kim The University of Sydney Multi-modality profiling of single cells represents one of the latest technological advancements in molecular biology. Among various single-cell multi-modality strategies, cellular indexing of transcriptomes and epitopes by sequencing (CITE-seq) allows simultaneous quantification of two distinct species: RNA and surface marker proteins (ADT). Here, we introduce CiteFuse, a streamlined package consisting of a suite of tools for the pre-processing, modality integration, clustering, ADT evaluation, RNA-ADT network construction, differential expression analysis, and interactive web-based visualization of CITE-seq data. We show the integrative capacity of CiteFuse to fuse the two data types and its relative advantage against data generated from single modality profiling. Furthermore, we illustrate the pre-processing steps in CiteFuse and in particular a novel doublet detection method based on a combined index of cell hashing and transcriptome data. Collectively, we demonstrate the utility and effectiveness of CiteFuse for the integrative analysis of transcriptome and epitope profiles from CITE-seq data. Comprehensive identification of nucleotide biochemical modifications from nanopore signal data Pablo Acera Mateos Australian National University Nanopore sequencing is currently the only technology able to sequence ultra-long DNA and RNA molecules in their native forms: hence, potentially enabling the detection naturally occurring covalent modifications in nucleotides. This raises the opportunity of creating algorithms that can detect such modifications. These tools will help us fill the gaps in the understanding of the role of nucleotide modifications in the regulation of transcription, RNA splicing, RNA translation, RNA transport, RNA degradation...etc. Currently, available tools are able to detect a reduced number of modifications with limited accuracy. These algorithms are mainly of two types: supervised machine learning models that show acceptable accuracy but are limited to specific modifications the algorithms have been trained on, and methods based on statistical tests on the nanopore signal distribution that usually have a high false positive rate but are able to identify modifications in a more unbiased fashion. Here, we describe a new algorithm that combines both principles, making use of deep-learning and speech recognition strategies to accomplish high accuracy and unbiased detection of DNA/RNA modifications. As our model is not trained with explicit information from nucleotide modifications, it can potentially be used to detect a broad range of them. Exploring somatic BAM compression. Rachel Bowen-James Children's Cancer Institute The application of next-generation sequencing technologies to the study of cancer reveals the specific mutations that give rise to an individual\u201a\u00c4\u00f6\u221a\u00d1\u221a\u00a5s cancer. Hence, the volume of data generated for somatic mutation analysis is growing rapidly. The cost-effective storage of this data is becoming increasingly dependent on compression methods that do not compromise the detection of low variant allele frequency (VAF) alterations. Here we investigate and optimise BAM compression methods for somatic variant detection. 'Truth' sets of variants were generated using Strelka2 on uncompressed BAM files, acting as a benchmark for the evaluation of the impact of compression. The BAM files were compressed using default and customized levels of Crumble \u201a\u00c4\u00f6\u221a\u00d1\u221a \u0308 a lossy compression tool developed for germline data. Strelka2 variants produced from the compressed files were then compared to the truth sets. Initial parameter optimisation was conducted using 2-chromosome BAM files. We analysed 9 standard Crumble levels and developed 18 optimised levels. The top performing optimised levels were used to compress two whole genome datasets. The best optimised level achieved a mean F-score of 0.95, and mean decrease in file-size of 36.68%. The most aggressive standard Crumble level achieved a marginally better mean decrease in file-size of 38.95% but gave less accurate results, with a mean F-score of 0.78. We have developed optimised Crumble parameters for the compression of somatic data with fewer negative impacts on variant calling. We minimised the loss of variants due to compression and achieved a false call rate similar to the disparity between different variant callers. Application ",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/ad9d694c876fe58b6bda535c53bccabe26ef3a55",
        "citation_count": 0
    },
    {
        "title": "A New Prediction Data Model of High-Risk COVID-19 Patient with Smart Noti\ufffdcation (HRCP-SN) Using Machine Learning Algorithm",
        "abstract": "A web application designed to predict high-risk patients affected by COVID-19 runs a machine learning (ML) model at the backend to generate results. The random forest classi\ufffdcation technique (a type of supervised ML approach) is used to predict the high-risk status of patients who are COVID-19 positive and are at the initial stage of infection. To predict high-risk patients, the model uses the patients\u2019 current underlying health conditions, such as age, sex, diabetes, asthma, hypertension, smoking, and other factors. After data preprocessing and training, the model could predict the severity of the patient with an accuracy of approximately in 65\u201370%. According to some studies, random forest ML models outperform other ML models for solving the challenge of predicting unusual events such as pneumonia, hypertension, diabetes, obesity, and chronic renal disease were the most contributory variables for model implementation. This project will help patients and hospital staff make necessary decisions and actions in advance. This will help healthcare workers arrange resources and hospital areas for high-risk COVID-19 patients. Thus, this study provides an effective and optimized treatment. Using this application and suitable patient data, hospitals can predict whether a patient will require urgent care.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/adacf9a004661aec16e68b723f93e15c1bb28c4d",
        "citation_count": 0
    },
    {
        "title": "Human Activity Identification using CNN",
        "abstract": "Human activity recognition [HAR] is a field of study that deals with identifying, interpreting, and analyzing the actions specific to the movement of human beings. Currently, the activity recognition system like (HAR) is becoming a huge field of innovative work with an emphasis on advanced machine learning algorithms, innovations that focus on increasing safety while decreasing the costs of monitoring, which helps in the field of healthcare, child care, surveillance, sports or keeping track of behavioral pattern of human beings. This model aims to develop a system that recognizes activities like sitting, standing, walking, sleeping, reading, and tilting using CNN. It is done by a supervised learning method, which is an ML task where a function is trained that provides output by mapping it to input, i.e., the activity will be recognized based on the activity defined/labeled in the data.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/ade0d6472166494a35e78d133115f2f4eceb8760",
        "citation_count": 6
    },
    {
        "title": "Inertia Based Recognition of Daily Activities with ANNs and Spectrotemporal Features",
        "abstract": "As mobile and personal health devices gain in popularity, increasing amounts of data is collected via their embedded sensors such as heart rate monitors and accelerometers. Data analytics and more specifically machine learning algorithms can transform this data into actionable information to improve personal healthcare and quality of life. The main objective of this study is to develop an algorithmic classification framework using feed-forward multilayer perceptrons and statistically rich spectrotemporal features to recognize daily activities based on 3-axis acceleration data. A multitude of MLP topologies and setups, such as different numbers and sizes of hidden layers, supervised output structuring, etc. are tested to comprehensively analyze the clustering capabilities of the artificial neural network for a wide-range of settings. In addition, the contribution of subset of features to classification accuracy is studied to identify respective information potentials and further improve accuracy. Publicly available wrist-worn accelerometer dataset from University of California Irvine's machine learning repository is used for fair comparison with the most recent literature published using the same dataset. Results indicate a significant improvement in recognition rate where the overall accuracy over seven selected activity classes is 91% compared to 54% of the latest publication using the same dataset.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/ae233ea79dfc0d4f4afe98a83b05746a0f587756",
        "citation_count": 9
    },
    {
        "title": "Clustering-Aided Approach for Predicting Patient Outcomes with Application to Elderly Healthcare in Ireland",
        "abstract": "Predictive analytics have proved promising capabilities and opportunities to many aspects of healthcare practice. Data-driven insights can provide an important part of the solution for curbing rising costs and improving care quality. The paper implements machine learning techniques in an attempt to support decision making in relation to elderly healthcare in Ireland, with a particular focus on hip fracture care. We adopt a combination of unsupervised and supervised learning for predicting patient outcomes. Initially, elderly patients are grouped based on the similarity of age, length of stay (LOS) and elapsed time to surgery. Using the K-Means algorithm, our clustering experiments suggest the presence of three coherent clusters of patients. Subsequently, the discovered clusters are utilised to train prediction models that address a particular cluster of patients individually. In particular, two machine learning models are trained for every cluster of patients in order to predict the inpatient LOS, and discharge destination. The developed models are claimed to make predictions with relatively high accuracy. Furthermore, the potential usefulness of the clustering-guided approach of prediction is discussed in general.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/aeb4145c5ab88d035e9d0966ecb1acefccca3571",
        "citation_count": 19
    },
    {
        "title": "Challenges include rapidly Clustering Genes using heterogeneous data Sources",
        "abstract": "Clustering of gene expression data is a standard exploratory technique used to identify closely related genes. Many other sources of data are also likely to be of great assistance in the analysis of gene expression data. This data provides a mean to begin elucidating the large-scale modular organization of the cell. The authors consider the challenging task of developing exploratory analytical techniques to deal with multiple complete and incomplete information sources. The Multi-Source Clustering (MSC) algorithm developed performs clustering with multiple, but complete, sources of data. To deal with incomplete data sources, the authors adopted the MPCK-means clustering algorithms to perform exploratory analysis on one complete source and other potentially incomplete sources provided in the form of constraints. This paper presents a new clustering algorithm MSC to perform exploratory analysis using two or more diverse but complete data sources, studies the effectiveness of constraints sets and robustness of the constrained clustering algorithm using multiple sources of incomplete biological data, and incorporates such incomplete data into constrained clustering algorithm in form of constraints sets. analyzing and interpreting data on thousands of genes measured with hundreds of different conditions, and assessing the biological significance of the results. Clustering is the exploratory, unsupervised process of partitioning the expression data into groups (or clusters) of genes sharing similar expression patterns (Yeung et al., 2003; Kerr et al., 2008). However, the quality of clusters can vary greatly, as can their ability to lead to biologically meaningful conclusions. DOI: 10.4018/jkdb.2010040102 International Journal of Knowledge Discovery in Bioinformatics, 1(2), 12-28, April-June 2010 13 Copyright \u00a9 2010, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited. On a different note, the biological and medical literature databases are information warehouses with a vast store of useful knowledge. In fact, text analysis has been successfully applied in bioinformatics for various purposes such as identifying relevant literature for genes and proteins, connecting genes with diseases, and reconstructing gene networks (Yandell & Majoros, 2002). Hence, including the literature in the analysis of gene expression data offers an opportunity to incorporate additional functional information about the genes when defining expression clusters. In more general terms, with the availability of multiple information sources, it is a challenging problem to conduct integrated exploratory analyses with the aim of extracting more information than what is possible from only a single source. The basic problem of learning from multiple information sources has been extensively studied by the machine learning community. In computer vision this problem is referred to as multi-modal learning. In general, there are two approaches to multi-modal learning: feature level integration and semantic integration (Wu et al., 1999). Methods that use feature level integration combine the information at the feature level and then perform the analysis in the joint feature space (Glenisson et al., 2003). On the other hand, the semantic level integration methods first build individual models based on separate information sources and then combine these models via techniques such as mutual information maximization (Becker, 1996). Microarray experiments usually provide gene expression data on all the genes in a genome. Hence they are inherently \u201ccomplete\u201d. A major challenge using other sources of data to assist the analysis of gene expression data is that they may not always be complete, i.e., do not provide information on all the genes in the genome. Recent work from the machine learning community has focused on the use of background information in the form of instance-level constraints. Two types of pair-wise constraints have been proposed: positive constraints that specify that two instances must remain in the same cluster, and negative constraints that specify that two instances must not be placed in the same cluster. Recent examples of work include methods that ensured that constraints were satisfied at each iteration (Wagsta et al., 2001), algorithms that used constraints as initial conditions (Basu et al., 2002), algorithms that learned a distance metric trained by a shortestpath algorithm (Klein et al., 2002), a convex optimization method using Mahalanobis distances (Xing et al., 2002), and semi-supervised clustering that incorporated both metric learning and the use of pair-wise constraints in a principled manner (Bilenko et al., 2004). While great efforts have been made to develop efficient constrained clustering algorithm variants, the role of constraint sets in constrained clustering algorithm has not been fully studied yet. Recently, Wagstaff et al. (2006) and Davidson et al. (2006) attempted to link the quality of constraint sets with clustering algorithm performance (Davidson et al., 2006; Wagsta et al., 2006). Two properties of constraint set \u2013 inconsistency and incoherence \u2013 were shown to be strongly negative correlated with clustering algorithm performance. This paper makes several important contributions. First, we investigate the problem of integrating two or more heterogeneous sources of data to produce biologically significant clusters. To address this problem, we have proposed an EM-based clustering algorithm called Multi-Source Clustering (MSC) to perform clustering using multiple, but complete, data sources. For our experiments with MSC, we focused on algorithms using gene expression data and biological text literature as the two main sources, although the techniques are general enough to be applicable to other data sources. Then, we consider the non-trivial task of proposing evaluation schemes to evaluate the results of clustering techniques by utilizing independent sources of data. This is performed by considering functional annotation data and transcription factor binding site data as the independent data sources. Next, we tackle the 15 more pages are available in the full version of this document, which may be purchased using the \"Add to Cart\" button on the product's webpage: www.igi-global.com/article/clustering-genes-usingheterogeneous-data/45163?camid=4v1 This title is available in InfoSci-Journals, InfoSci-Journal Disciplines Medicine, Healthcare, and Life Science. Recommend this product to your librarian: www.igi-global.com/e-resources/libraryrecommendation/?id=2",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/aebcf0e231ef1931b02e401f17a9a925d4028d97",
        "citation_count": 0
    },
    {
        "title": "Machine Learning Methods for Image Analysis in Medical Applications, from Alzheimer's Disease, Brain Tumors, to Assisted Living",
        "abstract": "Healthcare has progressed greatly nowadays owing to technological advances, where machine learning plays an important role in processing and analyzing a large amount of medical data. This thesis investigates four healthcare-related issues (Alzheimer's disease detection, glioma classification, human fall detection, and obstacle avoidance in prosthetic vision), where the underlying methodologies are associated with machine learning and computer vision. For Alzheimer\u2019s disease (AD) diagnosis, apart from symptoms of patients, Magnetic Resonance Images (MRIs) also play an important role. Inspired by the success of deep learning, a new multi-stream multi-scale Convolutional Neural Network (CNN) architecture is proposed for AD detection from MRIs, where AD features are characterized in both the tissue level and the scale level for improved feature learning. Good classification performance is obtained for AD/NC (normal control) classification with test accuracy 94.74%. In glioma subtype classification, biopsies are usually needed for determining different molecular-based glioma subtypes. We investigate non-invasive glioma subtype prediction from MRIs by using deep learning. A 2D multi-stream CNN architecture is used to learn the features of gliomas from multi-modal MRIs, where the training dataset is enlarged with synthetic brain MRIs generated by pairwise Generative Adversarial Networks (GANs). Test accuracy 88.82% has been achieved for IDH mutation (a molecular-based subtype) prediction. A new deep semi-supervised learning method is also proposed to tackle the problem of missing molecular-related labels in training datasets for improving the performance of glioma classification. In other two applications, we also address video-based human fall detection by using co-saliency-enhanced Recurrent Convolutional Networks (RCNs), as well as obstacle avoidance in prosthetic vision by characterizing obstacle-related video features using a Spiking Neural Network (SNN). These investigations can benefit future research, where artificial intelligence/deep learning may open a new way for real medical applications.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/aec0eef10df37c3c73956f919771c3f038e8828b",
        "citation_count": 0
    },
    {
        "title": "Machine Learning Technique for Practical Engineering Use",
        "abstract": "In the age of Industry 5.0, where the digital world generates massive amounts of data, AIML has emerged as a powerful tool for analyzing and interpreting this data. It has proven successful in various fields such as intelligent control, decision making, computer graphics, and computer vision and many more. The performance in AIML and deep learning methods has led to their widespread adoption in real-time engineering applications. These tools are necessarily required for creating intelligent, automated tools that can recognize the data in areas like healthcare, cybersecurity, and intelligent transportation systems. Machine learning encompasses different strategies, including reinforcement learning, semi- supervised, unsupervised and supervised learning algorithms. This study aims to comprehensively explore the utilization of ML in managing real world engineering applications, enhancing their functionality and intelligence. By investigating the applicability of various machine learning approaches in domains such as cybersecurity, healthcare, and intelligent transportation systems, this research contributes to our understanding of their effectiveness. Additionally, it addresses the research goals and difficulties associated with ML in practical life. This study serves as reference for industry professionals, academics, and decision-makers, providing insights and benchmarks for different use cases and real-world applications.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/aec457a2ddb36ec8239e042b682bf330c3f0ab3e",
        "citation_count": 0
    },
    {
        "title": "Interpretable Ensemble-based Deep Learning Approach for Automated Detection of Macular Telangiectasia Type 2 by Optical Coherence Tomography",
        "abstract": "We present an ensemble-based approach using deep learning models for the accurate and interpretable detection of Macular Telangiectasia Type 2 (MacTel) from a large dataset of Optical Coherence Tomography (OCT) scans. Leveraging data from the MacTel Project by the Lowy Medical Research Institute and the University of Washington, our dataset consists of 5200 OCT scans from 780 MacTel patients and 1820 non-MacTel patients. Employing ResNet18 and ResNet50 architectures as supervised learning models along with the AdaBoost algorithm, we predict the presence of MacTel in patients and reflect on interpretability based on the Grad-CAM technique to identify critical regions in OCT images influencing the models\u2019 predictions. We propose building weak learners for the AdaBoost ensemble by not only varying the architecture but also varying amounts of labeled data available for training neural networks to improve the accuracy and interpretability. Our study contributes to interpretable machine learning in healthcare, showcasing the efficacy of ensemble techniques for accurate and interpretable detection of rare retinal diseases like MacTel.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/aee0a963dd70af68b4adb23a4a0724e16a9d78ad",
        "citation_count": 0
    },
    {
        "title": "Clustering and Classification of a Qualitative Colorimetric Test",
        "abstract": "In this paper, we present machine learning based detection methods for a qualitative colorimetric test. Such an automatic system on mobile platform can emancipate the test result from the color perception of individuals and its subjectivity of interpretation, which can help millions of populations to access colorimetric test results for healthcare, allergen detection, forensic analysis, environmental monitoring and agricultural decision on point-of-care platforms. The case of plasmonic enzyme-linked immunosorbent assay (ELISA) based tuberculosis disease is utilized as a model experiment. Both supervised and unsupervised machine learning techniques are employed for the binary classification based on color moments. Using 10-fold cross validation, the ensemble bagged tree and k-nearest neighbors algorithm achieved 96.1% and 97.6% accuracy, respectively. The use of multi-layer perceptron with Bayesian regularization backpropagation provided 99.2% accuracy. Such high accuracy system can be trained off-line and deployed to mobile devices to produce an automatic colourimetric diagnostic decision anytime anywhere.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/aefb6b8bc58b50a6723a848c8b033f9c6aca618d",
        "citation_count": 4
    },
    {
        "title": "A Survey of Medical Image Analysis Based on Machine Learning Techniques",
        "abstract": "Machine learning is a result of the availability and accessibility of a massive amount of data collected via sensors and the internet. The concept of machine learning demonstrates and spreads the fact that computers can improve themselves. Deep learning is causing a paradigm shift in medical image analysis. A medical image is a visual representation of the interior of a body, typically used for diagnostic or therapeutic purposes. Researchers and policymakers interested in healthcare outcomes should read this; this research provides an overview of machine learning at a high level. Computer vision is the field of using computer algorithms to understand and analyze visual data, and machine learning is a key tool for developing these algorithms. This review discovered that there are three varieties of machine learning strategies: supervised, unsupervised, and semi-supervised, and they seem to be gaining traction in risk assessment, disease prognosis, and image-based diagnosis, with increasing success. Convolutional neural networks (CNNs), k-means clustering, random forests, transductive learning, and support vector machines are among the most commonly used algorithms. Image analysis using CNN is the most effective method for medical imaging.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/af60af7b72d8e2c7a1e911fbde502b6764333a78",
        "citation_count": 2
    },
    {
        "title": "Lung Cancer Detection: A Pioneering Machine Learning Approach for Predictive Precision",
        "abstract": "Lung Cancer has become serious health problem which affects all age groups from children to old age persons. An early-stage prognosis and diagnosis of lung cancer can save many humans from major causalities. X-rays, Ultrasounds and CT (Computerized Tomography) are further diagnostic tools. The goal of computer science, often known as machine learning (ML), is to develop algorithms that let computers pick up new practices from examples seen in the real world. There exist several machine learning methods which are used to categorize lung tumors which finally develop into lung cancer. Precision, Recall and F1 Score parameters are used for testing the model's capability. Using a test dataset of 200 epochs, the CNN system obtains a high accuracy of approx. 98.87% in identifying normal and cancerous cells. This study examines the use of optimized feature selection and image processing in the identification of initial phase of lung cancer. The rigorous evaluation is done on large dataset while taking in consideration healthy and malignant cells. The study includes training, pre-processing, model building and performance analysis of deep learning algorithm which gives better results in case of forecasting and curing lung cancer at the initial stage so that risk of causalities can be minimized as compared with conventional techniques. This paper also examines the benefits of machine learning techniques in healthcare, cancer prognosis, and detection. Many researchers have concentrated on creating cancer prediction systems that incorporate classification algorithms for accurate results and use supervised learning approaches in machine learning. The importance of deep learning and related algorithms in the healthcare industry is emphasized. The research recommends enhancing and expanding the lung cancer system through deep learning techniques in order to improve the accuracy of both lung cancer identification and prediction. With a view to implementing deep learning techniques for lung cancer prediction in the future, this contribution attempts to give researchers insights into various machine learning approaches applied to lung cancer. The proposed system overcomes these challenges which are used in detection system and classification techniques. In this paper, CNN machine learning algorithm and a categorization approach is shown achieving high accuracy of 99.4% with a dataset of 200 images used in the identification and prediction of lung cancer hence effectively distinguishes between healthy and poisonous cells for the future improvement. With the help of this paper different machine learning algorithms can be explored further for increasing the efficiency in terms of accuracy, sensitivity, F1-score respectively. The outcomes of CNN algorithm exhibit desirable performance in the dataset of chest scan images and provides better accuracy. The approach can be extended in future by enhancing a large number of lung cancer images or using any other statistical method so that early diagnosis, stage-wise classification, large datasets and treatment of lung cancer can be done efficiently and accurately to decrease the death rate.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/afbff822a7870a2632339e423bcb191cfbdb641e",
        "citation_count": 0
    },
    {
        "title": "Intent Recognition on Low-Resource Language Messages in a Health Marketplace Chatbot",
        "abstract": "In this paper we explore intent recognition models of user messages sent to a chatbot that primarily uses system-initiated navigation. The chatbot (askNivi) discusses sexual and reproductive health topics for educational purposes and to facilitate healthcare access. It is deployed in four languages, three of which are considered low-resource languages (Hausa, Hindi, and Swahili; the fourth language is English). Although the primary navigation mode is system-initiated, many users attempt to take initiative by expressing various intents with natural language messages. This paper describes a multi-lingual corpus of those initiative attempts manually annotated with intent labels as well as results of modeling experiments on the classification of these intents using context-dependent supervised machine learning.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b00d479615887820f09aea6529908d194fd4a34c",
        "citation_count": 4
    },
    {
        "title": "A Supervised Learning-Based Framework for Predicting COVID-19 in Patients",
        "abstract": "The integration of ML and loT can provide insightful details for critical decision making, automated responses, etc. Predicting future trends and detecting anomalies are some of the areas where loT and ML are being used at a rapid rate. Machine learning can help decode the hidden patterns in IoT data. It may complement or replace manual processes in critical areas with automated systems that use statistically derived behavior. In healthcare, wearable sensors used for tracking patient activity have been continuously producing a staggering amount of data. This paper proposes an IoT-based scalable architecture for detecting COVID-19-positive patients and storing and processing such massive amount of data on the cloud. The proposed architecture also employs machine learning algorithms for correct classification of patients. The proposed architecture employs gradient boosting classifier method for early detection of COVID-19 in the patient's body. In order to make the architecture scalable and faster in terms of computational power, the architecture employs cloud computing for data storage.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b0492c2e7b2ef7122d1e12d34576824d251d0ea4",
        "citation_count": 0
    },
    {
        "title": "Sparklinglight Transactions on Artificial Intelligence and Quantum Computing (STAIQC)",
        "abstract": "Human life has been made easier and more comfortable thanks to technological advancements. Predictive analytics is a revolutionary technique that utilizes a significant amount of historical data to create predictions about the future. Its goal is to analyze specific data in order to forecast the future and identify the risks connected with a certain decision. Using data-driven predictive models, decisions that were the product of several mathematical computations can be made more quickly and accurately. Banking, education, healthcare, entertainment, and other industries employ technologies to create difficult decisions and forecast future trends. The goal of predictive analytics is to make accurate and cost-effective predictions. The data required for the analysis comes from a variety of sources and will be in a structured, semi-structured, or unstructured format. The classification of a large volume of data during the data analytics process is a tough challenge. The purpose of classification is to turn accessible data into knowledge that will be useful in future research. It is possible to learn from the training data set using machine learning, and the knowledge gathered this way can be applied to effective decision-making. Classification algorithms examine at the training data and use that knowledge to categorize the test data. To maximize their profitability, organizations acquire experts in critical decision-making. Using human intelligence to make key decisions is costly, dangerous, and time-consuming. As a result, predictive analytics is getting lots of attention these days. It makes the most out of available data in order to make better and more informed decisions. It can be used to discover different patterns and relationships in data in order to forecast future events. Data analysis delivers useful insights and reliably identifies potential hazards. The predictive model and attributes chosen for analysis determine the accuracy of the prediction. The use of an incorrect model and erroneous data can be catastrophic for an organization. Artificial intelligence, cloud computing, machine learning, and other emergent technologies are used to collect, store, and analyze data effectively. The quality of the data acquired and the models employed for analysis are both important factors in forecasting. To analyze the data and make predictions, many supervised learning approaches can be applied. The authors of this paper attempt to provide a thorough overview of the many supervised learning approaches prevalent in machine learning. They also attempt to investigate several application areas in which these strategies are employed to aid decision-making.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/b063d93eb6751ca612b28ef3e1440867a98c56b3",
        "citation_count": 0
    },
    {
        "title": "Gaussian Distribution-Based Machine Learning Scheme for Anomaly Detection in Healthcare Sensor Cloud",
        "abstract": "Smart information systems are based on sensors that generate a huge amount of data. This data can be stored in cloud for further processing and efficient utilization. Anomalous data might be present within the sensor data due to various reasons (e.g., malicious activities by intruders, low quality sensors, and node deployment in harsh environments). Anomaly detection is crucial in some applications such as healthcare monitoring systems, forest fire information systems, and other internet of things (IoT) systems. This paper proposes a Gaussian distribution-based supervised machine learning scheme of anomaly detection (GDA) for healthcare monitoring sensor cloud, which is an integration of various body sensors of different patients and cloud. This work is implemented in Python. Use of Gaussian statistical model in the proposed scheme improves precision, throughput, and efficiency. GDA provides 98% efficiency with 3% and 4% improvements as compared to the other supervised learning-based anomaly detection schemes (e.g., support vector machine [SVM] and self-organizing map [SOM], respectively).",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/b0caa1f34ab2e93e2d6dff7a2be580b7c0aa134a",
        "citation_count": 25
    },
    {
        "title": "Developing a machine learning model with enhanced performance for predicting COVID\u201019 from patients presenting to the emergency room with acute respiratory symptoms",
        "abstract": "Abstract Artificial Intelligence is playing a crucial role in healthcare by enhancing decision\u2010making and data analysis, particularly during the COVID\u201019 pandemic. This virus affects individuals across all age groups, but its impact is more severe on the elderly and those with underlying health issues like chronic diseases. This study aimed to develop a machine learning model to improve the prediction of COVID\u201019 in patients with acute respiratory symptoms. Data from 915 patients in two hospitals in Saudi Arabia were used, categorized into four groups based on chronic lung conditions and COVID\u201019 status. Four supervised machine learning algorithms\u2014Random Forest, Bagging classifier, Decision Tree, and Logistic Regression\u2014were employed to predict COVID\u201019. Feature selection identified 12 key variables for prediction, including CXR abnormalities, smoking status, and WBC count. The Random Forest model showed the highest accuracy at 99.07%, followed by Decision Tree, Bagging classifier, and Logistic Regression. The study concluded that machine learning algorithms, particularly Random Forest, can effectively predict and classify COVID\u201019 cases, supporting the development of computer\u2010assisted diagnostic tools in healthcare.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b0f656375d2306c410e1894ce4c967378e8b5571",
        "citation_count": 0
    },
    {
        "title": "Application of Supervised Machine Learning Methods on the Multidimensional Knapsack Problem",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/b198b669f292486962c6fcf7e79bcb6e67911892",
        "citation_count": 6
    },
    {
        "title": "Employing advanced supervised machine learning approaches for predicting micronutrient intake status among children aged 6\u201323\u2009months in Ethiopia",
        "abstract": "Background Although micronutrients (MNs) are important for children\u2019s growth and development, their intake has not received enough attention. MN deficiency is a significant public health problem, especially in developing countries like Ethiopia. However, there is a lack of empirical evidence using advanced statistical methods, such as machine learning. Therefore, this study aimed to use advanced supervised algorithms to predict the micronutrient intake status in Ethiopian children aged 6\u201323\u2009months. Methods A total weighted of 2,499 children aged 6\u201323\u2009months from the Ethiopia Demographic and Health Survey 2016 data set were utilized. The data underwent preprocessing, with 80% of the observations used for training and 20% for testing the model. Twelve machine learning algorithms were employed. To select best predictive model, their performance was assessed using different evaluation metrics in Python software. The Boruta algorithm was used to select the most relevant features. Besides, seven data balancing techniques and three hyper parameter tuning methods were employed. To determine the association between independent and targeted feature, association rule mining was conducted using the a priori algorithm in R software. Results According to the 2016 Ethiopia Demographic and Health Survey, out of 2,499 weighted children aged 12\u201323\u2009months, 1,728 (69.15%) had MN intake. The random forest, catboost, and light gradient boosting algorithm outperformed in predicting MN intake status among all selected classifiers. Region, wealth index, place of delivery, mothers\u2019 occupation, child age, fathers\u2019 educational status, desire for more children, access to media exposure, religion, residence, and antenatal care (ANC) follow-up were the top attributes to predict MN intake. Association rule mining was identified the top seven best rules that most frequently associated with MN intake among children aged 6\u201323\u2009months in Ethiopia. Conclusion The random forest, catboost, and light gradient boosting algorithm achieved a highest performance and identifying the relevant predictors of MN intake. Therefore, policymakers and healthcare providers can develop targeted interventions to enhance the uptake of micronutrient supplementation among children. Customizing strategies based on identified association rules has the potential to improve child health outcomes and decrease the impact of micronutrient deficiencies in Ethiopia.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b1ad12dffc506a5200131f401ec16e745e23a848",
        "citation_count": 1
    },
    {
        "title": "Firm-Level Risk Exposures and Stock Returns in the Wake of COVID-19",
        "abstract": "Firm-level stock returns differ enormously in reaction to COVID-19 news. We characterize these reactions using the Risk Factors discussions in pre-pandemic 10-K filings and two text-analytic approaches: expert-curated dictionaries and supervised machine learning (ML). Bad COVID-19 news lowers returns for firms with high exposures to travel, traditional retail, aircraft production and energy supply -- directly and via downstream demand linkages -- and raises them for firms with high exposures to healthcare policy, e-commerce, web services, drug trials and materials that feed into supply chains for semiconductors, cloud computing and telecommunications. Monetary and fiscal policy responses to the pandemic strongly impact firm-level returns as well, but differently than pandemic news. Despite methodological differences, dictionary and ML approaches yield remarkably congruent return predictions. Importantly though, ML operates on a vastly larger feature space, yielding richer characterizations of risk exposures and outperforming the dictionary approach in goodness-of-fit. By integrating elements of both approaches, we uncover new risk factors and sharpen our explanations for firm-level returns. To illustrate the broader utility of our methods, we also apply them to explain firm-level returns in reaction to the March 2020 Super Tuesday election results.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/b2732c928c70350ea2992f78b7f7258b3142d91f",
        "citation_count": 48
    },
    {
        "title": "Intrusion Detection using Network Traffic Profiling and Machine Learning for IoT",
        "abstract": "The proliferation of the Internet of Things (IoT) in various sectors, including healthcare, smart cities, and industrial automation, has significantly enhanced operational efficiency and service delivery. However, this widespread adoption has introduced new vulnerabilities, making IoT networks a prime target for cyberattacks. Traditional security mechanisms often fall short in protecting IoT devices due to their limited computational resources and the unique nature of IoT network traffic. This paper introduces a novel intrusion detection system (IDS) that leverages network traffic profiling and machine learning techniques tailored for the IoT ecosystem. By analyzing the behavioral patterns of network traffic, the proposed system can accurately identify malicious activities and potential threats in real-time, ensuring the integrity and confidentiality of IoT networks. The methodology encompasses data collection, feature extraction, model training, and evaluation stages, employing a combination of supervised and unsupervised machine learning algorithms to optimize detection accuracy. Experimental results, conducted on real-world IoT network datasets, demonstrate the effectiveness of our approach in detecting a wide range of cyber threats with high precision and recall rates. This research contributes to the cybersecurity domain by providing a scalable, efficient, and adaptive IDS framework that can be integrated into various IoT infrastructures to mitigate the risk of cyber intrusions.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b298a6e1774c839107926435ee7ff71f39b74199",
        "citation_count": 0
    },
    {
        "title": "OncoNet: Weakly Supervised Siamese Network to automate cancer treatment response assessment between longitudinal FDG PET/CT examinations",
        "abstract": "FDG PET/CT imaging is a resource intensive examination critical for managing malignant disease and is particularly important for longitudinal assessment during therapy. Approaches to automate longtudinal analysis present many challenges including lack of available longitudinal datasets, managing complex large multimodal imaging examinations, and need for detailed annotations for traditional supervised machine learning. In this work we develop OncoNet, novel machine learning algorithm that assesses treatment response from a 1,954 pairs of sequential FDG PET/CT exams through weak supervision using the standard uptake values (SUVmax) in associated radiology reports. OncoNet demonstrates an AUROC of 0.86 and 0.84 on internal and external institution test sets respectively for determination of change between scans while also showing strong agreement to clinical scoring systems with a kappa score of 0.8. We also curated a dataset of 1,954 paired FDG PET/CT exams designed for response assessment for the broader machine learning in healthcare research community. Automated assessment of radiographic response from FDG PET/CT with OncoNet could provide clinicians with a valuable tool to rapidly and consistently interpret change over time in longitudinal multi-modal imaging exams.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/b2ed32d82b973280b16d6d0b8f66b2949a67952b",
        "citation_count": 2
    },
    {
        "title": "Automatic Construction of UMLS Metathesaurus with Deep Learning",
        "abstract": "\u200bThe Unified Medical Language System (UMLS) is a repository of biomedical vocabularies developed by the US National Library of Medicine to integrate a variety of ways the same concepts are expressed by different terminologies and provide cross-walk among them. However, the current approach of constructing and inserting new resources to the existing Metathesaurus relies heavily on lexical knowledge, semantic pre-processing, and manual audits by human editors. \u200bGiven the recent successes of supervised machine learning approach in their applications to the medical and healthcare domains, this project explores the use of Deep Learning to identify synonymy and non-synonymy among English UMLS concepts at the atom level. We use the Siamese network with LSTM and CNN models to learn the similarities and dissimilarities between pairs of atoms from the active subset of 2019AA UMLS. We generate about 15 million synonym pairs and for non-synonyms, interesting pairs that are lexically similar but differ in semantics are generated using a heuristic approach with Jaccard index. To disambiguate concepts with lexically identical atoms, we contextualize the pairs with various enrichment strategies that reflect the information available to the UMLS editors including the source synonymy, hierarchical context, and source semantic group. Using the base lexical features of the atoms yields an overall F1-score of 75.97%. Adding source synonymy to the base yields a higher precision and overall F-1 score of 86.54% and 87.63% respectively. Whereas, adding hierarchical context trades precision for higher recall of 90.38%. Adding source synonymy, hierarchical context, and the semantic group provides an overall increase in accuracy to 95.20%. However, adding source synonymy of hierarchical context does not yield any noticeable improvement. The Deep Learning approach provides relatively good performance in identifying synonymy and non-synonymy among atoms indicating a promising potential for emulating the current building process. \u200bFuture works include evaluations with the manual rule-based normalization process of constructing the Metathesaurus and investigate the scalability, maintenance, and applicability aspects of these models.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/b35026761c0906f958a073da1b95bface28105f7",
        "citation_count": 0
    },
    {
        "title": "Machine learning algorithms for the prognostication of abdominal aortic aneurysm progression: a systematic review.",
        "abstract": "INTRODUCTION\nAbdominal aortic aneurysm (AAA), often characterized by an abdominal aortic diameter over 3.0 cm, is managed through screening, surveillance, and surgical intervention. AAA growth can be heterogeneous and rupture carries a high mortality rate, with size and certain risk factors influencing rupture risk. Research is ongoing to accurately predict individual AAA growth rates for personalized management. Machine learning, a subset of artificial intelligence, has shown promise in various medical fields, including endoleak detection post-EVAR. However, its application for predicting AAA growth remains insufficiently explored, thus necessitating further investigation. Subsequently, this paper aims to summarize the current status of machine learning in predicting AAA growth.\n\n\nEVIDENCE ACQUISITION\nA systematic database search of Embase, MEDLINE, Cochrane, PubMed and Google Scholar from inception till December 2022 was conducted of original articles that discussed the use of machine learning in predicting AAA growth using the aforementioned databases.\n\n\nEVIDENCE SYNTHESIS\nOverall, 2742 articles were extracted, of which seven retrospective studies involving 410 patients were included using a predetermined criteria. Six out of seven studies applied a supervised learning approach for their machine learning (ML) models, with considerable diversity observed within specific ML models. The majority of the studies concluded that machine learning models perform better in predicting AAA growth in comparison to reference models. All studies focused on predicting AAA growth over specified durations. Maximal luminal diameter was the most frequently used indicator, with alternative predictors being AAA volume, ILT (intraluminal thrombus) and flow-medicated diameter (FMD).\n\n\nCONCLUSIONS\nThe nascent field of applying machine learning (ML) for Abdominal Aortic Aneurysm (AAA) expansion prediction exhibits potential to enhance predictive accuracy across diverse parameters. Future studies must emphasize evidencing clinical utility in a healthcare system context, thereby ensuring patient outcome improvement. This will necessitate addressing key ethical implications in establishing prospective studies related to this topic and collaboration among pivotal stakeholders within the AI field.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b356402364c4ef54d522258e5878e1d03a0c736c",
        "citation_count": 0
    },
    {
        "title": "A Hybrid Data-Driven Approach For Analyzing And Predicting Inpatient Length Of Stay In Health Centre",
        "abstract": "Patient length of stay (LoS) is a critical metric for evaluating the efficacy of hospital management. The primary objectives encompass to improve efficiency and reduce costs while enhancing patient outcomes and hospital capacity within the patient journey. By seamlessly merging data-driven techniques with simulation methodologies, the study proposes an all-encompassing framework for the optimization of patient flow. Using a comprehensive dataset of 2.3 million de-identified patient records, we analyzed demographics, diagnoses, treatments, services, costs, and charges with machine learning models (Decision Tree, Logistic Regression, Random Forest, Adaboost, LightGBM) and Python tools (Spark, AWS clusters, dimensionality reduction). Our model predicts patient length of stay (LoS) upon admission using supervised learning algorithms. This hybrid approach enables the identification of key factors influencing LoS, offering a robust framework for hospitals to streamline patient flow and resource utilization. The research focuses on patient flow, corroborating the efficacy of the approach, illustrating decreased patient length of stay within a real healthcare environment. The findings underscore the potential of hybrid data-driven models in transforming hospital management practices. This innovative methodology provides generally flexible decision-making, training, and patient flow enhancement; such a system could have huge implications for healthcare administration and overall satisfaction with healthcare.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/b38a52d472ba5eef7674a289b4c9677f065dba0a",
        "citation_count": 0
    },
    {
        "title": "Developing a data-driven predictive model for substance abuse prevention among youth using behavioral analytics",
        "abstract": "Substance abuse among youth presents a critical public health challenge, necessitating innovative approaches for early intervention and prevention. This study proposes the development of a data-driven predictive model that leverages behavioral analytics to identify youth at risk of substance abuse. The model utilizes data from multiple sources, including social media activity, school performance records, and mental health screenings, to analyze behavioral patterns that may indicate a predisposition toward substance misuse. The core methodology integrates machine learning algorithms to process and analyze large datasets, uncovering correlations between specific behaviors and the likelihood of substance abuse. Predictive features such as changes in social engagement, academic performance fluctuations, and indicators of emotional distress are identified and incorporated into the model to enhance its accuracy. By applying supervised learning techniques, the model is trained to recognize patterns in historical data, allowing it to make predictions about future substance use risks. Furthermore, the model's design emphasizes real-time monitoring and adaptability, enabling health professionals and educators to receive timely alerts and intervene early when behavioral warning signs are detected. The application of behavioral analytics in this context offers a more proactive, personalized approach to prevention, targeting at-risk individuals before they develop harmful substance use habits. In addition to its predictive capabilities, the model also provides actionable insights into effective intervention strategies. By identifying the most influential behavioral factors, it informs tailored prevention programs that address specific risk behaviors among youth. These findings can support policymakers and healthcare providers in developing data-driven, evidence-based prevention initiatives that better allocate resources to high-risk populations.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b3e83a3160f8253646b06dace84422c00f44cc10",
        "citation_count": 0
    },
    {
        "title": "A STUDY ON THYROID DISEASE USING DATAMINING ALGORITHM",
        "abstract": "\u2014 Data mining has been used intensively and extensively by many organizations. In healthcare, data mining is becoming increasingly popular, if not increasingly essential. Data mining applications can greatly benefit all parties involved in the healthcare industry. For example, data mining can help healthcare insurers detect fraud and abuse, healthcare organizations make customer relationship management decisions, physicians identify effective treatments and best practices, and patients receive better and more affordable healthcare services. The huge amounts of data generated by healthcare transactions are too complex and voluminous to be processed and analyzed by traditional methods. Data mining provides the methodology and technology to transform these mounds of data into useful information for decision making. There are two main methods of Data mining: Clustering and Classification. In many cases the concept of classification is confused by means of clustering, but there is difference between these two methods. According to the perspective of Machine learning clustering method is unsupervised learning and tries to group sets of objects having relationship between them, whereas classification method is supervised and assigning objects to sets of predefined classes. in proposed system are classified and cluster of the thyroid disease in data mining.",
        "year": 2015,
        "url": "https://www.semanticscholar.org/paper/b3fd2cf867c466d502e4432bc66510f168da07de",
        "citation_count": 3
    },
    {
        "title": "Machine Learning for Early Detection of Neurodegenerative Diseases",
        "abstract": ": Neurodegenerative disorders, encompassing conditions like Parkinson's disease (PD) and Amyotrophic Lateral Sclerosis (ALS), pose formidable challenges to global healthcare. Timely identification and accurate prognosis are essential for effective intervention and improved patient outcomes. This study investigates the use of machine learning (ML) models specifically designed for early Parkinson's disease diagnosis and predictive modeling of ALS progression. In the realm of Parkinson's disease, a variety of ML techniques are applied to analyze diverse datasets, including clinical assessments, neuroimaging, and genetic information. Supervised learning algorithms, such as support vector machines and random forests, exhibit promising outcomes in distinguishing individuals with early-stage Parkinson's disease from healthy counterparts. Furthermore, deep learning models, particularly convolutional neural networks, demonstrate high accuracy in detecting subtle patterns within neuroimaging data associated with early Parkinson's disease pathology. Regarding Amyotrophic Lateral Sclerosis, predictive models play a pivotal role in estimating disease progression and identifying factors influencing its course. ML algorithms, including linear regression and recurrent neural networks, utilize longitudinal clinical data and biomarkers to predict the rate of ALS progression. These models contribute to tailoring treatment strategies and enable clinicians to optimize care plans for individuals grappling with this rapidly progressing neurodegenerative disorder.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b53c2b70f1fe338499cd114d0bac6b6bb27444d0",
        "citation_count": 0
    },
    {
        "title": "A collaborative empirical analysis on machine learning based disease prediction in health care system",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b564b65d08fba33dfbc4a55d3a250cb008fb706b",
        "citation_count": 17
    },
    {
        "title": "A Comprehensive Framework for Machine Learning-Based Threat Intelligence in Health Information Systems",
        "abstract": "This research work provides a comprehensive architecture of Machine Learning based threat intelligence particularly for Health Information System (HIS). The number of cybersecurity threats executed by healthcare companies is even higher since healthcare organizations continue to introduce digitized data into medical data. This work employs complex machine learning techniques from the MIMIC-III Critical Care Database to develop a practical threat identification and mitigation system. In this case, the strategy of analysis involves selection of data, data processing, modeling and real time dangers identification considering both supervised and unsupervised learning. The results reveal that the proposed framework covers high performance indicators such as: accuracy that equals 97.92%, and the level of precision and recall which also equal 90% ROC AUC has reached 0.94. These results demonstrate that the framework can identify and categorise cybersecurity risks in systems of health information on a regular basis. It not only increases threat perception but also makes the system internally valuable for healthcare IT professionals since it contains real-time monitoring and anomaly detection functionality. Therefore, this study stands in support of the ongoing efforts to enhance the security of the healthcare bodies on the use of policies on cybersecurity so as to ensure the protection of individual patient\u2019s information against new forms of threats.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b62f09eec137ede88926660e8e7d9322c781703d",
        "citation_count": 0
    },
    {
        "title": "A Comprehensive Discourse on Shallow Learning and its Applications",
        "abstract": "Shallow learning, a fundamental approach in machine learning, encompasses a variety of algorithms and techniques aimed at learning patterns and making predictions from labelled data. Unlike deep learning, which involves complex architectures with multiple layers of abstraction, shallow learning focuses on simpler models with limited complexity. This abstract explores the essence of shallow learning, its algorithms, applications, and challenges. Shallow learning algorithms include classic methods such as decision trees, support vector machines, k-nearest neighbours, and logistic regression, among others. These algorithms are typically trained using supervised learning techniques, where the model learns from input-output pairs to make predictions on new, unseen data. Shallow learning models excel in tasks such as classification and regression, where the goal is to assign labels or predict continuous values to input data. Applications of shallow learning span across various domains, including healthcare, finance, marketing, and cyber security. In healthcare, shallow learning models are used for disease diagnosis and prognosis prediction based on patient data. In finance, these models aid in fraud detection, credit scoring, and stock market prediction. Marketing applications involve customer segmentation and churn prediction, while in cyber security; shallow learning is utilized for malware detection and network intrusion detection.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b65cd382313ebb989d45d8dff83cf7ad1fb7beec",
        "citation_count": 0
    },
    {
        "title": "Belief functions and uncertainty management in networks and telecommunication",
        "abstract": null,
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/b665e394340beaddd62b90bec7bf019b71c474ff",
        "citation_count": 0
    },
    {
        "title": "Using Convolutional Neural Networks to Extract Keywords and Keyphrases: A Case Study for Foodborne Illnesses",
        "abstract": "Keywords and keyphrases are important for Natural Language Processing (NLP) applications such as document classification, information retrieval, and topic identification. They are also useful for capturing different classes of entities from content related to healthcare, biology, food science, and journalism fields. There are different approaches to extract keywords and keyphrases. Deep learning approaches have achieved high-performance results in terms of keywords and keyphrase extraction. However, among deep learning approaches, Convolutional Neural Network (CNN) potentials have not been fully explored as a technique for extracting keywords and keyphrases. In this work, we performed a comparative study using a benchmark dataset, the IEEE Xplore collection to test the CNN generalization ability in selecting keywords and keyphrases. In addition, we further collected a corpus in the field of foodborne illness outbreaks. We utilize this corpus to develop a CNN-based identification approach of keywords and keyphrases related to foodborne illnesses. Results were compared with several supervised (KEA, GuidedLDA) and unsupervised (LDA) machine learning algorithms. CNN outperformed these algorithms in selecting relevant keywords and keyphrases for foodborne illnesses. The findings of this study have also confirmed superiority of CNN-based algorithm for keyphrase extraction to other machine learning approaches.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/b6b013ded8203e023a4d3e29b55252f1bc5b3dd6",
        "citation_count": 8
    },
    {
        "title": "A Supervised Model for Diabetes Divination",
        "abstract": "Diabetes is a most significant and sensitive metabolic disorder. It can disrupt entire metabolism of the body. The undiagnosed diabetes may exaggerate the risk of many other diseases too. It can cause problems such as weakness, stress and low interest in routine work. People with diabetes are among the most susceptible to novel corona virus (COVID-19) infection and may grieve from serious lungs infections, difficulties in breathing, or even death. It is a motive of world-wide apprehension as the cases are intensifying hastily. In the current scenario with the advent and outstretched growth of Machine learning (ML), the computer assisted automatic disease diagnosis in healthcare segment is speedily growing. The present research aims to apply supervised ML practises on Pima Indian Diabetes (PID) corpus to diagnose disease for the females and assist the doctors and health care professionals. The empirical research is carried out using three different predictive models namely support vector machine (SVM) with linear, RBF, Polynomial, sigmoid functions, k-nearest neighbor (k-NN), and Random forest (RF).The random forest model has delivered an improved accuracy of 76%.The performance of three models is measured by using accuracy, precision and recall.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/b6c9ef49463a00903a7ec8a11d0e9b36b9dd8eb4",
        "citation_count": 2
    },
    {
        "title": "The role of machine learning in developing non-magnetic resonance imaging based biomarkers for multiple sclerosis: a systematic review",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/b817cd8e26dfd8a8a8bcea0b2a0e425c5e0ab029",
        "citation_count": 9
    },
    {
        "title": "Supervised Anomaly Detection for Features Extraction from Normal Semantics",
        "abstract": "In the realm of anomaly detection, identifying deviations from normal behavior in data is critical across various applications, including cybersecurity, manufacturing, and healthcare. Traditional supervised methods rely on labeled datasets, which are often scarce or expensive to obtain. To address this challenge, we propose supervised anomaly detection framework that leverages deep learning techniques to extract features from normal semantic patterns. Our approach integrates Support Vector Machines (SVM), Convolutional Neural Networks (CNN), and ResNet-18 architectures to enhance the detection accuracy and efficiency. Initially, CNNs are employed to capture spatial hierarchies in the data, learning robust feature representations from normal samples. The extracted features are then fine-tuned using the ResNet-18 model, known for its depth and skip connections, to ensure comprehensive feature extraction and minimize information loss. Finally, these deep features are fed into an SVM to differentiate between normal and anomalous instances based on the learned semantics. Experimental results on benchmark datasets demonstrate the superiority of our method in detecting anomalies with high precision and recall, outperforming traditional anomaly detection techniques. Our framework's ability to operate without labeled anomalies and adapt to various domains underscores its potential for broad applicability in real-world scenarios.\n\nKeywords\u2014 Support Vector Machines (SVM), Convolutional Neural Networks (CNN), and ResNet-18 architectures, deep Learning.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b827db60555fda0155bdfc30c583d9ea453e3e5b",
        "citation_count": 0
    },
    {
        "title": "Inteligencia artificial en medicina: M\u00e9todos de modelamiento (Parte I)",
        "abstract": "The emergence of artificial intelligence and machine learning in medicine determines that healthcare professionals should understand generalities of their methodologies. This narrative review consists of two parts. The first consists of an exploration of the main methods used to model in machine learning, described in a simple way by medical and mathematical authors, with the purpose to bring this methodology healthcare workers. Here we will describe the basic structure of a machine learning algorithm (input information, task to execute, output result, optimization, and adjustment), its main classifications (supervised, unsupervised and by reinforcement) and the main modeling methods used. We will review regression and then explore decision trees, support vector machines, principal component analysis, clustering, K-means, hierarchical clustering, deep learning, and convolutional neural networks. In this way, we hope to bring this methodology closer to healthcare personnel to increase the interpretability of the published work in medicine that use these methodologies.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/b8deb8f0d1540117b754e2b5c29d5ea96b4ebd97",
        "citation_count": 1
    },
    {
        "title": "Study of Machine Learning Models to Detect Autism Spectrum Disorder",
        "abstract": "ASD is a spectrum disorder, some people with ASD may have mild symptoms and can live independently, while others may need more support and assistance in their daily lives. Some of the risk factors for ASD include having an older parent, being born prematurely, having a sibling with ASD, or being exposed to certain infections or toxins during pregnancy some of the common types of treatments include behavioural therapy, occupational therapy, physical therapy, and passionate about their interests. Such as the Modified Checklist for Autism in Toddlers, observational tools, such as the Autism Diagnostic Observation Schedule, and developmental assessments, such as the Mullen Scales of Early Learning. This study refers to some Machine Learning (ML) based applications that are able to detect Autism among individuals. This comprehensive review explores the innovative integration of machine learning (ML) models in the detection and diagnosis of Autism Spectrum Disorder (ASD). It begins by highlighting the complexities and diagnostic challenges of ASD, noting the limitations of traditional assessment methods. The review then delves into the realm of artificial intelligence (AI), discussing how AI, particularly ML and deep learning techniques, are revolutionizing the approach to ASD detection. It covers various ML models, including supervised, unsupervised, and reinforcement learning, and their application using behavioural, genetic, and neuroimaging data. A significant focus is given to the use of Logistic Regression and Hybrid Autism Screening Models in predicting ASD. The review also examines the efficacy and performance of supervised and deep learning models in ASD detection, evaluating their accuracy and precision. By providing a detailed analysis of the current state of AI in healthcare, specifically for ASD, this review underscores the potential of ML models in offering more accurate, accessible, and efficient diagnosis methods for ASD",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b8e4dbea3a1130c33a1e9089ed1e4048ee9a01f2",
        "citation_count": 0
    },
    {
        "title": "Early risk prediction of cervical cancer: A machine learning approach",
        "abstract": "Cervical cancer is a vital public health issue that affects women worldwide. As it is a fatal disease, early risk prediction of cervical cancer can play an important role in prevention by raising public awareness of this disease. Early prediction using a Machine Learning (ML) model can be a beneficial solution for both healthcare professionals and people at risk. In this study, eleven supervised ML algorithms are utilized to forecast early jeopardies of this disease using a dataset from UCI ML repository. The ML models are rummaged to prophesy the early threats, and performance parameters like accuracy, precision, F1-score, re-call, and ROC-AUC are estimated. Finally, a reasonable analysis is performed, revealing that this study achieved 93.33% prediction accuracy with Multi-Layer Perceptron (MLP) algorithm with default hyperparameters. However, employing the hyperparameter tuning method with Grid Search Cross Validation (GSCV), K-Nearest Neighbors (KNN), Decision Tree Classifier (DTC), Support Vector Machine (SVM), Random Forest Classifier (RFC), and Multi-Layer Perceptron (MLP) all portrayed accuracy of 93.33%.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/b90754bbdb8ce6ba9b026cc2fc3f0538660daafd",
        "citation_count": 36
    },
    {
        "title": "An active learning enhanced data programming (ActDP) framework for ECG time series",
        "abstract": "\n Supervised machine learning requires the estimation of multiple parameters by using large amounts of labelled data. Getting labelled data generally requires a substantial allocation of resources in terms of both cost and time. In such scenarios, weak supervised learning techniques like data programming (DP) and active learning (AL) can be advantageous for time-series classification tasks. These paradigms can be used to assign data labels in an automated manner, and time-series classification can subsequently be carried out on the labelled data. This work proposes a novel framework titled active learning enhanced data programming (ActDP). It uses DP and AL for ECG classification using single-lead data. ECG classification is pivotal in cardiology and healthcare for diagnosing a broad spectrum of heart conditions and arrhythmias. To establish the usefulness of this proposed ActDP framework, the experiments have been conducted using the MIT-BIH dataset with 94,224 ECG beats. DP assigns a probabilistic label to each ECG beat using nine novel polar labelling functions and a generative model in this work. Further, AL improves the result of DP by replacing the labels for sampled ECG beats of a generative model with ground truth. Subsequently, a discriminative model is trained on these labels for each iteration. The experimental results show that by incorporating AL to DP in the ActDP framework, the accuracy of ECG classification strictly increases from 85.7 % to 97.34 % in 58 iterations. Comparatively, the proposed framework (ActDP) has demonstrated a higher classification accuracy of 97.34 % In contrast, DP with data augmentation (DA) achieves an accuracy of 92.2 %, while DP without DA results in an accuracy of 85.7 %, majority vote yields an accuracy of 50.2 %, and the generative model achieves an accuracy of only 66.5 %.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b90e426474b0d3664647008ed1e3e9f43570d3bb",
        "citation_count": 1
    },
    {
        "title": "An AI Enabled Framework with Feature Selection for Efficient Heart Disease Prediction",
        "abstract": "Machine learning (ML) techniques as part of Artificial Intelligence (AI) are widely used to solve real world problems. They are widely used in healthcare domain. Many supervised ML techniques are used for heart disease prediction for improving prediction performance. However, it is understood that the accuracy greatly depends on training quality. Training quality gets deteriorated due to curse of dimensionality. In order to overcome third problem, In this study, we introduced a feature selection approach that is AI capable, called Filter Based Feature Selection(FBFS) which is meant for identifying contributing features and discard the features that are irrelevant and redundant. This filter-based approach leads to significant improvement of quality in prediction. With the proposed feature selection method, many ML prediction The empirical study makes use of models including K-Nearest Neighbors, SVM, Decision Tree, Supervised learning and regression methods, Bayesian Network, XGBoost, and Random Forest. Results from the experiments showed that FBFS had an impact on the estimation techniques. Random Forest model along with FBFS showed higher performance with 95.08% accuracy.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/b91b2ec059fc83c796ea08ef3ff8e06e69fbc7a4",
        "citation_count": 2
    },
    {
        "title": "Liver disease Prediction using Ensemble Learning",
        "abstract": "The increasing prevalence of liver disease necessitates efficient identification methods to alleviate the diagnostic burden on healthcare providers. Machine learning offers a promising solution by evaluating vital parameters to predict liver disease, thereby reducing the risk of incorrect diagnoses and subsequent financial burdens on patients. Ensuring that predictive models generalize well across diverse populations and demographics is crucial for their wide applicability. Standardized evaluation metrics for liver disease prediction models are essential for unbiased comparisons and benchmarking. Demonstrating the superiority of new models over existing clinical methods is key to their adoption in clinical practice. This research explores the use of ensemble learning techniques to enhance the accuracy of liver disease predictions. By combining various supervised machine learning models, including Support Vector Machines (SVM), logistic regression, gradient boosting, decision trees, random forests, and artificial neural networks, the predictive outcomes have been improved. Each model undergoes extensive hyperparameter tuning to identify the optimal parameters for the given dataset. Additionally, feature selection techniques are employed to determine the most significant features contributing to the prediction. The study implements both stacking and bagging classification methodologies, achieving an accuracy rate of 79%. This hybrid approach demonstrates significant potential in improving the reliability and accuracy of liver disease predictions, offering a robust tool for early diagnosis and management of liver disease in diverse patient populations.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b9988667c7732b17f05f334a33913ea2f6d23bd6",
        "citation_count": 0
    },
    {
        "title": "Robust Real-Time Mortality Prediction in the Intensive Care Unit using Temporal Difference Learning",
        "abstract": "The task of predicting long-term patient outcomes using supervised machine learning is a challenging one, in part because of the high variance of each patient's trajectory, which can result in the model over-fitting to the training data. Temporal difference (TD) learning, a common reinforcement learning technique, may reduce variance by generalising learning to the pattern of state transitions rather than terminal outcomes. However, in healthcare this method requires several strong assumptions about patient states, and there appears to be limited literature evaluating the performance of TD learning against traditional supervised learning methods for long-term health outcome prediction tasks. In this study, we define a framework for applying TD learning to real-time irregularly sampled time series data using a Semi-Markov Reward Process. We evaluate the model framework in predicting intensive care mortality and show that TD learning under this framework can result in improved model robustness compared to standard supervised learning methods. and that this robustness is maintained even when validated on external datasets. This approach may offer a more reliable method when learning to predict patient outcomes using high-variance irregular time series data.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/b9b7454fc05ab2e8649ef02101b52b8745da9cb4",
        "citation_count": 0
    },
    {
        "title": "Artificial Intelligence for Cognitive Health Assessment: State-of-the-Art, Open Challenges and Future Directions",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/b9e4b4ea648064ad382d1a4e73c604c9fbdbb10a",
        "citation_count": 26
    },
    {
        "title": "Intelligent Data Analytics for Diagnosing Melanoma Skin Lesions via Deep Learning in IoT System",
        "abstract": "Melanoma is considered to be one of the most dangerous human malignancy, which is diagnosed visually or by dermoscopic analysis and histopathological examination. However, as these traditional methods are based on human experience and implemented manually, there have been great limitations for general usability in current clinical practice. In this paper, a novel hybrid machine learning approach is proposed to identify melanoma for skin healthcare in various cases. The proposed approach consists of classic machine learning methods, including convolutional neural networks (CNNs), EfficientNet, and XGBoost supervised machine learning. In the proposed approach, a deep learning model is trained directly from raw pixels and image labels for classification of skin lesions. Then, solely based on modeling of various features from patients, an XGBoost model is adopted to predict skin cancer. Following that, a diagnostic system which composed of the deep learning model and XGBoost model is developed to further improve the prediction efficiency and accuracy. Different from experience-based methods and solely image-based machine learning methods, the proposed approach is developed based on the theory of deep learning and feature engineering. Experiments show that the hybrid model outperforms single model like the traditional deep learning model or XGBoost model. Moreover, the data-driven-based characteristics can help the proposed approach develop a guideline for image analysis in other medical applications.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/ba70fc2a816b58ec3a4d3547d07a7ee408b11797",
        "citation_count": 7
    },
    {
        "title": "Tackling Visual Illumination Variations in Fall Detection for Healthcare Applications",
        "abstract": "This paper presents an innovative approach for fall detection, a significant concern in elder care, using vision-based techniques and video analysis. By employing and comparing supervised machine learning algorithms for recognising falls, The paper examines the impact of different environmental conditions on the fall detection system, focusing on illumination, an aspect previously overlooked in the field. The study introduces a vision-based fall detection method using Human Pose Estimation (HPE) models, specifically MoveNet, for feature extraction from human gestures and temporal moving features. Selected machine learning algorithms and neural network models are then trained and compared using these features to recognise video events such as falls and non-falls. The presented results show promising 70.6% accuracy and real-time model efficiency. This study\u2019s findings hold significant potential for enhancing timely fall detection in real-world scenarios.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/ba98461e95c59dc1e3df6757e7035d68b81b93b8",
        "citation_count": 0
    },
    {
        "title": "Editorial: Smart Objects and Technologies",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/badfee3df4c3ac74be1b2f406e8a9aa6a15f5125",
        "citation_count": 2
    },
    {
        "title": "Prediction of Patients with Heart Disease using Artificial Neural Network and Adaptive Boosting techniques",
        "abstract": "Machine learning (ML) technique behind the most existing abilities fields in several areas like languages processing, robotics, including medicine. The most important medical applications are the early prediction system for heart diseases especially, coronary artery disease (CAD) also called atherosclerosis. The need for a medical diagnosis support system is to detect atherosclerosis at the earlier stages to optimize the diagnosis, avoid the advanced cases, and reduce treatment costs. Here, a supervised machine learning medical diagnosis support system (MDSS) for atherosclerosis prediction is presented that is able to obtain and learn automatically knowledge from each patient\u2019s clinical data. Therefore, we used the various ML classifiers for the proposed medical diagnosis support system for atherosclerosis. Two supervised ML algorithms (Artificial Neural Network and Adaptive Boosting) were used in order to compare which one is more efficient for atherosclerosis diagnosis. Thus, this work is accomplished using databases collected from the UCI repository (Cleveland, Hungarian) and Sani Z-Alizadeh dataset. The performance metrics were computed utilizing Recall, Accuracy and Precision. Furthermore and F1 score measures were also calculated to greatly increase the proposed system performance. Consequently, the proposed model can be used to support healthcare and facilitate large-scale clinical diagnostic of atherosclerosis diseases.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/baf4b21fedc2f156cae11e1548aa793d6d770338",
        "citation_count": 26
    },
    {
        "title": "Monadic Pavlovian associative learning in a backpropagation-free photonic network",
        "abstract": "Over a century ago, Ivan P. Pavlov, in a classic experiment, demonstrated how dogs can learn to associate a ringing bell with food, thereby causing a ring to result in salivation. Today, however, it is rare to find the use of Pavlovian type associative learning for artificial intelligence (AI) applications. Instead, other biologically-inspired learning concepts, in particular artificial neural networks (ANNs) have flourished, yielding extensive impact on a wide range of fields including finance, healthcare and transportation. However, learning in such \"conventional\" ANNs, in particular in the form of modern deep neural networks (DNNs) are usually carried out using the backpropagation method, is computationally and energy intensive. Here we report the experimental demonstration of backpropagation-free learning, achieved using a single (or monadic) associative hardware element. This is realized on an integrated photonic platform using phase change materials combined with on-chip cascaded directional couplers. We link associative learning with supervised learning, based on their common goal of associating certain inputs with \"correct\" outputs. We then expand the concept to develop larger-scale supervised learning networks using our monadic Pavlovian photonic hardware, developing a distinct machine-learning framework based on single-element associations and, importantly, using backpropagation-free single-layer weight architectures to approach general learning tasks. Our approach not only significantly reduces the computational burden imposed by learning in conventional neural network approaches, thereby increasing speed and decreasing energy use during learning, but also offers higher bandwidth inherent to a photonic implementation, paving the way for future deployment of fast photonic artificially intelligent machines.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/bb3a478fb2470216f4606a973f5acc5481f2555d",
        "citation_count": 12
    },
    {
        "title": "Implementing and Evaluating the Timed Up and Go Test Automation Using Smartphones and Smartwatches",
        "abstract": "Physical performance tests aim to assess the physical abilities and mobility skills of individuals for various healthcare purposes. They are often driven by experts and usually performed at their practice, and therefore they are resource-intensive and time-demanding. For tests based on objective measurements (e.g., duration, repetitions), technology can be used to automate them, allowing the patients to perform the test themselves, more frequently and anywhere, while alleviating the expert from supervising the test. The well-known Timed Up and Go (TUG) test, typically used for mobility assessment, is an ideal candidate for automation, as inertial sensors (among others) can be deployed to detect the various movements constituting the test without expert supervision. To move from expert-led testing to self-administered testing, we present a mHealth system capable of automating the TUG test using a pocket-sized smartphone or a wrist smartwatch paired with a smartphone, where data from inertial sensors are used to detect the activities carried out by the patient while performing the test and compute their results in real time. All processing (i.e., data processing, machine learning-based activity inference, results calculation) takes place on the smartphone. The use of both devices to automate the TUG test was evaluated (w.r.t. accuracy, reliability and battery consumption) and mutually compared, and set off with a reference method, obtaining excellent Bland-Altman agreement results and Intraclass Correlation Coefficient reliability. Results also suggest that the smartwatch-based system performs better than the smartphone-based system.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/bb4f1e5e2ae6665b19a159e29af7baba2814f249",
        "citation_count": 0
    },
    {
        "title": "Machine learning for mHealth apps quality evaluation",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bb87738f80c68a6f7ef814396bcba7c62dcd5fb6",
        "citation_count": 1
    },
    {
        "title": "Mental Condition Monitoring Based on Multimodality Biometry",
        "abstract": "We have developed a system with multimodality that monitors objective biomarkers for screening the mental distress in the office. A field study using a prototype of the system was performed over four months with 39 volunteers. We obtained PC operation patterns using a PC logger, sleeping time and activity levels using a wrist-band-type activity tracker, and brain activity and behavior data during a working memory task using optical topography. We also administered two standard questionnaires: the Brief Job Stress Questionnaire (BJS) and the Kessler 6 scale (K6). Supervised machine learning and cross validation were performed. The objective variables were mental scores obtained from the questionnaires and the explanatory variables were the biomarkers obtained from the modalities. Multiple linear regression models for mental scores were comprehensively searched and the optimum models were selected from 2,619,785 candidates. Each mental score estimated with each optimum model was well correlated with each mental score obtained with the questionnaire (correlation coefficient = 0.6\u20130.8) within a 24% of estimation error. Mental scores obtained by means of questionnaires have been in general use in mental health care for a while, so our multimodality system is potentially useful for mental healthcare due to the quantitative agreement on the mental scores estimated with biomarkers and the mental scores obtained with questionnaires.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/bc10f0feaa46889d9d4807e7f6880bd35d872503",
        "citation_count": 2
    },
    {
        "title": "Bachelor Thesis Project Machine Learning in Digital Telerehabilitation",
        "abstract": "The healthcare as a service is always under pressure and is in great demand. Despite living in a developed world with access to cars, trains, busses and other transportation means, sometimes accessing healthcare can be troublesome and costly. The continuous technological progress provides new means to provide different kind of services, healthcare included. One way of putting technology into good use in field of healthcare is remote rehabilitation. Remote rehabilitation is a matter of delivering physiotherapy on a distance. The use of remote rehabilitation potentially reduces waiting time for treatment and gives a possibility for people with long traveling distance, to be treated at their locations. The thesis addresses a solution to physiotherapy on distance that utilizes Kinect and machine learning technologies to provide physiotherapy offline. Thesis presents Kinect Digital Rehabilitation Assistant (KiDiRA), which provides simple functions to suffice the needs of a physiotherapist to plan therapeutical treatment and the ability of a patient to get access physiotherapy offline in real-time at home. More precisely KiDiRA is the system that combines Kinect motion capture device, an interactive graphical interface and a platform to assist with the design of physiotherapeutical exercises and an aid for the patient to execute therapeutic plan on his/her own. The system displays the exercise directives and monitors performance of patient. KiDiRA aims to incorporate science of machine-learning in process of performance evaluation during exercises. Preface Cordial thanks to my sister for supporting and encouraging. Also huge thanks to my teacher and my supervisor for good and thorough guidance.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/bc2d345525acce80b9b4e80a142e654b221f8864",
        "citation_count": 0
    },
    {
        "title": "AI-Driven Smart Device for Non-Invasive Detection of Peptic Ulcers for Sustainable Healthcare",
        "abstract": "Peptic ulcer disease (PUD) is a widespread issue globally, including in Bangladesh. It is largely caused by Helicobacter pylori (H. pylori) bacteria. H. pylori infects the human digestive tract and is a leading reason of gastric inflammation, peptic ulcers, and gastric cancer. Ritual diagnostic methods, though beneficial, often involve invasive procedures that cause patient discomfort. Recent Artificial Intelligence (AI) advancements have opened doorways for noninvasive diagnosis. This study proposed a device that gathers biomarker information through multiple sensors. The biomarker information was used to develop a supervised machine-learning model based on a dataset of 1190 samples. The machine learning model reached a precision of 96 percent on the train and test dataset. A survey of 100 randomly selected individuals revealed that 68 percent believe AI could improve diagnostic accuracy in a non-invasive manner, thereby reducing patient discomfort. This research introduces a novel method for the non-invasive diagnosis of PUD for sustainable healthcare.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/bc388b0b59cf356cc3c2f8ceff0bbe5e9458667a",
        "citation_count": 0
    },
    {
        "title": "Forecasting of Cardiovascular Disease Using Machine Learning",
        "abstract": "heart disease or cardiovascular disease includes several circumstances that affect the heart and is one among major reason of putting to demise globally. Here, we employ Machine Learning to predict cardiovascular disease using a data set containing 14 components. Computers are taught to learn knowledge on their own using machine learning, a form of artificial intelligence. Machine learning in healthcare is increasingly being used and helps victims and clinicians in a variety of ways. The automated identification and diagnosis system\u2019s performance is comparable to that of a skilled radiologist. This article presents multiple heart disease-related characteristics, and includes models constructed using supervised learning techniques such as the Random Forest and K-Nearest Neighbor algorithms. It also focuses on which patients, given certain medical characteristics, are more likely to suffer cardiovascular-disease.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bc436ad3058f1f5e18985849b23644db63fee3af",
        "citation_count": 0
    },
    {
        "title": "Automating Medical Data and Using Data Science For Heart Disease Prediction",
        "abstract": "Abstract: Technology has aided the improvement of individual health, healthcare, biomedical research as well as public health. Therefore, healthcare institutions are seeking to develop integrated information-management environments to consolidate the inevitable application of big data to health care. There exist various entry points into the medical world where computational tools assist patient care matters; reporting results of tests, allowing direct entry of orders or patient information by clinicians, facilitating access to transcribed reports, and in some cases supporting telemedicine applications, because of disorganized and incomplete patient records pose an obstacle to patient care. The most common medium by which records of medical history are kept is paper making data management a severe impediment to productivity. However, the promise of a more efficient healthcare service is obvious through the use of automated health records management systems. Heart disease is a common disease that is overlooked by most. In this study, we discuss how a person can figure out if they need to go to a doctor for a health check-up for any heart-related issues using machine learning algorithms. Keywords: Data Science, Statistics, Python, Data mining, Machine learning, Analytics, Big Data, Disease Prediction, Firebase, Supervised Learning, Unsupervised Learning, ElectrocardioGram(ECG).",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/bc59f0238387208e86dd27520f6b87445c411252",
        "citation_count": 0
    },
    {
        "title": "Artificial Intelligence as an Emerging Tool for Cardiologists",
        "abstract": ": In the world of data, there is an urgent need to \ufb01nd ways to extract knowledge and information for improving patient care. Arti\ufb01cial intelligence (AI) is an emerging tool that has the potential to provide cardiologists with new insights and knowledge. The healthcare industry has already begun the digital transformation of vast reams of data (Big Data) that are generated in routine clinical practice. AI has the potential to make a signi\ufb01cant impact on healthcare by improving the ef\ufb01ciency of clinical care, providing personalized treatment, and identifying new disease biomarkers. Machine learning (ML) and deep learning (DL) are AI techniques that utilize large datasets and computational power for analysis and decision making. There are three main ML techniques: supervised learning, unsupervised learning, and reinforcement learning. Another functional AI service that has been presented is natural language processing (NLP), and it is applicable for analyzing patient documentation. In this paper, the scope of AI work\ufb02ow, the most often used algorithms, and their performance metrics are explained. Explainable arti\ufb01cial intelligence (XAI) has a prominent potential to be a useful tool for clinicians as it provides full transparency into an AI model\u2019s decision-making process, but few applications have been reviewed. In this paper, the challenges and limitations of AI in cardiology are discussed in terms of ethical, methodological, and legal issues. Furthermore, the successful establishment of good practices toward the right development and deployment of automated ML-based systems will ensure a regulatory framework that can strengthen patients\u2019 trust in AI/ML-based clinical decision support systems.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bc5bccbbbb45ea89193e0f318e9733eeb5a6e307",
        "citation_count": 2
    },
    {
        "title": "SynSys: A Synthetic Data Generation System for Healthcare Applications",
        "abstract": "Creation of realistic synthetic behavior-based sensor data is an important aspect of testing machine learning techniques for healthcare applications. Many of the existing approaches for generating synthetic data are often limited in terms of complexity and realism. We introduce SynSys, a machine learning-based synthetic data generation method, to improve upon these limitations. We use this method to generate synthetic time series data that is composed of nested sequences using hidden Markov models and regression models which are initially trained on real datasets. We test our synthetic data generation technique on a real annotated smart home dataset. We use time series distance measures as a baseline to determine how realistic the generated data is compared to real data and demonstrate that SynSys produces more realistic data in terms of distance compared to random data generation, data from another home, and data from another time period. Finally, we apply our synthetic data generation technique to the problem of generating data when only a small amount of ground truth data is available. Using semi-supervised learning we demonstrate that SynSys is able to improve activity recognition accuracy compared to using the small amount of real data alone.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/bc639d6aad83e91f5e54eb4af83d20f7699428a9",
        "citation_count": 130
    },
    {
        "title": "PULSNAR - Positive unlabeled learning selected not at random: class proportion estimation when the SCAR assumption does not hold",
        "abstract": "Positive and Unlabeled (PU) learning is a type of semi-supervised binary classification where the machine learning algorithm differentiates between a set of positive instances (labeled) and a set of both positive and negative instances (unlabeled). PU learning has broad applications in settings where confirmed negatives are unavailable or difficult to obtain, and there is value in discovering positives among the unlabeled (e.g., viable drugs among untested compounds). Most PU learning algorithms make the selected completely at random (SCAR) assumption, namely that positives are selected independently of their features. However, in many real-world applications, such as healthcare, positives are not SCAR (e.g., severe cases are more likely to be diagnosed), leading to a poor estimate of the proportion, $\\alpha$, of positives among unlabeled examples and poor model calibration, resulting in an uncertain decision threshold for selecting positives. PU learning algorithms can estimate $\\alpha$ or the probability of an individual unlabeled instance being positive or both. We propose two PU learning algorithms to estimate $\\alpha$, calculate calibrated probabilities for PU instances, and improve classification metrics: i) PULSCAR (positive unlabeled learning selected completely at random), and ii) PULSNAR (positive unlabeled learning selected not at random). PULSNAR uses a divide-and-conquer approach that creates and solves several SCAR-like sub-problems using PULSCAR. In our experiments, PULSNAR outperformed state-of-the-art approaches on both synthetic and real-world benchmark datasets.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bc65190e23600b65718dd6217a8622544b383c5b",
        "citation_count": 3
    },
    {
        "title": "What Is the Accuracy of Three Different Machine Learning Techniques to Predict Clinical Outcomes After Shoulder Arthroplasty?",
        "abstract": "BACKGROUND\nMachine learning techniques can identify complex relationships in large healthcare datasets and build prediction models that better inform physicians in ways that can assist in patient treatment decision-making. In the domain of shoulder arthroplasty, machine learning appears to have the potential to anticipate patients' results after surgery, but this has not been well explored.\n\n\nQUESTIONS/PURPOSES\n(1) What is the accuracy of machine learning to predict the American Shoulder and Elbow Surgery (ASES), University of California Los Angeles (UCLA), Constant, global shoulder function, and VAS pain scores, as well as active abduction, forward flexion, and external rotation at 1 year, 2 to 3 years, 3 to 5 years, and more than 5 years after anatomic total shoulder arthroplasty (aTSA) or reverse total shoulder arthroplasty (rTSA)? (2) What is the accuracy of machine learning to identify whether a patient will achieve clinical improvement that exceeds the minimal clinically important difference (MCID) threshold for each outcome measure? (3) What is the accuracy of machine learning to identify whether a patient will achieve clinical improvement that exceeds the substantial clinical benefit threshold for each outcome measure?\n\n\nMETHODS\nA machine learning analysis was conducted on a database of 7811 patients undergoing shoulder arthroplasty of one prosthesis design to create predictive models for multiple clinical outcome measures. Excluding patients with revisions, fracture indications, and hemiarthroplasty resulted in 6210 eligible primary aTSA and rTSA patients, of whom 4782 patients with 11,198 postoperative follow-up visits had sufficient preoperative, intraoperative, and postoperative data to train and test the predictive models. Preoperative clinical data from 1895 primary aTSA patients and 2887 primary rTSA patients were analyzed using three commercially available supervised machine learning techniques: linear regression, XGBoost, and Wide and Deep, to train and test predictive models for the ASES, UCLA, Constant, global shoulder function, and VAS pain scores, as well as active abduction, forward flexion, and external rotation. Our primary study goal was to quantify the accuracy of three machine learning techniques to predict each outcome measure at multiple postoperative timepoints after aTSA and rTSA using the mean absolute error between the actual and predicted values. Our secondary study goals were to identify whether a patient would experience clinical improvement greater than the MCID and substantial clinical benefit anchor-based thresholds of patient satisfaction for each outcome measure as quantified by the model classification parameters of precision, recall, accuracy, and area under the receiver operating curve.\n\n\nRESULTS\nEach machine learning technique demonstrated similar accuracy to predict each outcome measure at each postoperative point for both aTSA and rTSA, though small differences in prediction accuracy were observed between techniques. Across all postsurgical timepoints, the Wide and Deep technique was associated with the smallest mean absolute error and predicted the postoperative ASES score to \u00b1 10.1 to 11.3 points, the UCLA score to \u00b1 2.5 to 3.4, the Constant score to \u00b1 7.3 to 7.9, the global shoulder function score to \u00b1 1.0 to 1.4, the VAS pain score to \u00b1 1.2 to 1.4, active abduction to \u00b1 18 to 21\u00b0, forward elevation to \u00b1 15 to 17\u00b0, and external rotation to \u00b1 10 to 12\u00b0. These models also accurately identified the patients who did and did not achieve clinical improvement that exceeded the MCID (93% to 99% accuracy for patient-reported outcome measures (PROMs) and 85% to 94% for pain, function, and ROM measures) and substantial clinical benefit (82% to 93% accuracy for PROMs and 78% to 90% for pain, function, and ROM measures) thresholds.\n\n\nCONCLUSIONS\nMachine learning techniques can use preoperative data to accurately predict clinical outcomes at multiple postoperative points after shoulder arthroplasty and accurately risk-stratify patients by preoperatively identifying who may and who may not achieve MCID and substantial clinical benefit improvement thresholds for each outcome measure.\n\n\nCLINICAL RELEVANCE\nThree different commercially available machine learning techniques were used to train and test models that predicted clinical outcomes after aTSA and rTSA; this device-type comparison was performed to demonstrate how predictive modeling techniques can be used in the near future to help answer unsolved clinical questions and augment decision-making to improve outcomes after shoulder arthroplasty.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/bc82d4deba752dc541eae57a998f2ab9181772ce",
        "citation_count": 42
    },
    {
        "title": "A Computational Analysis of Drug-Expanse Predictions from Biomaterials Using Ensemble Model for Healthcare Applications",
        "abstract": "The results of materials research laboratories' acquisition and evaluation of X-ray diffraction (XRD) data take a significant amount of time and include a lot of laborious and monotonous engineering through humans. To put this into perspective, a synopsis of the process of material synthesis that culminates in an investigation into the composition of the material can take several days to complete. This article explores an alternative approach that employs supervised learning algorithms based on ensemble-stacked neural network techniques. The method involves predicting the behavior of biomaterial granules incorporated with calcium phosphates (CaPs) as a matrix for carrying the anticancer drug carboplatin. The high-vacuum method is utilized for loading, and a set of five compositions is examined: hydroxyapatite (HA), $\\beta$ - tricalciumphosphate($\\beta$ - TCP), biphasicHAp(60% $\\beta$ - TCP, 40%HA), - $\\beta$ TC-$P$/MgOnanocomposite, and $\\beta$ TCP/SiO2. Additionally, the study investigates the deposition of the carboplatin drug on the CaPs' surface at concentrations of 50, 60, and 70 mg/g, applying various machine-learning techniques for analysis. The deep neural network model successfully predicted the delivery release of different NPs with different amounts of phosphorous and calcium in the drug, and it did better than the stacked neural network (SNN) model ways. The determination of the results with the dataset for the following drug release with different compositions was around 97%. This study presents a quantitative approach that can improve the prediction of the drug release efficacy of nanomedicine in a manner that is both accurate and efficient.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bca1e4597d82f1fecad10e46d20cac68a66630bf",
        "citation_count": 0
    },
    {
        "title": "Comparative Analysis of Life Expectancy between Developed and Developing Countries using Machine Learning",
        "abstract": "Life Expectancy is an important metric to assess the health of a nation. This paper presents a comparative analysis of life expectancy between developed and developing countries with the help of a Supervised Machine Learning model. The prediction model is trained using three regression models, namely Linear Regression, Decision Tree Regressor and Random Forest Regressor. The selection of model is done on the basis of R2 score, Mean Squared Error & Mean Absolute Error. Random Forest Regressor is selected for the development of the prediction model for life expectancy, as it had R2 score as 0.99 and 0.95 on training & testing data respectively, along with 4.43 and 1.58 as the Mean Squared Error & Mean Absolute Error. The comparative analysis is done on the basis of HIV/AIDS, Adult Mortality and Expenditure on Healthcare, as they are the important features suggested by the model. The study undertaken suggests that, developed countries have high life expectancy as compared to developing countries. India has high adult mortality as compared to considered developed countries because of the low expenditure on healthcare. The insights from this analysis can be used by Government and Healthcare sectors for the betterment of society.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/bd1aee016f77f3cdb4f267164b0457ab85e32ac3",
        "citation_count": 7
    },
    {
        "title": "Enhancing Cardiac Arrhythmia Detection in WBAN Sensors Through Supervised Machine Learning and Data Dimensionality Reduction Techniques",
        "abstract": "In recent years, the global medical community has endeavored to provide swift and efficient patient care by leveraging real-time patient databases. However, the efficacy of these systems, particularly wireless body area network (WBAN) sensors, has been undermined by inaccurate and low-performance readings, leading to unnecessary alarm triggers. This study scrutinizes the potential of data dimensionality reduction techniques and machine learning algorithms in augmenting the detection accuracy of cardiac abnormalities in WBAN sensors. Dimensionality reduction was performed using principal component analysis (PCA), independent component analysis (ICA), and spatial correlation methods. For arrhythmia prediction, Decision Tree and Multilayer Perceptron algorithms were implemented and their performance compared. Numerical simulations and Python code analysis revealed that the application of data reduction techniques significantly improved the reliability and effectiveness of WBAN sensors in handling voluminous datasets. Furthermore, the use of PCA, ICA, and spatial correlation strategies notably reduced WBAN sensor battery energy consumption, data storage needs, computational complexity, and processing time. These pragmatic solutions could potentially empower healthcare practitioners to intervene proactively before patients encounter life-threatening conditions. The results also demonstrated that feature selection effectively eliminated irrelevant attributes from noisy Electrocardiograms (ECGs), thereby enhancing the precision of the analyses.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bd64f148cedc369263213cc923b469c31b95b324",
        "citation_count": 2
    },
    {
        "title": "Detecting Subclinical Social Anxiety Using Physiological Data from a Wrist-worn Wearable: A Small-Scale Feasibility Study (Preprint)",
        "abstract": "\n BACKGROUND\n Subclinical (i.e., threshold) social anxiety can greatly affect young people\u2019s lives, but existing solutions appear inadequate considering its rising prevalence. Wearable sensors may provide a novel way to detect social anxiety and result in new opportunities for monitoring and treatment that would be greatly beneficial for sufferers, society and healthcare services. Nevertheless, indicators such as skin temperature from wrist-worn sensors have not been used in prior work on physiological social anxiety detection.\n \n \n OBJECTIVE\n This study aimed to investigate whether subclinical social anxiety in young adults can be detected using physiological data obtained from wearable sensors, including Heart Rate (HR), Skin Temperature (ST) and Electrodermal Activity (EDA).\n \n \n METHODS\n Young adults (N = 12) with self-reported subclinical social anxiety (measured by the widely used self-reported version of the Liebowitz Social Anxiety Scale, LSAS-SR) participated in an impromptu speech task. Physiological data was collected using an E4 Empatica wearable device. Using the pre-processed data and following a supervised machine learning approach, various classification algorithms such as Support Vector Machine (SVM), Decision Tree, Random Forest and K-Nearest Neighbours (KNN) were used to develop models for three different contexts. Models were trained to (1) classify between baseline and socially anxious states, (2) differentiate between baseline, anticipation anxiety and reactive anxiety states, and (3) classify between social anxiety experienced by individuals with differing social anxiety severity. The predictive capability of the singular modalities was also explored in each of the three supervised learning experiments. The generalisability of the developed models was evaluated using 10-fold cross validation as a performance index.\n \n \n RESULTS\n With modalities combined, the developed models yielded accuracies between 97.54% and 99.48% when detecting between baseline and socially anxious states. Models trained to differentiate between baseline, anticipation anxiety and reactive anxiety states yielded accuracies between 95.18% and 98.10%. Alongside this, the models developed to detect between social anxiety experienced by individuals with differing anxiety severity scores successfully classified with accuracies between 98.86% and 99.52%. Surprisingly, EDA was identified as the most effective singular modality when differentiating between baseline and social anxiety states, whereas ST was the most effective modality when differentiating between anxiety experienced by individuals with differing social anxiety severity.\n \n \n CONCLUSIONS\n The results indicate that it is possible to accurately detect social anxiety as well as distinguish between levels of severity in young adults by leveraging physiological data collected from wearable sensors.\n",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/bd81c05ad7bae92ca903143dc8fc0732b4c337a7",
        "citation_count": 1
    },
    {
        "title": "Post-COVID Cardiovascular Risk Assessment Using an Efficient Machine Learning Model",
        "abstract": "Individuals who were exposed to COVID-19 in different parts of their bodies, including heart attacks, faced major consequences. The frequency of cardiovascular diseases is increasing in the healthcare industry. This illness most commonly affects people aged 20 to 48. In supervised learning, data mining mainly depends on categorization algorithms. Using various combinations of calculations and algorithms, the information obtained from hospital data analysis is used for early-stage prediction of post-Covid cardiovascular disease. Machine learning is one of the strange inventions that have been widely used in a variety of fields, including the application of medical services to disease prediction. We examined the accuracy of machine learning algorithms that can be used in this study to predict heart disease analyzes and predict overall risk. One of the most current data mining methods is classification. The classification method\u2019s primary goal is to keep the data in the correct class. In this work, classification methods such as Logistic Regression Classifier, Naive-Bayes, and Ensemble Cardiovascular Prediction Classification Algorithm were used (ECVDPCA) and the dataset is taken from Kaggle repository. The goal of this study is to find the most exact classification approach and to improve accuracy in predicting Post-Covid Cardio-Vascular illness. Python was used to get the ideal solution in this case to predict the accuracy of the classifier in which the proposed classifier gave the best accuracy when compared with the other two classifiers i.e., 95",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/be32847762b4e7c0bce5a061bb0faed6ef47169f",
        "citation_count": 0
    },
    {
        "title": "New Trends in Applied Artificial Intelligence, 20th International Conference on Industrial, Engineering and Other Applications of Applied Intelligent Systems, IEA/AIE 2007, Kyoto, Japan, June 26-29, 2007, Proceedings",
        "abstract": null,
        "year": 2007,
        "url": "https://www.semanticscholar.org/paper/be43803704936febcf16f70cfa177223cb94ebc6",
        "citation_count": 2
    },
    {
        "title": "Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models",
        "abstract": "Alzheimer's disease (AD) is the fifth-leading cause of death among Americans aged 65 and older. Screening and early detection of AD and related dementias (ADRD) are critical for timely intervention and for identifying clinical trial participants. The widespread adoption of electronic health records (EHRs) offers an important resource for developing ADRD screening tools such as machine learning based predictive models. Recent advancements in large language models (LLMs) demonstrate their unprecedented capability of encoding knowledge and performing reasoning, which offers them strong potential for enhancing risk prediction. This paper proposes a novel pipeline that augments risk prediction by leveraging the few-shot inference power of LLMs to make predictions on cases where traditional supervised learning methods (SLs) may not excel. Specifically, we develop a collaborative pipeline that combines SLs and LLMs via a confidence-driven decision-making mechanism, leveraging the strengths of SLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this pipeline using a real-world EHR data warehouse from Oregon Health \\&Science University (OHSU) Hospital, encompassing EHRs from over 2.5 million patients and more than 20 million patient encounters. Our results show that our proposed approach effectively combines the power of SLs and LLMs, offering significant improvements in predictive performance. This advancement holds promise for revolutionizing ADRD screening and early detection practices, with potential implications for better strategies of patient management and thus improving healthcare.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/be446890b5f7abaded0b2d5b6b2e349cd62c50d0",
        "citation_count": 1
    },
    {
        "title": "Artificial Intelligence Applications in Fraud Detection and Prevention: Emerging Opportunities",
        "abstract": "In today's digital landscape, technology plays a central role in nearly every aspect of business, including supply chain management, manufacturing, sales, marketing, and finance. However, the increasing reliance on digitisation has made organisations across various sectors more vulnerable to fraud. As businesses adopt technology to enhance efficiency, their exposure to these risks grows, necessitating the protection of intellectual property, business data, consumer information, and more. Recently, Artificial Intelligence (AI) and Machine Learning (ML) have emerged as promising tools for detecting and preventing fraud. This article explores the potential of AI and ML to collaborate with both supervised and unsupervised systems to better address security risks. By analysing financial transactions, customer behaviour, and real-time traffic, these technologies can detect anomalies and raise alerts for suspected fraud. This study investigates the fraud detection and prevention capabilities of AI applications in the e-commerce, healthcare, and tourism sectors. Data is collected and analysed to provide meaningful insights into the managerial factors influencing various AI applications in fraud detection and prevention. The analysis of different AI applications and software, focusing on their technological models, key features, and industry use, demonstrates that tech developers have successfully integrated fraud monitoring and detection systems. Furthermore, these applications could be adapted for use in other sectors to address critical security infrastructure gaps. The survey results also strongly indicate that while organisational strategy, structure, resources, and trust support the implementation of AI, broader environmental factors such as organisational culture may significantly affect the effectiveness of AI in fraud detection and prevention.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/be4f4e9fac747af5c43866640078c68f101638f6",
        "citation_count": 0
    },
    {
        "title": "Utilizing Machine Learning for Context-Aware Digital Biomarker of Stress in Older Adults",
        "abstract": "Identifying stress in older adults is a crucial field of research in health and well-being. This allows us to take timely preventive measures that can help save lives. That is why a nonobtrusive way of accurate and precise stress detection is necessary. Researchers have proposed many statistical measurements to associate stress with sensor readings from digital biomarkers. With the recent progress of Artificial Intelligence in the healthcare domain, the application of machine learning is showing promising results in stress detection. Still, the viability of machine learning for digital biomarkers of stress is under-explored. In this work, we first investigate the performance of a supervised machine learning algorithm (Random Forest) with manual feature engineering for stress detection with contextual information. The concentration of salivary cortisol was used as the golden standard here. Our framework categorizes stress into No Stress, Low Stress, and High Stress by analyzing digital biomarkers gathered from wearable sensors. We also provide a thorough knowledge of stress in older adults by combining physiological data obtained from wearable sensors with contextual clues from a stress protocol. Our context-aware machine learning model, using sensor fusion, achieved a macroaverage F-1 score of 0.937 and an accuracy of 92.48% in identifying three stress levels. We further extend our work to get rid of the burden of manual feature engineering. We explore Convolutional Neural Network (CNN)-based feature encoder and cortisol biomarkers to detect stress using contextual information. We provide an in-depth look at the CNN-based feature encoder, which effectively separates useful features from physiological inputs. Both of our proposed frameworks, i.e., Random Forest with engineered features and a Fully Connected Network with CNN-based features validate that the integration of digital biomarkers of stress can provide more insight into the stress response even without any self-reporting or caregiver labels. Our method with sensor fusion shows an accuracy and F-1 score of 83.7797% and 0.7552, respectively, without context and 96.7525% accuracy and 0.9745 F-1 score with context, which also constitutes a 4% increase in accuracy and a 0.4 increase in F-1 score from RF.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/be6a1b20babf84d8d70ff30ba65b149b860e18d4",
        "citation_count": 5
    },
    {
        "title": "A review on different techniques used to combat the non-IID and heterogeneous nature of data in FL",
        "abstract": "Federated Learning (FL) is a machine-learning approach enabling collaborative model training across multiple decentralized edge devices that hold local data samples, all without exchanging these samples. This collaborative process occurs under the supervision of a central server orchestrating the training or via a peer-to-peer network. The significance of FL is particularly pronounced in industries such as healthcare and finance, where data privacy holds paramount importance. However, training a model under the Federated learning setting brings forth several challenges, with one of the most prominent being the heterogeneity of data distribution among the edge devices. The data is typically non-independently and non-identically distributed (non-IID), thereby presenting challenges to model convergence. This report delves into the issues arising from non-IID and heterogeneous data and explores current algorithms designed to address these challenges.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/be875b4a0297266ce7f1a8150cf04df6132f57e7",
        "citation_count": 5
    },
    {
        "title": "Hidden Effects of COVID-19 on Healthcare Workers: A Machine Learning Analysis",
        "abstract": "In this paper, we analyze some effects of the COVID-19 pandemic on healthcare workers. We specifically focus on alcohol consumption habit changes among healthcare workers using a mental health survey data obtained from the University of Michigan Inter-University Consortium for Political and Social Research. We use supervised and unsupervised machine learning methods and models such as Decision Trees, Logistic Regression, Naive Bayes classifier, k-Nearest Neighbors, Support Vector Machines, Multilayer perceptron, Random Forests, XGBoost, CatBoost, LightGBM, Synthetic Minority Oversampling, Chi-Squared Test and mutual information method to find out relationships between COVID-19 related negative effects and alcohol use changes in healthcare workers. Our findings suggest that some effects of the COVID-19 pandemic such as school closure, work schedule change and COVID-related news exposure may lead to an increase in alcohol use.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/be9b83a1526c70cba37e68445b4f1382d5559340",
        "citation_count": 2
    },
    {
        "title": "Analyzing the Interactions between Environmental Parameters and Cardiovascular Diseases Using Random Forest and SHAP Algorithms",
        "abstract": "Background: Cardiovascular diseases (CVD) remain the predominant global cause of mortality, with both low and high temperatures increasing CVD-related mortalities. Climate change impacts human health directly through temperature fluctuations and indirectly via factors like disease vectors. Elevated and reduced temperatures have been linked to increases in CVD-related hospitalizations and mortality, with various studies worldwide confirming the significant health implications of temperature variations and air pollution on cardiovascular outcomes. Methods: A database of daily Emergency Room admissions at the Giovanni XIII Polyclinic in Bari (Southern Italy) was developed, spanning from 2013 to 2019, including weather and air quality data. A Random Forest (RF) supervised machine learning model was used to simulate the trend of hospital admissions for CVD. The Seasonal and Trend decomposition using Loess (STL) decomposition model separated the trend component, while cross-validation techniques were employed to prevent overfitting. Model performance was assessed using specific metrics and error analysis. Additionally, the SHapley Additive exPlanations (SHAP) method, a feature importance technique within the eXplainable Artificial Intelligence (XAI) framework, was used to identify the feature importance. Results: An R2 of 0.97 and a Mean Absolute Error of 0.36 admissions were achieved by the model. Atmospheric pressure, minimum temperature, and carbon monoxide were found to collectively contribute about 74% to the model\u2019s predictive power, with atmospheric pressure being the dominant factor at 37%. Conclusions: This research underscores the significant influence of weather-climate variables on cardiovascular diseases. The identified key climate factors provide a practical framework for policymakers and healthcare professionals to mitigate the adverse effects of climate change on CVD and devise preventive strategies.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/beb5eeeb5273fa32350fc011623d51744d60d6ba",
        "citation_count": 2
    },
    {
        "title": "Early Detection of Chronic Kidney Disease Using a Machine learning Approach for Better Results",
        "abstract": "Chronic Kidney Disease has also become one of the serious public health threats worldwide because of its chronic nature and potential progression to End-Stage Renal Disease if left untreated or undiagnosed. This paper aims to utilize machine learning techniques for the early detection of CKD using algorithms such as KNeighborsClassifier, Gaussian Naive Bayes, Support Vector Machine, and Random Forest. Models applied to a data set that contains clinical attributes such as age, blood pressure, and albumin levels after preprocessing for data quality normalization, feature selection, and outlier management. The performance metrics of the developed models were based on the accuracy, precision, recall, and F1 score; Random Forest has the highest diagnostic accuracy at 98.06%. The results show that machine learning models, in this case, Random Forest, are useful for prediction of CKD and may support non-invasive, low-cost early detection in clinical practice. Future work will focus on ensemble and deep learning approaches in order to enhance the robustness of models and their applicability in healthcare.\n\nIndex Terms\u2014Chronic kidney disease , Machine Learning\n\n,KNeighborsClassifier, Support vector machine, Health Infor- matics, Supervised Learning, Medical Data Preprocessing, Early Disease Detection.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/bebe5ca43a234cc707382d6b5e47ea446f25d771",
        "citation_count": 0
    },
    {
        "title": "Machine learning-based analytics of the impact of the Covid-19 pandemic on alcohol consumption habit changes among United States healthcare workers",
        "abstract": null,
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/beeadfaebf3116dfda72072e9c533f5336d5a41f",
        "citation_count": 7
    },
    {
        "title": "Early diabetes risk classification using supervised learning algorithms",
        "abstract": "Diabetes is one of the most devastating diseases and affects many people. Diabetes can be caused by a variety of causes, including ageing, obesity, inactivity, genetics, a poor diet, high blood pressure, and others. Diabetes increases the likelihood of developing several illnesses, including heart disease, renal disease, stroke, eye problems, nerve damage, etc. The information needed to diagnose diabetes is currently gathered through a variety of tests used in hospitals, and the diagnosis is then used to determine the best course of treatment. The healthcare sector has a considerable application for machine learning (ML). Databases in the healthcare sector are very vast. Big datasets can be examined using ML techniques to find hidden information and patterns, allowing one to learn from the data and predict outcomes properly. Using the existing methods, the forecast\u2019s accuracy is not very good. In this study, we proposed an early diabetes prediction model that incorporates several extrinsic characteristics that contribute to the development of diabetes together with more widely used measures like polyuria, weight loss, polyphagia, visual blurring, alopecia, obesity, etc. The Support Vector Machine (SVM), the Logistic Regression (LOR), the Boosted Tree (BOT), and the Bagged Tree (BAT) are four different classifiers that are utilized in this paper to predict diabetes early on. The device\u2019s performance is assessed in terms of accuracy, recall, specificity, precision, and f-measure. Results show that among the classifiers, BAT has the highest accuracy, at 98%.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/bf0f0c1a09d91beba120ece89b49ec2f7cea9fd1",
        "citation_count": 1
    },
    {
        "title": "Transforming self-reported outcomes from a stroke register to the modified Rankin Scale: a cross-sectional, explorative study",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/bf697f5b989a62f71cb7ea6b4282c225df51934a",
        "citation_count": 6
    },
    {
        "title": "Predictive analysis and supervised detection for fraudulent cases in healthcare",
        "abstract": "Healthcare is perhaps one of the most crucial industry for humanity and it has been, and it will always be a growing industry. This increases the risk of being exploited. In our paper, we performed and analyzed different trends for the suspicious/fraudulent medical activities. We categorized different groups of patients involved and analyzed their distribution on the basis of multiple factors. Healthcare is a massive and widely distributed sector with a numerous entities and stakeholders involved. Limited connectivity within these distributed management create various loopholes that people try to exploit. We performed multiple analysis for suspicious and fraudulent activities in the healthcare/Medicare industry and tried to look for popular trends people opt to exploit the system. We also tried various supervised machine learning algorithms to see how they behave with our dataset and what is the accuracy of their detection. This can be helpful in choosing the best model while building a solution to deal with various use cases involved in fraudulent activity detection. Healthcare is one of the sectors that will always be relevant to living beings and should be taken special care of.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/bf6b4ee3f5656c984475b7425a8b32823e8e8745",
        "citation_count": 0
    },
    {
        "title": "Weakly Supervised Classification of Vital Sign Alerts as Real or Artifact",
        "abstract": "A significant proportion of clinical physiologic monitoring alarms are false. This often leads to alarm fatigue in clinical personnel, inevitably compromising patient safety. To combat this issue, researchers have attempted to build Machine Learning (ML) models capable of accurately adjudicating Vital Sign (VS) alerts raised at the bedside of hemodynamically monitored patients as real or artifact. Previous studies have utilized supervised ML techniques that require substantial amounts of hand-labeled data. However, manually harvesting such data can be costly, time-consuming, and mundane, and is a key factor limiting the widespread adoption of ML in healthcare (HC). Instead, we explore the use of multiple, individually imperfect heuristics to automatically assign probabilistic labels to unlabeled training data using weak supervision. Our weakly supervised models perform competitively with traditional supervised techniques and require less involvement from domain experts, demonstrating their use as efficient and practical alternatives to supervised learning in HC applications of ML.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/bf6f05d4b3a58d34dd2c52b36bc0e0f1cbb23827",
        "citation_count": 1
    },
    {
        "title": "Extraction of Features from Lung Image for the Detection of Covid-19",
        "abstract": "The World Health Organization has identified two new human cases of Coronavirus type 2 (CoV-2)-induced severe acute respiratory syndrome and a new pandemic illness known as coronavirus disease (COVID-19). It was initially discovered in Wuhan, China, in December 2019, and afterwards spread widely. The novel COVID-19 continues to increase with confirmed cases that may result in deaths worldwide as a result of respiratory failure and alveolar damage. The common symptoms of SARS- CoV- include dyspnea, chest pain, fatigue and less common symptoms include headache, vomiting and nausea. The diagnosis of SARS-CoV2 infection was the key step to identify the infection and then prevention and quarantine are next steps to be considered as the way to stop the spreading of virus, since there is no specific vaccine, drugs or antiviral against the COVID-19 virus. The patients with COVID-19 are helped with oxygen therapy and antivirals like Lopinavir, Ritonavir, Ribavirin and Favipiravir are currently used. The essential way to control and reduce the human transmission of the virus is by implementing the precautionary steps and hygienic measures. Machine learning technologies were used by healthcare organizations and medical professionals all around the world to combat the pandemic by lowering the need for human intervention and enhancing the pandemic medication development process\u2019s screening, prediction, and forecasting capabilities. One method for finding the COVID-19 is X-ray imaging. We provide a supervised machine learning method in this study for identifying and categorizing COVID-19 infection from x-ray pictures. It is less necessary to manually label x-ray pictures when COVID-19 cases can be accurately detected and distinguished from non-COVID-19 instances. Performance metrics including Accuracy, Sensitivity, Specificity, F1-score, and Positive Predictive Value (PPV) are then used to assess the outcomes.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c009b5e4e623fb6696ae3b5a79a667153320de4c",
        "citation_count": 0
    },
    {
        "title": "Predicting Healthcare-Associated Infections at Admission: Implications for Nursing Care.",
        "abstract": "BACKGROUND\nAccurate, real-time models to predict hospital adverse events could facilitate timely and targeted interventions to improve patient outcomes. Advances in computing enable the use of supervised machine learning (SML) techniques to predict hospital-onset infections.\n\n\nOBJECTIVES\nThe purpose of this study was to trial SML methods to predict urinary tract infections (UTI) during inpatient hospitalization at the time of admission.\n\n\nMETHOD\nIn a large cohort of adult hospitalizations in three New York City acute care facilities (N = 897,344), we used two SML methods-neural networks and decision trees-to predict having a hospital-onset UTI using data available and accessible on the first day of admission at healthcare facilities in the United States.\n\n\nRESULTS\nPerformance for both neural network and decision tree models were superior compared to logistic regression methods. The decision tree model had a higher sensitivity compared to neural network but a lower specificity.\n\n\nDISCUSSION\nSML methods show potential for automated accurate UTI risk stratification using electronic data routinely available at admission; this could relieve nurses from the burden of having to complete and document additional risk assessment forms in the electronic medical record. Future studies should pilot and test interventions linked to the risk stratification results, such as short nursing educational modules or alerts triggered for high-risk patients.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c02c82563f392ca42b67e5ce5d45e350f05739c3",
        "citation_count": 6
    },
    {
        "title": "Optimizing Tuberculosis Treatment Predictions: A Comparative Study of XGBoost with Hyperparameter in Penang, Malaysia",
        "abstract": "The bacterium Mycobacterium tuberculosis causes a viral infection affecting the lungs and liver. Tuberculosis (TB) is a significant public health concern in developing countries, where it is often associated with poverty, poor living conditions, and limited access to healthcare services. According to the World Health Organization (2023), Tuberculosis continues to pose a substantial risk to public health on a global scale, with millions of people affected each year and around 1.5 million deaths in 2020. Healthcare providers often encounter significant challenges in addressing TB, leading to uncertain treatment outcomes. This study introduces a novel method for enhancing TB treatment using sophisticated machine learning techniques, particularly emphasizing the application of XGBoost and various predictive models in Penang State, Malaysia, to predict individual treatment outcomes based on clinical data. The models were trained using 2017 Penang data. Comparing predicted accuracy helps establish the optimum method. Clinical data was anonymized and analyzed. Decision tree accuracy is 63.7% using 2017 data. Logistic Regression is 63.3% accurate, while XGBoost is 66.3%. Hyperparameter-tuned XGBoost performs best at 68.1%. Comparing observed and expected results determines accuracy. TB result predictions are accurate using supervised learning. Calibrated ensemble models like XGBoost makes reliable predictions. Additional clinical characteristics may improve forecasts. The primary objective was to develop a reliable, clinically validated instrument that enhances TB treatments while optimizing resource efficiency across diverse healthcare environments.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/c070f39a01e5c950c21949a51423b6b9498b9a05",
        "citation_count": 0
    },
    {
        "title": "A Comparative Analysis of Machine Learning Algorithms for Big Data Applications in Predictive Analytics",
        "abstract": "As the volume and complexity of data continue to grow, predictive analytics has emerged as a vital tool for extracting actionable insights from big data, driving decision-making across various domains such as healthcare, finance, and e-commerce. However, selecting an appropriate machine learning algorithm for predictive analytics applications is challenging due to differences in algorithmic performance, computational requirements, and scalability, especially in the context of big data. This paper provides a comprehensive comparative analysis of popular machine learning algorithms utilized in predictive analytics, specifically focusing on their effectiveness and feasibility in big data environments.\nThe study categorizes algorithms based on learning types\u2014supervised, unsupervised, and reinforcement learning\u2014and evaluates their performance across multiple dimensions: prediction accuracy, computational efficiency, scalability, and suitability for real-time analytics. Through a detailed analysis of algorithms, including linear regression, decision trees, support vector machines, neural networks, and clustering techniques, we assess each method\u2019s strengths and limitations in handling large datasets. Additionally, the study introduces a series of metrics, such as accuracy, F1-score, and training time, as benchmarks for assessing the algorithms\u2019 predictive capabilities and computational viability.\nA hypothetical case study demonstrates the application of these algorithms on a sample big data set, providing insights into their real-world performance across different predictive analytics scenarios. Visual data representations, including comparative tables and performance graphs, offer a clearer perspective on the trade-offs among algorithm choices. The findings highlight that while certain algorithms like random forests and neural networks achieve higher accuracy in prediction tasks, they may also require substantial computational resources, posing limitations for real-time processing in big data applications.\nThis paper concludes with recommendations for selecting machine learning algorithms based on specific predictive analytics objectives, data characteristics, and processing requirements. Furthermore, it discusses the challenges associated with implementing these algorithms in big data contexts and explores potential advancements, such as the integration of deep learning and the use of distributed computing, as promising directions for enhancing predictive analytics performance in future applications.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c0821040527862862526fd266c6ac72ce9df91e1",
        "citation_count": 1
    },
    {
        "title": "Enhancing Hospitalized Patients' Palliative Care Referrals via Machine Learning-Based Predictive Modeling within Electronic Health Record Systems",
        "abstract": "Abstract Access to palliative care (PC) holds significance for hospital-admitted patients grappling with the symptoms of life limiting illnesses. Nonetheless, numerous such patients who could gain from PC fail to receive it promptly or even at all. We can leverage the prior year's historical data extracted from electronic health records of hospitalized patients to train a machine learning (ML) model. This model's purpose would be to prognosticate the requirement for PC consultation using real-time data. The model, operating as a semi-supervised system, will be integrated into institutional data pipelines, and utilized by a downstream display application overseen by the PC team. In cases where the PC team deems it suitable, a team member will communicate with the respective care team of the patient. The ML model's training efficacy will be assessed using the area under the curve (AUC) metric, employing a 20% reserved validation set. The threshold for PC consultations will be grounded in historical data. To enhance the ML model's precision, the pivotal variables within the model will be pinpointed, and any sources of biases or errors in the model will be identified for meticulous refinement. The AUC values of successive ML models will be juxtaposed with cross-validation data. Automatizing the referral procedure through electronic health record systems has the potential to usher in a more effective and streamlined approach to healthcare delivery.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c09d5c7d7be80af6da13b3910459a606bc90d910",
        "citation_count": 0
    },
    {
        "title": "A Brief History of Machine Learning in Neurosurgery.",
        "abstract": null,
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c0bac27ef3093e1b9fed2bd3014febb32dce71da",
        "citation_count": 32
    },
    {
        "title": "Abstract PO1-28-06: Development of a plasma-based real-time qPCR gene expression assay for targeted screening and diagnosis of early-stage breast cancer",
        "abstract": "\n Background Over 12 million US women undergo follow-up breast imaging and exams annually due to breast cancer suspicions, incurring an $8 billion total cost, of which $2.18 billion is attributed to false-positive breast biopsies. Recent updates published to the Mammography Quality Standards Act (MQSA) now recommend supplemental imaging for women with heterogeneously dense and extremely dense breasts, regardless of suspicious findings. Given sensitivity limitations associated with mammography in dense-breasted women, as low as 30-47%, and non-specificity associated with ultrasound and MRI, these recent recommendations are likely to further strain the healthcare system and place substantial burden on patients and providers. With an estimated 25 million dense-breasted women who regularly screen for breast cancer now considered at-risk, there is a critical need for affordable and highly accurate testing, offering better specificity without sacrificing sensitivity. To address this gap, we developed an affordable and accurate plasma-based gene expression assay using real-time qPCR for targeted screening and diagnosis of early-stage breast cancer. Methods In previous studies, 26 cross-correlated mRNA gene targets were discovered and independently validated for non-invasive breast cancer detection across five independent patient cohorts using microarray gene expression profiling, comprised of peripheral blood mononuclear cells (n=337) and saliva (n=20), demonstrating strong efficacy, reproducibility, and concordance across bio-fluids and assay platforms in all studies. A sixth independent validation cohort comprised of 203 plasma samples was subsequently obtained for real-time qPCR clinical assay development and validation in our CLIA laboratory. The CLIA validation cohort was designed to be representative of different diagnosis status, stage, and ethnicity, and included Caucasian, Black/African American, Hispanic, and Asian women. After normalizing mRNA expression and clustering analysis, the signature was refined to 8 target genes and was assessed in a cohort of 87 plasma samples [Table 1] to verify the assay\u2019s diagnostic performance for stage I breast cancer detection, under locked laboratory protocols. We leveraged machine learning methods derived from XGBoost classification, a supervised-learning algorithm that uses sequentially built shallow decision trees to provide accurate results and avoidance of overfitting. Results The XGBoost model, selecting from the 8 mRNA gene targets and patient age, achieved >99% sensitivity, 89% specificity for stage I breast cancer detection in the held-out test set, with an overall diagnostic accuracy of 94.5%. Normalized data showed significant differences in gene expression between healthy controls and stage I patients, and distinct clustering was observed for the 8 mRNA gene signature, including patient age. Conclusions Our plasma-based real-time qPCR gene expression clinical assay, with machine learning, is positioned as a highly accurate non-invasive tool for targeted screening and diagnosis of early-stage breast cancer. Furthermore, a clinically validated assay in this space addresses the need for more targeted diagnostics, while serving as a promising tool for clinicians as they make critical care decisions across the breast health continuum, accelerating time to earlier and more precise intervention and treatment, mitigating unnecessary healthcare expenditures, and reducing the mental, emotional, and financial burden on patients and their families.\n \n Citation Format: Martin Keiser, Elizabeth Cormier-May, Matthew Alderdice, Joy Kavanagh, William Guesdon, Heather Healy, Nathalie Jean-Charles, Jay Harness. Development of a plasma-based real-time qPCR gene expression assay for targeted screening and diagnosis of early-stage breast cancer [abstract]. In: Proceedings of the 2023 San Antonio Breast Cancer Symposium; 2023 Dec 5-9; San Antonio, TX. Philadelphia (PA): AACR; Cancer Res 2024;84(9 Suppl):Abstract nr PO1-28-06.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c0cc17bd2435080db86f01f5716c036042cd4d86",
        "citation_count": 0
    },
    {
        "title": "Cardiac ailment recognition using ML techniques in E-healthcare",
        "abstract": "Heart ailments can take numerous forms, and they are frequently referred to as cardio vascular illnesses. These can range from heart rhythm problems to birth anomalies to blood vessel disorders. It has been the main cause of death worldwide for several decades. To recognize the illness early and properly manage, it is critical to discover a precise and trustworthy approach for automating the process. Processing massive amounts of data in the field of medical sciences necessitates the application of data science. Here we employ a range of machine learning approaches to examine enormous data sets and aid in the accurate prediction of cardiac diseases. This paper explores the supervised learning models of Naive Bayes, Support Vector Machine, K-Nearest Neighbors, Decision Tree, in order to provide a comparison investigation for the most effective method. When compared to other algorithms, K-Nearest Neighbor provides the best accuracy at 86.89%.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/c104744de9b899d054d794f633758117bd103b78",
        "citation_count": 0
    },
    {
        "title": "Performance evaluation of Machine Learning models to predict heart attack",
        "abstract": "Coronary Artery Disease is the type of cardiovascular disease (CVD) that happens when the blood vessels which stream the blood toward the heart, either become tapered or blocked. Of this, the heart is incapable to push sufficient blood to encounter its requirements. This would lead to angina (chest pain). CVDs are the leading cause of mortality worldwide. According to WHO, in the year 2019 17.9 million people deceased from CVD. Machine Learning is a type of artificial intelligence that uses algorithms to help analyse large datasets more efficiently. It can be used in medical research to help process large amounts of data quickly, such as patient records or medical images. By using Machine Learning techniques and methods, scientists can automate the analysis of complex and large datasets to gain deeper insights into the data. Machine Learning is a type of technology that helps with gathering data and understanding patterns. Recently, researchers in the healthcare industry have been using Machine Learning techniques to assist with diagnosing heart-related diseases. This means that the professionals involved in the diagnosis process can use Machine Learning to help them figure out what is wrong with a patient and provide appropriate treatment. This paper evaluates different machine learning models performances. The Supervised Learning algorithms are used commonly in Machine Learning which means that the training is done using labelled data, belonging to a particular classification. Such classification methods like Random Forest, Decision Tree, K-Nearest Neighbour, XGBoost algorithm, Naive Bayes, and Support Vector Machine will be used to assess the cardiovascular disease by Machine Learning.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/c15e711cbfb004c5eae250682a4f4584ca0cc80a",
        "citation_count": 1
    },
    {
        "title": "Comparative Analysis of Machine Learning Algorithms for Heart Disease Prediction",
        "abstract": "In the last few years, cardiovascular diseases have emerged as one of the most common causes of deaths worldwide. The lifestyle changes, eating habits, working cultures etc, has significantly contributed to this alarming issue across the globe including the developed, underdeveloped and developing nations. Early detection of the initial signs of cardiovascular diseases and the continuous medical supervision can help in reducing rising number of patients and eventually the mortality rate. However with limited medical facilities and specialist doctors, it is difficult to continuously monitor the patients and provide consultations. Technological interventions are required to facilitate the patient monitoring and treatment. The healthcare data generated through various medical procedures and continuous patient monitoring can be utilized to develop efficient prediction models for cardiovascular diseases. The early prognosis of cardiovascular illnesses can aid in making decisions on life-style changes in high hazard sufferers and in turn lessen the complications, which may be an outstanding milestone inside the field of medicine. This paper studies some of the most widely used machine learning algorithms for heart disease prediction by using the medical data and historical information. The various techniques are discussed and a comparative analysis of the same is presented. This report compares five common strategies for predicting the chance of heart attack that have been published in the literature. KNN, Decision Tree, Gaussian Naive Bayes, Logistic Regression, and Random Forest are some of the approaches used. Further, the paper also highlights the advantages and disadvantages of using the various techniques for developing the prediction models.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c17b3c3d607d34cd5b19b687310e6d77ed6b21c0",
        "citation_count": 12
    },
    {
        "title": "Decoding the Future: A Comprehensive Review of Machine Learning Innovations and Applications",
        "abstract": "Abstract: In the current scenario of the 4th Industrial Revolution (4IR or Industry 4.0), the digital world is a full of data, such as Internet of Things (IoT) data, business data, mobile data, cyber security data, social media data, etc. To intelligently analyze these data and develop the corresponding smart and automated applications, the knowledge of artificial intelligence (AI), particularly, machine learning (ML) is the key. Supervised, unsupervised, semi-supervised and reinforcement learning are the different types of machine learning algorithms. In addition to the deep learning is part of a broader family of machine learning methods that can wisely analyze the data on a large scale. This study's primary contribution is its explanation of the fundamentals of numerous machine learning techniques and how they can be applied in a wide range of real-world application areas, including e-commerce, cyber security systems, smart cities, healthcare, and agriculture, among many others. The main use of machine learning is to show off its potential for generating consistently accurate estimations. This review paper's primary objective is to give an overview of machine learning and provide machine learning approaches",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c183c9327083f918a435e2b5784c224e543d8519",
        "citation_count": 0
    },
    {
        "title": "Coping with Mistreatment in Fair Algorithms",
        "abstract": "Machine learning actively impacts our everyday life in almost all endeavors and domains such as healthcare, finance, and energy. As our dependence on the machine learning increases, it is inevitable that these algorithms will be used to make decisions that will have a direct impact on the society spanning all resolutions from personal choices to world-wide policies. Hence, it is crucial to ensure that (un)intentional bias does not affect the machine learning algorithms especially when they are required to take decisions that may have unintended consequences. Algorithmic fairness techniques have found traction in the machine learning community and many methods and metrics have been proposed to ensure and evaluate fairness in algorithms and data collection. In this paper, we study the algorithmic fairness in a supervised learning setting and examine the effect of optimizing a classifier for the Equal Opportunity metric. We demonstrate that such a classifier has an increased false positive rate across sensitive groups and propose a conceptually simple method to mitigate this bias. We rigorously analyze the proposed method and evaluate it on several real world datasets demonstrating its efficacy. Reproducibility: All source code, and experimental results are available at https://anonymous. 4open.science/r/b6c6653c-5f50-477c-bb13-7dfdeb39d4f4/",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c1acbc8e0ff87c55d663930ff32745be4a5ab73e",
        "citation_count": 3
    },
    {
        "title": "Role of Predictive Analytics in Improving Implantable Medical Device Lifespan",
        "abstract": "Predictive analytics has emerged as an essential approach in increasing the lifespan of Implantable Medical\nDevices (IMDs) such as cardiac pacemakers and defibrillators. This approach uses statistical modeling,\nmachine learning, and data mining to combine patient health information, device performance data, and\nreal-time sensor information. These predictive models enable clinicians and manufacturers to identify the\nonset of device failure, optimize calibration parameters, and perform preventive repairs or replacements,\nthus cutting down on overall healthcare expenditures and enhancing patient welfare. However, there are\nstill some issues, including the privacy of data, the robustness of data, and the complexity of regulations.\nThis paper aims to explore how predictive analytics can enhance the design and supervision of IMDs with\nthe help of the methods and findings that support the possibility of developing better and safer medical\ndevices.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/c1d75d7738894bf3dc33235baeab01cd4a89df8c",
        "citation_count": 0
    },
    {
        "title": "Role and Performance of Different Traditional Classification and Nature-Inspired Computing Techniques in Major Research Areas",
        "abstract": "In the last few years, different machine learning techniques such as supervised, unsupervised, and reinforcement learning have been effectively employed to solve distinct real-life multidisciplinary problems. These techniques have been effectively applied to accurately predict the problems related to stock values, disease diagnosis, sentiment analysis, text processing, gene classification, crop prediction, and weather forecasting. The objective of this manuscript is to present the systematic review on the use of these techniques in five major domains i.e. agriculture, finance, healthcare, education and engineering. A standard review methodology has been adapted to include and exclude the related literature. The performance of different supervised and nature-inspired computing techniques have been accessed on the basis of different performance metrics. The publication trend on the use of machine learning techniques in these five research areas has been also explored. Finally, the gaps in the study have been identified that will assist prospective researchers who want to pursue their research in these areas.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/c1ff54a5ac01ed407ebff503555239665ba2ce87",
        "citation_count": 10
    },
    {
        "title": "A New Data Science Model With Supervised Learning and its Application on Pesticide Poisoning Diagnosis in Rural Workers",
        "abstract": "In a Data Science project, it is essential to determine the relevance of the data and identify patterns that contribute to decision\u2013making based on domain\u2013specific knowledge. Furthermore, a clear definition of methodologies and creation of documentation to guide a project\u2019s development from inception to completion are essential elements. This study presents a Data Science model designed to guide the process, covering data collection through training with the aim of facilitating knowledge discovery. Motivated by deficiencies in existing Data Science methodologies, particularly the lack of practical step\u2013by\u2013step guidance on how to prepare data to reach the production phase. Named \u201cData Refinement Cycle with Supervised Machine Learning (DRC\u2013SML)\u201d, the proposed model was developed based on the emerging needs of a Data Sciense project aimed at assisting healthcare professionals in diagnosing pesticide poisoning among rural workers. The dataset used in this project resulted from scientific research in which 1027 samples were collected, containing data related to toxicity biomarkers and clinical analyses. We achieved an accuracy of 99.61% with only 27 rules for determining the diagnosis. The results optimized healthcare practices and improved quality of life in rural areas. The project outcomes demonstrated the success of the proposed model.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c2033349e7327c7c13387617ea4dc6b8a00f0b06",
        "citation_count": 0
    },
    {
        "title": "Supervised Machine Learning Methods for Seasonal Influenza Diagnosis",
        "abstract": "Influenza has been a stationary disease in Mexico since 2009, and this causes a high cost for the national public health system, including its detection using RT-qPCR tests, treatments, and absenteeism in the workplace. Despite influenza\u2019s relevance, the main clinical features to detect the disease defined by international institutions like the World Health Organization (WHO) and the United States Centers for Disease Control and Prevention (CDC) do not follow the same pattern in all populations. The aim of this work is to find a machine learning method to facilitate decision making in the clinical differentiation between positive and negative influenza patients, based on their symptoms and demographic features. The research sample consisted of 15480 records, including clinical and demographic data of patients with a positive/negative RT-qPCR influenza tests, from 2010 to 2020 in the public healthcare institutions of Mexico City. The performance of the methods for classifying influenza cases were evaluated with indices like accuracy, specificity, sensitivity, precision, the f1-measure and the area under the curve (AUC). Results indicate that random forest and bagging classifiers were the best supervised methods; they showed promise in supporting clinical diagnosis, especially in places where performing molecular tests might be challenging or not feasible.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/c20a536df28754a505dfc0cb5c0d57e2fae3a959",
        "citation_count": 2
    },
    {
        "title": "A Sentiment Analysis of Breast Cancer Treatment Experiences and Healthcare Perceptions Across Twitter",
        "abstract": "Background: Social media has the capacity to afford the healthcare industry with valuable feedback from patients who reveal and express their medical decision-making process, as well as self-reported quality of life indicators both during and post treatment. In prior work, [Crannell et. al.], we have studied an active cancer patient population on Twitter and compiled a set of tweets describing their experience with this disease. We refer to these online public testimonies as \"Invisible Patient Reported Outcomes\" (iPROs), because they carry relevant indicators, yet are difficult to capture by conventional means of self-report. Methods: Our present study aims to identify tweets related to the patient experience as an additional informative tool for monitoring public health. Using Twitter's public streaming API, we compiled over 5.3 million \"breast cancer\" related tweets spanning September 2016 until mid December 2017. We combined supervised machine learning methods with natural language processing to sift tweets relevant to breast cancer patient experiences. We analyzed a sample of 845 breast cancer patient and survivor accounts, responsible for over 48,000 posts. We investigated tweet content with a hedonometric sentiment analysis to quantitatively extract emotionally charged topics. Results: We found that positive experiences were shared regarding patient treatment, raising support, and spreading awareness. Further discussions related to healthcare were prevalent and largely negative focusing on fear of political legislation that could result in loss of coverage. Conclusions: Social media can provide a positive outlet for patients to discuss their needs and concerns regarding their healthcare coverage and treatment needs. Capturing iPROs from online communication can help inform healthcare professionals and lead to more connected and personalized treatment regimens.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/c25e88b643218c9c87b6c858309747b20ca3fcae",
        "citation_count": 33
    },
    {
        "title": "Improved Intrusion Detection System using Quantal Response Equilibrium-based Game Model and Rule-based Classification",
        "abstract": "Wireless sensor network has large number of low-cost tiny nodes with sensing capability.\u00a0 These provide low cost solutions to many real world problems such as such as defence, Internet of things, healthcare, environment monitoring and so on. The sensor nodes of these networks are placed in vulnerable environment. Hence, the security of these networks is very important. Intrusion Detection System (IDS) plays an important role in providing a security to such type of networks. The sensor nodes of the network have limited power and, traditional security mechanisms such as key-management, encryption decryption and authentication techniques cannot be installed on the nodes. Hence, there is a need of special security mechanism to handle the intrusions. In this paper, intrusion detection system is designed and implemented using game theory and machine learning to identify multiple attacks. Game theory is designed and used to apply the IDS optimally in WSN. The game model is designed by defining the players and the corresponding strategies. Quantal Response Equilibrium (QRE) concept of game theory is used to select the strategies in optimal way for the intrusion\u2019s detection. Further, these intrusions are classified as denial of service attack, rank attack or selective forwarding attacks using supervised machine learning technique based on different parameters and rules. Results show that all the attacks are detected with good detection rate and the proposed approach provides optimal usage of IDS.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c29dc57b1916c8890bbdb58984950a5bd97b6a1c",
        "citation_count": 4
    },
    {
        "title": "AI-Powered Blockchain Technology for Public Health: A Contemporary Review, Open Challenges, and Future Research Directions",
        "abstract": "Blockchain technology has been growing at a substantial growth rate over the last decade. Introduced as the backbone of cryptocurrencies such as Bitcoin, it soon found its application in other fields because of its security and privacy features. Blockchain has been used in the healthcare industry for several purposes including secure data logging, transactions, and maintenance using smart contracts. Great work has been carried out to make blockchain smart, with the integration of Artificial Intelligence (AI) to combine the best features of the two technologies. This review incorporates the conceptual and functional aspects of the individual technologies and innovations in the domains of blockchain and artificial intelligence and lays down a strong foundational understanding of the domains individually and also rigorously discusses the various ways AI has been used along with blockchain to power the healthcare industry including areas of great importance such as electronic health record (EHR) management, distant-patient monitoring and telemedicine, genomics, drug research, and testing, specialized imaging and outbreak prediction. It compiles various algorithms from supervised and unsupervised machine learning problems along with deep learning algorithms such as convolutional/recurrent neural networks and numerous platforms currently being used in AI-powered blockchain systems and discusses their applications. The review also presents the challenges still faced by these systems which they inherit from the AI and blockchain algorithms used at the core of them and the scope of future work.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/c2ac0dad5897bf8be7bf055a0dd7196af6a3d890",
        "citation_count": 28
    },
    {
        "title": "Applying Supervised Machine Learning Algorithms to Detect Cardiac Events",
        "abstract": "Within the realm of machine learning, numerous research advancements have enhanced the understanding of data analytics and prediction models. One of the more recent achievements in artificial intelligence is the rise of machine learning in healthcare, aiding in the development of streamlined treatment and diagnosis. Cardiac focus in this paper is due to an interest in how the pandemic restricted extracurriculars and athletics in school, which led to a decrease in physical activity in adolescents. With a decrease in physical activity, the cardiac systems of students might have weakened thus fostering an interest in applying machine learning to cardiac health in adolescents. By using wearable devices and mobile devices to collect data from participants (mainly adolescents), machine learning algorithms can be applied to the data and then analyzed to get information about the cardiac states of adolescents. Cardiac features were measured using the YAMAY Smart Watch wearable device; a variety of supervised machine learning algorithms (KNN, Na\u00efve Bayes, Random Forest, and Decision Trees) were used to predict the expected data with the target data. Overall, after testing each of the supervised machine learning algorithms, Random Forest had the best prediction accuracy of 75.86%. With these results in mind, research focusing on applying supervised machine learning algorithms to detect cardiac events would benefit from using Random Forest.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c2c440f347e10782a1d828e02594665e27348731",
        "citation_count": 0
    },
    {
        "title": "Using artificial intelligence to reduce diagnostic workload without compromising detection of urinary tract infections",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/c36c9c6e80735b6740ecc54eb2661bcfe79a5569",
        "citation_count": 87
    },
    {
        "title": "Predicting the Severity of Lockdown-Induced Psychiatric Symptoms with Machine Learning",
        "abstract": "During the COVID-19 pandemic, an increase in the incidence of psychiatric disorders in the general population and an increase in the severity of symptoms in psychiatric patients have been reported. Anxiety and depression symptoms are the most commonly observed during large-scale dramatic events such as pandemics and wars, especially when these implicate an extended lockdown. The early detection of higher risk clinical and non-clinical individuals would help prevent the new onset and/or deterioration of these symptoms. This in turn would lead to the implementation of public policies aimed at protecting vulnerable populations during these dramatic contingencies, therefore optimising the effectiveness of interventions and saving the resources of national healthcare systems. We used a supervised machine learning method to identify the predictors of the severity of psychiatric symptoms during the Italian lockdown due to the COVID-19 pandemic. Via a case study, we applied this methodology to a small sample of healthy individuals, obsessive-compulsive disorder patients, and adjustment disorder patients. Our preliminary results show that our models were able to predict depression, anxiety, and obsessive-compulsive symptoms during the lockdown with up to 92% accuracy based on demographic and clinical characteristics collected before the pandemic. The presented methodology may be used to predict the psychiatric prognosis of individuals under a large-scale lockdown and thus supporting the related clinical decisions.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/c3a597925e86364274b22922b6b3511beeb0fdbf",
        "citation_count": 7
    },
    {
        "title": "Exploring the growth of COVID\u201019 cases using exponential modelling across 42 countries and predicting signs of early containment using machine learning",
        "abstract": "Abstract The coronavirus disease 2019 (COVID\u201019) pandemic spread by the single\u2010stranded RNA severe acute respiratory syndrome coronavirus 2 (SARS\u2010CoV\u20102) belongs to the seventh generation of the coronavirus family. Following an unusual replication mechanism, its extreme ease of transmissivity has put many countries under lockdown. With the uncertainty of developing a cure/vaccine for the infection in the near future, the onus currently lies on healthcare infrastructure, policies, government activities, and behaviour of the people to contain the virus. This research uses exponential growth modelling studies to understand the spreading patterns of SARS\u2010CoV\u20102 and identifies countries that showed early signs of containment until March 26, 2020. Predictive supervised machine learning models are built using infrastructure, environment, policies, and infection\u2010related independent variables to predict early containment. COVID\u201019 infection data across 42 countries are used. Logistic regression results show a positive significant relationship between healthcare infrastructure and lockdown policies, and signs of early containment. Machine learning models based on logistic regression, decision tree, random forest, and support vector machines are developed and show accuracies between 76.2% and 92.9% to predict early signs of infection containment. Other policies and the decisions taken by countries to contain the infection are also discussed.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c3eda81fe15d67708be68cdc74fed0af5d48f035",
        "citation_count": 32
    },
    {
        "title": "Hybrid Feature Vector-Assisted Action Representation for Human Action Recognition Using Support Vector Machines",
        "abstract": "Human action recognition (HAR) is one of most significant research topics, and it has attracted the concentration of many researchers. Automatic HAR system is applied in several fields like visual surveillance, data retrieval, healthcare, etc. Based on this inspiration, in this chapter, the authors propose a new HAR model that considers an image as input and analyses and exposes the action present in it. Under the analysis phase, they implement two different feature extraction methods with the help of rotation invariant Gabor filter and edge adaptive wavelet filter. For every action image, a new vector called as composite feature vector is formulated and then subjected to dimensionality reduction through principal component analysis (PCA). Finally, the authors employ the most popular supervised machine learning algorithm (i.e., support vector machine [SVM]) for classification. Simulation is done over two standard datasets; they are KTH and Weizmann, and the performance is measured through an accuracy metric.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c4228fb85a0d7064a2335a6ce895692eea54d6d4",
        "citation_count": 0
    },
    {
        "title": "THYROID PROBLEM DETECTION USING NAIVE BAYESIAN CLASSIFICATION",
        "abstract": "Thyroid disease is a commonly occurring disease. Thyroid disease can result from conditions that cause over-or underfunction of the thyroid gland. The overactive thyroid is known as Hyperthyroidism and the underactive thyroid is known as Hypothyroidism. A TSH test is done to find out if your thyroid gland is working the way it should. TSH stands for \u201cThyroid Stimulating Hormone\u201d and the test measures how much of this hormone is in your blood. However TSH test is not enough to detect all the problems of Thyroid. Additional tests like T3 test and T4 test need to be carried out. A T3 test measures the blood level of the hormone T3 (triiodothyronine), and T4 test measures thyroxin. A Naive Bayes classifier is a probabilistic machine learning model that\u2019s used for classification task by using Bayes theorem of probability. It is a supervised learning algorithm which makes predictions for new data using Bayes theorem. Naive Bayesian Classification is used to classify the given sample and detect the thyroid problem. Index Terms Hyperthyroidism, Hypothyroidism, TSH, Supervised Learning, Naive Bayesian Classification. INTRODUCTION One of the fourth leading diseases in India is thyroid disease which acts as a serious threat to the society as the change in family population, climate, urbanization, food increases the occurrence of change in thyroid hormone simulation which leads to thyroid diseases. The techniques available in the data analytics is a boon for the healthcare industry. The analysis helps in the accurate prediction of diseases, by creating the knowledge prediction model for the patients by analysing the patient\u2019s history. This help in accurate decision making for the clinicians to diagnose the disease. The untreated hypothyroidism can be a hazardous disease which even leads to death. Surprisingly there are certain factors like change in food style, environmental changes and a balanced iodized intake keeps the thyroid hormone secretion in control. According to the survey in India, 1 out of 10 adults are suffering from any one of the thyroid diseases. Moreover the philistinism, inadequacy of treatment facility are the main reasons for this wide spread. The early detection and prediction of thyroid deficiency will reduce the risks of survival. Many precision and diagnosis models have been designed for the prediction of thyroid diseases. Data analytics is yet another scientific access that enhances numerous algorithms, formulation and scientific approach to interpret the knowledge from the bigger data sources. Classification techniques process the data from the larger data sets and group the data instance for better results. Henceforth the classification algorithms and techniques are universally acceptable for the healthcare industry for prediction of diseases. The thyroid gland is the biggest gland (butterfly shape) in the neck, whose function is to stimulate thyroid hormone, which results in effect on nearly all tissues of the body. The main function of the thyroid is to maintain the regulation of the body\u2019s metabolism. In general, disorders of the thyroid gland can be classified into two classes including hyperthyroidism and hypothyroidism. Hyperthyroidism occurs when the thyroid gland produces too much hormone, the body uses energy faster than it should. While the hypothyroidism happens under the condition when the thyroid simulating hormones doesn\u2019t produce enough hormones, which means the body uses energy slower than it should be. There are many different reasons why either of these conditions might develop. Now, it is said that about 30 million Indians have at least any one form of thyroid disease, and people of all ages and races can have the possibility to get thyroid disease. It is surprised to find the women are five to eight times more likely than men to get thyroid disease especially in highly altitude areas. The symptoms are complex but easily confused with other conditions as well, which make tougher diagnosis of thyroid disease to be difficult. Naive Bayes is a statistical classification technique based on Bayes Theorem. The statement of Bayes Theorem is P(A\u2223B) = P(B\u2223A) P(A)/P(B). Naive Bayes is one of the simplest supervised learning algorithms. Naive Bayes classifier is the fast, accurate and reliable algorithm. Naive Bayes classifiers have high accuracy and speed on large datasets. Naive Bayes classifier assumes that the effect of a particular feature in a class is independent of other features. Bayes classifier calculate the posterior probability for every class www.ijcrt.org \u00a9 2020 IJCRT | Volume 8, Issue 2 February 2020 | ISSN: 2320-2882 IJCRT2002146 International Journal of Creative Research Thoughts (IJCRT) www.ijcrt.org 1341 and for each observation. Then it classifies the new observation based on the class with the largest posterior probability. Naive Bayes classifier performs well even when the dataset is small. So, the Naive Bayes classifier predicts the thyroid disease with more accuracy. LITERATURE SURVEY Earlier, the use of computer was to build knowledge based clinical decision support system which uses knowledge from medical experts and transfers this knowledge into computer algorithms manually. This process is time consuming and really depends on medical experts opinions which may be subjective. To handle this problem, machine learning techniques have been developed to gain knowledge automatically from examples or raw data. Here, a weighted fuzzy rule-based clinical decision support system (CDSS) is presented for the diagnosis of disease, automatically obtaining knowledge from the patient\u2019s clinical data. The clinical decision support system for the risk prediction of patient\u2019s disease consists of two phases: automated approach for the generation of weighted fuzzy rules and developing a fuzzy rule-based decision support system. In the first phase, it can be used the mining technique, attribute selection and attribute weight, age method to obtain the weighted fuzzy rules. Then, the fuzzy system is constructed in accordance with the weighted fuzzy rules and chosen attributes. To detect thyroid disorders various image processing techniques have been used. Most image processing algorithms consists of pre-processing, segmentation, feature extraction, feature selection and classification. The image processing algorithm takes the MRI image of the thyroid as input. The pre-processing step is done to reduce the noise and improve the quality of the image. In segmentation step, the region containing abnormalities are detected and then the features are extracted in feature extraction and the best features are selected. The classification is done on the basis of selected features from the image. Finally, the experimentation is carried out on the proposed system using the dataset created by collecting test levels details of patients and the performance of the system is compared with the neural network-based system utilizing accuracy, sensitivity and specificity. In this project, an attempt is made to utilize Naive Bayesian classification to classify the Thyroid problem.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c48a13db6a47881191cddc323924370d568f7cf5",
        "citation_count": 0
    },
    {
        "title": "Artificial intelligence models for clinical usage in dentistry with a focus on dentomaxillofacial CBCT: a systematic review",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/c48a396b86097665b50ac2c0a30eb37853ec1aba",
        "citation_count": 30
    },
    {
        "title": "Interactive Weak Supervision: Learning Useful Heuristics for Data Labeling",
        "abstract": "Obtaining large annotated datasets is critical for training successful machine learning models and it is often a bottleneck in practice. Weak supervision offers a promising alternative for producing labeled datasets without ground truth annotations by generating probabilistic labels using multiple noisy heuristics. This process can scale to large datasets and has demonstrated state of the art performance in diverse domains such as healthcare and e-commerce. One practical issue with learning from user-generated heuristics is that their creation requires creativity, foresight, and domain expertise from those who hand-craft them, a process which can be tedious and subjective. We develop the first framework for interactive weak supervision in which a method proposes heuristics and learns from user feedback given on each proposed heuristic. Our experiments demonstrate that only a small number of feedback iterations are needed to train models that achieve highly competitive test set performance without access to ground truth training labels. We conduct user studies, which show that users are able to effectively provide feedback on heuristics and that test set results track the performance of simulated oracles.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c50ac3bb4fbed9c92de1afb88bdb889716b6d469",
        "citation_count": 67
    },
    {
        "title": "Fast Machine Learning Algorithms for Massive Datasets with Applications in the Biomedical Domain",
        "abstract": "The continuous increase in the size of datasets introduces computational challenges for machine learning algorithms. In this dissertation, we cover the machine learning algorithms and applications in large-scale data analysis in manufacturing and healthcare. We begin with introducing a multilevel framework to scale the support vector machine (SVM), a popular supervised learning algorithm with a few tunable hyperparameters and highly accurate prediction. The computational complexity of nonlinear SVM is prohibitive on large-scale datasets compared to the linear SVM, which is more scalable for massive datasets. The nonlinear SVM has shown to produce significantly higher classification quality on complex and highly imbalanced datasets. However, a higher classification quality requires a computationally expensive quadratic programming solver and extra kernel parameters for model selection. We introduce a generalized fast multilevel framework for regular, weighted, and instance weighted SVM that achieves similar or better classification quality compared to the state-of-the-art SVM libraries such as LIBSVM. Our framework improves the runtime more than two orders of magnitude for some of the well-known benchmark datasets. We cover multiple versions of our proposed framework and its implementation in detail. The framework is implemented using PETSc library which allows easy integration with scientific computing tasks. Next, we propose an adaptive multilevel learning framework for SVM to reduce the variance between prediction qualities across the levels, improve the overall prediction accuracy, and boost the runtime. We implement multi-threaded support to speed up the parameter fitting runtime that results in more than an order of magnitude speed-up. We design an early stopping criteria to reduce the extra computational cost when we achieve expected prediction quality. This approach provides significant speed-up, especially for massive datasets. Finally, we propose an efficient low dimensional feature extraction over massive knowledge networks. Knowledge networks are becoming more popular in the biomedical domain for knowledge representation. Each layer in knowledge networks can store the information from one or",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c5349f016a03ab4fad861c073481067f42513cc3",
        "citation_count": 1
    },
    {
        "title": "Enhancing the Performance of Classification Using Super Learning",
        "abstract": null,
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/c58abbd1b739d2c30ee54842e3268a05ae57a8e5",
        "citation_count": 33
    },
    {
        "title": "Modeling user context for valence prediction from narratives",
        "abstract": "Automated prediction of valence, one key feature of a person's emotional state, from individuals' personal narratives may provide crucial information for mental healthcare (e.g. early diagnosis of mental diseases, supervision of disease course, etc.). In the Interspeech 2018 ComParE Self-Assessed Affect challenge, the task of valence prediction was framed as a three-class classification problem using 8 seconds fragments from individuals' narratives. As such, the task did not allow for exploring contextual information of the narratives. In this work, we investigate the intrinsic information from multiple narratives recounted by the same individual in order to predict their current state-of-mind. Furthermore, with generalizability in mind, we decided to focus our experiments exclusively on textual information as the public availability of audio narratives is limited compared to text. Our hypothesis is, that context modeling might provide insights about emotion triggering concepts (e.g. events, people, places) mentioned in the narratives that are linked to an individual's state of mind. We explore multiple machine learning techniques to model narratives. We find that the models are able to capture inter-individual differences, leading to more accurate predictions of an individual's emotional state, as compared to single narratives.",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/c5d796bdce25f9a65b56db9dde65bb767897e92e",
        "citation_count": 7
    },
    {
        "title": "Prediction of Preterm Deliveries from EHG Signals Using Machine Learning",
        "abstract": "There has been some improvement in the treatment of preterm infants, which has helped to increase their chance of survival. However, the rate of premature births is still globally increasing. As a result, this group of infants are most at risk of developing severe medical conditions that can affect the respiratory, gastrointestinal, immune, central nervous, auditory and visual systems. In extreme cases, this can also lead to long-term conditions, such as cerebral palsy, mental retardation, learning difficulties, including poor health and growth. In the US alone, the societal and economic cost of preterm births, in 2005, was estimated to be $26.2 billion, per annum. In the UK, this value was close to \u00a32.95 billion, in 2009. Many believe that a better understanding of why preterm births occur, and a strategic focus on prevention, will help to improve the health of children and reduce healthcare costs. At present, most methods of preterm birth prediction are subjective. However, a strong body of evidence suggests the analysis of uterine electrical signals (Electrohysterography), could provide a viable way of diagnosing true labour and predict preterm deliveries. Most Electrohysterography studies focus on true labour detection during the final seven days, before labour. The challenge is to utilise Electrohysterography techniques to predict preterm delivery earlier in the pregnancy. This paper explores this idea further and presents a supervised machine learning approach that classifies term and preterm records, using an open source dataset containing 300 records (38 preterm and 262 term). The synthetic minority oversampling technique is used to oversample the minority preterm class, and cross validation techniques, are used to evaluate the dataset against other similar studies. Our approach shows an improvement on existing studies with 96% sensitivity, 90% specificity, and a 95% area under the curve value with 8% global error using the polynomial classifier.",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/c5f8fd2d925e2bbb2191175a4f6e0b28db19248e",
        "citation_count": 146
    },
    {
        "title": "Machine Learning-Based Detection of Dengue from Blood Smear Images Utilizing Platelet and Lymphocyte Characteristics",
        "abstract": "Dengue fever, also known as break-bone fever, can be life-threatening. Caused by DENV, an RNA virus from the Flaviviridae family, dengue is currently a globally important public health problem. The clinical methods available for dengue diagnosis require skilled supervision. They are manual, time-consuming, labor-intensive, and not affordable to common people. This paper describes a method that can support clinicians during dengue diagnosis. It is proposed to automate the peripheral blood smear (PBS) examination using Artificial Intelligence (AI) to aid dengue diagnosis. Nowadays, AI, especially Machine Learning (ML), is increasingly being explored for successful analyses in the biomedical field. Digital pathology coupled with AI holds great potential in developing healthcare services. The automation system developed incorporates a blob detection method to detect platelets and thrombocytopenia from the PBS images. The results achieved are clinically acceptable. Moreover, an ML-based technique is proposed to detect dengue from the images of PBS based on the lymphocyte nucleus. Ten features are extracted, including six morphological and four Gray Level Spatial Dependance Matrix (GLSDM) features, out of the lymphocyte nucleus of normal and dengue cases. Features are then subjected to various popular supervised classifiers built using a ten-fold cross-validation policy for automated dengue detection. Among all the classifiers, the best performance was achieved by Support Vector Machine (SVM) and Decision Tree (DT), each with an accuracy of 93.62%. Furthermore, 1000 deep features extracted using pre-trained MobileNetV2 and 177 textural features extracted using Local binary pattern (LBP) from the lymphocyte nucleus are subjected to feature selection. The ReliefF selected 100 most significant features are then fed to the classifiers. The best performance was attained using an SVM classifier with 95.74% accuracy. With the obtained results, it is evident that this proposed approach can efficiently contribute as an adjuvant tool for diagnosing dengue from the digital microscopic images of PBS.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/c5fbfebff83fe92ac8507f052a7cc5b036f6f9d9",
        "citation_count": 10
    },
    {
        "title": "Quantum-Assisted Activation for Supervised Learning in Healthcare-Based Intrusion Detection Systems",
        "abstract": "Intrusion detection systems (IDSs) are amongst the most important automated defense mechanisms in modern industry. It is guarding against many attack vectors, especially in healthcare, where sensitive information (patient\u2019s medical history, prescriptions, electronic health records, medical bills/debts, and many other sensitive data points) is open to compromise from adversaries. In the big data era, classical machine learning has been applied to train IDS. However, classical IDS tend to be complex: either using several hidden layers susceptible to overfitting on training data or using overly complex architectures such as convolutional neural networks, long-short term memory systems, and recurrent neural networks. This article explored the combination of principles of quantum mechanics and neural networks to train IDS. A hybrid classical-quantum neural architecture is proposed with a quantum-assisted activation function that successfully captures patterns in the dataset while having less architectural memory footprint than classical solutions. The experimental results are demonstrated on the popular KDD99 dataset while comparing our solution to other classical models.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c610773264ea0715cbf9e9be8ec24870a463535d",
        "citation_count": 12
    },
    {
        "title": "Heart Risk Prediction System Based on Supervised ANN",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/c6876c90ba294cbbe42d55f1b29acd0763e99690",
        "citation_count": 1
    },
    {
        "title": "Evaluating the Performance of Machine Learning Models in Cancer Prediction through ROC and PRC Metrics",
        "abstract": "Cancer is one of the major killers of diseases worldwide and early diagnosis has proven to be one of the best practices to help patients recover. The use of Predictive Analytic in conjunction with Machine Learning Techniques has been very promising in Healthcare, particularly in Cancer Prediction. The study tries to exhaustively examine a cancer prediction data set that would include the demographic details of a patient, their medical history, markers of genetics, and how lifestyle relates to the patient. The data set is prepared to allow the development of predictive models of identifying people who are most likely to develop any type of cancer. The data includes breast, lung, and colorectal cancers. It contains a wide variety of features, including clinical test results, imaging data, and genomics profiles, structured in such a way that would allow the insights from a variety of analyses, both supervised and unsupervised, and would look more directly into the correlations between a risk factor and cancer characteristics. Advanced machine learning algorithms, including random forests, support vector machines, and deep learning, enable researchers to build models that will predict - based on the past patterns of historical data - the probable possibility of cancer formation. This data set has immense opportunities for furthering personalized medicine, indicating individuals at risk early on for possible strategies in treatment. Moreover, the model's ability to predict the truth or accuracy, precision, recall, and other relevance metrics may be measured. The usage of this data set promotes open data use in cancer research, leading to a reduced number of cancers-related mortality and improvement of the accuracy of both prediction and early diagnosis.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c6d3d997dfb36a6c419697c52c1b8bfff8c848f9",
        "citation_count": 0
    },
    {
        "title": "WiWeHAR: Multimodal Human Activity Recognition Using Wi-Fi and Wearable Sensing Modalities",
        "abstract": "Robust and accurate human activity recognition (HAR) systems are essential to many human-centric services within active assisted living and healthcare facilities. Traditional HAR systems mostly leverage a single sensing modality (e.g., either wearable, vision, or radio frequency sensing) combined with machine learning techniques to recognize human activities. Such unimodal HAR systems do not cope well with real-time changes in the environment. To overcome this limitation, new HAR systems that incorporate multiple sensing modalities are needed. Multiple diverse sensors can provide more accurate and complete information resulting in better recognition of the performed activities. This article presents WiWeHAR\u2014a multimodal HAR system that uses combined Wi-Fi and wearable sensing modalities to simultaneously sense the performed activities. WiWeHAR makes use of standard Wi-Fi network interface cards to collect the channel state information (CSI) and a wearable inertial measurement unit (IMU) consisting of accelerometer, gyroscope, magnetometer sensors to collect the user\u2019s local body movements. We compute the time-variant mean Doppler shift (MDS) from the processed CSI data and magnitude from the inertial data for each sensor of the IMU. Thereafter, we separately extract various time- and frequency-domain features from the magnitude data and the MDS. We apply feature-level fusion to combine the extracted features, and finally supervised learning techniques are used to recognize the performed activities. We evaluate the performance of WiWeHAR by using a multimodal human activity data set, which was obtained from 9 participants. Each participant carried out four activities, such as walking, falling, sitting, and picking up an object from the floor. Our results indicate that the proposed multimodal WiWeHAR system outperforms the unimodal CSI, accelerometer, gyroscope, and magnetometer HAR systems and achieves an overall recognition accuracy of 99.6%\u2013100%.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c7669741d238521d519742d7ab38d0da6aec67d7",
        "citation_count": 40
    },
    {
        "title": "Supervised Classification with Short-Term Memory of Sleep Stages using Cardio-respiratory and Body Movement Variables",
        "abstract": "In the context of the Internet of Things (IoT) healthcare, biophysical features collected during sleep needs robust analysis methods to be efficiently used to detect sleep disorders. In this paper, analysis methods using a limited number of input variables (cardiac, respiratory, and body movement) have been used to perform the classification of sleep stages. The efficiency of each classification method has been compared to a reference method that combines a large number of biophysical features referred to as PolySomnoGraphy (PSG). Five classical machine learning methods were evaluated by testing their accuracy on the same collected data. Finally, using a neural network with a short memory method, the classification task fitted 91.34% of the PSG classification.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c771ea8a4e66cf3ec6c4349ebbdd90074060b42e",
        "citation_count": 1
    },
    {
        "title": "Extracting Clinical Relationships from Patient Narratives",
        "abstract": "The Clinical E-Science Framework (CLEF) project has built a system to extract clinically significant information from the textual component of medical records, for clinical research, evidence-based healthcare and genotype-meets-phenotype informatics. One part of this system is the identification of relationships between clinically important entities in the text. Typical approaches to relationship extraction in this domain have used full parses, domain-specific grammars, and large knowledge bases encoding domain knowledge. In other areas of biomedical NLP, statistical machine learning approaches are now routinely applied to relationship extraction. We report on the novel application of these statistical techniques to clinical relationships. \n \nWe describe a supervised machine learning system, trained with a corpus of oncology narratives hand-annotated with clinically important relationships. Various shallow features are extracted from these texts, and used to train statistical classifiers. We compare the suitability of these features for clinical relationship extraction, how extraction varies between inter- and intra-sentential relationships, and examine the amount of training data needed to learn various relationships.",
        "year": 2008,
        "url": "https://www.semanticscholar.org/paper/c78c1a8fd57eea93c649ebf670f14944934d28f6",
        "citation_count": 67
    },
    {
        "title": "Post-Care Continuum: Predictive Analytics Platform for Continuous Patient Monitoring After Hospital Discharge",
        "abstract": "Through the implementation of an effective post-discharge patient monitoring system, we intend to significantly reduce the risk of Cognitive Heart Failure (CHF). This study proposes a highly advanced machine-learning platform for real-time detection and risk assessment of current patient data. More specifically, reinforced learning and supervised learning will be used. We also plan to integrate historical data, providing both healthcare providers and patients with more accurate results. Patients can enter daily health metrics to facilitate trend analysis and capture oncoming health issues. After this input, the patient data will be assessed with a built-in risk assessment algorithm developed by our model. Based on results from this algorithm, healthcare providers will be notified. This patient-centered design facilitates the process of proactive care, enhances the level of communication between patients and their providers, and shortens diagnosis and time required for treatment initiation. Data sources used by the platform to model predictive ability include PhysioNet, OpenNeuro, and OpenfMRI. Rigorous validation through clinical trials shall prove the reliability, effectiveness, and scalability of the platform toward bettering patient outcomes and supporting global healthcare enhancements. Through this continuously adapting model, we hope to successfully bridge the gap between accurate healthcare monitoring and post-discharge care. Clinical Relevance- Currently, healthcare providers are not able to have an easy method of tracking patient conditions post-discharge, especially when it comes to chronic conditions like Cognitive Heart Failure (CHF). This model allows for both providers and patients to have a device that simulates whether or not the patients need to go in for a check-up, based on the machine learning and risk assessment model that we developed. This can significantly improve patient-provider communication.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/c80e7f2334f2d9897ff4943200af57c1f87e7171",
        "citation_count": 0
    },
    {
        "title": "Classifying Unstructured Clinical Notes via Automatic Weak Supervision",
        "abstract": "Healthcare providers usually record detailed notes of the clinical care delivered to each patient for clinical, research, and billing purposes. Due to the unstructured nature of these narratives, providers employ dedicated staff to assign diagnostic codes to patients' diagnoses using the International Classification of Diseases (ICD) coding system. This manual process is not only time-consuming but also costly and error-prone. Prior work demonstrated potential utility of Machine Learning (ML) methodology in automating this process, but it has relied on large quantities of manually labeled data to train the models. Additionally, diagnostic coding systems evolve with time, which makes traditional supervised learning strategies unable to generalize beyond local applications. In this work, we introduce a general weakly-supervised text classification framework that learns from class-label descriptions only, without the need to use any human-labeled documents. It leverages the linguistic domain knowledge stored within pre-trained language models and the data programming framework to assign code labels to individual texts. We demonstrate the efficacy and flexibility of our method by comparing it to state-of-the-art weak text classifiers across four real-world text classification datasets, in addition to assigning ICD codes to medical notes in the publicly available MIMIC-III database.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/c82238e32e26415839b3799daea1897b1d7680c4",
        "citation_count": 8
    },
    {
        "title": "Detecting inappropriate access to electronic health records using collaborative filtering",
        "abstract": null,
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/c827bc4edb603864b13cf80aa81719dfcc9122bc",
        "citation_count": 39
    },
    {
        "title": "A paradigm of an interaction context-aware pervasive multimodal multimedia computing system",
        "abstract": "Communication is a very important aspect of human life; it is communication that helps human beings to connect with each other as individuals and as independent groups. Communication is the fulcrum that drives all human developments in all fields. In informatics, one of the main purposes of the existence of computer is information dissemination \u2013 to be able to send and receive information. Humans are quite successful in conveying ideas to one another, and reacting appropriately. This is due to the fact that we share the richness of the language, have a common understanding of how things work and an implicit understanding of everyday situations. When humans communicate with humans, they comprehend the information that is apparent to the current situation, or context, hence increasing the conversational bandwidth. This ability to convey ideas, however, does not transfer when humans interact with computers. On its own, computers do not understand our language, do not understand how the world works and cannot sense information about the current situation. In a typical computing set-up where we have an impoverished typical mechanism for providing computer with information using mouse, keyboard and screen, the end result is we explicitly provide information to computers, producing an effect that is contrary to the promise of transparency and calm technology in Weiser\u2019s vision of ubiquitous computing (Weiser 1991; Weiser and Brown 1996). To reverse this trend, it is imperative that we researchers find ways that will enable computers to have access to context. It is through context-awareness that we can increase the richness of communication in human-computer interaction, through which we can reap the most likely benefit of more useful computational services. \n \nContext is a subjective idea as demonstrated by the state-of-the art in which each researcher has his own understanding of the term, which continues to evolve nonetheless. The acquisition of contextual information is essential but it is the end user, however, that will have the final say as to whether the envisioned context is correctly captured/acquired or not. Current literature informs us that some contextual information is already predefined by some researchers from the very beginning \u2013 this is correct if the application domain is fixed but is incorrect if we infer that a typical user does different computing tasks on different occasions. With the aim of coming up with more conclusive and inclusive design, we conjecture that what contextual information should be left to the judgment of the end user who is the one that has the knowledge determine which information is important to him and which is not. This leads us to the concept of incremental acquisition of context where context parameters are added, modified or deleted one context parameter at a time. \n \nIn conjunction with our idea of inclusive context, we broaden the notion of context that it has become context of interaction. Interaction context is the term that is used to refer to the collective context of the user (i.e. user context), of his working environment (i.e. environmental context) and of his computing system (i.e. system context). Logically and mathematically, each of these interaction context elements \u2013 user context, environment context and system context \u2013 is composed of various parameters that describe the state of the user, of his workplace and his computing resources as he undertakes an activity in accomplishing his computing task, and each of these parameters may evolve over time. For example, user location is a user context parameter and its value will evolve as the user moves from one place to another. The same can be said about noise level as an environment context parameter; its value evolves over time. The same can be said with available bandwidth that continuously evolves which we consider as a system context parameter. To realize the incremental definition of incremental context, we have developed a tool called the virtual machine for incremental interaction context. This tool can be used to add, modify and delete a context parameter on one hand and determine the sensor-based context (i.e. context that is based on parameters whose values are obtained from raw data supplied by sensors) on the other. \n \nIn order to obtain the full benefit of the richness of interaction context with regards to communication in human-machine interaction, the modality of interaction should not be limited to the traditional use of mouse-keyboard-screen alone. Multimodality allows for a much wider range of modes and forms of communication, selected and adapted to suit the given user\u2019s context of interaction, by which the end user can transmit data to the computer and computer can respond or yield results to the user\u2019s queries. In multimodal communication, the weaknesses of one mode of interaction, with regards to its suitability to a given situation, is compensated by replacing it with another mode of communication that is more suitable to the situation. For example, when the environment becomes disturbingly noisy, using voice may not be the ideal mode to input data; instead, the user may opt for transmitting text or visual information. Multimodality also promotes inclusive informatics as those with a permanent or temporary disability are given the opportunity to use and benefit from information technology advancement. For example, the work on presentation of mathematical expressions to visually-impaired users (Awde 2009) would not have been made possible without multimodality. With mobile computing within our midst coupled with wireless communication that allows access to information and services, pervasive and adaptive multimodality is more than ever apt to enrich communication in human-computer interaction and in providing the most suitable modes for data input and output in relation to the evolving interaction context. \n \nA look back at the state of the art informs us that a great amount of effort was expended in finding the definition of context, in the acquisition of context, in the dissemination of context and the exploitation of context within a system that has a fixed domain of application (e.g. healthcare, education, etc.). Also, another close look tells us that much research efforts on ubiquitous computing were devoted to various application domains (e.g. identifying the user whereabouts, identifying services and tools, etc.) but there is rarely, if ever, an effort made to make multimodality pervasive and accessible to various user situations. In this regard, we come up with a research work that will provide for the missing link. Our work \u2013 the paradigm of an interaction context-sensitive pervasive multimodal multimedia computing system is an architectural design that exhibits adaptability to a much larger context called interaction context. It is intelligent and pervasive, meaning it is functional even when the end user is stationary or on the go. It is conceived with two purposes in mind. First, given an instance of interaction context, one which evolves over time, our system determines the optimal modalities that suit such interaction context. By optimal, we mean a selection decision on appropriate multimodality based on the given interaction context, available media devices that support the modalities and user preferences. We designed a mechanism (i.e. a paradigm) that will do this task and simulated its functionality with success. This mechanism employs machine learning (Mitchell 1997; Alpaydin 2004; Hina, Tadj et al. 2006) and uses case-based reasoning with supervised learning (Kolodner 1993; Lajmi, Ghedira et al. 2007). An input to this decision-making component is an instance of interaction context and its output is the optimal modality and its associated media devices that are for activation. This mechanism is continuously monitoring the user\u2019s context of interaction and on behalf of the user continuously adapts accordingly. This adaptation is through dynamic reconfiguration of the pervasive multimodal system\u2019s architecture. Second, given an instance of interaction context and the user\u2019s task and preferences, we designed a mechanism that allows the automatic selection of user\u2019s applications, the preferred suppliers to these applications and the preferred quality of service (QoS) dimensions\u2019 configurations of these suppliers. This mechanism does its task in consultation with computing resources, sensing the available suppliers and possible configuration restrictions within the given computing set-up. \n \nApart from the above-mentioned mechanisms, we also formulated scenarios as to how a computing system must provide the user interface given that we have already identified the optimal modalities that suit the user\u2019s context of interaction. We present possible configurations of unimodal and bimodal interfaces based on the given interaction context as well as user preferences. \n \nOur work is different from previous work in that while other systems capture, disseminate and consume context to suit the preferred domain of application, ours captures the interaction context and reconfigures its architecture dynamically in generic fashion in order that the user could continue working on his task anytime, anywhere he wishes regardless of the application domain the user wishes to undertake. In effect, the system that we have designed along with all of its mechanisms, being generic in design, can be adapted or integrated with ease or with very little modification into various computing systems of various domains of applications. \n \nSimulations and mathematical formulations were provided to support our ideas and concepts related to the design of the paradigm. An actual program in Java was developed to support our concept of a virtual machine for incremental interaction context.",
        "year": 2010,
        "url": "https://www.semanticscholar.org/paper/c82c1cddcc94288aa8a68645ef84a0b98c6cde26",
        "citation_count": 1
    },
    {
        "title": "Predicting the behavioral intentions of hospice and palliative care providers from real-world data using supervised learning: A cross-sectional survey study",
        "abstract": "Background Hospice and palliative care (HPC) aims to improve end-of-life quality and has received much more attention through the lens of an aging population in the midst of the coronavirus disease pandemic. However, several barriers remain in China due to a lack of professional HPC providers with positive behavioral intentions. Therefore, we conducted an original study introducing machine learning to explore individual behavioral intentions and detect factors of enablers of, and barriers to, excavating potential human resources and improving HPC accessibility. Methods A cross-sectional study was designed to investigate healthcare providers' behavioral intentions, knowledge, attitudes, and practices in hospice care (KAPHC) with an indigenized KAPHC scale. Binary Logistic Regression and Random Forest Classifier (RFC) were performed to model impacting and predict individual behavioral intentions. Results The RFC showed high sensitivity (accuracy = 0.75; F1 score = 0.84; recall = 0.94). Attitude could directly or indirectly improve work enthusiasm and is the most efficient approach to reveal behavioral intentions. Continuous practice could also improve individual confidence and willingness to provide HPC. In addition, scientific knowledge and related skills were the foundation of implementing HPC. Conclusion Individual behavioral intention is crucial for improving HPC accessibility, particularly at the initial stage. A well-trained RFC can help estimate individual behavioral intentions to organize a productive team and promote additional policies.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/c82d04328fb34e7c6adc012ebf997c3f32b5787d",
        "citation_count": 2
    },
    {
        "title": "A labeled medical records corpus for the timely detection of rare diseases using machine learning approaches",
        "abstract": null,
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/c8b7c4b54758a1cf3db004f02d2a8e8f04572eea",
        "citation_count": 0
    },
    {
        "title": "Biosignal And Medical Image Processing Third Edition",
        "abstract": "Machine Learning in Bio-Signal Analysis and Diagnostic Imaging presents original research on the advanced analysis and classification techniques of biomedical signals and images that cover both supervised and unsupervised machine learning models, standards, algorithms, and their applications, along with the difficulties and challenges faced by healthcare professionals in analyzing biomedical signals and diagnostic images. These intelligent recommender systems are designed based on machine learning, soft computing, computer vision, artificial intelligence and data mining techniques. Classification and clustering techniques, such as PCA, SVM, techniques, Naive Bayes, Neural Network, Decision trees, and Association Rule Mining are among the approaches presented. The design of high accuracy decision support systems assists and eases the job of healthcare practitioners and suits a variety of applications. Integrating Machine Learning (ML) technology with human visual psychometrics helps to meet the demands of radiologists in improving the efficiency and quality of diagnosis in dealing with unique and complex diseases in real time by reducing human errors and allowing fast and rigorous analysis. The book's target audience includes professors and students in biomedical engineering and medical schools, researchers and engineers. Examines a variety of machine learning techniques applied to bio-signal analysis and diagnostic imaging Discusses various methods of using intelligent systems based on machine learning, soft computing, computer vision, artificial intelligence and data mining Covers the most recent research on machine learning in imaging analysis and includes applications to a number of domains Advanced techniques in image processing have led to many innovations supporting the medical field, especially in the area of disease diagnosis. Biomedical imaging is an essential part of early disease detection and often considered a first step in the proper management of medical pathological conditions. Classification and Clustering in Biomedical Signal Processing focuses on existing and proposed methods for medical imaging, signal processing, and analysis for the purposes of diagnosing and monitoring patient conditions. Featuring the most recent empirical research findings in the areas of signal processing for biomedical applications with an emphasis on classification and clustering techniques, this essential publication is designed for use by medical professionals, IT developers, and advanced-level graduate students. With the advances in image guided surgery for cancer treatment, the role of image segmentation and registration has become very critical. The central engine of any image guided surgery product is its ability to quantify the organ or segment the organ whether it is a magnetic resonance imaging",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c8e170cf3fce5b4ed9b67a130ba8ffa7fef3c024",
        "citation_count": 4
    },
    {
        "title": "On the identification of thyroid nodules using semi\u2010supervised deep learning",
        "abstract": "Detecting malign cases from thyroid nodule examinations is crucial in healthcare particularly to improve the early detection of such cases. However, malign thyroid nodules can be extremely rare and is hard to find using the traditional rule based or expert\u2010based methods. For this reason, the solutions backed by Machine Learning (ML) algorithms are key to improve the detection rates of such rare cases. In this paper, we investigate the application of ML in the healthcare domain for the detection of rare thyroid nodules. The utilized dataset is collected from 636 distinct patients in 99 unique days in Turkey. In addition to the texture feature data of the Ultrasound (US), we have also included the scores of different assessment methods created by different health institutions (e.g., Korean, American and European thyroid societies) as additional features. For detection of extremely rare malign cases, we use auto\u2010encoder based neural network model. Through numerical results, it is shown that the auto\u2010encoder based model can result in an average Recall score of 0.98 and a Sensitivity score of 1.00 for detecting malign and non\u2010malign cases from the healthcare dataset outperforming the traditional classification algorithms that are trained after Synthetic Minority Oversampling Technique (SMOTE) oversampling.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/c8e8aa5831316feaf24a93901874d27f700ae06e",
        "citation_count": 7
    },
    {
        "title": "Safety in medical simulation\u2013overlooked or underappreciated?",
        "abstract": null,
        "year": 2011,
        "url": "https://www.semanticscholar.org/paper/c8f3b72513393b181186890bc9de5c293786d0bb",
        "citation_count": 2
    },
    {
        "title": "eGAP: An Evolutionary Game Theoretic Approach to Random Forest Pruning",
        "abstract": "To make healthcare available and easily accessible, the Internet of Things (IoT), which paved the way to the construction of smart cities, marked the birth of many smart applications in numerous areas, including healthcare. As a result, smart healthcare applications have been and are being developed to provide, using mobile and electronic technology, higher diagnosis quality of the diseases, better treatment of the patients, and improved quality of lives. Since smart healthcare applications that are mainly concerned with the prediction of healthcare data (like diseases for example) rely on predictive healthcare data analytics, it is imperative for such predictive healthcare data analytics to be as accurate as possible. In this paper, we will exploit supervised machine learning methods in classification and regression to improve the performance of the traditional Random Forest on healthcare datasets, both in terms of accuracy and classification/regression speed, in order to produce an effective and efficient smart healthcare application, which we have termed eGAP. eGAP uses the evolutionary game theoretic approach replicator dynamics to evolve a Random Forest ensemble. Trees of high resemblance in an initial Random Forest are clustered, and then clusters grow and shrink by adding and removing trees using replicator dynamics, according to the predictive accuracy of each subforest represented by a cluster of trees. All clusters have an initial number of trees that is equal to the number of trees in the smallest cluster. Cluster growth is performed using trees that are not initially sampled. The speed and accuracy of the proposed method have been demonstrated by an experimental study on 10 classification and 10 regression medical datasets.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/c9725bf4656b6b556978e601c197f6305a92204d",
        "citation_count": 4
    },
    {
        "title": "Identification of Best Classifier Method for Aphasia Classification",
        "abstract": "Aphasia is a disorder, causing someone to lose communication abilities which is resulted from brain damage on the part for linguistic abilities. Speech therapy is the primary treatment for individuals with aphasia, but access to therapy can be limited by a number of factors, including distance, cost, and availability of healthcare professionals. Telerehabilitation has emerged as an approach to delivering speech therapy services to individuals with aphasia, overcoming barriers associated with in-person therapy. Speech therapy telerehabilitation based on the Western Aphasia Battery (WAB) was designed and developed as mobile applications system in this study. The mobile apps tests four of the user communication skills, which are the ability to read, write, understanding the communication, and naming things, as advised by the speech therapy specialist. This study focused on the usage of developed mobile application for Malay- speaking people with aphasia and classifying aphasia using various supervised machine learning to identify best classifier methods for it. Five healthy participants and twenty aphasia patients participated in this study. Sequential machine learning methods consisted of decision tree, k-nearest neighbor, logistic regression, sequential minimal optimization for support vector classifier and the machine learning ensemble methods which were AdaBoost, and random forest, are used for analysis of the data collected from the developed mobile apps system. The study focused on evaluating the performance of various supervised machine learning methods in classifying healthy individuals and aphasia patients based on their scores and time taken for completing the exercise and identifying the best machine learning methods. Machine learning ensemble methods are very proficient in classification between healthy individual and aphasia people.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/ca2373d8690fecc6459a069a40eda95e0a725c7e",
        "citation_count": 0
    },
    {
        "title": "Classification of Sleep Stages Using Machine Learning Methods",
        "abstract": "This dissertation was written as a part of the MSc in Data Science at the International Hellenic University. Sleep is a necessary part in every human\u2019s life. Effective diagnosis and treatment of patients with sleep-related complaints is currently an urgent and heavily researched topic in the healthcare community. Sleep stage classification was introduced almost 50 years ago and manual approaches are sometimes used until today. Automatic sleep stage classification using machine learning can increase consistency and reliability, assisting experts at diagnosing sleep related health problems. In this dissertation, multiple classifiers are tested on 3 different datasets of healthy and patient subjects. The optimal algorithm achieves accuracy over 90% for the healthy subjects\u2019 dataset. In the results, the difference between the EEG patterns of healthy and patient subjects is highlighted. It is finally concluded that, using mixed datasets from healthy people and patients with minor sleep disorders, decent classification accuracies can be achieved. In addition to that, algorithms can generalize better as they can be used for a larger number of people. I would first like to thank my thesis supervisor Professor Konstantinos Diamantaras for giving me the chance to elaborate on such an interesting field of research. His guidance and technical tips were valuable and crucial for the completion of this study. I would also like to thank the thesis co-supervisor Assistant Professor Ioanna Chouvarda who provided her valuable experience as an expert on the sleep stage classification problem. My deepest gratitude goes to my family for their support, encouragement and patience throughout all the years of my studies.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/ca36830ca129981b9164ce31d47154526e1fc9cd",
        "citation_count": 2
    },
    {
        "title": "HYBRID MODEL FOR BEHAVIOUR-BASED RECOMMENDER SYSTEM : A HEALTHCARE PERSPECTIVE",
        "abstract": "As medicine moves ahead, there is indigence for sophisticated decision support systems to make real-time predictions. It provides the ability to sense and acclimate to the needs and inclination, and provides decision support for domain experts and individuals. This paper elaborates the feasibility of providing personalized recommendation for healthcare. A healthcare system must ensure information quality, influences perceived usefulness and perceived usability, both mediated by the trust. Besides, researchers often measure information quality in terms of relevance, accuracy, timeliness, completeness, and consistency. This research work tries to enhance the information quality by analyzing the Personal Health Record to provide individual based personalized recommendation, prediction based on the behavior and disease, predicting the patterns that forecast the incidence of disease in human races. The proposed model will learn from the personal health record samples by employing multi-class supervised machine learning technique to generate accurate predictions. This approach recommends life style modification based on the behavior of the user using hybrid filtering; thereby enhance the health of our communities and the nation.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/ca63242e42f27e00834d778bf39bd2f9b15ab01c",
        "citation_count": 0
    },
    {
        "title": "Supervising Healthcare Schemes Using Machine Learning in Breast Cancer and Internet of Things (SHSMLIoT)",
        "abstract": null,
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/ca6440c9ffa1c908d10f6b5af967f3acbe157c15",
        "citation_count": 5
    },
    {
        "title": "Bone Health Classification using Machine Learning",
        "abstract": "Osteoporosis is a serious medical condition. Currently, the healthcare system employs a number of techniques to identify osteoporosis at an early stage. However, these techniques are damaging to skin and tissue, ineffective economically, and difficult to carry around. Microwaves have become more widely used in the medical field recently. It is a non-ionizing, non-invasive method that causes minor tissue damage. Previously, the Bone Health Analyser was designed using a microstrip patch antenna for frequencies ranging from 3GHz to 8GHz, and it was discovered that at lower frequencies, the transfer characteristics of the antenna for different bones are more distinct and easier to classify. Thus, in this paper, microwave signal ranging from 1.5GHz to 4.5GHz is transmitted from a Bow-Tie antenna, and a change in attenuation of the signal is received at another Bow - tie antenna. The simulated signal attenuation (S21) is recorded as it passes through various osteoporotic bones. The motive behind this research is to classify the different stages of osteoporosis using machine learning. Three supervised classification algorithms, Support Vector Machine for Classification (SVC), Random Forest (RF), and Decision Tree (DT) are applied to classify the different stages and their performance is analyzed. Features are extracted from attenuated signals and used to train the model. The results demonstrate that implementing machine learning to classify stages of osteoporosis is promising.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/ca76d02acc7f098022e5e26258fe43fccaa9970f",
        "citation_count": 2
    },
    {
        "title": "Optimizing Diabetes Prediction: An Evaluation of Machine Learning Models Through Strategic Feature Selection",
        "abstract": "Diabetes, a widespread chronic ailment in the United States, imposes significant economic and health burdens, impacting quality of life and life expectancy. This study analyzes a clinical dataset of 253,680 patients from the Behavioral Risk Factor Surveillance System (BRFSS). The dataset encompasses 21 predictors, including high blood pressure, cholesterol, body mass index (BMI), smoking, stroke, heart disease, physical activity, fruit consumption, vegetable consumption, alcohol consumption, insurance coverage, lack of medical visits due to financial constraints, general health, days with mental health issues, days with physical injuries in the past 30 days, difficulties in walking, gender, age, income, and education level. The objective is to balance the training dataset, compare different supervised machine learning models, and identify critical clinical features contributing to diabetes using unsupervised feature selection methods. A total of 34 machine learning models in MATLAB2023a were trained and compared. Quadratic Support Vector Machine (SVM), Coarse Gaussian SVM, and Narrow Neural Networks achieved the highest training accuracy (76.3%), while the Bilayered Neural Network attained 74.7% on an unseen test dataset. Among all, Quadratic SVM demonstrated the best overall performance based on average accuracy, precision, recall, and F1 score. Feature selection highlighted nine key predictors: high blood pressure, high cholesterol, BMI, heart disease, physical activity, general health, recent bodily injuries, mobility issues, and age. A model trained on these features achieved a commendable accuracy of 75.4%, demonstrating the feasibility of a simplified, efficient diagnostic tool with a diagnostic efficacy of 0.7.\nThis study underscores the potential of streamlined models to predict diabetes with fewer parameters while maintaining high accuracy, offering a valuable tool for healthcare diagnostics.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/caaef25fe1b481d6d8f89317575e86734e5e9c14",
        "citation_count": 0
    },
    {
        "title": "Predicting 30-day Readmission in Heart Failure using Machine Learning Techniques",
        "abstract": "Heart Failure (HF) is a syndrome that reduces patients\u2019 quality of life, and has severe impacts on healthcare systems worldwide, such as the high rate of readmissions. In order to reduce the readmissions and improve patients\u2019 quality of life, several studies are trying to assess the risk of a patient to be readmitted, so that taking right actions clinicians can prevent patient deterioration and readmission. Predictive models have the ability to identify patients at high risk. Henceforth, this paper studies predictive models to determine the risk of a HF patient to be readmitted in the next 30 days after discharge. We present two different approaches. In the first one, we combine unsupervised and supervised classification and achieved AUC score of 0.64. In the second one, we combine decision tree and Na\u00efve Bayes classifiers and achieved AUC score of 0.61. Additionally, we discover that the results improve when training the predictive models with different readmission\u2019s threshold outcome, reaching the AUC score of 0.73 when applying the first approach.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/cb01d072e6d9de1464dceaca2706fc7781d544cc",
        "citation_count": 13
    },
    {
        "title": "Supervised Machine Learning Models for COVID-19 Prediction",
        "abstract": "The COVID-19 pandemic had a profound impact on global public health, resulting in millions of deaths worldwide. Understanding the factors influencing patient survival outcomes is crucial.This study conducts a comparative analysis of various supervised machine learning models to predict COVID-19 survivors. The dataset sourced from Kaggle repository containing 373 records; however, only 74 records were selected for analysis due to missing data in several feature variables. The outliers were addressed using the Z-Score method, while missing values were imputed using Multiple Imputation by Chained Equations (MICE).We partitioned the dataset into two distinct subsets: 80% (59 data points) for training and 20% (15 data points) for testing. Supervised classification models, including Support Vector Machine, Random Forest, Naive Bayes, Logistic Regression, Decision Tree, and Artificial Neural Network, were employed. The results indicated that the Random Forest model outperformed the others in predicting COVID-19 survivors, with an accuracy of 0.97\u00b10.06, followed by Naive Bayes with an accuracy of 0.75\u00b10.12. This findings demonstrate that Oxygen levels and Age emerge as strong predictors of COVID-19 severity; thus guiding patient outcomes and healthcare services.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/cb229e61a1397140d961c349e950fcd5286d5658",
        "citation_count": 0
    },
    {
        "title": "Convolutional Neural Network based Framework for Automatic Lung Cancer Detection from Lung CT Images",
        "abstract": "Lung cancer is one of the major causes of death across the globe. Medical interventions with modern healthcare facilities are widely used to cure lung cancer. However, it is indispensable to have research on early detection of lung cancer as it has potential to save lives of people. With innovations in machine learning Computer Aided Design (CAD) systems for automatic detection of lung cancer has become an important solution. Particularly deep learning models such as Convolutional Neural Network (CNN) is found to have necessary mechanisms to learn features from Computed Tomography (CT) scan images and detect the probability of lung cancer. In this paper, we propose a CNN based model for automatic detection of lung cancer provided lung CT scan image. We proposed an algorithm known as CNN based Automatic Lung Cancer Detection (CNN-ALCD) which is based on supervised learning phenomenon. The learned model is capable of detecting lung cancer from any newly arrived test sample. The proposed solution has different mechanisms such as preprocessing, building CNN with different layers, training the CNN model and performing lung cancer detection. Empirical study revealed that the proposed CNN based model outperforms many existing neural network-based methods with highest accuracy 94.11%. Therefore, the proposed system can be integrated with a Clinical Decision Support System (CDSS) in healthcare units for automatic diagnosis of lung cancer.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/cb6fd547b1520644a940c9419d58de1a4f74e395",
        "citation_count": 12
    },
    {
        "title": "Machine learning models predicting multidrug resistant urinary tract infections using \u201cDsaaS\u201d",
        "abstract": null,
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/cbab220b3516829b415eefbeb6b7a1fbdd5fc1d0",
        "citation_count": 39
    },
    {
        "title": "Application of Latent Semantic Analysis and Supervised Learning Methods to Automate Triage of Referral Letters for Spinal Surgery",
        "abstract": "Referral letters are the most common mean used by healthcare practitioners to exchange information relevant to patient care. However, their triage takes a significant amount of administrative resources, which may be amenable to automation. This study aims to evaluate a pilot study for automating the triage of referral letters sent to a spine surgery department in secondary care using Natural Language Processing (NLP) techniques and supervised machine learning methods. Text data in referral letters were represented using Term Frequency-Inverse Document Frequency (TF-IDF) scores and Latent Semantic Analysis (LSA) and fed into supervised learning models to classify it into urgent and non-urgent. Their outcomes have been evaluated using performance metrics (precision, recall, F1, area under the curve (AUC), and accuracy), and their clinical value is assessed based on decision curve analysis. The AdaBoost classifier obtained the maximum AUC score (61.8%) in the test set. The model also reached an F1 score of 53.1% with 48.6% and 58.6% of recall and precision scores, respectively. Comparing its net benefit against baseline clinical alternatives proves that the model has potential clinical value, and it might be a valuable tool for automating the referrals\u2019 triaging process. This study successfully demonstrated the potential for automating the triage of referrals and provides a foundation for further work.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/cbc55cd9fc01891d989408d645778f2a26bf1db2",
        "citation_count": 0
    },
    {
        "title": "Machine Learning Algorithms, Perspectives, and Real - World Application: Empirical Evidence from United States Trade Data",
        "abstract": ": Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without being explicitly programmed. It is one of today\u2019s most rapidly growing technical fields, lying at the crossroads of computer science and statistics, and at the core of artificial intelligence (AI) and data science. Various types of machine learning algorithms such as supervised, unsupervised, semi - supervised, and reinforcement learning exist in this area. Recent progress in ML has been driven both by the development of new learning algorithms theory, and by the ongoing explosion in the availability of vast amount of data (commonly known as \u201cbig - data\u201d) and low - cost computation. The adoption of data - intensive ML - based methods can be found throughout science, technology, and commerce, leading to more evidence - based decision - making across many walks of life, including finance, manufacturing, international trade, economics, education, healthcare, marketing, policymaking, and data governance. The present paper provides a comprehensive view on these machine learning algorithms that can be applied to enhance the intelligence and capabilities of an application. Moreover, the paper attempts to determine the accurate clusters of similar industries in United States that collectively account for more than 85 percent of economy\u2019s aggregate export and import flows over the period 2002 - 2021 through clustering algorithm (unsupervised learning). Four clusters of mapping labels have been used, namely the low investment (LL), category 1 medium investment (HL), category 2 medium investment (LH) and high investment (HH). The empirical results indicate that machinery and electrical equipment is classified as a high investment sector due to its efficient production mechanism. The analysis further underlines the need for upstream value chain integration through skill - augmentation and innovation especially in low investment industries. Overall, this paper aims to explain the trends of ML approaches and their applicability in various real - world domains, as well as serve as a reference point for academia",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/cc268c4a5162cd25484f7045780c9ca13828d670",
        "citation_count": 4
    },
    {
        "title": "Introduction to Gaussian Processes",
        "abstract": "Adaptive and Natural Computing AlgorithmsAdvances in Knowledge Discovery and Data MiningLectures on Gaussian ProcessesAn introduction to continuity and related topics for general Gaussian ProcessesLarge Deviations for Gaussian QueuesGaussian Markov Random FieldsAsymptotic Methods in the Theory of Gaussian Processes and FieldsModelling and Control of Dynamic Systems Using Gaussian Process ModelsAn Introduction to Continuity, Extrema, and Related Topics for General Gaussian ProcessesThe Gaussian Approximation PotentialAn Introduction to Continuity, Extrema, and Related Topics for General Gaussian ProcessesStochastic Analysis for Gaussian Random Processes and FieldsMachine LearningNeural Networks and Machine LearningBayesian Time Series ModelsGraphical Models for Machine Learning and Digital CommunicationMarkov Processes, Gaussian Processes, and Local TimesThe Generic ChainingTime Series AnalysisProbability in Banach SpacesDark DataMachine LearningSurrogatesIntroduction and Implementations of the Kalman FilterMachine Learning and Knowledge Discovery in DatabasesLearning Kernel ClassifiersThe Concentration of Measure PhenomenonBayesian Data Analysis, Third EditionKernels for Vector-Valued FunctionsAdvanced Lectures on Machine LearningGaussian Processes for Machine LearningEfficient Reinforcement Learning Using Gaussian ProcessesGaussian Process Regression Analysis for Functional DataGaussian Processes on TreesBayesian Learning for Neural NetworksReinforcement Learning and Optimal ControlInterpolation of Spatial DataQuantum Processes Systems, and InformationHigh-Dimensional ProbabilityIntroduction to Empirical Processes and Semiparametric Inference The three volume proceedings LNAI 11906 \u2013 11908 constitutes the refereed proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2019, held in W\u00fcrzburg, Germany, in September 2019. The total of 130 regular papers presented in these volumes was carefully reviewed and selected from 733 submissions; there are 10 papers in the demo track. The contributions were organized in topical sections named as follows: Part I: pattern mining; clustering, anomaly and outlier detection, and autoencoders; dimensionality reduction and feature selection; social networks and graphs; decision trees, interpretability, and causality; strings and streams; privacy and security; optimization. Part II: supervised learning; multi-label learning; large-scale learning; deep learning; probabilistic models; natural language processing. Part III: reinforcement learning and bandits; ranking; applied data science: computer vision and explanation; applied data science: healthcare; applied data science: e-commerce, finance, and advertising; applied data science: rich data; applied data science: applications; demo track. Chapter \"Incorporating Dependencies in Spectral Kernels for Gaussian Processes\" is available open access under a Creative Commons Attribution 4.0 International License via link.springer.com.This book is devoted to a systematic analysis of asymptotic behavior of distributions of various typical functionals of Gaussian random variables and fields. The text begins with an extended introduction, which explains fundamental ideas and sketches the basic methods fully presented later in the book. Good approximate formulas and sharp estimates of the remainders are obtained for a large class of Gaussian and similar processes. The author devotes special attention to the development of asymptotic analysis methods, emphasizing the method of comparison, the double-sum method and the method of moments. The author has added an extended introduction and has significantly revised the text for this translation, particularly the material on the double-sum method.This monograph opens up new horizons for engineers and researchers in academia and in industry dealing with or interested in new developments in the field of system identification and control. It emphasizes guidelines for working solutions and practical advice for their implementation rather than the theoretical background of Gaussian process (GP) models. The book demonstrates the potential of this recent development in probabilistic machine-learning methods and gives the reader an intuitive understanding of the topic. The current state of the art is treated along with possible future directions for research. Systems control design relies on mathematical models and these may be developed from measurement data. This process of system identification, when based on GP models, can play an integral part of control design in data-based control and its description as such is an essential aspect of the text. The background of GP regression is introduced first with system identification and incorporation of prior knowledge then leading into full-blown control. The book is illustrated by extensive use of examples, line drawings, and graphical presentation of computer-simulation results and plant measurements. The research results presented are applied in real-life case studies drawn from successful applications including: a gas\u2013liquid separator control; urban-traffic signal modelling and reconstruction; and prediction of atmospheric ozone concentration. A MATLAB\u00ae toolbox, for identification and simulation of dynamic GP models is provided for download.Sensor data fusion is the process of combining error-prone, heterogeneous, incomplete, and ambiguous data to gather a higher level of situational awareness. In principle, all living creatures are fusing information from their complementary senses to coordinate their actions and to detect and localize danger. In sensor data fusion, this process is transferred to electronic systems, which rely on some \"awareness\" of what is happening in certain areas of interest. By means of probability theory and statistics, it is possible to model the relationship between the state space and the sensor data. The number of ingredients of the resulting Kalman filter is limited, but its applications are not.Kosorok\u2019s brilliant text provides a self-contained introduction to empirical processes and semiparametric inference. These powerful research techniques are surprisingly useful for developing methods of statistical inference for complex models and in understanding the properties of such methods. This is an authoritative text that covers all the bases, and also a friendly and gradual introduction to the area. The book can be used as research reference and textbook.The two-volume set LNAI 12084 and 12085 constitutes the thoroughly refereed proceedings of the 24th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2020, which was due to be held in Singapore, in May 2020. The conference was held virtually due to the COVID-19 pandemic. The 135 full papers presented were carefully reviewed and selected from 628 submissions. The papers present new ideas, original research results, and practical development experiences from all KDD related areas, including data mining, data warehousing, machine learning, artificial intelligence, databases, statistics, knowledge engineering, visualization, decision-making systems, and the emerging applications. They are organized in the following topical sections: recommender systems; classification; clustering; mining social networks; representation learning and embedding; mining behavioral data; deep learning; feature extraction and selection; human, domain, organizational and social factors in data mining; mining sequential data; mining imbalanced data; association; privacy and security; supervised learning; novel algorithms; mining multimedia/multi-dimensional data; application; mining graph and network data; anomaly detection and analytics; mining spatial, temporal, unstructured and semi-structured data; sentiment analysis; statistical/graphical model; multi-source/distributed/parallel/cloud computing.Isoperimetric, measure concentration and random",
        "year": 2008,
        "url": "https://www.semanticscholar.org/paper/cc2a5a9d07e46484422cc7628486f31f4b2fe074",
        "citation_count": 725
    },
    {
        "title": "Applying natural language processing and machine learning techniques to patient experience feedback: a systematic review",
        "abstract": "Objectives Unstructured free-text patient feedback contains rich information, and analysing these data manually would require a lot of personnel resources which are not available in most healthcare organisations.To undertake a systematic review of the literature on the use of natural language processing (NLP) and machine learning (ML) to process and analyse free-text patient experience data. Methods Databases were systematically searched to identify articles published between January 2000 and December 2019 examining NLP to analyse free-text patient feedback. Due to the heterogeneous nature of the studies, a narrative synthesis was deemed most appropriate. Data related to the study purpose, corpus, methodology, performance metrics and indicators of quality were recorded. Results Nineteen articles were included. The majority (80%) of studies applied language analysis techniques on patient feedback from social media sites (unsolicited) followed by structured surveys (solicited). Supervised learning was frequently used (n=9), followed by unsupervised (n=6) and semisupervised (n=3). Comments extracted from social media were analysed using an unsupervised approach, and free-text comments held within structured surveys were analysed using a supervised approach. Reported performance metrics included the precision, recall and F-measure, with support vector machine and Na\u00efve Bayes being the best performing ML classifiers. Conclusion NLP and ML have emerged as an important tool for processing unstructured free text. Both supervised and unsupervised approaches have their role depending on the data source. With the advancement of data analysis tools, these techniques may be useful to healthcare organisations to generate insight from the volumes of unstructured free-text data.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/cc375e2130cae2bc1f390a6c84a0258bbf9971a8",
        "citation_count": 92
    },
    {
        "title": "Early prediction of nephropathy chronic with supervised machine learning algorithms and feature selection method",
        "abstract": "The application of technology for detecting chronic kidney disease was vital in preventing serious health complications. In today\u2019s medical landscape, this technological advancement empowered physicians to promptly and accurately interpret diseases, thereby improving patient care and outcomes. Predicting chronic kidney diseases held immense importance due to its significant implications for public health. Despite the efforts of numerous researchers over the years to develop precise prediction models, this field encountered significant challenges stemming from inadequate relevant datasets and suitable prediction methodologies. This research endeavored to tackle these challenges by concentrating on predictive analysis within the healthcare sector, with specific focus on chronic kidney diseases. Two models of supervised machine learning, K-Nearest Neighbors and Gradient Boosting, were employed, utilizing the feature selection method LASSO. The performance of these models was assessed using a separate test dataset. According to our findings, the supervised Gradient Boosting model demonstrated the highest accuracy, indicating its effectiveness in predicting CKD. This underscored the potential of advanced machine learning techniques in improving early detection and management of chronic nephropathy, thereby contributing to better healthcare outcomes.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/cc7eef82847cc5dd8fb4ccb2738284a878d595dd",
        "citation_count": 0
    },
    {
        "title": "Comparative Analysis on Cardiac and Diabetic Disease Prediction Using Machine Learning Techniques",
        "abstract": "Diabetes and cardiac conditions are essentially distinguished by elevated blood glucose levels and cardiovascular disorders, respectively. A diverse array of complex illnesses, including but not limited to heart attack, renal failure, and stroke, are associated with it. Diabetes has a global prevalence of over 422 million people in 2014, making it the most common metabolic disease on the planet. The primary objective of this study is to evaluate and compare the performance of Support Vector Machines (SVM), Decision Trees, Artificial Neural Networks (ANN), and k-nearest Neighbors (KNN) in classifying diabetes and cardiac patients using a specific dataset. The present study serves as a roadmap for future research in predictive analytics for cardiac and diabetes ailments by analyzing current literature and identifying research gaps. The primary objective is to create the way for the generation of robust, accessible, and clinically feasible ML models that can significantly contribute to the early identification and management of these common health conditions, thus enhancing the outcomes of patients as well as decreasing the burden on healthcare systems around the world. Models based on supervised learning algorithms have been discussed along with other interesting findings that are important in developing overall understanding of model for disease prediction algorithms. This study carefully assesses the selected papers and finds gaps in the current literature that will be helpful for researchers to develop and use in clinical domains, especially on heart and diabetic disease data sets. This study will also help medical professionals to identify cardiac and diabetic risks in advance, enabling them to take preventive actions.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/ce1f0f438da617ba1b3ce46ff5b10b7664febfba",
        "citation_count": 0
    },
    {
        "title": "Intelligent Cloud Based Heart Disease Prediction System Empowered with Supervised Machine Learning",
        "abstract": ": The innovation in technologies related to health facilities today is increasingly helping to manage patients with different diseases. The most fatal of these is the issue of heart disease that cannot be detected from a naked eye, and attacks as soon as the human exceeds the allowed range of vital signs like pulse rate, body temperature, and blood pressure. The real challenge is to diagnose patients with more diagnostic accuracy and in a timely manner, followed by prescribing appropriate treatments and keeping prescription errors to a minimum. In developing countries, the domain of healthcare is progressing day by day using different Smart healthcare: emerging technologies like cloud computing, fog computing, and mobile computing. Electronic health records (EHRs) are used to manage the huge volume of data using cloud computing. That reduces the storage, processing, and retrieval cost as well as ensuring the availability of data. Machine learning procedures are used to extract hidden patterns and data analytics. In this research, a combination of cloud computing and machine learning algorithm Support vector machine (SVM) is used to predict heart diseases. Simulation results have shown that the proposed intelligent cloud-based heart disease prediction system empowered with a Support vector machine (SVM)-based system model gives 93.33% accuracy, which is better than previously published approaches.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/ce5b567f602c52b8f3e6812c7e98dda0000b9b39",
        "citation_count": 48
    },
    {
        "title": "Fake It Till You Make It: Guidelines for Effective Synthetic Data Generation",
        "abstract": "Synthetic data provides a privacy protecting mechanism for the broad usage and sharing of healthcare data for secondary purposes. It is considered a safe approach for the sharing of sensitive data as it generates an artificial dataset that contains no identifiable information. Synthetic data is increasing in popularity with multiple synthetic data generators developed in the past decade, yet its utility is still a subject of research. This paper is concerned with evaluating the effect of various synthetic data generation and usage settings on the utility of the generated synthetic data and its derived models. Specifically, we investigate (i) the effect of data pre-processing on the utility of the synthetic data generated, (ii) whether tuning should be applied to the synthetic datasets when generating supervised machine learning models, and (iii) whether sharing preliminary machine learning results can improve the synthetic data models. Lastly, (iv) we investigate whether one utility measure (Propensity score) can predict the accuracy of the machine learning models generated from the synthetic data when employed in real life. We use two popular measures of synthetic data utility, propensity score and classification accuracy, to compare the different settings. We adopt a recent mechanism for the calculation of propensity, which looks carefully into the choice of model for the propensity score calculation. Accordingly, this paper takes a new direction with investigating the effect of various data generation and usage settings on the quality of the generated data and its ensuing models. The goal is to inform on the best strategies to follow when generating and using synthetic data.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/ce883407031150f18a2fec90d83dd8d5698bc9ba",
        "citation_count": 76
    },
    {
        "title": "Predicting the Diagnosis of Type 2 Diabetes Using Electronic Medical Records",
        "abstract": "As of 2013, over 382 million people worldwide have diabetes [5]. Diabetes puts patients at a higher risk for blindness, kidney failure, heart disease, and stroke and it is especially prevalent in the United States in racial groups with low access to healthcare, such as Native Americans (15.9%), African Americans (13.2%) and Hispanics (12.8%) [6]. Although the onset of diabetes mellitus type 2 (DMT2) can be prevented or delayed with behavioral changes, e.g. physical activity or dietary changes, an estimated 27.8% of people with DMT2 in the United States are undiagnosed. In order to improve diagnosis methodologies, supervised and unsupervised machine learning algorithms trained on electronic medical records (EMR) were implemented and evaluated for effectiveness.",
        "year": 2014,
        "url": "https://www.semanticscholar.org/paper/cf02959dabd20175ff0bf852e52275682e526a5f",
        "citation_count": 0
    },
    {
        "title": "PRERISK: A Personalized, daily and AI-based stroke recurrence predictor for patient awareness and treatment compliance",
        "abstract": "BACKGROUND The risk prediction of stroke recurrence for individual patients is a difficult task. Individualised prediction may enhance stroke survivors selfcare engagement. We have developed PRERISK: a statistical and Machine Learning (ML) classifier to predict individual stroke recurrence risk. METHODS We analysed clinical and socioeconomic data from a prospectively collected public healthcare-based dataset of 44623 patients admitted with stroke diagnosis in 88 public hospitals over 6 years in Catalonia-Spain. We trained several supervised-ML models to provide individualised risk along time and compared them with a Cox regression model. RESULTS Overall, 16% of patients presented a stroke recurrence along a median follow-up of 2.65 years. Models were trained for predicting early, late and long-term recurrence risk, within 90, 91-365 and >365 days, respectively. Most powerful predictors of stroke recurrence were time since index stroke, Barthel index, atrial fibrillation, dyslipidemia, haemoglobin and body mass index, which were used to create a simplified model with similar performance. The balanced AUROC were 0.77 ({+/-}0.01), 0.61 ({+/-}0.01) and 0.71 ({+/-}0.01) for early, late and long-term recurrence risk respectively (Cox risk class probability: 0.74({+/-}0.01), 0.59({+/-}0.01) and 0.68({+/-}0.01), c-index 0.88). Overall, the ML approach showed statistically significant improvement over the Cox model. Stroke recurrence curves can be simulated for each patient under different degrees of control of modifiable factors. CONCLUSION PRERISK represents a novel approach that provides continuous, personalised and fairly accurate risk prediction of stroke recurrence along time according to the degree of modifiable risk factors control.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/cf421a14d72630323ab5b3171ae18414e39856f1",
        "citation_count": 0
    },
    {
        "title": "Accurate COVID-19 Health Outcome Prediction and Risk Factors Identification through an Innovative Machine Learning Framework Using Longitudinal Electronic Health Records",
        "abstract": "COVID-19 is a respiratory disease that has caused a worldwide pandemic and put a strain on the global healthcare systems. To better protect and treat higher risk individuals and alleviate the burden on healthcare systems, it is crucial to identify risk factors and build accurate predictive models for COVID-19 related health outcomes. However, current predictive models focus on predicting the risk of mortality, and rely on COVID-19 specific medical data such as CT scans and COVID-19 lab tests results after a positive COVID-19 diagnosis. To address these issues, we developed an innovative supervised machine learning framework using synthetic veteran Electronic Health Records (EHR) which were routinely collected during past clinic visits. Our models accurately predicted COVID-19 related health outcomes including mortality, ventilation, days in hospital or ICU. In particular, we developed a series of unique and effective data processing algorithms, including data cleaning, vector representation, initial feature screening. Then we trained models using state-of-the-art machine learning strategies combined with different parameter settings. Our machine learning pipeline not only consistently outperformed those developed by other research groups using the same set of EHR, but also achieved similar accuracy as those trained on medical data that were only available after COVID-19 diagnosis. In addition, top risk factors for COVID-19 were identified, which include age, diabetes, metabolic syndromes, heart disease, kidney disease etc., and are consistent with epidemiology findings. Built on veteran\u2019s EHR, our results were especially relevant to veterans and filled in the gap of missing COVID-19 research for veterans who are at much higher risk of severe COVID-19 illness than the general population. This project also demonstrated that longitudinal EHR data can be successfully leveraged to provide a holistic prediction of an individual\u2019s health risk based on past health records, which is critical for controlling emerging infectious diseases such as COVID-19.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/cf7d897c1717ece3278f0169912bd0bd02e68b5e",
        "citation_count": 4
    },
    {
        "title": "Learning self-supervised molecular representations for drug\u2013drug interaction prediction",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/cf8ec487982eecef1cee464fe0312893d308c1d9",
        "citation_count": 6
    },
    {
        "title": "Towards Enhanced Breast Cancer Prediction: A Comparative Evaluation Study",
        "abstract": "Breast cancer remains a foremost cause of mortality among and prevalent malignancy globally, constituting 30 % of all cancer diagnoses in women as of 2022. Timely detection of cancer before metastasis and accurate diagnosis of tumors as malignant poses a significant challenge in healthcare. Deploying accurate predictive models is crucial for facilitating life-saving early interventions. This study presents a comparative evaluation of Machine Learning (ML) classification algorithms for tumor type through the analysis of patient tumor structure quantification. Our research employed supervised ML algorithms that distinguish between malignant and benign tumors using tuning parameters to discern the optimal configurations for multiplying precision and minimizing the error rates. Additionally, a comparative analysis of K-Nearest Neighbors (KNN), Logistic Regression (LR), and Random Forest (RF) algorithms is carried out. The study's findings highlight the superiority of the RF Classification model, which attained an impressive 97 % accuracy, surpassing KNN and LR, with recorded accuracies of 96% and 94 %, respectively. Furthermore, performance metrics such as accuracy, precision, recall, f1-score, true and false positive and negative rates, and area under the Receiver Operating Curve (ROC) were applied for a comprehensive analysis of the algorithms. The results reveal improved accuracy compared to existing literature by 0.9 %. Although limited to a single dataset, our methodology shows promising results for real-world applications using analogous input parameters. Future research should aim for the application of advanced tuning encompassing Deep Learning and Neural Networks.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/cffa0a6af32f2eaca37f68d02f5f45cd180e8374",
        "citation_count": 0
    },
    {
        "title": "Active Media Technology - 8th International Conference, AMT 2012, Macau, China, December 4-7, 2012. Proceedings.",
        "abstract": "Active Media Data Mining and Machine Learning Techniques.- Movie Genre Classification Using SVM with Audio and Video Features.- Automatic Player Behavior Analyses from Baseball Broadcast Videos.- Hot Topic Detection in News Blogs from the Perspective of W2T.- A Clustering Ensemble Based on a Modified Normalized Mutual Information Metric.- Influence of Erroneous Pairwise Constraints in Semi-supervised Clustering.- User Correlation Discovery and Dynamical Profiling Based on Social Streams.- Extraction of Human Social Behavior from Mobile Phone Sensing.- Continuity of Defuzzification on L2 Space for Optimization of Fuzzy Control.- A On-Line News Documents Clustering Method.- Agent-Based Applications and Multi-agent Systems Distributed Protocols for Multi-Agent Coalition Formation: A Negotiation Perspective.- Multi-agent Liquidity Risk Management in an Interbank Net Settlement System.- An Enhanced Mechanism for Agent Capability Reuse.- A Bayesian Network Approach to Investigating User-Robot Personality Matching.- Modelling Multi-Criteria Decision Making Ability of Agents in Agent-Based Rice Pest Risk Assessment Model.- Agent Based Assistance for Electric Vehicles - An Evaluation.- Ubiquitous Intelligent Devices and Systems.- Event Calculus-Based Adaptive Services Composition Policy for AmI Systems.- QoS- and Resource-Aware Service Composition and Adaptation.- An Event-Driven Energy Efficient Framework for Wearable Health-Monitoring System.- Learning Style Model for e-Learning Systems.- A Trajectory-Based Recommender System for Tourism.- An Adaptive Method for the Tag-Rating-Based Recommender System.- Comparative Study of Joint Decision-Making on Two Visual Cognition Systems Using Combinatorial Fusion.- Active Media Based Information Retrieval and Processing.- Research on Touch as a Means of Interaction in Digital Art.- Perceptual Image Hashing with Histogram of Color Vector Angles.- Data Hiding Method Based on Local Image Features.- Fast Flow Visualization on CUDA Based on Texture Optimization.- A Message Passing Graph Match Algorithm Based on a Generative Graphical Model.- Fast Content-Based Retrieval from Online Photo Sharing Sites.- Interactive Exploration of Image Collections on Mobile Devices.- The Derived Kernel Based Recognition Method of Vehicle Type.- An Approach to Define Flexible Structural Constraints in XQuery.- DC Stream Based JPEG Compressed Domain Image Retrieval.- Semantic Computing for ActiveMedia, Social Networks, and AMT-Based Systems A Comparative Study of Community Structure Based Node Scores for Network Immunization.- Semantic Precision and Recall for Evaluating Incoherent Ontology Mappings.- A Self-organization Method for Reorganizing Resources in a Distributed Network.- Extracting Property Semantics from Japanese Wikipedia.- An Ontology Based Privacy Protection Model for Third-Party Platform.- Evaluating Ontology-Based User Profiles.- Semantic Information with Type Theory of Acyclic Recursion.- Pyxis: An Active Replication Approach for Enhancing Social Media Services.- Social Network Analysis of Virtual Worlds.- Active Media Framework for Network Processing Components.- Semantic Network Monitoring and Control over Heterogeneous Network Models and Protocols.- International Workshop on Meta-synthesis and Complex Systems.- Opinion Dynamics on Triad Scale Free Network.- Distribution of Node Characteristics in Complex Networks of Tree Class.- Dynamic Mergers Drive Industrial Competition Evolution: A Network Analysis Perspective.- A Study of Collective Action Threshold Model Based on Utility and Psychological Theories.- Recognition of Online Opinion Leaders Based on Social Network Analysis.- Critical Infrastructure Management for Telecommunication Networks.- Developing Self-Organizing Systems by Policy-Based Self-Organizing Multi-Agent Systems.- On Prioritized 2-tuple Ordered Weighted Averaging Operators.- Special Session on Social Knowledge Discovery and Management.- A Novel Collaboration Partner Model Based on the Personal Relationships of SNS.- An Innovative Way for Mining Clinical and Administrative Healthcare Data.- An Adaptive Recommendation System for Museum Navigation.- Adaptive SVM-Based Classification Systems Based on the Improved Endocrine-Based PSO Algorithm.- A Probability Model for Recognition of Dynamic Gesture Based on a Finger-Worn Device.- Design of a Situation-Aware System for Abnormal Activity Detection of Elderly People.- Special Session on Human-Computer Interaction and Knowledge Discovery from Big Data.- Revealing Cultural Influences in Human Computer Interaction by Analyzing Big Data in Interactions.- Predicting Student Exam's Scores by Analyzing Social Network Data.- SPTrack: Visual Analysis of Information Flows within SELinux Policies and Attack Logs.- Using Mixed Node Publication Network Graphs for Analyzing Success in Interdisciplinary Teams.- On Text Preprocessing for Opinion Mining Outside of Laboratory Environments.- Human Involvement in Designing an Information Quality Assessment Technique - Demonstrated in a Healthcare Setting.- On Applying Approximate Entropy to ECG Signals for Knowledge Discovery on the Example of Big Sensor Data.- Towards a Framework Based on Single Trial Connectivity for Enhancing Knowledge Discovery in BCI.",
        "year": 2012,
        "url": "https://www.semanticscholar.org/paper/d0d36b11abcc5990a5fbce2356b6737e9751682c",
        "citation_count": 1
    },
    {
        "title": "A supervised machine learning statistical design of experiment approach to modeling the barriers to effective snakebite treatment in Ghana",
        "abstract": "Background Snakebite envenoming is a serious condition that affects 2.5 million people and causes 81,000\u2013138,000 deaths every year, particularly in tropical and subtropical regions. The World Health Organization has set a goal to halve the deaths and disabilities related to snakebite envenoming by 2030. However, significant challenges in achieving this goal include a lack of robust research evidence related to snakebite incidence and treatment, particularly in sub-Saharan Africa. This study aimed to combine established methodologies with the latest tools in Artificial Intelligence to assess the barriers to effective snakebite treatment in Ghana. Method We used a MaxDiff statistical experiment design to collect data, and six supervised machine learning models were applied to predict responses whose performance showed an advantage over the other through 6921 data points partitioned using the hold-back validation method, with 70% training and 30% validation. The results were compared using key metrics: Akaike Information Criterion corrected, Bayesian Information Criterion, Root Average Squared Error, and Fit Time in milliseconds. Results Considering all the responses, none of the six machine learning algorithms proved superior, but the Generalized Regression Model (Ridge) performed consistently better among the candidate models. The model consistently predicted several key significant barriers to effective snakebite treatment, such as the high cost of antivenoms, increased use of unorthodox, harmful practices, lack of access to effective antivenoms in remote areas when needed, and resorting to unorthodox and harmful practices in addition to hospital treatment. Conclusion The combination of a MaxDiff statistical experiment design to collect data and six machine learning models allowed the identification of barriers to accessing effective therapies for snakebite envenoming in Ghana. Addressing these barriers through targeted policy interventions, including intensified advocacy, continuous education, community engagement, healthcare worker training, and strategic investments, can enhance the effectiveness of snakebite treatment, ultimately benefiting snakebite victims and reducing the burden of snakebite envenoming. There is a need for robust regulatory frameworks and increased antivenom production to address these barriers.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d124a896c0c98e3cadadf80876c101f639657469",
        "citation_count": 0
    },
    {
        "title": "Artificial intelligence, machine learning and the evolution of healthcare",
        "abstract": "vol. 7, No. 3, MaRch 2018 223 First proposed by Professor John Mccarthy at Dartmouth college in the summer of 1956,1 artificial Intelligence (aI) \u2013 human intelligence exhibited by machines \u2013 has occupied the lexicon of successive generations of computer scientists, science fiction fans, and medical researchers. The aim of countless careers has been to build intelligent machines that can interpret the world as humans do, understand language, and learn from realworld examples. In the early part of this century, two events coincided that transformed the field of aI. The advent of widely available Graphic Processing Units (GPUs) meant that parallel processing was faster, cheaper, and more powerful. at the same time, the era of \u2018Big Data\u2019 \u2013 images, text, bioinformatics, medical records, and financial transactions, among others \u2013 was moving firmly into the mainstream, along with almost limitless data storage. These factors led to a dramatic resurgence in interest in aI in both academic circles and industries outside traditional computer science. once again, aI occupies the zeitgeist, and is poised to transform medicine at a basic science, clinical, healthcare management, and financial level. Terminology surrounding these technologies continues to evolve and can be a source of confusion for non-computer scientists. aI is broadly classified as: general aI, machines that replicate human thought, emotion, and reason (and remain, for now, in the realm of science fiction); and narrow aI, technologies that can perform specific tasks as well as, or better than, humans. Machine learning (Ml) is the study of computer algorithms that can learn complex relationships or patterns from empirical data and make accurate decisions.2 Rather than coding specific sets of instructions to accomplish a task, the machine is \u2018trained\u2019 using large amounts of data and algorithms that confer it the ability to learn how to perform the task. Unlike normal algorithms, it is the data that \u2018tells\u2019 the machine what the \u2018good answer\u2019 is, and learning occurs without explicit programming. Ml problems can be classified as supervised learning or unsupervised learning.3 In a supervised machine learning algorithm, such as face recognition, the machine is shown several examples of \u2018face\u2019 or \u2018non-face\u2019 and the algorithm learns to predict whether an unseen image is a face or not. In unsupervised learning, the images shown to the machine are not labelled as \u2018face\u2019 or \u2018non-face\u2019. artificial Neural Networks (aNN)4 are one group of algorithms used for machine learning. While aNNs have existed for over 60 years, they fell out of favour during the 1990s and 2000s. In the last half-decade, aNNs have had a resurgence under a new name: deep artificial networks (or \u2018Deep learning\u2019). aNNs are uniquely poised to take full advantage of the computational boost offered by GPUs, allowing them to crunch through data sets of enormous sizes. These range from computer vision tasks, such as image classification, object detection, face recognition, and optical character recognition (ocR), to natural language processing and even gameplaying problems (from mastering simple atari games to the recent alphaGo victory against human grandmasters).5 aNNs work by constructing layers upon layers of simple processing units (often referred to as \u2018neurons\u2019), interconnected via many differentially weighted connections. aNNs are \u2018trained\u2019 by using backpropagation algorithms, essentially telling the machine how to alter the internal parameters that are used to compute the representation in each layer from the representation in the previous Artificial intelligence, machine learning and the evolution of healthcare",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/d14ac2acf1b18e815385c631216eb4ee3a4fc842",
        "citation_count": 65
    },
    {
        "title": "Cardiac Diagnostic Feature and Demographic Identification Models: A Futuristic Approach for Smart Healthcare Using Machine Learning",
        "abstract": "Around the world, every year, about 17 million people death cause happen due to CardioVascular Diseases (CVD). As per clinical records, primarily sufferers exhibit myocardial infarctions and Heart Failures (HF). Creatinine is a Musculo - skeletal waste product. The kidneys filter creatinine from the blood and excrete it through the urine in a healthy body. High creatinine levels can suggest renal problems. Elevated Serum Creatinine (SC) has been well established in the HF. Patients\u2019 electronic medical records can be used to quantify symptoms and other related clinical laboratory test values, which would then be utilized to direct biostatistics exploration to uncover patterns and associations that doctors would otherwise miss. The latest American Heart Association guidelines for 1500 mg/d sodium tend to be sufficiently relevant for patients with stage A and B with HF. In this article, we used a dataset of the year 2015 of heart patients records of 299 patients. The present paper used the data analytic and statistical tools to verify the significant differences between alive and dead patients\u2019 SC and Serum Sodium (SS). It also demonstrates the impact of significant features on abnormal SC and SS on the Survival-Status levels. The Age-Group feature, which is derived from age attribute and, Ejection Fraction (EF), anemia, platelets, Creatinine Phosphokinase (CPK), Blood-Pressure (BP), gender, diabetes, and smoking-status were utilized to determine the potential contributing features to mortality with Cox regression model. The Kaplan Meier plot was used to investigate the overall pattern of survival concerning age-group. During pre-processing of the dataset, Age and SS were removed due to multicollinear features during performing machine learning algorithms experiments. This paper also predicted patients\u2019 survival, age group, and gender using supervised machine learning classifiers. Detection of significant features would help in making informed decisions to balance the lifestyle of heart patients. The author revealed that the patient\u2019s follow-up months, as well as SC, EF, CPK, and platelets, are sufficient key features to predict heart patient survival using Random Forest (RF) stratified 10-fold CV method with accuracy (96%) with 5% Standard Deviation (SD) from medical records dataset. We identified the age-group and gender of the patient, and the RF model outperformed others with the best accuracy 96% and 94% in both cases having 11% SD. Also, prominent features such as CPK, SC, follow-up month, platelets, and ejection were found to be significant factors in predicting the patient\u2019s age-group. Smoking habits, CPK, platelets, follow-up month, and SC of each patient were discovered to be significant predictors of patient gender. The hypothetical study proved that SC and SS making substantial differences in the survival of patients (p &lt; 0.05) and failed to reject that anemia, diabetes, and BP making a significant impact on the creatinine and sodium of each patient (p &gt; 0.05). With \u03c72(1) = 8.565, the Kaplan Meier plot revealed that mortality was high in the extremely elder age-group. The finding has possible effects on clinical practice and becomes a new medical support system when predicting whether a patient can survive a heart attack or not. The doctor should primarily concentrate on follow-up month, SC and EF, CPK, and platelet count since the aim is to understand whether a patient survives after HF.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d1799e7667a1ba84a33412a0d93eeef23d961b90",
        "citation_count": 3
    },
    {
        "title": "Comparative Analysis of Predictive Algorithms for Performance Measurement",
        "abstract": "Predictive algorithms, also known as mathematical models, utilize historical data to accurately predict future outcomes. These algorithms identify patterns and relationships within the data, resulting in precise predictions. The growing importance of predictive algorithms in various domains, such as finance, healthcare, marketing, weather forecasting, E-commerce, etc., has led to an increasing need for robust and accurate models. Machine learning (ML) and deep learning (DL) algorithms, including supervised, unsupervised, & reinforcement learning, play a crucial role in prediction. Supervised algorithms include classification and regression, while unsupervised algorithms primarily focus on clustering. In this study, a detailed comparative analysis of eight classification algorithms, six regression algorithms, and five clustering algorithms is performed using diverse datasets and performance metrics. ROBERTA, ResNet, Random Forest Regression, and K-means clustering algorithms outperformed traditional algorithms in textual classification, image classification, regression, and clustering. This study enables data scientists and practitioners to make informed decisions when selecting appropriate models for their specific applications.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d23f5a8c1113109303096921b07f192e91c26776",
        "citation_count": 2
    },
    {
        "title": "\uae30\uacc4\ud559\uc2b5\uc744 \uc801\uc6a9\ud55c \uc790\uae30\ubcf4\uace0 \uc99d\uc0c1 \uae30\ubc18\uc758 \uc5b4\ud608 \ubcc0\uc99d \ubaa8\ub378 \uad6c\ucd95",
        "abstract": "Objectives : This study is aimed at developing and discussing the prediction model of blood stasis pattern of traditional Korean medicine(TKM) using machine learning algorithms: multiple logistic regression and decision tree model. Methods : First, we reviewed the blood stasis(BS) questionnaires of Korean, Chinese, and Japanese version to make a integrated BS questionnaire of patient-reported outcomes. Through a human subject research, patients-reported BS symptoms data were acquired. Next, experts decisions of 5 Korean medicine doctor were also acquired, and supervised learning models were developed using multiple logistic regression and decision tree. Results : Integrated BS questionnaire with 24 items was developed. Multiple logistic regression models with accuracy of 0.92(male) and 0.95(female) validated by 10-folds cross-validation were constructed. By decision tree modeling methods, male model with 8 decision node and female model with 6 decision node were made. In the both models, symptoms of \u2018recent physical trauma\u2019, \u2018chest pain\u2019, \u2018numbness\u2019, and \u2018menstrual disorder(female only)\u2019 were considered as important factors. Conclusions : Because machine learning, especially supervised learning, can reveal and suggest important or essential factors among the very various symptoms making up a pattern identification, it can be a very useful tool in researching diagnostics of TKM. With a proper patient-reported outcomes or well-structured database, it can also be applied to a pre-screening solutions of healthcare system in Mibyoung stage.",
        "year": 2016,
        "url": "https://www.semanticscholar.org/paper/d25411d9efb8b865e30c7c437ef739ef8866756d",
        "citation_count": 0
    },
    {
        "title": "Development of an Integrate E-Medical System Using Software Defined Networking and Machine Learning",
        "abstract": "Scholars and medical professionals have recognizes the importance of electronic medical monitoring services for tracking elderly people's health. These platforms generate a large amount of data, requiring privacy and data security. on the contrary, Using Software Defined Networking (SDN) to maintain network efficiency and flexibility, which is especially important in the case of healthcare observation, could be a viable solution. Moreover, machine learning can additionally utilized as a game changing tool which incorporated with SDN for optimal level of privacy and security. Even so, integrating SDN into machine learning, which heavily relies on health sensors of patients, is incredibly difficult. In this paper, an Integrate Medical Platform (IMP) with a focus on SDN and Machine learning integration is proposed. We produce a platform that reduces complexity by identifying high level SDN regulations based on the extracted flow classes and utilizing machine learning traffic flow classification techniques. F or various types of traffic, We employ supervised learning approaches based on models that have already been trained. We use four algorithms for supervised learning: Random forest, Logistic Regression classifiers, K-NN, and SVM, with different characteristics. Finally, we evaluated IMP by using accuracy, precision, TPR, TNR, FPR, MAE, and energy consumption.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/d264c41b07788f53bcbfe6c7db411fc953fa9aaa",
        "citation_count": 2
    },
    {
        "title": "Heart Disease Prediction Model using various Supervised Learning Algorithm",
        "abstract": "A computer can learn from data and improve its predictive abilities without requiring human interaction through artificial intelligence (AI) derived from machine learning (ML). Machine learning\u2019s core concept is to replicate how the brain functions. ML approaches have proven to be effective predictors in a variety of application fields, including healthcare and medicine. In this study, supervised machine learning approaches for predicting cardiac disorders were analyzed and compared using medical records from the UCI Machine Learning repository. This research examines the effectiveness of various models, including K-Nearest Neighbor (KNN), Logistic Regression (LR) models and Support Vector Machines (SVM), and The (Area Under ROC Curve) AUC score was used to evaluate the effectiveness of various algorithms. AUC is a measurement. In order to evaluate the effectiveness of various algorithms, we used the (Area Under ROC Curve) AUC score. The choice to adopt a machine learning algorithm is made if the AUC score is more than 0.5, which is an evaluation metric that aids in validating how effective the algorithm is. AUC scores for logistic regression are the highest of all ML algorithms in the trial (0.87).",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d2752fe2da456f5c3896e90a5845b0ec0e9a3bf4",
        "citation_count": 5
    },
    {
        "title": "Machine Learning Based Framework for Maintaining Privacy of Healthcare Data",
        "abstract": "The Adoption of Artificial Intelligence (AI), Machine Learning (ML), Internet of Things (IoT), cloud services, web-based software systems, and other wireless sensor devices in the healthcare infrastructure have led to phenomenal improvements and benefits in the healthcare sector. Digital healthcare has ensured early diagnosis of the diseases, greater accessibility, and mass outreach in terms of treatment. Despite this unprecedented success, the privacy and confidentiality of the healthcare data have become a major concern for all the stakeholders. Data breach reports reveal that the healthcare data industry is one of the key targets of cyber invaders. In fact the last few years have registered an unprecedented rise in healthcare data breaches. Hacking incidents and privilege abuse are the most common threats and have exposed sensitive and protected health data. Experts and researchers are working on various techniques, tools, and methods to address the security issues related to healthcare data. In this article, the main focus is on evaluating the impact of research studies done in the context of healthcare data breach reports to identify the contemporary privacy and confidentiality issues of sensitive healthcare data. Analysis of the research studies depicts that there is a need for proactive security mechanisms that will help the healthcare organizations to identify abnormal user behavior while accessing healthcare data. Moreover, studies also suggest that ML techniques would be highly effective in securing the privacy and confidentiality of the healthcare data. Working further on this premise, the present study also proposes a conceptual framework that will secure the privacy and confidentiality of healthcare data proactively. The proposed framework is based on ML techniques to detect deviated user access against Electronic Health Records. Further, fuzzy-based Analytical Network Process (ANP), a multi-criteria decision-making approach, is used to assess the accuracy of the supervised and unsupervised ML approaches for achieving a dynamic digital healthcare data security environment. This work is licensed under a Creative Commons Attribution 4.0 International License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. Intelligent Automation & Soft Computing DOI:10.32604/iasc.2021.018048 Article ech T Press Science",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d2ac6bf08842f881e8765658e9545bd90e617d9f",
        "citation_count": 12
    },
    {
        "title": "Data reduction techniques for highly imbalanced medicare Big Data",
        "abstract": null,
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d2b244d7ad9019d26dbc88e13c1b2e1838cf6084",
        "citation_count": 10
    },
    {
        "title": "Continuous Assessment of Children\u2019s Emotional States Using Acoustic Analysis",
        "abstract": "Emotional and behavioral disorders (EBD) are a widespread healthcare concern in children and adolescents. Prevention and early intervention are the most powerful tools in ameliorating the problem, and therefore, timely and accurate detection of abnormal emotional patterns is of vital importance. In this paper, we propose a system that detects second-level emotional states of children using hour-level audio recordings. The proposed system consists of an audio segmentation and speaker tracking front-end along with an emotion recognition back-end. Supervised support vector machine is used in the front-end to improve its robustness to short and inconsistent child speech pattern and end-to-end deep learning is used in the emotion recognition back-end to improve its robustness to noise and segmentation error. We further demonstrate the potential of the proposed system as an automated emotion analysis tool.",
        "year": 2017,
        "url": "https://www.semanticscholar.org/paper/d2d00ef3f9796581342ea68a132d97e74a8fb615",
        "citation_count": 7
    },
    {
        "title": "Assessing the capture of sociodemographic information in electronic medical records to inform clinical decision making",
        "abstract": "There is a growing need to document sociodemographic factors in electronic medical records to produce representative cohorts for medical research and to perform focused research for potentially vulnerable populations. The objective of this work was to assess the content of family physicians\u2019 electronic medical records and characterize the quality of the documentation of sociodemographic characteristics. Descriptive statistics were reported for each sociodemographic characteristic. The association between the completeness rates of the sociodemographic data and the various clinics, electronic medical record vendors, and physician characteristics was analyzed. Supervised machine learning models were used to determine the absence or presence of each characteristic for all adult patients over the age of 18 in the database. Documentation of marital status (51.0%) and occupation (47.2%) were significantly higher compared to the rest of the variables. Race (1.4%), sexual orientation (2.5%), and gender identity (0.8%) had the lowest documentation rates with a 97.5% missingness rate or higher. The correlation analysis for vendor type demonstrated that there was significant variation in the availability of marital and occupation information between vendors (\u03c72 > 6.0, P < 0.05). Variability in documentation between clinics indicated that the majority of characteristics exhibited high variation in completeness rates with the highest variation for occupation (median: 47.2, interquartile range: 60.6%) and marital status (median: 45.6, interquartile: 59.7%). Finally, physician sex, years since a physician graduated, and whether a physician was a foreign vs a Canadian medical graduate were significantly associated with documentation rates of place of birth, citizenship status, occupation, and education in the electronic medical records. Our findings suggest a crucial need to implement better documentation strategies for sociodemographic information in the healthcare setting. To improve completeness rates, healthcare systems should monitor, encourage, enforce, or incentivize sociodemographic data collection standards.",
        "year": 2025,
        "url": "https://www.semanticscholar.org/paper/d30b6240d00194d4ec8ddb94a1bd0c702a54e6c6",
        "citation_count": 0
    },
    {
        "title": "A Supervised Approach for\u00a0Patient-Specific ICU Mortality Prediction Using Feature Modeling",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/d317e182bf858f30315509bc0cc014a09c6194d5",
        "citation_count": 1
    },
    {
        "title": "Paradigm shift in Nutritional Science: Using Machine Learning to Predict Macronutrient Requirements",
        "abstract": "Dietary interventions are necessary to lead a healthy life. Most of these interventions are done by adjusting daily macronutrient intake. Assessing daily macronutrient intake for users based on their health profile is a tedious task. In this paper, a supervised learning-based system to predict macronutrient categories is presented. The system is built using synthetic data generated from live user profiles. The generated dataset is validated and annotated with macronutrient category labels. Along with the category labels, the system also presents reasons for the prediction. Various experiments pertaining to the efficacy and trustworthiness of the models are performed and presented. Results suggest that macronutrient category prediction and its interpretability are highly reliable and could be easily adopted by the healthcare industry.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d34ae9f7de965792d9ecc5ee71257277023cfe08",
        "citation_count": 0
    },
    {
        "title": "Leveraging Algorithmic and Machine Learning Technologies for Breast Cancer Management in Sub-Saharan Africa",
        "abstract": "Due to delayed diagnosis, few treatment choices, and inadequate healthcare infrastructure, breast cancer continues to be a major worldwide health concern, with some of the greatest fatality rates occurring in Sub-Saharan Africa. By improving the treatment of breast cancer, machine learning (ML) and algorithmic technologies provide a game-changing chance to solve these issues. This study examines the current state of breast cancer in Sub-Saharan Africa, emphasizing the disease's startling prevalence and death rates as well as the structural and systemic obstacles to quality care, such as a lack of diagnostic resources, restricted access to treatment, and socioeconomic considerations. ML has a lot of potential in the medical field, especially in the areas of breast cancer early detection, diagnosis, and therapy planning. Medical image analysis and patient prediction have shown the effectiveness of machine learning models, including supervised, unsupervised, and reinforcement learning methods. However, implementing these technologies in Sub-Saharan Africa requires overcoming several barriers, including poor data availability, limited infrastructure, and a shortage of trained professionals. This paper highlights the importance of partnerships between governments, international organizations, and the tech industry in bridging these gaps. Recommendations include improving healthcare infrastructure, training healthcare workers, and developing region-specific ML models using local datasets to ensure cultural and contextual relevance. Addressing ethical concerns, such as data privacy and equitable access, is also emphasized to ensure the sustainable and inclusive adoption of these technologies. By leveraging ML and algorithmic technologies, Sub-Saharan Africa has the potential to significantly improve breast cancer outcomes, reduce mortality rates, and build a more robust and equitable healthcare system. Continued research, investment, and collaboration will be pivotal in achieving this vision.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/d4059483f484917e03fdb8f8556ab4fbf96a65c4",
        "citation_count": 0
    },
    {
        "title": "Multiple Disease Prediction Based on User Symptoms using Machine Learning Algorithms",
        "abstract": "Every day, many individuals encounter different illnesses. The prognosis of a disease is the most pivotal part of treatment. Enormous increase in healthcare and medical data enabled accurate medical data analysis, which aids in early sickness discovery and beforehand patient care. This study focuses on performing research on the enormous medical data by exercising numerous supervised classification algorithms like Decision Tree, Support Vector Machine, K- Nearest Neighbor, Logistic Regression, Naive Bayes and Random Forest to anticipate the most probable disease grounded on the symptoms and also to directly prognosticate the possibility of whether or not the person might be suffering from that particular illness. Based on the symptoms, the model uses the results of the supervised classification algorithms and gives a final validation indicating the disease that the existent might be suffering. On combining the prognostications from all the below classification algorithms, the model returns a more accurate verification when compared to the prognostications made by individual models. This study enhances the swiftness of decision-making and can reduce the rate of false cons. It helps healthcare associations make better decisions about how to proceed with early patient care. It also aids healthcare professionals in developing further effective ways of treating patients.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d406f4753026b2347b1a0e254c3e38ec2111d30e",
        "citation_count": 4
    },
    {
        "title": "Authentication based on electrocardiography signals and machine learning",
        "abstract": "Among the information security problems involved in Telemedicine Information Systems (TMIS), the authentication area of the various entities involved has been extensively discussed in recent years and shown a wide range of possibilities. The problems caused by the application of inadequate authentication processes may lead to the death of patients who depend on Mobile Healthcare (M-Health) services. User authentication can be based on several physiological traits (e.g., iris, retina, and fingerprint) for biometric recognition, including electrocardiography (ECG) signals. Some ECG patterns are relatively robust to daily changes associated with normal heart rate variability. In fact, the relative lengths of PQ, QR, and RS intervals, as well as Q, R, and S relative amplitudes constitute individual traits. A few studies have succeeded in using ECG signals as an accurate authentication input and offered some advantages in comparison to biometrics traditional approaches. ECG-based user authentication can be built on Machine Learning (ML) models, used for classification purposes and reductions in distortions caused by misinterpretation of ECG data. Among the ML models adopted for ECG signals classification, ensembles have shown a good research opportunity. Random Under-Sampling Boosting (RUSBoost), a boosting algorithm not yet explored (to the best of our knowledge) for such a problem, can achieve comparatively high performance after a supervised training stage, even from relatively few training examples. This manuscript reports on a comparison of RUSBoost with Nearest Neighbour Search (NNS) regarding the classification of ECG signals for biometric authentication applications. The two ML techniques were compared by a random subsampling technique that considers four analysis metrics, namely accuracy, precision, sensitivity, and F1-score. The experimental results showed the better performance of RUSBoost regarding accuracy (97.4%), sensitivity (96.1%) and F1-score (97.4%). On the other hand, NNS provided better precision (99.5%).",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d486e63aa2f7ba7ae850d8a1a8ab0bf40f166695",
        "citation_count": 3
    },
    {
        "title": "Anomaly Detection using Machine Learning to Discover Sensor Tampering in IoT Systems",
        "abstract": "With the rapid growth of the Internet of Things (IoT) applications in smart regions/cities, for example, smart healthcare, smart homes/offices, there is an increase in security threats and risks. The IoT devices solve real-world problems by providing real-time connections, data and information. Besides this, the attackers can tamper with sensors, add or remove them physically or remotely. In this study, we address the IoT security sensor tampering issue in an office environment. We collect data from real-life settings and apply machine learning to detect sensor tampering using two methods. First, a real-time view of the traffic patterns is considered to train our isolation forest-based unsupervised machine learning method for anomaly detection. Second, based on traffic patterns, labels are created, and the decision tree supervised method is used, within our novel Anomaly Detection using Machine Learning (AD-ML) system. The accuracy of the two proposed models is presented. We found 84% with silhouette metric accuracy of isolation forest. Moreover, the result based on 10 cross-validations for decision trees on the supervised machine learning model returned the highest classification accuracy of 91.62% with the lowest false positive rate.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d4cd95c72d87052ceed7fc39e586bacb7b63824f",
        "citation_count": 22
    },
    {
        "title": "SPECIFICATION OF HEALTHCARE EXPERT SYSTEMS USING A MULTI-MECHANISM RULE-EXTRACTION PIPELINE",
        "abstract": "The application of knowledge extraction methodologies in support of medical informatics promises interesting developments that could potentially improve many aspects of healthcare services. In this paper we outline a multi-stage rule extraction pipeline for rule-based knowledge discovery. The featured methodology would facilitate operationally straightforward extraction of symbolic rules from medical datasets, in particular those with unannotated ordinal or continuous-valued datavectors. The extracted rulesets will be used in the construction or enrichment of rule-based expert systems. Our pipeline incorporates well-established supervised and unsupervised machine learning methods used for data mining. The motivation for our work stems from the individual effectiveness of data mining methods available for datavector clustering, attribute discretisation and rule extraction. The featured knowledge extraction architecture will be tested and analysed using several well- known medical datasets.",
        "year": 2000,
        "url": "https://www.semanticscholar.org/paper/d5061612644394427516404d1a78d4019bb0cced",
        "citation_count": 1
    },
    {
        "title": "Artificial intelligence and prostate cancer: Advances and challenges",
        "abstract": "Artificial intelligence (AI) is a branch of computer science related to building smart machines able to perform tasks that typically require human intelligence.1 In particular, AI is \u201cthe use of mathematical algorithms to mimic human cognitive abilities\u201d and, in the field of medicine, \u201cto address difficult healthcare challenges, including complex biological abnormalities like cancer.\u201d2 Many of the AI algorithms are powered by machine learning (ML), and, some of them, by deep learning (DL). Neural networks (NN), also known as artificial neural networks or simulated neural networks, are the base for ML and DL. Their name and structure are inspired by the human brain, mimicking the way that biological neurons signal to one another. ML, one of the algorithms of AI, allows the machine to resolve problems in a manner similar to that followed by the human brain.2 In particular, it \u201crelies on statistical methods to detect hidden patterns within a dataset and improve performance with experience.\u201d1 DL is one of the ML techniques. It mimics the ability of the human brain in data processing in order to assist humans in making decisions, upgrading precision medicines, and improving drug discovery; \u201cit can also work and suggest an output without human supervision.\u201d2 Figure 1 shows the applications of AI, ML, and DL \u201cto solve healthcare-related issues and to predict optimal treatment and outcome.\u201d2",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d52cf64533b46a75b1dffb4e5db9b91af47d9025",
        "citation_count": 2
    },
    {
        "title": "EXPRESS: Predictive Modeling of Mortality in Carbapenem-Resistant Acinetobacter baumannii Bloodstream Infections Using Machine Learning.",
        "abstract": "Acinetobacter baumannii, a notable drug-resistant bacterium, often induces severe infections in healthcare settings, prompting a deeper exploration of treatment alternatives due to escalating carbapenem resistance. This study meticulously examined clinical, microbiological, and molecular aspects related to in-hospital mortality in patients with carbapenem-resistant A. baumannii (CRAB) bloodstream infections (BSI). From 292 isolates, 153 cases were scrutinized, reidentified through MALDI-TOF-MS, and evaluated for antimicrobial susceptibility and carbapenemase genes via multiplex PCR. Utilizing supervised machine learning, the study constructed models to predict 14-day and 30-day mortality rates, revealing the Na\u00efve Bayes model's superior specificity (0.75) and area under the curve (AUC; 0.822) for 14-day mortality, and the Random Forest model's impressive recall (0.85) for 30-day mortality. These models delineated 8 and 9 significant features for 14-day and 30-day mortality predictions, respectively, with 'septic shock' as a pivotal variable. Additional variables such as neutropenia with neutropenic days prior to sepsis, mechanical ventilator support, chronic kidney disease, and heart failure were also identified as ranking features. However, empirical antibiotic therapy appropriateness and specific microbiological data had minimal predictive efficacy. This research offers foundational data for assessing mortality risks associated with CRAB BSI and underscores the importance of stringent infection control practices in the wake of the scarcity of new effective antibiotics against resistant strains. The advanced models and insights generated in this study serve as significant resources for managing the repercussions of A. baumannii infections, contributing substantially to the clinical understanding and management of such infections in healthcare environments.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d53457f5dd738139030964abf3f38836435c13ec",
        "citation_count": 0
    },
    {
        "title": "Clustering of Disease Trajectories with Explainable Machine Learning: A Case Study on Postoperative Delirium Phenotypes",
        "abstract": "The identification of phenotypes within complex diseases or syndromes is a fundamental component of precision medicine, which aims to adapt healthcare to individual patient characteristics. Postoperative delirium (POD) is a complex neuropsychiatric condition with significant heterogeneity in its clinical manifestations and underlying pathophysiology. We hypothesize that POD comprises several distinct phenotypes, which cannot be directly observed in clinical practice. Identifying these phenotypes could enhance our understanding of POD pathogenesis and facilitate the development of targeted prevention and treatment strategies. In this paper, we propose an approach that combines supervised machine learning for personalized POD risk prediction with unsupervised clustering techniques to uncover potential POD phenotypes. We first demonstrate our approach using synthetic data, where we simulate patient cohorts with predefined phenotypes based on distinct sets of informative features. We aim to mimic any clinical disease with our synthetic data generation method. By training a predictive model and applying SHAP, we show that clustering patients in the SHAP feature importance space successfully recovers the true underlying phenotypes, outperforming clustering in the raw feature space. We then present a case study using real-world data from a cohort of elderly surgical patients. The results showcase the utility of our approach in uncovering clinically relevant subtypes of complex disorders like POD, paving the way for more precise and personalized treatment strategies.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d54555ebff419b8f4216b352c4033305818e6ed3",
        "citation_count": 0
    },
    {
        "title": "The diabacare cloud: predicting diabetes using machine learning",
        "abstract": "Machine learning (ML) is the buzz all around the technology industry and is illuminating each and every sector of human lives, be it, healthcare, finance, bioinformatics, data science, mechanical engineering, agriculture or even smart cities nowadays. ML consists of supervised and unsupervised techniques. Due to the availability of data in abundance, supervised ML has been the most preferred method in the field of data mining. In this research paper, a publicly available dataset for diabetes detection is tested to understand the efficiency of classification of a number of supervised ML algorithms to find the most accurate model. The dataset consisted of data of 768 persons out of which 500 were control and 268 were patients we found that the Random Forest algorithm outperformed the other 6 classification algorithm. In the first iteration, the Random Forest algorithm reached 78.44% accuracy. The tweaks performed in the paper outclassed the original random forest algorithm with a difference of 1.08% reaching a score of 79.52%. Further, iteration I gave 171 whilst iteration II gave 173 correct predictions out of the total 218 test data.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d54b62e8ba0fb81cb67f5e288101531d5dd1bd86",
        "citation_count": 1
    },
    {
        "title": "A Framework Based On Intelligent Agents And Artificial Intelligence Techniques For The Diagnosis Of Liver Disease",
        "abstract": "Artificial intelligence (AI) is a relatively new field of study that use computer methods to impart intelligence on machines. Data mining (DM) is a technique for efficiently extracting useful information from big data sets with the goal of revealing previously unknown relationships within the data. We decided to use DM because we hypothesised that, with the right DM approach applied to patient data, we might extract useful information about the relationship between symptoms and illness. The gleaned information was put to good use when combined with the created agent-based framework to provide specific suggestions to individual patients. The designed agent-based system communicates with other parts of the integrated system to aid in the diagnosis of liver illness. This study uses two datasets including more than 900 patient records from the University of California, Irvine Machine Learning Repository to investigate the role of machine learning approaches in the identification of liver disorders. We believe that implementing the proposed intelligent agent-based system will result in a more precise and accurate diagnostic system for clinical ailments of varying types, as evidenced by the results showing that both the C4.5 decision tree algorithm and the Random Tree algorithm yielded 100% accuracy in classifying the liver disorders. This is the first effort we are aware of to investigate the use of such a comprehensive set of supervised machine learning methods in the development of intelligent agent-based healthcare systems for diagnostic purposes.",
        "year": null,
        "url": "https://www.semanticscholar.org/paper/d562d7694ebb242e0642b0e66b034aef1f1c1c3e",
        "citation_count": 0
    },
    {
        "title": "Performance Analysis of Naive Bayes Computing Algorithm for Blood Donors Classification Problem",
        "abstract": null,
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/d5e6a5c1454cd8ae950bb6ba0d3e67a31511ec88",
        "citation_count": 0
    },
    {
        "title": "2107. Decision Trees vs. Neural Networks for Supervised Machine Learning-Based Prediction of Healthcare-Associated Urinary Tract Infections",
        "abstract": "Abstract Background Supervised machine learning (SML)-based methods could facilitate early prediction of healthcare-related adverse events. The role of SML in stratifying patient-risk of infectious events during hospitalization and their performance using limited subsets of standardized and widely available predictors is less known. Using a large cohort of adult inpatients, we use SML techniques to predict a diagnosis of urinary tract infection (UTI) during hospitalization. Methods We used previously validated data from adults (\u226518 years old) hospitalized between 2009 and 2016 in a healthcare system as part of a federally funded study. The outcome was a UTI detected >2 days after admission. Predictors measured clinical complexity, history of healthcare-associated complications and specific risk factors for UTI. Predictors were restricted to those standardized and readily obtainable across facilities (e.g., ICD codes). Two SML methods, neural networks (NN) and decision trees (DT) were used. The NN used two hidden layers and a sigmoid output function. The DT used binary recursive portioning and Gini coefficient to measure node impurity. 60% of available hospitalizations were the training set, and 40% used as test set for validation. Cross validation was used to refine the model. Oversampling was used to adjust for the rare outcome. The area under the curve (AUC) for the test set measured model performance. Results From a total of 897,344 hospitalizations there were 16,069 UTIs identified from the data set during the study period. Applying NN and DT to the raw dataset, AUC\u2019s of 0.55 and 0.69 were achieved respectively with the test set. Model performance for DNN and DT improved with oversampling to 0.77 and 0.78, outperforming traditional logistic regression (Figure 1). The optimal DT is presented (Figure 2). Conclusion Reasonable prediction performance for an infectious event during hospitalization was achieved using a limited set of routinely available and standardized variables. While both SML methods had comparable performance, the DT was more interpretable. Further work will extend these methods to other infectious events, use more specific EHR data and link these predictions to interventions in real time. Disclosures All authors: No reported disclosures.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/d602d4cce1cb07745410edbee7ab7677c245d74a",
        "citation_count": 1
    },
    {
        "title": "Heart Disease Predictive Analysis Using Machine Learning Approaches",
        "abstract": "Machine Learning (ML) has found widespread applications in the healthcare sector worldwide, including the diagnosis and treatment of heart diseases, locomotor disorders, and various other medical conditions. ML methods have revolutionized healthcare by enabling the analysis of large and complex medical datasets, leading to valuable insights and predictions that aid healthcare professionals in providing better patient care. ML's ability to analyze vast amounts of healthcare data, uncover patterns, and make predictions has significant potential to improve patient outcomes, optimize medical workflows, and advance medical research. However, it's essential to address privacy and ethical considerations when using ML in healthcare, ensuring the responsible and secure use of sensitive patient information. Supervised Learning methods like SVM, Random Forest, and Logistic Regression are used for the analysis of the dataset downloaded from Kaggle. The various performance parameters such as Precision, F-1 score, Accuracy, and Recall were used to compare the performance of different ML classification techniques. Among the various methods evaluated, the Random Forest classification algorithm was found to outperform the other methods across the fourteen available parameters.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d607037bf979456b02db20977782e1deb8ac4c95",
        "citation_count": 1
    },
    {
        "title": "Enhancing Prediction Accuracy in Gastric Cancer Using High-Confidence Machine Learning Models for Class Imbalance",
        "abstract": "\u2014Gastric Cancer (GC) diagnosis and prognosis present significant challenges in the clinical industry. To address the issue of low prediction accuracy resulting from imbalanced positive and negative GC cases, this study proposes a medical Decision Support System (DSS) based on supervised Machine Learning (ML) methods. Four ML models, including Na\u00efve Bayes (NB), Logistic Regression (LR), and Multilayer Perceptron (MLP), were employed in this study. The impact of data imbalance on GC prediction was assessed through two procedures. Among the ML models, the MLP model demonstrated the best performance in weighted GC prediction, achieving a sensitivity of 0.930 and a Positive Predictive Value (PPV) of 0.932 for balanced predictions, and a sensitivity of 0.918 and a PPV of 0.908 for unbalanced predictions. The NB model showed promise in handling the data imbalance issue, achieving a sensitivity of 0.722 and a PPV of 0.420 on the unbalanced dataset. Additionally, a DSS was developed specifically for the NB and LR models to improve prediction accuracy. The proposed method significantly improved the sensitivity of optimistic GC case prediction, with the Na\u00efve Bayes model achieving a sensitivity of 0.936 and the Logistic Regression model achieving a sensitivity of 0.8306. These improvements enhance the reliability and efficiency of GC diagnostics, offering valuable decision support in healthcare. This research provides insights into addressing class imbalance in GC likelihood prediction and has potential implications for clinical practice",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d6198336f11deb6a3ede3f01e6a89e8fb44ed39b",
        "citation_count": 2
    },
    {
        "title": "Text Mining Data Based Summarization of Novel Approach for Covid-19 with the Use of Machine Learning Techniques",
        "abstract": "At the start of the year 2020, the World Health Organization (WHO) officially recognized COVID-19 as a novel pandemic and subsequently released a corresponding declaration. The aforementioned lethal virus had the capacity to disseminate and proliferate across many countries worldwide. Throughout the duration of the pandemic, social media platforms like as Twitter played a pivotal role in generating considerable amounts of data that contributed to enhancing the efficacy of healthcare-related decision-making processes. Consequently, we propose that the viewpoint articulated by users might be examined by using effective Supervised Machine Learning (SML) algorithms for the purpose of predicting the onset of ailments and providing timely alerts. This study presents a text mining classifier that use machine learning approaches to create summary text. Upon gathering the tweets, we proceeded to prepare them for preprocessing and assign class labels to each instance, including categories such as right, wrong, and neutral, among others. During the second step, a variety of commonly used techniques, including TF-IDF, co-relational analysis, Natural Language Processing (NLP), and relational dependency analysis, are utilized to extract many features from the text. These features are then used to construct the feature vector. For the classification module, we used a binary classification method together with five machine learning algorithms to assess the effectiveness of the suggested model. The NLP-SVM model has a classification accuracy of 95.10%, while the TFIDF-SVM model achieves a classification accuracy of 93.50%. This finding provides evidence that the suggested model is efficacious in the categorization of extensive textual data pertaining to COVID-19, namely on twitter data.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d69cd23ac3b4d55644496df36b4e62128c1a4c10",
        "citation_count": 1
    },
    {
        "title": "Performance Assessment of Supervised Learning Techniques for Caesarean Rate Prediction",
        "abstract": "Machine learning techniques automate the decision making process. These techniques, when applied to the healthcare industry, improve the health conditions of the patient and offers a reduction of the cost of healthcare services. The current study used machine learning classification techniques to predict the chances of caesarean. The dataset used in the study includes 80 instances of pregnant women with six health attributes. In this study, 14 classification techniques are applied to the dataset using ten cross-fold validation training methods. The results obtained from the prediction conclude that the Naive Bayes algorithm provides more accurate results as compared to other models applied onto the dataset.",
        "year": 2020,
        "url": "https://www.semanticscholar.org/paper/d6e2c1f56cd1c71bcc88f53d9b89cf212516d43f",
        "citation_count": 0
    },
    {
        "title": "Domain Adaptation Methods for Lab-to-Field Human Context Recognition",
        "abstract": "Human context recognition (HCR) using sensor data is a crucial task in Context-Aware (CA) applications in domains such as healthcare and security. Supervised machine learning HCR models are trained using smartphone HCR datasets that are scripted or gathered in-the-wild. Scripted datasets are most accurate because of their consistent visit patterns. Supervised machine learning HCR models perform well on scripted datasets but poorly on realistic data. In-the-wild datasets are more realistic, but cause HCR models to perform worse due to data imbalance, missing or incorrect labels, and a wide variety of phone placements and device types. Lab-to-field approaches learn a robust data representation from a scripted, high-fidelity dataset, which is then used for enhancing performance on a noisy, in-the-wild dataset with similar labels. This research introduces Triplet-based Domain Adaptation for Context REcognition (Triple-DARE), a lab-to-field neural network method that combines three unique loss functions to enhance intra-class compactness and inter-class separation within the embedding space of multi-labeled datasets: (1) domain alignment loss in order to learn domain-invariant embeddings; (2) classification loss to preserve task-discriminative features; and (3) joint fusion triplet loss. Rigorous evaluations showed that Triple-DARE achieved 6.3% and 4.5% higher F1-score and classification, respectively, than state-of-the-art HCR baselines and outperformed non-adaptive HCR models by 44.6% and 10.7%, respectively.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d7038cf187e4a4cf23dd0368527f56519690c356",
        "citation_count": 4
    },
    {
        "title": "Prediction of Heart Disease through Machine Learning Algorithms and Techniques",
        "abstract": "Heart disease, by preference popular as CVD (Cardio Vascular Disease), encases differing environment that effect the soul and it is the basic physical foundation of end of life general from the period of the past some decades. And yes it involved with many risk determinant fashionable illness (disease) of the heart and a required some times to catch correct, trustworthy, and sensible approaches to create an early identification of problem to reach a goal prompt persons running an organization of the disease. Data excavating happen a usually used method for subject to series of actions to achieve result very large data fashionable the healthcare rule. Researchers put into use assorted data excavating and machine intelligence method to analyses huge complex healing information in visible form, portion of food healthcare professionals to express an outcome in advance disease of the heart. This paper stating beliefs presents miscellaneous attributes related to disease of the heart, and the model ahead of action of supervised knowledge algorithms as Na\u00efve- Bayes, resolution reached abundant plant placed within in bark and peeling leaves, K-nearest neighbor, and haphazard area with a large number of trees invention. It uses the existent dataset from the Cleveland collection of data of UCI storage place of ailment of the soul person essential nature medicate for healing question. The basic document file make up 303 instances and 76 attributes. Of these 76 attributes, only 14 attributes happen deliberate for experiment, influential to plan the acting of miscellaneous algorithms. This long person actively learning essay aims to conceive the chance of something happening of something occurrence of nurture ailment of the soul fashionable the human being existence treated for healing question. The results pretend to be that the maximum precision or correctness score occur brings to profitable judgment following K-expected neighbor.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d7791d9444a1dc59f2f61dfc4b42c551464228a7",
        "citation_count": 2
    },
    {
        "title": "AyuPredict \u2013 A Disease Prediction Model",
        "abstract": "The AyuPredict model is a machine learning-based healthcare system designed to predict diseases and provide Ayurvedic treatment recommendations. This system aims to bridge the gap in healthcare accessibility, particularly in remote areas where medical facilities are scarce. The model leverages unsupervised learning algorithms, such as Random Forest, for disease prediction and supervised learning algorithms, like K-Nearest Neighbours (KNN), for recommending nearby hospitals.\nThe system's architecture includes a user-friendly interface, disease prediction module, Ayurvedic treatment recommendation module, and hospital recommendation module. The model's performance is evaluated using accuracy metrics, with the Random Forest algorithm achieving an accuracy of 99.59% and F1 score of 99.58%. \nThe KNN algorithm is used for hospital recommendations, providing a list of nearby hospitals based on user input. Future scope includes integrating virtual consultation platforms, voice assistants, and multilingual support to enhance accessibility and usability. The AyuPredict model has the potential to revolutionize healthcare services by providing accurate disease predictions and personalized treatment recommendations, ultimately improving patient outcomes",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d7b1ee3b59ff77aa8507e2715a3decfb3c83082d",
        "citation_count": 0
    },
    {
        "title": "Abstract TP178: AI Based Personalized Stroke Predictor For Patient Awareness And Treatment Compliance",
        "abstract": "Personal prediction of stroke recurrence based on modifiable factors may enhance patient compliance to treatments and healthy lifestyles while optimizing resources of health centers. Vascular risk factors, socio-economic indicators and habits correlate with stroke morbidity and further recurrence. We aimed to estimate stroke recurrence probability as a function of time (3 months, < 1 year and > 1year), both at individual level and with larger classes of individuals. Clinical and socioeconomic public healthcare-based dataset of 41325 patients admitted with stroke diagnosis in 88 public hospitals over 6 years were analyzed.\n Overall, 8509 patients presented a stroke (one or more) recurrence (20.6%), with the following temporal distribution: 3 months, 1 year and > 1 year, 57%, 17% and 26% respectively. We developed a supervised-machine learning based study and identified modifiable and non-modifiable risk factors with stronger impact on risk of stroke recurrence. An algorithm able to provide individualized risk of stroke recurrence at 3 and 12 months was developed (AUROC = 0.80, for balanced classes). The risk can be continuously updated according to the status of modifiable risk factors.\n We also calculated the survival curve for each patient, to detect different risk recurrence periods along time.\n \n \n \n \n a) ROC curve for the three classes predicted.\n \n \n b) Feature importance to explain the model for features modifiable by the patient or not\n c) Probability over time of \u201cNo stroke recurrence\u201d in an example patient according to optimal (orange) or poor (blue) control of vascular risk factors\n \n Machine learning analyses can improve risk prediction and offer individualized information to patients that can be used as feedback for secondary prevention strategies. Our approach is compatible with prevention strategies which, by continuous patient communication and feedbacks, make patients more likely to comply with treatment prescribed or lifestyle changes suggested.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/d7f69ec1b7a29e2c0c8bd7d570f013bd35f60684",
        "citation_count": 0
    },
    {
        "title": "Heart Disease Prediction Using Machine Learning Techniques",
        "abstract": "Cardiovascular diseases (CVDs), heart disease, acknowledged as the most common cause of death during the preceding several decades, is now recognized as the most lethal condition, not just in India but throughout the globe. In humans, the heart is important. A small error can result in tiredness issues or even death. One of the most significant challenges confronting medical sector today is the prediction or forecasting of heart illness. It is associated with numerous and intimidating factors and components. An early diagnosis must be made using a prediction model that is reliable, trustworthy, and reasonable in order to achieve rapid disease treatment. It has been discovered that machine learning may help with decision-making and prediction-making using the vast amounts of data that gathered from several healthcare firms. Machine learning methods and approaches have been used to automate the study of big and complicated medical information. Recently, some researchers have employed various machine learning to assist the healthcare sectors and professionals to identify heart- related illness. Represented research evaluates the effectiveness of multiple models built based on supervised machine learning techniques and schemes such as K-Nearest Neighbor (KNN), Logistic Regression (LR), and Random Forest (RF). The ultimate goal of the presented study is to foretell which individuals having heartdisease based on particular attributes. The result of the proposed model demonstrates that the Random Forest Algorithm has the highest accuracy rating.",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d8dc33422a7bd450f8c66451578caac6150d1751",
        "citation_count": 2
    },
    {
        "title": "Interpretable representation learning for visual intelligence",
        "abstract": "Recent progress of deep neural networks in computer vision and machine learning has enabled transformative applications across robotics, healthcare, and security. However, despite the superior performance of the deep neural networks, it remains challenging to understand their inner workings and explain their output predictions. This thesis investigates several novel approaches for opening up the \u201cblack box\u201d of neural networks used in visual recognition tasks and understanding their inner working mechanism. I first show that objects and other meaningful concepts emerge as a consequence of recognizing scenes. A network dissection approach is further introduced to automatically identify the internal units as the emergent concept detectors and quantify their interpretability. Then I describe an approach that can efficiently explain the output prediction for any given image. It sheds light on the decision-making process of the networks and why the predictions succeed or fail. Finally, I show some ongoing efforts toward learning efficient and interpretable deep representations for video event understanding and some future directions. Thesis Supervisor: Antonio Torralba Title: Professor of Electrical Engineering and Computer Science",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/d8df018cc74cbf7f7115ee271460149718702f6d",
        "citation_count": 2
    },
    {
        "title": "A New Hybrid Model for Mapping Spatial Accessibility to Healthcare Services Using Machine Learning Methods",
        "abstract": "The unequal distribution of healthcare services is the main obstacle to achieving health equity and sustainable development goals. Spatial accessibility to healthcare services is an area of interest for health planners and policymakers. In this study, we focus on the spatial accessibility to four different types of healthcare services, including hospitals, pharmacies, clinics, and medical laboratories at Isfahan\u2019s census blocks level, in a multivariate study. Regarding the nature of spatial accessibility, machine learning unsupervised clustering methods are utilized to analyze the spatial accessibility in the city. Initially, the study area was grouped into five clusters using three unsupervised clustering methods: K-Means, agglomerative, and bisecting K-Means. Then, the intersection of the results of the methods is considered to be conclusive evidence. Finally, using the conclusive evidence, a supervised clustering method, KNN, was applied to generate the map of the spatial accessibility situation in the study area. The findings of this study show that 47%, 22%, and 31% of city blocks in the study area have rich, medium, and poor spatial accessibility, respectively. Additionally, according to the study results, the healthcare services development is structured in a linear pattern along a historical avenue, Chaharbagh. Although the scope of this study was limited in terms of the supply and demand rates, this work gives more information and spatial insights for researchers, planners, and policymakers aiming to improve accessibility to healthcare and sustainable urban development. As a recommendation for further research work, it is suggested that other influencing factors, such as the demand and supply rates, should be integrated into the method.",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/d95d0e24b904f7c2266618ab79ed05367d9ff111",
        "citation_count": 14
    },
    {
        "title": "Docaid: Predictive Healthcare Analytics Using Na\\\"{i}ve Bayes Classification",
        "abstract": "With the advancement in the field of medical research, there has been a copious increase in the data that is stored in the various public and private hospitals, clinics and other places of medical practice. This large store of data needs to be administered in a proper manner so that we can derive useful insights and conclusions using a proper analysis system. Such large amount of data is aptly handled through analyzing the unstructured or structured data by utilizing machine learning algorithms. Predictive analytics, a key component of machine learning algorithms, helps users make enhanced and supervised decisions. Visual Analytics is a tool to cost-effectively sort the exuberant and rapidly incrementing data in the field of medical research. It helps us cope with the assorted data in an organized manner, which the human brain would be able to visualize easily. This would in turn provide new innovative and potential results. This analytics not only provides structured data but also initiates structured thoughts in the mind of humans. As practitioners analyze certain anomalous situations, the process of visual analytics process would provide sorted relevant data related to it. This would in turn decrease the cost of maintaining huge amount of data.",
        "year": 2013,
        "url": "https://www.semanticscholar.org/paper/d9736484694c01f0a5d8740d849f6a5fc2b3d45d",
        "citation_count": 10
    },
    {
        "title": "Signed Graph Laplacian for Semi-Supervised Anomaly Detection",
        "abstract": "Anomaly detection is a cutting-edge technology in the fields of healthcare and machine failure detection. It is well known that the performance of anomaly detection can be improved with more labeled data. However, it is common to predict anomalous and normal data in where are large unlabeled data and small labeled data. Generally, using a large amount of labeled data can lead to high accuracy prediction. However, the cost of labeling data is expensive, which can lead to challenges in anomaly detection. To achieve high prediction rate of anomaly detection, it is required to utilize a large amount of unlabeled data. The only way to achieve high rates of anomaly detection using both unlabeled data and labeled data is to use semi-supervised learning. However, if semi-supervised learning is used without data preprocessing, there is a limitation to obtain high detection rates. To perform effectively preprocess, we propose a scheme that leverages graph theory and semi-supervised learning to address the limitation. The proposed scheme uses graph Laplacian to get high accuracy in situations where there is little labeled data and a lot of unlabeled data. We further extend our scheme by considering friendly-antagonistic interactions into graph Laplacian, which is called signed graph Laplacian. We show that using signed graph Laplacian can improve the performance of our anomaly detection scheme. Furthermore, we evaluate our proposed scheme on a variety of validated datasets and show that it outperforms state-of-the-art semi-supervised anomaly detection methods.",
        "year": 2024,
        "url": "https://www.semanticscholar.org/paper/d98e0c436e979da8c43f48feb865c7c33fa46ce2",
        "citation_count": 0
    },
    {
        "title": "Survival Prediction of Heart Failure Patients using Stacked Ensemble Machine Learning Algorithm",
        "abstract": "Heart failure (HF) is the leading cause of global death from chronic diseases. Data mining using machine learning (ML) converts massive volumes of raw data created by healthcare institutions into meaningful information that can aid in making predictions and crucial decisions. After an HF, collecting and analyzing follow-up data from patients is critical to monitor their health recovery. The aim of this study is to use ML and predict the survival possibility of patients after HF based on the follow-up data. Three supervised classifiers i.e., Random Forest (RF), XGBoost (XGB), and Decision Tree (DT) have been used in our study. Moreover, we proposed to design a supervised stacked ensemble learning model that can achieve a prediction accuracy, precision, recall, and F1 score of 99.98%, 100%, 99.98%, and 99.98%, respectively. The ensemble structure has three base learners (DT, RF & XGB) and one meta learner (RF). The integration of multiple algorithms boosted the prediction performance, which is a significant improvement from the other contemporary studies. Our results demonstrate that Ensemble ML can be a powerful intervention tool to predict accurately, beforehand, the recovery status of a chronic HF patient and prevent potential fatalities.",
        "year": 2021,
        "url": "https://www.semanticscholar.org/paper/d9bc4feaa00231b9b659986b35e2872a4c05b80d",
        "citation_count": 12
    },
    {
        "title": "Data Wrangling and Data Leakage in Machine Learning for Healthcare",
        "abstract": "Nowadays, healthcare and life sciences overall have produced massive amounts of real-time data by enterprise resource planning (ERP). These large of amount data is a difficult task to handle, and intimidation of data leakage by inside worker rises, the firms are smearing way out for security such as Data Loss Prevention (DLP) and Digital Rights Management (DRM) to prevent data leakage. On the other hand, data leakage system also turns into varied and challenging to avert data leakage. Machine learning techniques are used for the handling of significant data by evolving algorithms and set of rules to provide the prerequisite results to the workers. Deep learning has automatic feature extraction that grasps the essential features necessary for the solution of the problem. It reduces the issue of the workers to select elements explicitly to solve the problems for supervised, unsupervised and semi-supervised for healthcare data\u2019s.",
        "year": 2018,
        "url": "https://www.semanticscholar.org/paper/d9c6b6f77fa966f9b3587c2bac3b5c3582537ce6",
        "citation_count": 23
    },
    {
        "title": "Data science in modern evidence-based medicine",
        "abstract": "To practise evidence-based medicine, clinicians need to apply the findings of scientific research to the circumstances of individual patients as part of their decision-making process. For centuries, medicine and clinical reasoning was based on subjective personal experience, until the wider adoption of evidence-based medicine, defined as \u2018The conscientious explicit and judicious use of current best evidence in making decisions about the care of individual patients\u2019. To date, simple mathematical and statistical methods have been used to describe patterns within relatively small-size datasets. We are now faced with a generation of novel datasets in large quantities, from an almost infinite number of digital fingerprints (phenomes) and sources such as electronic health records, high-resolution medical imaging, wearable devices and biosensors, more widely available genetic testing and even inputs from social media. It appears that the standard means of critical appraisal and data interpretation have reached a point of saturation. Evidence-based medicine, as we know it today, is necessary, but not sufficient to meet the demands of analysing large and complex datasets, as it can be time-consuming, resource-intensive, slow to completion and expensive. Data science is still a novel field, at the intersection of several disciplines including computer science, mathematics, statistics, and health and business analytics. It has evolved across many industries to be an advanced statistical method of gathering insights from large amounts of data in order to achieve business objectives or understand user behaviours. We are at a point in healthcare where data are more widely available and accessible in a computer readable fashion than before, coincided with the surge in computer processing power that occurred over the past decade. Recently, there has been significant interest in the field of artificial intelligence and its applications to healthcare and artificial intelligence was one of the major topics of the recently published Topol Review. Artificial intelligence broadly implies the operation of computer programmes with human cognitive ability in order to enable automated solving of complex problems, including perception, recognition, memory and learning. With a growing number of massive datasets and the increased computational power of the machines, a more unique type of artificial intelligence called machine learning has emerged. Machine learning transforms the inputs of an algorithm into outputs using statistical, data-driven rules that are automatically derived from a large set of examples, rather than being explicitly specified by humans. More specifically, a subfield of machine learning called deep learning where the algorithms are created from the data itself and determined by the number of layers (unsupervised learning) rather than initial human rules and postulates (supervised learning) is gaining increasing application in healthcare and already showing to compare with clinicians in the field of imaging, pathology, skin disease diagnosis, ophthalmology, cardiac arrhythmia detection and even sepsis management. Although the majority of the described examples have not been tested in pragmatic clinical trials, they hold significant potential, primarily because they could enable assessment, monitoring, diagnosis and management of a greater number of patients at a lower cost. In addition, artificial intelligence has the potential to reduce diagnostic errors as a quality assurance tool, as well as being used in workflow management. Consequently, it could reduce the administrative burden of clinicians and provide them with the \u2018gift of time\u2019 to prioritise treating patients. To derive meaningful inferences from newly generated data, the data need to be stored and analysed with advanced statistical methods; it appears that the next step of evidence-based medicine could be data science with processing software through increased Journal of the Royal Society of Medicine; 2019, Vol. 112(12) 493\u2013494",
        "year": 2019,
        "url": "https://www.semanticscholar.org/paper/d9ce0a58a1e4d2d080a61beba7ed2a3b2692dd20",
        "citation_count": 10
    },
    {
        "title": "Health Monitoring System Using Machine Learning Techniques Algorithm",
        "abstract": "Abstract: One of the most crucial aspects of someone's capacity to progress in life is their physical and mental well-being. Given the resources and requirements of society, the health-care system seeks to improve the populace as effectively as feasible. Due to a lack of timely medical equipment and treatments, death rates are growing in most nations. These health concerns can be prevented by offering standard healthcare services. The Flask framework was used to create the web application that houses our health monitoring system. In this Health Monitoring System, we employed Decision Tree Classification (Supervised Machine Learning method) to precisely anticipate outcomes. We used our own dataset to train and test our model. We could anticipate the patient's health level and area of risk based on that evaluation",
        "year": 2023,
        "url": "https://www.semanticscholar.org/paper/d9d7a7a57225b52a94aa8501966f838e635538dd",
        "citation_count": 0
    },
    {
        "title": "Prediction of Covid-19 using Kalman filter algorithm",
        "abstract": "The Disease Prediction system is based on the user's symptoms provides input to the system. In medical and healthcare, due to management and the availability of computers, data mining is growing. Such a large amount of data cannot be processed by humans in a short time to make a diagnosis and treatment schedules. In this paper, machine learning-based algorithms are used for predicting the number of novel corona virus (COVID-19) positive and negative reported cases. The proposed methodology includes two stages. The first stage, Covid-19 India cases are classified using a supervised Na\u00efve Bayes classifier. In the second stage, the final major Covid-19 India cases predict using the machine learning-based Kalman filter method. Indian states are classified into several zones based on the spread of positive and daily growth rates for simple classification of novel corona virus hot- spots. The proposed method results show better than the current state-of-the-art approaches. \u00a9 2022 Author(s).",
        "year": 2022,
        "url": "https://www.semanticscholar.org/paper/d9e147b20c4b8d8c0777e7eb60a35964ac222464",
        "citation_count": 5
    }
]