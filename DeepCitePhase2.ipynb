{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33865393-1634-4362-9883-723948b243f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.32.3)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743d372d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (1.15.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Installing collected packages: sentence_transformers\n",
      "Successfully installed sentence_transformers-3.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipywidgets) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets)\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.50)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/DEVAM/Library/Python/3.13/lib/python/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "Successfully installed ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers\n",
    "%pip install --upgrade ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f56132-be1d-4af4-a4b1-5d18363386d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42e49c1b-3845-409f-9934-344952a897a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "CROSSREF_BASE_URL = \"https://api.crossref.org/works\"\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def fetch_crossref_metadata(title, rows=1000):\n",
    "    \"\"\"Fetch metadata from CrossRef API using the paper title.\"\"\"\n",
    "    params = {\"query.title\": title, \"rows\": rows}  # Increase rows to 1000\n",
    "    response = requests.get(CROSSREF_BASE_URL, params=params, headers=HEADERS)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if \"message\" in data and \"items\" in data[\"message\"]:\n",
    "            papers = data[\"message\"][\"items\"]\n",
    "            result = []\n",
    "            for paper in papers:\n",
    "                paper_title = paper.get(\"title\", [\"Unknown\"])[0]\n",
    "                result.append({\n",
    "                    \"title\": paper_title,\n",
    "                    \"doi\": paper.get(\"DOI\", \"N/A\"),\n",
    "                    \"citation_count\": paper.get(\"is-referenced-by-count\", 0),\n",
    "                    \"year\": paper.get(\"published-print\", {}).get(\"date-parts\", [[None]])[0][0]\n",
    "                })\n",
    "            return result  # Return the list of papers\n",
    "\n",
    "    return None  # No valid papers found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ed2770e-b110-4499-97bc-57a66c39c28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c79303ecd4c44a789002c51b68091cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c6956a37414b229e3f5f07fdee87c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4b8f0b3e3c1424fb387d393b9178d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d9b6f6f1434933b758b675bbd7ed65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73499d2ffc674c178ba7a74c0a374205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af58d9df56ae4b58a1ad75b2c2ce5a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601b05ee66844ad3859b5056a463ed05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd3897f182a41ef99b28cd5f4728e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc1bc2a0df64628bc7e35408e07adab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db846368795b447e8e2803fcbed758a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d711410ef64ca186c444bdc1766c38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained model (you can try other models like SPECTER for academic papers)\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def get_embeddings(papers):\n",
    "    \"\"\"Generate embeddings for the list of papers using SentenceTransformer.\"\"\"\n",
    "    titles = [paper['title'] for paper in papers]\n",
    "    embeddings = model.encode(titles, convert_to_tensor=True)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975a10c5-5c2a-419c-8b92-aed4e6979958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "def create_faiss_index(embeddings):\n",
    "    \"\"\"Create and store embeddings in FAISS index.\"\"\"\n",
    "    # Convert embeddings to a NumPy array for FAISS\n",
    "    embeddings_np = np.array(embeddings.cpu().detach().numpy()).astype('float32')\n",
    "    \n",
    "    # Create the FAISS index\n",
    "    index = faiss.IndexFlatL2(embeddings_np.shape[1])  # L2 distance (Euclidean)\n",
    "    index.add(embeddings_np)  # Add embeddings to the index\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9267ba-3fb2-4ac6-988f-7f895b45820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query, faiss_index, papers, top_k=5):\n",
    "    \"\"\"Search query in FAISS index and retrieve the most relevant papers.\"\"\"\n",
    "    # Generate the embedding for the user query\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    query_embedding_np = np.array(query_embedding.cpu().detach().numpy()).astype('float32')\n",
    "    \n",
    "    # Perform the search in the FAISS index\n",
    "    distances, indices = faiss_index.search(query_embedding_np, top_k)\n",
    "    \n",
    "    # Retrieve the top K papers from the indices\n",
    "    recommended_papers = [papers[i] for i in indices[0]]\n",
    "    return recommended_papers, distances[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6986f11a-5768-4076-80a9-4fe783198826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_by_citations_and_similarity(recommended_papers, distances):\n",
    "    \"\"\"Rank papers by citation count and semantic similarity.\"\"\"\n",
    "    ranked_papers = sorted(zip(recommended_papers, distances),\n",
    "                           key=lambda x: (x[0]['citation_count'], -x[1]), reverse=True)\n",
    "    return ranked_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b37f85ac-753c-4e82-b68d-4eff3f1e8bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_papers(query):\n",
    "    \"\"\"Main function to fetch, rank, and return relevant papers based on query.\"\"\"\n",
    "    # Step 1: Fetch papers from CrossRef API\n",
    "    papers = fetch_crossref_metadata(query, rows=1000)\n",
    "    if not papers:\n",
    "        return \"No relevant papers found.\"\n",
    "    \n",
    "    # Step 2: Generate embeddings for the fetched papers\n",
    "    embeddings = get_embeddings(papers)\n",
    "    \n",
    "    # Step 3: Create FAISS index with the embeddings\n",
    "    faiss_index = create_faiss_index(embeddings)\n",
    "    \n",
    "    # Step 4: Search the query in the FAISS index to get top-k relevant papers\n",
    "    recommended_papers, distances = search_query(query, faiss_index, papers, top_k=10)\n",
    "    \n",
    "    # Step 5: Rank papers based on citation count and similarity\n",
    "    ranked_papers = rank_by_citations_and_similarity(recommended_papers, distances)\n",
    "    \n",
    "    # Step 6: Format the result for output\n",
    "    ranked_results = []\n",
    "    for paper, dist in ranked_papers:\n",
    "        ranked_results.append({\n",
    "            \"Title\": paper['title'],\n",
    "            \"DOI\": paper['doi'],\n",
    "            \"Citation Count\": paper['citation_count'],\n",
    "            \"Year\": paper['year'],\n",
    "            \"Similarity Distance\": dist\n",
    "        })\n",
    "    \n",
    "    return ranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80ceb2f-a166-4cfd-abf8-68ccd14a4dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: A Study of Machine Learning in Healthcare, DOI: 10.1109/compsac.2017.164, Citation Count: 133, Year: 2017, Similarity Distance: 7.934821128845215\n",
      "Title: Appropriate use of machine learning in healthcare, DOI: 10.1016/j.ibmed.2021.100041, Citation Count: 13, Year: 2021, Similarity Distance: 7.723365783691406\n",
      "Title: Application of Machine Learning Techniques in Healthcare, DOI: 10.4018/978-1-5225-9902-9.ch015, Citation Count: 12, Year: 2020, Similarity Distance: 8.307032585144043\n",
      "Title: Use of Machine Learning in Healthcare, DOI: 10.1201/9781003322597-12, Citation Count: 0, Year: 2022, Similarity Distance: 7.713277816772461\n",
      "Title: Use of Machine Learning in Healthcare, DOI: 10.1002/9781119769293.ch13, Citation Count: 0, Year: 2022, Similarity Distance: 7.713277816772461\n",
      "Title: A Survey of Machine Learning in Healthcare, DOI: 10.1201/9781003241409-1, Citation Count: 0, Year: 2022, Similarity Distance: 7.787750244140625\n",
      "Title: Exploring the Use of Machine Learning in Healthcare, DOI: 10.2991/978-94-6463-540-9_21, Citation Count: 0, Year: 2024, Similarity Distance: 8.106351852416992\n",
      "Title: Machine Learning Techniques in Healthcare—A Survey, DOI: 10.1166/jctn.2020.9061, Citation Count: 0, Year: 2020, Similarity Distance: 8.127236366271973\n",
      "Title: APPLICATION OF MACHINE LEARNING IN HEALTHCARE, DOI: 10.36106/ijsr/2522696, Citation Count: 0, Year: 2024, Similarity Distance: 8.15632438659668\n",
      "Title: Application of Machine Learning Techniques in Healthcare, DOI: 10.4018/978-1-6684-6291-1.ch067, Citation Count: 0, Year: 2022, Similarity Distance: 8.307032585144043\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"Supervised Machine Learning usage in Healthcare\"\n",
    "ranked_papers = get_ranked_papers(query)\n",
    "for paper in ranked_papers:\n",
    "    print(f\"Title: {paper['Title']}, DOI: {paper['DOI']}, Citation Count: {paper['Citation Count']}, Year: {paper['Year']}, Similarity Distance: {paper['Similarity Distance']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d146377-f199-4db0-ae0c-5bb31dbcf58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Supervised Machine Learning Chatbots for Perinatal Mental Healthcare, DOI: 10.1109/ichci51889.2020.00086, Citation Count: 20, Year: 2020\n",
      "Title: Supervised Machine Learning Techniques for Power Consumption Usage Level Prediction, DOI: 10.1109/csecs60003.2023.10428312, Citation Count: 0, Year: 2023\n",
      "Title: Prognosis of Supervised Machine Learning Algorithms in Healthcare Sector, DOI: 10.1109/rteict52294.2021.9573665, Citation Count: 1, Year: 2021\n",
      "Title: Machine Learning – Supervised Learning, DOI: 10.1201/9780429326813-6, Citation Count: 0, Year: 2019\n",
      "Title: Automatic emotion recognition in healthcare data using supervised machine learning, DOI: 10.7717/peerj-cs.751, Citation Count: 14, Year: None\n",
      "Title: Supervised learning (machine learning), DOI: 10.53347/rid-56096, Citation Count: 0, Year: None\n",
      "Title: Supervised Machine Learning, DOI: 10.1007/978-981-97-0217-6_8, Citation Count: 0, Year: 2024\n",
      "Title: Supervised machine learning, DOI: 10.1007/978-3-662-67882-4_6, Citation Count: 1, Year: 2023\n",
      "Title: Supervised Machine Learning, DOI: 10.1007/978-3-030-74394-9_9, Citation Count: 2, Year: 2021\n",
      "Title: Supervised (Machine) Learning, DOI: 10.1007/978-3-540-47648-1_5582, Citation Count: 1, Year: None\n"
     ]
    }
   ],
   "source": [
    "# Fetch papers from CrossRef (this step is independent of ranking)\n",
    "papers = fetch_crossref_metadata(query, rows=1000)\n",
    "\n",
    "# Print the top 10 papers fetched from CrossRef\n",
    "top_10_papers_from_crossref = papers[:10]\n",
    "for paper in top_10_papers_from_crossref:\n",
    "    print(f\"Title: {paper['title']}, DOI: {paper['doi']}, Citation Count: {paper['citation_count']}, Year: {paper['year']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
